{"pages":[{"title":"","text":"个人简介 93年生人，从事java服务端开发工作4年，现居上海 Icarus 主题以白色的简洁为主，但有时候我们希望在文章中用特别的样式注明一些内容，markdown 语法就不够用了，所以在此分享一下我的高级玩法。","link":"/about/index.html"}],"posts":[{"title":"Druid-类图-属性表","text":"所属文章：池化技术（一）Druid是如何管理数据库连接的？ 本篇为「工具人」文章，建议直接用「ctrl+f」进行查找属性、方法、类名，快速了解其含义和所属类。 主要流程里主要涉及到的类名称、类属性、类方法如下图（淡黄色表示属性，淡蓝色表示方法）： DruidAbstractDataSource抽象类这个类是druid连接池基础类，定义了一些连接池该有的基本属性，以及生成驱动连接对象的方法。 属性表 属性名 说明 username 用户名 password 密码 jdbcUrl 驱动连接 driverClass 驱动class，可以不用配置 initialSize 初始化连接池（主流程2）时需要预先生成的连接对象个数 maxActive 池内最大连接数，也就是说生成连接的线程在当前池内连接数超过这个指标后就不再工作了，参考主流程3 minIdle 池内最小闲置连接数，参考流程4.1 maxWait 在业务线程拿不到可用连接而发生排队时，等待获取到可用连接对象的最大等待时间，参考主流程1和流程1.2 notFullTimeoutRetryCount 获取不到连接时，会尝试重试，这里表示最大重试次数，参考主流程1 testOnBorrow 在取出链接时，是否进行连接可用性测试，默认不开启，参考主流程1 testOnReturn 在回收连接时，是否进行连接可用性测试，默认不开启，参考主流程5 testWhileIdle 在闲置时间超出指定时间（timeBetweenEvictionRunsMillis）后进行连接可用性测试 timeBetweenEvictionRunsMillis 默认60s，一个连接闲置时间超出该值，且设置了testWhileIdle为true时，进行连接可用性测试 inited 是否已被初始化过，参考主流程2 filters（集合） 触发责任链执行时需要执行的所有filter maxWaitThreadCount 默认不开启（-1），表示取不到连接发生等待时阻塞的最大业务线程数，参考流程1.2 removeAbandoned 是否主动回收一些被拿出去使用长久没有归还的连接，默认不开启，参考流程4.2 removeAbandonedTimeoutMillis 表示在removeAbandoned开启的情况下，触发主动归还的时间间隔。 dbType 标记该连接池对象是属于什么数据库类型（根据驱动协议头推算出来） validConnectionChecker druid有多个验证长连接可用性的checker对象，该属性最终会根据数据库类型适配合适的checker对象，参考流程1.3里的init-checker lock 控制连接池线程安全的全局重入锁（参考全部流程里出现的lock） notEmpty 由lock创建的Condition，用于连接不够用时阻塞业务线程，同时唤起主流程3的守护线程追加连接，解释参考主流程2的特别说明第2条 empty 由lock创建的Condition，用于连接足够时（不发生线程等待），阻塞主流程3的守护线程，解释参考主流程2的特别说明第2条 activeConnectionLock 活动连接重入锁，被借出去的连接称为active连接，这类连接在removeAbandoned开启时会被保存进下面的activeConnections里，利用该锁完成对其操作的安全性，参考主流程1和流程4.2 activeConnections（k-v） 解释参考上面的描述，参考主流程1和流程4.2 表1-1 方法表 方法名 说明 testConnectionInternal 测试连接可用性的基本方法，参考流程1.3 createPhysicalConnection 新增真正的数据库物理连接，参考流程2.1 表1-2 DruidDataSource类这个类也是druid连接池基础类，扩展了一些其父类的功能，几乎所有的有关连接池管理的操作都在此类完成。 属性表 属性名 说明 connectCount 一共成功从该池获取了多少次连接（只要获取成功一次，就累加一次） recycleCount 一共成功归还了多少次连接到该池（成功归还一次，累加一次） removeAbandonedCount 在removeAbandoned开启的情况下，被检查后强制归还的连接数 connections（数组） 最终池子里没有被使用的闲置连接存放的地方，类型是DruidConnectionHolder poolingCount pollingCount就是指上面connections的真实数量 activeCount 当前处于借出状态的连接数（也即是被拿出去使用的连接数），poolingCount+activeCount就是当前该池子里一共有多少个连接，不能超过maxActive，参考主流程3 discardCount 被丢弃的连接数，触发丢弃的地方有很多，比如流程1.4、流程4.1 evictConnections（数组） 参考流程4.1 keepAliveConnections（数组） 参考流程4.1 createConnectionThread（线程） 生产连接的守护线程，参考主流程3 destroyConnectionThread（线程） 抛弃连接的守护线程，参考主流程4 logStatsThread（线程） 打印连接池各项监控指标日志的守护线程，参考主流程2，默认关闭 initedLatch（CountDownLatch） 倒计数器，用来保证createConnectionThread和destroyConnectionThread两个守护线程全部开启成功。 enable 连接池对象是否可用，在连接池整体close后，该值为false，表示已关闭的连接池不可用。 keepAlive 参考流程4.1 loadSpifilterSkip 是否启用通过SPI机制加载责任链上的filter，默认开启 表2-1 方法表 方法名 说明 init 初始化整个连接池，参考主流程2 initFromSPIServiceLoader 通过SPI机制加载责任链中的filters initValidConnectionChecker 初始化（适配）检测器，参考流程1.3中的init-checker createAndLogThread 启动上面表2-1里的logStatsThread线程 createAndStartCreatorThread 启动上面表2-1里的createConnectionThread线程 createAndStartDestroyThread 启动上面表2-1里的destroyConnectionThread线程 getConnection 获取连接方法，参考主流程1 getConnectionDirect 获取连接方法（通过getConnection触发），参考主流程1 pollLast 真正从池子里获取连接对象的方法（通过getConnectionDirect触发），参考流程1.2 putLast 真正归还连接进池子的方法（通过recycle触发），参考主流程5 put 新增连接对象放进池子里的方法，通过主流程3触发 close 连接池关闭，不再提供服务，迅速干掉所有连接进入贤者模式。 recycle 连接回收方法，通过下面DruidPooledConnection类的close方法触发，参考主流程5 shrink 连接池瘦身，参考主流程4、流程4.1 removeAbandoned 回收长期未回收的连接，默认关闭不检查，通过表1-1里的removeAbandoned属性控制 emptySignal 触发表1-1里的empty执行signal，用于唤起主流程3新增连接 表2-2 DruidConnectionHolder类最终存放进池子里的基本类型，该类持有驱动产生的真实Connection对象，同时提供一些连接池需要的标记性的属性。 属性表 属性名 说明 dataSource（DruidDataSource） 本身包含一个持有自己实例的连接池对象 conn（Connection） 真实的驱动连接对象 lastActiveTimeMillis 上次活动时间，该值在归还连接时会被刷新一次，参考主流程5，除此之外在一句sql执行结束后，这个值也会被刷新 defaultReadOnly 是否默认为只读模式，默认不是 defaultAutoCommit 是否默认开启AutoCommit，默认开启 discard 当前连接是否已被抛弃 表3-1 方法表 方法名 说明 reset 在连接对象被归还时，由于使用时可能被业务代码人为的改动一些属性（比如autoCommit等）需要把一些属性重新置为默认值，就需要该方法 表3-2 DruidPooledConnection类对外暴露给业务方的连接对象包装类，实际上其内部是包了一层上面的holder对象。 属性表 属性名 说明 conn（Connection） 实际的驱动连接对象，通过下面持有的holder对象获得并赋值 holder（DruidConnectionHolder） 持有的holder对象 disable 标记是否可用 ownerThread 标记最初获取到自己的那个线程（用于决定在close时走下方的close还是syncClose，参考主流程5） closed 标记是否已被关闭 running 标记是否正在运行中，running被置为true的地方，就是执行excute方法时。 abandoned 标记是否已被检查并丢弃，参考流程4.2 表4-1 方法表 方法名 说明 close 关闭该连接，将实际连接归还至连接池，参考主流程5 syncClose 如果是别的线程执行close方法，就得启用该方法去做，该方法与上面close的区别就是加了锁控制，参考流程5 recycle 实际触发datasource.recycle方法的方法，参考流程5 常规操作 有createStatement、commit、rollback等等常规操作，本篇文章不涉及到，仅做连接池的说明，暂时忽略。 表4-2","link":"/2019/09/20/Druid-%E7%B1%BB%E5%9B%BE-%E5%B1%9E%E6%80%A7%E8%A1%A8/"},{"title":"IDEA插件开发（一）一个简单的表单demo","text":"🐜 版本信息：&nbsp;&nbsp; 🐝 插件项目基于gradle构建。 🦟 知识背景：swing 🦇 参考文档： http://www.jetbrains.org/intellij/sdk/docs/tutorials/build_system/prerequisites.html http://www.jetbrains.org/intellij/sdk/docs/user_interface_components/tool_windows.html http://www.jetbrains.org/intellij/sdk/docs/user_interface_components/dialog_wrapper.html https://intellij-support.jetbrains.com/hc/en-us/community/posts/360003338799-Build-compatible-plugin 目标本实例实现一个Idea的插件，弹出一个表单Dialog，然后点击按钮，获取表单里输入的内容，然后将内容打印在表单的上方。 成品图展示： 一、项目初始化新建一个gradle项目，修改其build.gradle文件： 代码块112345678910111213141516171819202122232425262728293031323334353637383940plugins { id 'java' id 'org.jetbrains.intellij' version '0.4.14' //引入intellij的gradle插件} group 'org.example'version '1.0' //定义jar包/zip包的版本号 sourceCompatibility = 1.8 //限制jdk的使用版本号，这里限制到8，表示生成的idea插件只能运行在jdk8以上的环境中 repositories { mavenCentral() //远程仓库} dependencies { //这里引别的依赖包 testCompile group: 'junit', name: 'junit', version: '4.12'} // See https://github.com/JetBrains/gradle-intellij-plugin/intellij { // 这里是指打插件包的时候用idea什么版本的依赖包打 // 比如这里用2019.3打包，如果你的插件实现源码里用了2019.3不存在的依赖包或类，就会报错 // 一般就填当前IDEA的版本号即可 version \"2019.3\"} patchPluginXml { //changeNotes里的内容展示位置参考图14 changeNotes \"\"\" 1.0版本. 第1.0版本：初始化这个测试插件项目\"\"\" // 这个意思是说当前定义的这个插件最早支持到什么版本的IDEA // 这里配置sinceBuild=191，表示插件只能被版本号大于等于2019.1版本的IDEA安装，低于这个版本的将抛无法兼容的错误 // ↑上方参考这篇问答：https://intellij-support.jetbrains.com/hc/en-us/community/posts/360003338799-Build-compatible-plugin sinceBuild \"191\"} 然后Idea的右边栏gradle将会多出intellij选项： 这里说下runIde，它用来调试插件，运行它会再次启动一个Idea，这个Idea会自动安装上你当前定义的插件包，让你用来调试。 二、新增plugin.xml这个文件非常重要，它可以指定你定义的插件出现在IDEA的哪个位置，可以指定具体的处理逻辑，还可以定义插件名称、子名称等等。 这个文件位于MATE-INF下： 配置内容为： 代码块2123456789101112131415161718192021222324252627282930313233343536&lt;idea-plugin&gt; &lt;!--插件的id，注意不要跟其他插件重复，这个id全局唯一，尽可能复杂些--&gt; &lt;id&gt;plugin.test&lt;/id&gt; &lt;!--插件的名称--&gt; &lt;name&gt;PluginTest&lt;/name&gt; &lt;vendor email=\"xxxx@qq.com\" url=\"http://www.bilibili.com\"&gt;你公司的名字&lt;/vendor&gt; &lt;!--插件的描述信息，支持html，展示的位置参考图14--&gt; &lt;description&gt;&lt;![CDATA[ Plugin Test&lt;br&gt; 第一行：单纯只是个测试&lt;br&gt; 第二行：都说了只是个测试(●￣(ｴ)￣●)&lt;br&gt; &lt;a href='https://www.bilibili.com'&gt;你猜猜这是哪个网站？&lt;/a&gt; &lt;em&gt;v1.0&lt;/em&gt; ]]&gt;&lt;/description&gt; &lt;extensions defaultExtensionNs=\"com.intellij\"&gt; &lt;!-- Add your extensions here --&gt; &lt;/extensions&gt; &lt;!--跟build.gradle里的sinceBuild一致即可，意义相同，必须配置--&gt; &lt;idea-version since-build=\"191\"/&gt; &lt;actions&gt; &lt;!--下面的group是分组，分组需要有一个唯一的id标识，text用来控制分组出现在IDEA时呈现的文案，description是描述，不会展现出来，简单描述下分组就行--&gt; &lt;group id=\"PluginTest\" text=\"插件测试组\" description=\"插件测试描述\"&gt; &lt;!--add-to-group控制把该分组加到IDEA里，group-id用来描述加在哪个位置，MainMenu表示加在IDEA上方的主菜单栏里， anchor表示顺序，last表示最后一个，所以下面的配置可以描述为：将该插件加到IDEA上方主菜单栏的最后一位--&gt; &lt;add-to-group group-id=\"MainMenu\" anchor=\"last\"/&gt; &lt;!--这个用来指定一个分组下的触发动作，同样的需要一个id，自定义；class就是用来处理这个动作的逻辑类，具体的插件逻辑都会写到对应的action类里，text用来控制文案，description为描述--&gt; &lt;action id=\"Plugin.Test.Action\" class=\"plugin.test.FromAction\" text=\"表单测试\" description=\"表单测试描述\"/&gt; &lt;/group&gt; &lt;/actions&gt;&lt;/idea-plugin&gt; 然后定义一个Action类，记为FormAction，继承AnAction，实现其抽象方法actionPerformed即可： 代码块3123456public class FromAction extends AnAction { @Override public void actionPerformed(@NotNull AnActionEvent e) { //TODO 这里放插件逻辑 }} 三、启动现在双击runIde即可调出另外一个安装了这个插件的IDEA界面，然后可以看运行结果进行调试。 runIde还支持debug模式，不过运行时要右击选择： 来看下调试IDEA的界面运行效果： 四、定义Action4.1：定义会话框类经过上面三步的配置，插件的基本样式已经展示出来，但是点击下方“表单测试”的action，并没有什么用，因为其绑定的FormAction类里没有任何有意义的实现。现在来实现开始的目标，点击“表单测试”后，弹出一个自定义的表单会话框，然后点击按钮，获取表单内容后打印在会话框内。 会话框（Dialog）需要定义一个继承了IDEA的DialogWrapper抽象类的子类，这个子类就是自定义的会话框实现，所有的样式定义、功能触发都是放到这个子类里的，现定于如下子类： 代码块412345678910111213141516171819202122232425262728293031public class FormTestDialog extends DialogWrapper { private String projectName; //假如需要获取到项目名，作为该类的属性放进来 // DialogWrapper没有默认的无参构造方法，所以需要重写构造方法，它提供了很多重载构造方法， // 这里使用传project类型参数的那个，通过Project对象可以获取当前IDEA内打开的项目的一些属性， // 比如项目名，项目路径等 public FormTestDialog(@Nullable Project project) { super(project); setTitle(\"表单测试~~\"); // 设置会话框标题 this.projectName = project.getName(); } // 重写下面的方法，返回一个自定义的swing样式，该样式会展示在会话框的最上方的位置 @Override protected JComponent createNorthPanel() { return null; } // 重写下面的方法，返回一个自定义的swing样式，该样式会展示在会话框的最下方的位置 @Override protected JComponent createSouthPanel() { return null; } // 重写下面的方法，返回一个自定义的swing样式，该样式会展示在会话框的中央位置 @Override protected JComponent createCenterPanel() { return null; }} 4.2：会话框模块&amp;类元素对照找个实际的会话框为例，针对上述中几个方法所控制的会话框里的元素如下： 4.3：自定义会话框元素4.3.1：会话框方法重定义按照本文的实现目标，自定义的表单主体部分可以位于createCenterPanel里，然后表单的大标题可以放到createNorthPanel里，提交按钮可以放到createSouthPanel里，现在改写如下： 代码块512345678910111213141516171819202122232425262728293031public class FormTestDialog extends DialogWrapper { private String projectName; //swing样式类，定义在4.3.2 private FormTestSwing formTestSwing = new FormTestSwing(); public FormTestDialog(@Nullable Project project) { super(true); setTitle(\"表单测试~~\"); //设置会话框标题 this.projectName = project.getName(); //获取到当前项目的名称 init(); //触发一下init方法，否则swing样式将无法展示在会话框 } @Override protected JComponent createNorthPanel() { return formTestSwing.initNorth(); //返回位于会话框north位置的swing样式 } // 特别说明：不需要展示SouthPanel要重写返回null，否则IDEA将展示默认的\"Cancel\"和\"OK\"按钮 @Override protected JComponent createSouthPanel() { return formTestSwing.initSouth(); } @Override protected JComponent createCenterPanel() { //定义表单的主题，放置到IDEA会话框的中央位置 return formTestSwing.initCenter(); }} 4.3.2：自定义swing样式下面是放置swing样式的类： 代码块612345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public class FormTestSwing { private JPanel north = new JPanel(); private JPanel center = new JPanel(); private JPanel south = new JPanel(); //为了让位于底部的按钮可以拿到组件内容，这里把表单组件做成类属性 private JLabel r1 = new JLabel(\"输出：\"); private JLabel r2 = new JLabel(\"NULL\"); private JLabel name = new JLabel(\"姓名：\"); private JTextField nameContent = new JTextField(); private JLabel age = new JLabel(\"年龄：\"); private JTextField ageContent = new JTextField(); public JPanel initNorth() { //定义表单的标题部分，放置到IDEA会话框的顶部位置 JLabel title = new JLabel(\"表单标题\"); title.setFont(new Font(\"微软雅黑\", Font.PLAIN, 26)); //字体样式 title.setHorizontalAlignment(SwingConstants.CENTER); //水平居中 title.setVerticalAlignment(SwingConstants.CENTER); //垂直居中 north.add(title); return north; } public JPanel initCenter() { //定义表单的主体部分，放置到IDEA会话框的中央位置 //一个简单的3行2列的表格布局 center.setLayout(new GridLayout(3, 2)); //row1：按钮事件触发后将结果打印在这里 r1.setForeground(new Color(255, 47, 93)); //设置字体颜色 center.add(r1); r2.setForeground(new Color(139, 181, 20)); //设置字体颜色 center.add(r2); //row2：姓名+文本框 center.add(name); center.add(nameContent); //row3：年龄+文本框 center.add(age); center.add(ageContent); return center; } public JPanel initSouth() { //定义表单的提交按钮，放置到IDEA会话框的底部位置 JButton submit = new JButton(\"提交\"); submit.setHorizontalAlignment(SwingConstants.CENTER); //水平居中 submit.setVerticalAlignment(SwingConstants.CENTER); //垂直居中 south.add(submit); return south; }} 现在点击下runIde按钮，同样的，在调试IDE里点击“表单测试”，然后就会弹出如下表单框： 🌿 除非有特殊情况需要自定义swing样式，否则建议不加任何swing样式，这样自定义的swing界面是会随着IDEA的主题改变而去自适应的，比如将图7中的调试IDE的主题设置成Darcula，自定义的表单也会自适应的变成黑色背景： 4.3.3：事件绑定定义好了样式，现在给“提交”按钮绑定一个事件，现在改写下FormTestSwing.initSouth方法： 代码块71234567891011121314151617181920public JPanel initSouth() { //定义表单的提交按钮，放置到IDEA会话框的底部位置 JButton submit = new JButton(\"提交\"); submit.setHorizontalAlignment(SwingConstants.CENTER); //水平居中 submit.setVerticalAlignment(SwingConstants.CENTER); //垂直居中 south.add(submit); //按钮事件绑定 submit.addActionListener(e -&gt; { //获取到name和age String name = nameContent.getText(); String age = ageContent.getText(); //刷新r2标签里的内容，替换为name和age r2.setText(String.format(\"name:%s, age:%s\", name, age)); }); return south;} 现在再来点击下“提交”按钮，就可以输出表单内容了： 4.4：插件绑定类：FormAction之前讲过，这个类是插件的入口，结合上面定义好的表单Dialog，来看下它是怎么写的： 代码块812345678public class FromAction extends AnAction { @Override public void actionPerformed(@NotNull AnActionEvent e) { FormTestDialog formTestDialog = new FormTestDialog(e.getProject()); formTestDialog.setResizable(true); //是否允许用户通过拖拽的方式扩大或缩小你的表单框，我这里定义为true，表示允许 formTestDialog.show(); }} 五、插件的打包&amp;安装截止到第四步，都只是在调试IDE里查看效果，如果一个插件开发完成后，需要被实际的IDEA安装，这个时候就需要借助打包选项来打包你的插件，点击下面的选项构建插件： 构建完成后，查看build包下的distributions目录，里面的zip包就可以直接安装进你的IDEA： 然后选择IDEA的Preferences下的plugins选项，弹出如下框，按照图里的指示选择zip包安装即可： 然后安装完成，重启IDEA即可： 各个展示模块对应插件项目里配置的来源参考下图： 重启后出现了跟调试IDEA里一样的菜单栏，选中后运行成功： 写在最后截止到这里，一个插件的开发、调试、安装就完成了，理论上通过这个简单的例子就可以实现一些实际的功能了，因为其完整展示了数据输入到数据获取整个过程。 因为工作当中需要写一个代码生成器，想要以一个IDEA插件的方式提供服务，所以在这里做个记录，防止以后再次用到时从零开始。。 要有一定的swing基础，我在开发代码生成器的时候，就是因为swing基础太差，布局花了非常多的时间。 🍒 之后不会深入去研究插件的开发，如果后续工作中有用到插件开发的其他的功能点，会更新在这个系列里，如果想深入搞IDEA插件开发，建议看IDEA的官方文档，官方文档有点乱，有很多只是简单介绍几句甚至没有示例，好在他们有个问答社区，建议搜索时用google搜英文关键词（google对英文搜索支持强大，没试过度娘，应该也可以搜到），里面会有人提问，比如版本兼容的问题就是google出来的，社区里正好有一篇问答。（链接放到开头里了）","link":"/2019/12/13/IDEA%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91%EF%BC%88%E4%B8%80%EF%BC%89%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E8%A1%A8%E5%8D%95demo/"},{"title":"InfluxDB（一）初探时序数据库","text":"最近公司有个需求需要借助InfluxDB实现（或者更准确的说，使用该数据库可以更容易的实现），因此稍微看了下这个数据库，把比较重要的一些东西先简单记录一下，日后如果踩坑，也会继续在下面补充。 零、下载&amp;安装官方地址：https://portal.influxdata.com/downloads/ 一、什么是时序数据库，它可以用来做什么？简单来说时序数据库就是存储带有时间戳且包含随时间发生变化的数据，InfluxDB属于一种时序数据库。这类数据具体指什么数据呢？这里举几个例子： 监控，比如某一时段CPU占用率、服务QPS、服务耗时等监控数据 某飞机在运行过程中各时刻的高度、速度、机舱内温度、湿度 某地区每时每刻的室外温度记录 上述的数据都满足某一个具体的事物（监控指标、飞机、地区）随着时间的变化而需要记录的一些数据（监控数据、速度、温度等），这些数据被称为时序性数据，这些数据可以被用来做大数据分析、人工智能等。 ❓ 疑问点：通过上述的例子，这些无非是一些指标数据嘛，为什么非得用时序性数据库记录？不可以用Mysql这种关系型数据库来做吗？ 不可以，首先对于这种数据，量级上是巨大的，比如每时每刻都要记录某飞机的坐标变化，类似这种指标，量级很庞大，关系型数据库设计之初并不是为了处理这种大数据量级的，即便是后来的分表分库，也是为了优化数据量和访问量大了以后查询和写入性能问题的，所以不适合用来存储数量如此庞大的数据，所以这并不是能不能实现的问题，而是适不适合的问题，而时序型数据库的写入速度非常快，其次内部还会对存储数据进行压缩，同时提供了更高的可用性，比如数据保留策略、数据聚合函数、连续查询等。数据保留策略可以保证超过指定期限的数据被回收，释放磁盘空间。 二、InfluxDB基本概念2.1：建表不需要专门建表，一般insert执行过去时，如果发现表不存在，就自动创建。 2.2：基本概念与mysql中概念的对应关系 概念名称 概念解释 MySQL类比 database 数据库 类似mysql里的库 measurement 表 类似mysql里的表 point 一行数据记录 类似mysql里的一行数据 表1 2.3：point详解point的概念就类似于mysql里一行数据（data point，直译为数据点，可以理解成一行数据），point的构成部分有三个： point属性 属性解释 备注 time 时间戳 influxdb自带字段，单位：纳秒 tags 有各种索引的属性 可设置多个，逗号隔开 fields 没有索引的属性 可设置多个，逗号隔开 表2 tags和fileds的区别： 121. field无索引，一般表示会随着时间戳而发生改变的属性，比如温度、经纬度等，类型可以是 string, float, int, bool2. tag有索引，一般表示不会随着时间戳而发生改变的属性，比如城市、编号等，类型只可为 string 比较值得注意的是：在InfluxDB中，tags决定了series的数量，而series的数量越大，对于系统CPU和InfluxDB的性能影响越大，series估算方法下面会说。 2.4：sql语句示范建库： 1create database \"库名\" 一般来说，新建完库，还要对该库设置自己的时效策略（RP），下面会详细说明RP的设置方法，一般建好库后都会有一个默认的RP策略 插入数据： 12345insert results,hostname=index2,name=index2333 value=2,value2=4 -------- ---------------------------- ------------------------- 表名 tags的设置 fields的设置 上面这句sql的意思就是说在名为result的表里，插入两个分别命名为hostname和name取值分别为index2和index2333的tags，以及两个分别命名为value和value2取值分别为2和4的fields的数据。 ⚠️ 注意：这里的指令直接输入整数，InfluxDB是按照浮点型处理的，如果一定要让上面的value=2和value2=4中的2和4是整型数据，那么需要在后面加上修饰词：value=2i，i就代表整型。 检索数据： 1select * from results 打印结果为： 1234name: results2time hostname name value value2---- -------- ---- ----- ------1560928150794920700 index2 index2333 2 4 分页检索： 1SELECT * FROM 表 WHERE 条件 LIMIT rows OFFSET (page - 1)*rows rows代表每页展示行数，page表示页码 删除表： 1drop measurement \"表名\" 三、InfluxDB的时效设置很遗憾，InfluxDB是不支持删除和修改的，删除有专门的操作，但是性能很低，不建议使用。 InfluxDB支持定期清除数据策略。 查看当前库对应策略配置的命令为： 1show retention policies on \"库名\" 结果： 123name duration shardGroupDuration replicaN default------- --------- ------------------ --------- -------autogen 0s 168h0m0s 1 true name：过期策略名 duration：保留多长时间的数据，比如3w，意思就是把三周前的数据清除掉，只保留三周内的，支持h（小时），d（天），w（星期）这几种配法。 shardGroupDuration：存储数据的分组结构，比如设置为1d，表示的是每组存储1d的数据量，也就是说数据将按照天为单位划分存储分组，然后根据每条数据的时间戳决定把它放到哪个分组里，因此这个概念还会影响到过期策略，因为InfluxDB在清除过期数据时不可能逐条清理，而是通过清除整个ShardGroup的方式进行，因为通过跟当前时间对比就可以知道哪些分组里的数据一定是过期的，从而进行整组清理，效率往往更高。 replicaN：副本数量，一般为1个（这个大概就是备份的意思？这个配置在单实例模式下不起作用） default：是否是默认配置，设置为true表示默认的意思，主要用于查询时是否指定策略，如果不指定，则这个查询就是针对default=true的策略进行的，注意，本文章里的sql都没有指明保留策略的名字，如果有需要，那么请指定。一个库允许有多套策略配置（每套策略里都可以有自己的一份数据，比如同样一张表的数据在策略A和策略B的情况下是不同的，可以理解为一个库对应N个策略，每个策略里有自己的N多张表，相互独立），在不指定策略名称的情况下写的sql，默认使用default=true的策略。 当然，策略也支持修改，指令如下： 1alter retention policy \"autogen\" on \"test\" duration 30d default 上面这条指令就会把上面策略明为autogen的策略有效保存时间改为30天。 四、InfluxDB的存储结构4.1：结构层级了解完策略，结合上面提到的series、tags、fields等概念，画一下单个InfluxDB库的存储结构： 图里没有体现出tags、fields这些数据层面的东西，它们最终被存放在了Shard里，之前说过tags会影响series的大小，其实series就相当于一个唯一化分类，eries估算方式为： series的个数 = RP × measurement × tags（tags去重后的个数） 比如一个database中有一个measurement，叫test，有两个RP（7d, 30d），tag有host，server。host的值有hostA、hostB，server为server1，server2。那么这个database的series值为2RP x 4tags = 8 4.2：LSM-Tree回归图1前，先来了解下LSM-Tree，几乎所有的k-v存储的写密集型数据库都采用该数据结构实现，该数据结构的结构如下（注意下面说的层级并非树的层级，而是合并逻辑发生时的层级）： 如图2，该结构写入流程如下： 写入的数据首先加到0层，0层的数据存储在内存中，短期内查询的数据一般在0层，由于是内存操作，因此效率会非常高，当0层的数据达到一定大小时，此时会把0层 和位于它下面的1层进行合并，然后合并出来的新的数据（0层+1层的数据）会顺序写磁盘（这里由于是顺序写入磁盘，因此写性能会非常好），然后替换掉原来老的1层数据，当1层达到一定大小的时候，将继续和它的下层合并，以此类推，一级一级的往下递，除此之外还可以将合并之后旧文件全部删掉，留下最新的。 LSM-Tree参考文章：LSM-tree 基本原理及应用 然后回归图1，最终的数据会被存储进Shard，Shard里存在几个区域，就是最终存放数据的地方，下面针对这几个区域说明下它们的作用： 4.3：Cache相当于上面说的LSM-Tree的0层，存放于内存中，写入的数据时首先被该模块接收并存储，该模块在内存中表现为一个map结构，k = seriesKey + 分隔符 + fieldsName，v = 具体的filed对应的值的数组，具体结构体如下（参考网上资料）： 123456789101112131415161718192021type Cache struct { commit sync.Mutex mu sync.RWMutex store map[string]*entry size uint64 // 当前使用内存的大小 maxSize uint64 // 缓存最大值 // snapshots are the cache objects that are currently being written to tsm files // they're kept in memory while flushing so they can be queried along with the cache. // they are read only and should never be modified // memtable 快照，用于写入 tsm 文件，只读 snapshot *Cache snapshotSize uint64 snapshotting bool // This number is the number of pending or failed WriteSnaphot attempts since the last successful one. snapshotAttempts int stats *CacheStatistics lastSnapshot time.Time} 代码块1 基于前面说的LSM-Tree，可以知道这里的cache不是持续增长的，而是达到一定值就会进行跟下层存储在磁盘上的数据（1~n层）进行合并，然后清空cache，在InfluxDB中，这一部分存储在磁盘上的数据，就是指TSM File模块，下面会介绍。 4.4：WAL在上面对于Cache的描述中，Cache是基于内存做的写入数据接收方，那么如果中途机器宕掉，那么就会造成Cache里数据丢失的问题，为了解决这个问题，InfluxDB就设计了WAL模块，实际在写入一个数据时，不仅会先写进Cache，还会写入WAL，可以简单理解WAL就是对Cache里数据的备份，防止数据丢失，在Cache做完一次合并清除掉自身时，旧的WAL文件也会随之删除，然后新建一个WAL，迎接新一轮的写入。同样的，在InfluxDB启动时，也会先去读取WAL文件初始化Cache模块。 4.5：TSM File用于组成TSM-Tree结构的主要磁盘文件（可以对应图2的1~n层），内部做了很多存储以及压缩优化，单个TSM File的最大大小为2GB。 4.6：Compactor在后台持续运行的一个task（频率为1s），主要做以下事情： 在Cache达到阈值时，进行快照，然后将数据合并并保存在TSM File中 合并TSM File，将多个小型TSM File进行合并，使得每个文件的大小尽可能达到单个文件最大大小（也就是上面说到的2GB） 检查并删除一些已关闭的WAL文件 五、具体案例，以及实际的存储目录结合图1的结构以及图2的数据结构，再加上对shard内部各组件的介绍，下面通过一个实际的例子来探索下InfluxDB实际的存储目录。 现在创建出来一个叫style_rank的库，且设置默认RP为7d，保存周期为7天，默认分组策略为24h分一次，如图： 图中名为7d的rp策略被设置为默认策略，其中duration被设置为168h，shardGroupDuration被设置为了24h，意味着该策略里的表数据将以7天为一个周期过期，期间以1天为单位分组。 5.1：InfluxDB配置文件下载下来一个InfluxDB后，通过配置文件influxdb.conf可以配置各个文件存放的目录： 这几个配置决定了你将产生的数据存放在哪里，建议自定义这个，默认的目录很迷=_= 5.2：具体的数据目录配置完上面的文件，启动，然后录入数据，然后再去具体的目录下查找具体的数据文件： 元数据层：用来存放当前库的属性，比如RP、默认RP、分组策略等。 wal层：用来存放刚写入数据的信息，会先写入内存，然后异步写入wal文件，wal文件用来重启InfluxDB时恢复内存数据用，当wal文件达到一定大小时，会压入data层，wal层的结构和data层的几乎一致： 上面进入wal目录后，需要选择正确的库，这里选择style_rank，进入库后，会显示出该库的所有RP，这里选择7d，然后对应图1，你现在来到了ShardGroup层，图6中的编号，就是生成的ShardGroup，随便进入一个，则可以看到最终的wal文件（事实上只有当天建的group内的wal才有数据）。 data层：用来最终存放数据的目录，所有wal文件内的数据达到一定大小后，均会被压缩进data层，现在进入data层，然后进入style_rank： 可以看到下方除了有两个RP策略外，还有_series目录，这个目录就是存放索引（tags字段所产生的索引数据）的地方，用于服务重启时恢复索引数据用。 进入7d，可以看到跟wal层差不多的ShardGroup分层，你现在又来到了图1的ShardGroup层： 然后再次进入一个分组内： 最终的tsm文件就存在该目录下，fields.idx存放的是表里的fields元数据，用于写入数据时做效验用。 六、执行计划然后继续由上面的style_rank库，在7d这个RP下，新建两张表： 12insert season_views,date=\"201907\" season_id=666,views=56789insert season_views_v2,season_id=666 views=56789 目的很简单，只是为了记录下season_id=xxx的数据在某一时刻对应的views值，俩表的区别在于，season_view仅仅以日期为tag（作为索引字段，可以忽略不计），season_views_v2则以season_id作为tag，某一时刻，两张表的数据量均达到了5kw且数据一致，下面，让我们以最简单的方式，查询下这两张表： ℹ️ ps：sql前加explain关键字可以查看其执行计划，加explain analyze可以看到具体每一步执行的耗时。 同样的查询，season_id加了索引和不加索引的区别： NUMBER OF SERIES（扫描系列数，加了索引后根据series的哈希算法，同一个season_id都被分在了同一个Shard里，这里之所以为8，是因为ShardGroup不同）由不加索引的64个，减少到了8个 NUMBER OF FILES（扫描文件数）由不加索引的54个减少到11个 NUMBER OF BLOCKS（扫描的数据块）由不加索引的152058减少到了184 七、总结 在使用时，尽可能按照某具体时间段进行过滤，如果过滤条件筛选出的数据量过大，则会严重影响查询效率。 适度使用函数，若使用，请保证筛选条件筛选出的数据量，如果过大，效率会极低，比如在season_views_v2中启用TOP函数，查出前三名，查询耗时超过10s，加上season_id条件后，则迅速返回。 加索引时需要注意，尽量避免大数据量的属性做tag，否则会产生大量series，生成大量索引数据，占用过多内存，比如用户级别的tag（这里的用户级别是指大型网站用户数量级，一般1亿以上的情况）。 免费版的InfluxDB不支持集群，主从需要借助influx-proxy实现，也可以自己通过监听wal文件写入，通过消息队列的方式实现主从同步，wal类似mysql里的binlog。 建议使用的时候，先把自己的库建好，然后再把RP建好，如果嫌麻烦，可以直接把自己新建的RP定义成默认RP，如果RP设置为默认，只会对查询产生影响（当然写的时候也需要指定），在sql中不指定RP的情况下执行，则认为就是走的默认RP。 分库，建议按照日期分。","link":"/2019/06/21/InfluxDB%EF%BC%88%E4%B8%80%EF%BC%89%E5%88%9D%E6%8E%A2%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"title":"JAVA有关位运算的全套梳理","text":"一、在计算机中数据是如何进行计算的？1.1：java中的byte型数据取值范围我们最开始学习java的时候知道，byte类型的数据占了8个bit位，每个位上或0或1，左边第一位表示符号位，符号位如果为1表示负数，为0则表示正数，因此要推算byte的取值范围，只需要让数值位每一位上都等于1即可。我们来用我们的常规思维来分析下byte类型的取值范围： 如果按照这种思路来推算，七个1的二进制数转换为十进制是127，算上符号位，取值范围应为：-127+127，但事实上我们知道，byte的取值范围是-128127，这里先打个问号，接着往下看。现在让我们计算下byte类型的7加上byte类型的-2是多少： 诶？跟我们预想的不一样，因为我们是知道7和-2的和应该是5才对，结果应该表示为：00000101，但事实上通过图2的结果来看确实跟预想的不一样，所以计算机在做计算的时候，肯定不是表面上的符号位+数值位的方式进行的计算的。 1.2：原码，反码，补码我们先来看下定义： 👉 原码定义：符号位加后面的数值，比如图2里的00000111和10000010都是原码，原码比较简单，就是我们在上面单纯理解上的原值。 👉 反码定义：正数的反码就是它的原码，负数的反码符号位不变，其余数值位全部按位取反，例如： 00000111的反码：00000111 10000010的反码：11111101 👉 补码定义：同样的，正数的补码仍然等于它的原码本身，负数的补码等于它自己的反码+1，例如： 00000111的补码：00000111 10000010的补码：11111110 🌴 总结：正数的原码、反码、补码完全一致，负数的反码等于它原码的数值位按位取反，负数的补码等于它的反码+1 现在让我们用反码的方式来计算下图2中的式子： 利用数值的反码计算出的结果已经很接近正确答案了，+4的反码等于它的原码，现在只需要让它+1就是正确答案，还记得补码的定义吗？负数的补码等于它的反码+1，那现在让我们用补码做下计算试试？ ok，我们发现，用它们的补码做加法，得到的数值就是我们想要的正确答案，事实上，计算机并没有减法运算器，所有的减法运算，都是以一个正数加上一个负数的形式来交给加法运算器计算的，由于负数的符号位为1，虽然我们人是知道它的含义，但是作为计算机，它是不知道第一位是符号位的，它要做的就仅仅是让两个数相加而已，正是因为如此，我们才不能简简单单保存负数，通过图4我们知道，两个数的补码相加，可以得到一个准确的数值。 再举个相加结果为负数的例子，让两个负数相加： 如果结果为负数的话，也是适用的，只是它仍然是以补码的形式存放的，需要转成原码才符合我们人的理解方式。 现在回到上面留下的问题，为什么byte的取值范围是-128~127呢？ 我们之前按照图1里的理解，理所应当的以为它应该是-127~127的范围，那是因为我们按照图1的理解方式，数值就是以符号位+数值位的方式理解的（也就是按照原码的方式理解的），但是你可以想一下，如果按照图1那种理解方式，是不是会存在两个0值呢？ 即：10000000和00000000，+0和-0； 其次如果站在机器角度上来说，所有的负数都很大，至少要比所有正数大，因为负数的最高位也就是符号位都是1，显然这是不对的，通过本节我们知道了，所有的数均通过自己的补码完成计算，如果将最后得到的结果转成原码，就是我们人眼可以理解的最终值（符号位+数值位），如果现在利用补码的方式做理解，符号位为0的数没啥好说的，自然取值区间为：0~127，但是符号位为1的负数呢？负数就存在一个特殊值（也就是我们之前片面理解的-0）：10000000，如果按照原码理解它是-0，但我们前面说过，计算机里所有数字，都是以补码的方式参与运算的，而负数的补码不等于其原码，这个10000000在计算机里显然是某个负数的补码，那么问题就变的简单多了，即10000000是谁的补码呢？答案是：-128，这也是为什么负数的取值范围会比正数多一个的原因，byte类型如此，其它类型也是如此，比如int型的负数取值也比正数多1。 这一块的定义要清晰，对理解后面的位运算会有很大的帮助。 二、java中的位运算2.1：与运算与运算符号：&amp; 与运算特点：1&amp;1=1、1&amp;0=0、0&amp;1=0、0&amp;0=0 现在我们来举一个例子： 让我们再来试试负数： 2.2：或、异或跟与运算的运算方式一致，只不过规则不太一样： 或运算符号：| 或运算规则：1|1=1、1|0=1、0|1=1、0|0=0 异或运算符号：^ 异或运算规则：1^1=0、1^0=1、0^1=1、0^0=0 2.3：按位取反取反符号：~ 即一个数对自己取反，例如： 某个数字a的二进制为： 1010110，则~a为： 0101001 2.4：左移运算左移运算符：&lt;&lt; 例如： 位运算越界&amp;数位抛弃： 图8中的116的二进制数的数值位为7位，符号位为0，此时如果左移超过24位，就会出现负数，为什么会这样？因为java中的位移越界时，java会抛弃高位越界部分，我们知道java里int类型的第一位是符号位，如果符号位是1，则表示其为负数，现在将数值位占7bit符号位为0的116左移24位，就会出现下方结果： 01110100000000000000000000000000 正好31位占全，顶至符号位，低位补0，我们称24为116的不越界的最大左移值，若超出这个值，就会越界，比如左移25位： 11101000000000000000000000000000 显然左移25位后会把数值位的1移动到符号位，这时它表示为一个负数的补码。根据这个规则，我们如果让其左移28位，则值为： 01000000000000000000000000000000 也就是十进制的1073741824，即：116 &lt;&lt; 28 = 1073741824，那如果越界过多呢？比如int型的数据，左移32位：116 &lt;&lt; 32 = 116 会发现，如果左移自己位数一样多的位数，那么这个数就等于它本身，因此运算符合以下规则： 设x为被位移值，y为本次位移的位数，z为x所属类型的最大存储位数： x &lt;&lt; y = x &lt;&lt; (y%z) 如果是int型（32位，long型就用64代入计算），符合如下规则： 116 &lt;&lt; 4 = 116 &lt;&lt; (4%32) = 116 &lt;&lt; 4 = 1856 116 &lt;&lt; 32 = 116 &lt;&lt; (32%32) = 116 &lt;&lt; 0 = 116 116 &lt;&lt; 36 = 116 &lt;&lt; (36%32) = 116 &lt;&lt; 4 = 1856 2.5：有符号右移运算&amp;无符号右移运算有符号右移运算符：&gt;&gt; 无符号右移运算符：&gt;&gt;&gt; 例如：a &gt;&gt; b表示a右移b位，跟上面的左移例子一样，右移也会有越界问题，只是右移越界是从右边开始抛弃越界部分的，右移操作有符号位干扰，如果是正数右移，无此干扰项，因为符号位本就是0右移不会影响值的准确性，但如果是负数，第一位是符号位，且值为1，右移就有影响了，现在仍然以116为例： 正数右移： 上述是正数，右移无影响，但是负数，这里以-116为例，我们知道负数在计算机里是以补码的形式存储的，所以图里直接用-116的补码做运算，位移过程如下： 你会发现右移跟左移不一样，左移是不用担心自己符号位存在“补位”问题的，但是右移存在，如图中-116右移4位后，左边第一位，也就是符号位，就面临着补位的问题，那我现在是该补1呢，还是补0呢？这也就是为什么右移操作会存在有符号右移和无符号右移两种移动方式： ☘️ 有符号右移：依照原符号位，如果原符号位是1，那么图4里需要补位的空位全部补1，如果原符号位为0，则全部补0 ☘️ 无符号右移：无视原符号位，全部补0 现在让我们用有符号的方式将-116右移4位，即-116 &gt;&gt; 4，按照有符号的规则，补位符合原符号位，则右边4位全部补1： 得到的仍然是个负数，它仍然是一个补码，图里展示不开，它的结果为：11111111111111111111111111111000，经转换可知它是-8的补码，即：-116 &gt;&gt; 4 = -8 现在再试试用无符号右移，根据无符号的特点，右移后的前四位无脑补0： 图里展示不开，它的结果为：00001111111111111111111111111000 可见它是个正数，转换成十进制为：268435448，即：-116 &gt;&gt;&gt; 4 = 268435448 最后说一下，跟左移一样，右移里不管是有符号还是无符号，也符合取余的方式，计算出位移的最终位数： -116 &gt;&gt; 4 = -116 &gt;&gt; (4%32) = -116 &gt;&gt; 4 = -8 -116 &gt;&gt; 32 = -116 &gt;&gt; (32%32) = -116 &gt;&gt; 0 = -116 -116 &gt;&gt; 36 = -116 &gt;&gt; (36%32) = -116 &gt;&gt; 4 = -8 2.6：类型转换溢出了解完位运算，来看一个比较实际的问题，看下面的代码： 12long a = 8934567890233345621L;int b = (int) a; //b的值为-1493678507 最终b的值是一个负数，这是由于long型64位，让int型强行接收，会出现位溢出的问题，这个流程如下： 三、位运算在实际项目中的运用位运算的性能是非常好的，相比运算流程，计算机更喜欢这种纯粹的逻辑门和移动位置的运算，但位运算在平常的业务代码里并不太常见，因为它的可读性不太好，但是我们仍然可以利用位运算来解决一些实际项目里的问题。 比如用来表示开关的功能，比如需求里经常有这种字段：是否允许xx（0不允许，1允许），是否有yy权限（0没有，1有），是否存在zz（0不存在，1存在） 上面只是举例，类似这种只有两种取值状态的属性，如果当成数据库字段放进去的话，太过浪费，如果之后又有类似的字段，又得新增数据库字段，为了只有两种取值的字段，实在是不太值得。 这个时候何不用一个字段来表示这些字段呢？你可能已经猜到要怎么做了： 顶一个int型或者long型的字段，让它的每一个二进制位拥有特殊含义即可，然后按照位运算将其对应的位置上的数值变成0或1，那如何将某个数的二进制位第x位上的数值变成1或0呢？其实这在位图结构里经常用到，就是利用1这个特殊的值作位移运算后再与原值进行位运算，让我们看下这个过程： 把一个数的第2位的字符变成1，现在假设这个数初始化为0，int型，我们把它当成二进制展示出来： 现在如何把这个数的第二位变成1呢？目前是这样做的： 10 | 1 &lt;&lt; 1 即原值跟1左移1位后的值作或运算，先来看看1 &lt;&lt; 1的结果： 然后拿着图16的结果，跟原数（也就是0）进行或运算： 可以看到，原数的第二位已经被置为1了，它的十进制对应2，其它位的数置为1也大同小异，例如，现在让第6位也变成1只需要： 12 | 1 &lt;&lt; 5 即拿着原值（现在为2）跟1左移5位后的数做或运算，这个流程如下： 看完了把某个位置的数值置为1，那如何把某位设置为0呢？我们现在把图18里的结果的第6位重新置回0，目前的做法为： 134 &amp; ~(1 &lt;&lt; 5) 即拿着原值（经过上面几步的运算，现在值为34）跟1左移5位按位取反后的数做与运算，来看下这个流程： 经过上面的流程，就可以把原值的第6位变成0了。 那么我们知道了让一个数的二进制位的某位变成0或1的方法，那如何知道一个数的某位上究竟是0还是1呢？毕竟我们业务代码需要知道第几位代表什么意思并且获取到对应位置上的值。 假如我现在想知道十进制int型数34的第6位是0还是1，写法如下： 134 &gt;&gt; 5 &amp; 1 即让原值（34）右移5位后跟1做与运算，来看下这个流程： 由图可以看出，想要知道一个数的第几位是1还是0，只需要将其对应位置上的值“逼”到最后一位，然后跟1相与即可，如果对应位置上的值是0，那么与1相与后的结果一定为0，反之一定为1. ☘️ 总结 到这里已经说完了为什么要用一个数表示那么多开关，以及如何给一个开关位设置对应的开关值，以及如何找到对应开关位的值，有了这些操作，我们再也不需要为这种只有0和1取值的字段新增数据库字段了，因为一个int型的数字，就可以表达32个开关属性，如果超了，还可以扩成64位的long型~","link":"/2020/03/10/JAVA%E6%9C%89%E5%85%B3%E4%BD%8D%E8%BF%90%E7%AE%97%E7%9A%84%E5%85%A8%E5%A5%97%E6%A2%B3%E7%90%86/"},{"title":"JAVA进化论（序）","text":"序章 最近有一项工作，让测试同学对java这门语言进行入门，并且可以独立review开发写出来的代码，还可以朝着测试开发工程师去做。想着自己正式做java开发已经快4年了，不知不觉接触java这门计算机语言也已经6年多了，想着给别人讲一些基础做下入门应该没啥大问题了吧，但其实在整理过程中发现，有些东西想要整理的很通俗详细还是很难的，不过基础篇的教程最后还是坚持下来了，自己收获也不少，很多基础知识在自己整理的过程中又加深了一遍记忆，同时，作为一种个人经历，我也想把这些文档放到个人博客里。关于进阶篇，没有继续更新，因为整理的太细，课程耗时会很久，就采用了另外一种速成的方式交给他们这些进阶的知识点了，所以课程文档本身到基础篇就断掉了。 下面的脑图是对java基础知识&amp;进阶知识的梳理（可能有些地方漏掉了）","link":"/2020/02/24/JAVA%E8%BF%9B%E5%8C%96%E8%AE%BA%EF%BC%88%E5%BA%8F%EF%BC%89/"},{"title":"JVM基础回顾记录（一）：JVM的内存模型","text":"一、JAVA程序执行流程JAVA程序执行的基本流程（基于HotSpot）： 二、内存模块划分2.1：程序计数器程序计数器是一块较小的内存空间，是当前线程执行字节码的行号指示器，字节码解释器就是通过改变这个计数器的值来获取下一条需要执行的字节码指令，其中分支、循环、跳转和异常处理，线程恢复等基础功能均需要依赖该计数器完成。由于jvm的多线程是通过线程轮流切换并分配CPU执行时间的方式实现，在任何时刻，一个CPU都只会执行其中一条线程里的指令，为了使线程发生切换后可以顺利的定位到上次发生切换时的执行位置，每个线程都有一个独立的程序计数器，每条线程的计数器相互独立，这块存储区域被称为线程私有内存。 2.2：方法区也是线程共享的一块区域，这块区域主要用来存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据，HotSpot虚拟机实现该区域时采用堆的一块区域实现，目的是为了让GC分代收集扩展至方法区（比如类卸载时是需要GC参与的），因此在堆空间里划分出一个代来存储方法区里的内容，这块区域通常被称作“永久代”，该块区域大小通过-XX:MaxPermSize来设置（因此可能会出现OOM的情况），不过需要说明的是，J8已经没有这块区域了，而且J7的时候已经将常量池由该块区域转移到实际的堆内存里了（实验证明，J7和J8的时候，常量池已经被存进了实际的堆内存，但区别是J7的类信息等还放在永久代中）。J8有了元数据存储，已经彻底去除了永久代的概念，具体了解：Java8内存划分 2.3：堆jvm管理的最大一块区域，jvm启动时创建，用来存放对象实例，几乎所有的对象都在这里分配内存，通过-Xmx和-Xms控制其大小。这块区域是GC管理的主要区域，从内存回收角度来看，现在的内存回收基本都采用分代收集算法，所以该区域还可以细分（如图1堆空间细分），进一步划分的目的是为了更好的回收内存或更快的分配内存。这里列一下例子里用到的参数（也是比较常用的参数）： 名称 含义 -xms 堆初始化大小 -xmx 堆最大大小（一般来说，-xms和-xmx设置大小一致，以避免每次垃圾回收完成后JVM重新分配内存） -xmn 新生代大小（结合图1理解），这里需要提一下-XX:newSize、-XX:MaxnewSize这俩参数，第一个是指新生代初始大小，第二个是指新生代最大大小，同样为了避免JVM重新分配内存，这俩数值一般设置为一样的，所以jdk4出来了-xmn，一个配置，可以对上述俩参数同时生效 -XX:NewRatio 新生代（Eden+2Survivors）与老年代的大小比值，如果值为2，则新生代:老年代=1:2（如果设置了-xmn指定了新生代大小，则无需设置此项，两个都设置，只生效一个） -XX:SurvivorRatio 新生代中，Eden区与两个Survivor的大小比值，如果设置为4，则eden:survivor1:survivor2 = 4:1:1） -xss 栈大小，一般默认128k，如果调用栈不是很深（比如很深的递归程序），保持默认即可 表1 2.3.1：堆配置详解现在让我们把图1中的“堆空间细分”部分放大，结合下面的配置信息和表1中的含义（-Xss和永久代不会体现在图里），来用图说明下： 配置1：-Xmx3072m -Xms3072m -Xmn2g -XX:SurvivorRatio=4 -Xss128k 上面的配置表示堆区总大小为3550M，新生代大小为2G（2048M，这里只是说明问题才配置这么大，实际生产中，新生代要小于老年代），新生代Eden区和两个Survivor区的比例为4:1:1，用图来直观的表达一下这个配置： 配置2：-Xmx3072m -Xms3072m -XX:NewRatio=2 -XX:SurvivorRatio=4 -Xss128k 上面的配置表示堆区总大小为3550m，新生代:老年代=1:2（HotSpot默认），新生代eden区和两个survivor区的比例为4:1:1，用图来直观的表达一下这个配置： 2.4：虚拟机栈也就是常说的栈，线程私有，生命周期与线程相同，虚拟机栈用来描述java方法（java method）执行的内存模型，每个方法执行时都会创建一个栈帧，用于存储局部变量表、操作数栈、动态链接、方法出口等信息，一个方法的调用到其完成调用对应一个栈帧在虚拟机的入栈到出栈。 局部变量表里存放着编译期可知的基本数据类型、对象引用Reference（可能是指向实例对象地址的一个引用指针，也可能是代表实例对象的一个句柄）、以及returnAddress（指向一条字节码的执行命令的地址）。在此区域，如果线程的请求深度大于虚拟机允许的深度，将会抛出StackOverFlowError异常，这个可以通过一个无限制递归或者递归深度设置一个很大的数来证明： 123456789101112131415161718public class Recursion { public static int i = 0; public static void main(String[] args) { Recursion t = new Recursion(); t.recursion(); System.out.println(\"程序正常结束~\"); } public void recursion(){ i++; if(i &gt; 30000){ //这里做适当调整，减小则不报栈溢出异常，扩大（比如这里的3w）就会报栈溢出 return; } recursion(); }} 代码块1 看注释那里调整即可证明。栈大小通过-Xss参数来调整，需要注意的是，这个参数是对每个线程生效的（栈帧），一般情况下，这个设置的值越小，支持创建的线程数就越多（并非可以无限多，最终受操作系统限制，操作系统针对每个进程也有个最大线程数的限制），栈里存储的大部分数据，都会随着栈帧的结束（即method调用完成）而被回收，所以一般递归更容易造成栈溢出问题。 2.5：本地方法栈意义类似虚拟机栈，只不过本地方法栈服务于本地native方法调用（JNI），我们常用的虚拟机HotSpot已将该区和虚拟机栈做了合并。","link":"/2019/04/06/JVM%E5%9F%BA%E7%A1%80%E5%9B%9E%E9%A1%BE%E8%AE%B0%E5%BD%95%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9AJVM%E7%9A%84%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"},{"title":"JVM基础回顾记录（二）：垃圾收集","text":"上一篇介绍了jvm的内存模型，本篇将介绍虚拟机中最为复杂的一部分：垃圾收集，本篇会从垃圾回收前的准备工作到后面的收集阶段的方式以及HotSpot虚拟机对这些工作的实现做个较为系统的记录，方便自己以后查找阅读。 一、栈帧、变量类型、引用分析讲解垃圾收集器的实现之前，结合之前讲的jvm内存区域划分，先来看下HotSpot虚拟机中对于对象的访问定位是怎样的，对象访问定位如下图所示： 一般来说，一个方法视为一个栈帧，栈帧内会存放当前方法所有的变量，这就是栈的本地变量表，变量分为基本类型变量和引用类型变量，基本类型是直接在栈空间分配存储空间的（也即是当前栈帧内，受-Xss一定的影响），而引用类型则是预先无法知晓其内存占用量为多大，因此需要动态分配内存，这就需要借助堆区的存储，这种一般是堆区创建对象实例，而栈帧内创建一个引用reference，其存放的实际上是指向堆区实例对象的地址，实例对象的内部也有很多成员变量，其次实例对象也会有一个指针指向方法区里的属于该对象的类型数据（这一步就标记了当前实例属于哪个Class）。 先来看一段程序： 123456789101112131415161718192021222324public class Student { private int id; private int age; private Teacher teacher;}public class Teacher { private int id;}public static void main(String[] args) { int a = 1; long b = 2L; Student student = new Student(); student.setId(1); student.setAge(2); Teacher teacher = new Teacher(); teacher.setId(1); student.setTeacher(teacher);} 代码块1 上面是很简单的一个程序，main方法里声明了一些变量以及初始化了一些对象，那么上面的程序执行过程中的引用关系表示为下图： 上图就是执行到main方法尾部的最终引用关系，我们知道像栈帧里的数据（本地变量表）随着方法的执行结束，自然就被释放了，因此像main方法里的a、b、student、teacher是不需要GC来关心的，GC需要关心的是图2里堆区的俩实例对象，这俩实例对象是不会随着栈帧的结束而被回收掉的，因此需要借助GC来进行回收，那么什么样的对象可以被回收呢？这又回到上一篇里对可达性分析算法的描述了，其实就是看看当前实例还有没有被GC Root引用，针对上例，GC Root就是student和teacher，这俩引用没了，引用局面就变成了下面这样： 很显然，两个实例已经失去了GC Root的引用，尽管Teacher实例还存在一个强引用，但是基于可达性分析算法的特性，也会被判定为“不可达”对象，最终俩实例会被GC回收掉。 到这里总结一下，栈帧里存放的本地变量表，存在两种类型的变量：基本类型&amp;引用类型，基本类型由于预先知道要为其分配多大内存，因此会直接在栈帧内创建，创建完毕后随着栈帧的结束而销毁，引用变量（非基本类型的其他类型变量）由于预先并不清楚需要分配多大的内存，可能后续需要动态扩容等，需要放入堆空间，栈帧内保留一个指向其内存地址的引用变量，而放入堆空间意味着实例本身无法随着栈帧的消失而被释放，需要借助GC来完成回收。 二、预回收阶段2.1：回收前的对象判活通过第一部分，大致了解了两种变量类型，而GC需要关心的则是GC Root，典型的作为GC Root的类型，则是引用类型，而判定变量是否为引用类型变量，往往影响着GC的实现。 这里所处的阶段是预回收阶段，这个阶段的GC不会发生回收，所以先不说回收阶段的算法（下面将要介绍的标记-清除算法、标记-压缩算法、复制算法），GC要进入回收阶段，首先要做的事情就是判断出“哪些对象还是活着的”，那么这个阶段需要做的事情是分析出对象的存活状态，有哪些方式可以判断出对象的活性呢？这里有两种主要方式：引用计数&amp;可达性分析算法，其中可达性分析算法是根据GC Root来进行判断的，所以需要关心栈帧里的引用类型变量，这个判断引用变量的方式，又分为保守式和准确式，这些判定方法的选择往往会影响GC的实现。 2.1.1：引用计数法这种判定算法非常简单，给对象添加一个引用计数器，每当有一个地方引用它，就加1，每当一个引用失效，就减1，当引用计数器为0的时候，就认为该对象失活，处于可回收状态。但是这种算法是有缺陷的，比如对象的循环引用问题，如下： 123456A a = new A();B b = new B();a.b = b;b.a = a;a = null;b = null; 如上代码，首先A、B的实例首先被a、b引用，这时加1，然后又被a.b、b.a引用一次，再次加1，然后a、b指向null，A、B实例失去了一个引用，但是计数器里的引用数还是1，单看上面的代码，A、B对象的实例应该是需要被回收的的，因为不存在任何方法栈的引用，反而是它们内部的属性互相引用着彼此，因此利用这个算法，很大程度上会造成内存泄漏的问题。jvm在上述代码中，也是会把A和B的实例对象给回收掉的，因此JVM并不是采用这种方法分析对象活性的。 2.1.2：可达性分析算法这个算法的基本思路就是通过一系列的GC Roots的对象作为起点，然后从这些节点往下搜索，搜索走过的路径被称作“引用链”，当一个对象到GC Roots没有任何引用链相连时，则认为该对象死亡，GC Roots通常包含：虚拟机栈（栈帧中的本地变量表）中引用的对象、方法区中的类静态属性引用的对象以及常量引用的对象、本地方法栈中的native方法引用的对象。 那么再利用此算法来看看上述AB循环依赖问题例子的引用变化： 通过图4可以看到，最后失去GC Roots的引用后，A、B的实例对象到GC Roots没有任何引用链相连，因此最终会被判定为死亡对象，进而被回收。 目前JVM的对象死亡判定也是通过该算法来进行判断的，当一个对象到GC Roots“不可达”时，即被认为“可回收”。 通过之前对可达性分析算法的介绍，这种判活方法主要根据判定一个对象是否直接或间接被一个GC Root引用，而引用类型的变量才会作为GC Root，因此采用这种判活算法，往往要先分析出哪些变量属于引用类型，因为有了这一步，所以可达性分析算法又根据JVM的实现不同，影响着GC的实现方式，因而GC又被分为了两种分析方式： 2.1.2.1：可达性分析算法-保守式GC如果JVM不选择记录下来栈帧中的变量哪些是引用类型，哪些是基本类型，对于GC而言，是无法知道变量类型，于是GC在回收前夕，需要遍历栈帧里的每一个变量，通过一些判定条件来分析出当前变量是否是引用变量，这些条件包括边界检查、对齐检查等，符合标准的，会被视为引用类型变量，否则为基本类型变量，这种判定方式比较简单，但是存在缺点，比如一个对象实际上没有任何引用存在了，但是仍然存在“疑似指向”它的指针，使得其逃过被GC的命运，这里“疑似指向”的意思是说，栈帧里可能恰好存在一个通过了条件检查（边界、对齐等检查都符合引用类型数据的条件）的变量，这时GC会认为它就是一个GC Root，被认为是GC Root后，其值正好对应上这个无用对象的地址，那么这个死对象仍然被认为“可达”，此时就会绕过了一次GC。 2.1.2.2：可达性分析算法-准确式GC这是目前HotSpot虚拟机会采用的一种枚举GC Roots的方式（下面③会介绍实现方式），准确式GC不同于保守式GC，准确式GC是在枚举GC Roots时，GC已经知道了栈帧里所有对象的类型，这就免去了上面的不确定检查，因为预先知道栈帧里的变量是引用类型还是基本类型，那么枚举GC Roots就变的非常准确，这就是准确式GC。 2.1.2.3：HotSpot对于准确式GC的实现-OopMapHotSpot虚拟机是采用OopMap来实现引用类型标记的，OopMap可以记录下当前栈帧里所有引用类型变量，GC时，只需要读取这里面的变量即可，很多资料会提到OopMap是提高了枚举GC Roots的效率，其实这不是OopMap真正的目的，OopMap的实现是HotSpot用来实现准确式GC的，而这样处理，恰好对枚举效率的提升也起到一定的帮助（比如枚举时完全可以忽略掉那些基本类型变量了，因为他们不会被记到OopMap里）。 2.2：STW上面说了GC开始前针对对象的判活方法，HotSpot通过OopMap实现了准确式GC，现在来讲下GC前的准备工作，GC前往往需要将所有正在运行的线程挂起，这是为了防止一些引用在GC过程中还在不停的发生变化而做的一致性保护，这种行为叫做STW（Stop The World），一般来说，STW发生时的线程中断，HotSpot虚拟机需要每个线程将自己的程序执行到指定位置，根据线程是否已经让出CPU资源（即线程状态）而分为两种意义上的位置： 2.2.1：安全点（Safe Point）针对的是GC发生时还在运行的线程，这时候需要等待该线程主动运行到指定位置才中断线程，这些指定的位置，被称为安全点，安全点的意义是什么呢？上面说到HotSpot通过OopMap来完成准确式GC，但是引用关系的变化是不可避免的，每变化一次，就更新一次OopMap显然效率不高，因此JVM更新OopMap的实现就用到了安全点，当线程运行到安全点，记录下当前引用，更新至OopMap即可，这也就解释了为什么程序中断前必须要停靠在最近的安全点上。可作为安全点的位置有：循环末尾、方法临近返回前、方法调用后、抛出异常的位置。 2.2.2：安全区域（Safe Region）意义类似安全点，这个概念是针对GC发生前，程序线程处于“CPU让出状态”，比如线程的sleep状态或者blocked状态，这时该线程是没有能力运行到就近的安全点的，针对此情况，便有了安全区域概念，安全区域是指在一段代码区域中，引用关系是不会发生变化的，在此区域的任意位置开始GC都是安全的。线程在运行到安全区域内，首先会标记自己已经到达了安全区域，那么当JVM需要GC时，发现该线程已经进入安全区域，则不会再去管其状态（无视sleep、blocked等让出CPU的状态），直接对其内部进行OopMap更新，完成GC Roots的枚举，当然，如果线程离开安全区域时，就需要判断是否已经完成了GC或者GC Roots枚举，若完成则继续执行，否则就必须等待直到收到可以离开安全区域的信号为止。 2.2.3：STW中断线程的两种方式安全点和安全区域均为HotSpot虚拟机为了保证枚举GC Roots的准确性而做出的实现，结合安全点、安全区域，在达到安全点时GC对线程的中断（STW）又分为两种中断方式： 2.2.3.1：抢先式中断在GC发生时，首先中断所有线程，然后检查各个线程是否执行到了安全点，如果没有，则恢复对应线程让其运行到安全点再次完成中断。 2.2.3.2：主动式中断在GC发生时，不直接操作线程中断，而是简单设置一个标记，让各个线程去轮询这个标记，如果轮询到该标记，则自己主动中断挂起自己。JVM就采用该中断方式，轮询标记的位置和安全点的位置一般是重合的。 三、回收阶段-垃圾回收算法第二部分讲的是GC前的准备工作，以及HotSpot在GC前针对枚举GC Roots的实现，下面来看下完成GC Roots枚举后的回收阶段的几种回收算法。 3.1：标记-清除算法这是一种最基础的收集算法，这种算法分为两个阶段： 标记出所有需要回收的对象（这里的标记使用可达性分析算法进行判定） 标记完成后统一回收所有被标记的对象 这个算法两个阶段的效率都不高，而且会产生大量的内存碎片，碎片过多可能会导致无法找到连续内存存储较大的对象，所以会被迫提前触发一次GC，图示如下： 由上图可以看到，在回收后，产生了大量不连续的内存单元碎片。单纯从图5看，只能知道这个算法会产生内存碎片，并不能了解整个算法的细节，因此单纯通过上图，是没办法体现该算法效率问题的，图5是大部分资料里都会展示的一个最终态，算法细节则全部省略，导致很多时候，标记-清除算法相比复制算法的效率究竟弱在哪里没有很清晰的认知，下面，通过一幅图来说明下其具体的执行细节： 上图就是标记-清除算法的执行过程，首先从标记阶段到清除阶段，GC执行流程如下： 把从root开始的可能被引用的对象（可达对象）进行一个个的标记，图中的“标记阶段”就是在干这件事，被标记的对象图里已染成绿色。 重复1步骤就可以把所有从root出发的被引用或间接引用的对象全部打上标记 在上述两个过程完成后，标记阶段就算告一段落，接下来就是清除阶段，清除阶段将上述被标记的对象视为“存活对象”，这时会扫描全部对象，将没有被标记的对象清除，同时将有标记的对象的标记去除，方便下次GC使用。 了解完这个算法的执行过程，大致上就知道了为什么这个算法的效率会很低了，如果系统中会创建大量的对象，但只有很少的对象会存活的比较久，这时候该算法的效率在清除阶段的时候，耗时就会很久，因为要整体遍历，而且还要进行大量回收。 3.2：复制算法这种算法将可用内存划分为大小相等的两块，每次只使用其中一块，GC触发时，就将该块内存里还存活着的对象整体复制到另外一块内存上去，然后再把已使用的内存一次性清除掉，下面来展示下回收状态： 同样的，这张图仅用来表现清理过程和最终态，下面，通过图8来说明下这种算法的执行流程： 上图就是复制算法的执行过程： 根据root，找出来所有的可达对象（存活对象），整体复制到新空间里（这个过程类似标记-清除算法里的标记阶段）。 将原来的旧空间里的所有对象整体清除掉（完成复制后，可以认为原来的旧空间里的所有对象都可以回收），下次GC的时候，本次GC意义上的“新空间”就变成了下次GC意义上的“旧空间”，以此类推。 相比标记-清除算法，复制算法虽然内存被一分为二，但是节省了整体遍历所有对象这一步操作，对于那种产生大量对象，但是对象生命周期极短的情况，这个算法相比标记-清除算法效率高了不止一个档次，因为每次仅复制一小批存活的对象，没必要整体遍历所有的对象进行标记判断+清理的操作。所以这种算法适合那种对象多，但大部分对象生命周期短的情况，如果对象多，生命周期长，那么意味着复制算法每次对复制这个动作的开销，是非常大的，这也就解释了，为什么jvm新生代的回收算法采用复制算法，而老年代则不用。 3.3：标记-压缩算法也分为两个阶段： 标记阶段，这个阶段跟标记-清除算法一致，具体流程可以参考图6 压缩阶段，相比标记-清除算法，该算法不再整体遍历所有的对象，而是将带有标记的“存活对象”依次压缩排列，排列完成后，存活对象将紧紧挨在一起，清除时只需要将存活对象边界以外的区域全部清理即可。 过程如图所示： 这里不再画算法的执行流程图，标记步骤参考图6，压缩过程参考图9即可。 这个算法的好处就是不会产生内存碎片，不会大量复制，相比复制算法，内存也不会减半，由于少了一层遍历所有对象的操作，因此一般效率也要比标记-清除算法高。 3.4：分代收集算法目前商业虚拟机的垃圾回收都采用分代收集算法，这种算法基于上述几个基本的垃圾回收算法，通过「分代」的方式分类不同生命周期特征的对象，将不同「代」使用适合的收集算法来实现回收，比如jvm新生代，新生代中的对象特征为生命周期短，每次回收只有少量对象存活，且要求快速，因此适合用复制-收集算法来实现（比如新生代里的Eden区和两个Survivor区，就是为复制算法而拆分出来的），而老年代里的对象因为生命周期长，每次回收大量的对象还处于存活期，如果再使用复制-收集算法来实现，那么复制成本是很高的，因此老年代则适合使用标记-整理算法，这种不使用单一算法，会根据对象的生命周期特征进行算法隔离分区的方式就叫做「分代收集」。","link":"/2019/05/07/JVM%E5%9F%BA%E7%A1%80%E5%9B%9E%E9%A1%BE%E8%AE%B0%E5%BD%95%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86/"},{"title":"Java NIO学习与记录（一）：初识NIO","text":"工作中有些地方间接用到了netty，netty是一个NIO框架，对于NIO却不是那么熟悉，这个系列的文章是我在学习NIO时的一个记录，也期待自己可以更好的掌握NIO。 一、NIO是什么？一组由操作系统提供的底层API，java支持对它们的封装，我们需要做的是利用java来使用它们。非阻塞式IO，与传统的BIO（阻塞式IO）不同，NIO可以通过通道（Channels）来监听各通道的动作，一个线程就可以完成对多个通道的动作监听，这些动作包括连接就绪、写就绪、读就绪等，举个例子，建立连接这个动作在BIO中会发生阻塞，直到连接建立完成，而在NIO中，建连只是单线程里Selector监听的一个动作，也就是说在建立连接之前（即建连就绪之前），这个线程是可以继续处理其他动作的（比如读、写等等）。没有传统IO在IO交互时的阻塞现象，仅通过一个线程来处理n多IO通道（Channels），大大提升了程序的处理能力。 二、NIO核心组成部分2.1：Channels &amp; Buffer这两个放在一起讲，Channel是指各种IO通道（包括File、Socket等），也可以理解为双向IO流，即：Channel既可以将自己的内容读到Buffer中，也可以从Buffer中读取数据写入到自己里面。其次，Channel并不一定是双向的，一个Channel如果实现定义read( )方法的 ReadableByteChannel 接口,而另一个 Channel 类也许实现 WritableByteChannel 接口以提供write( )方法。实现这两种接口其中之一的类都是单向的，只能在单个方向上传输数据。如果一个类同时实现这两个接口,那么它是双向的,可以双向传输数据（读&amp;写）。 结合上面描述，Buffer是一个容器，负责存储从Channel里读到的数据或者存储准备写入Channel的数据，属于一个缓冲区。 常见的Channel： FileChannel：文件通道 DatagramChannel：一个能收发UDP包的通道。因为UDP是无连接的网络协议，所以不能像其它通道那样读取和写入。它发送和接收的是数据包 SocketChannel：一个连接到TCP网络套接字的通道 ServerSocketChannel：一个可以监听新进来的TCP连接的通道 常见的Buffer： ByteBuffer、CharBuffer、DoubleBuffer、FloatBuffer、IntBuffer、LongBuffer、ShortBuffer 可以发现，涵盖了基本传输的数据类型。 2.2：Selector可以理解为“Channel事件选择处理器”，第一部分有提到说NIO属于非阻塞式IO，关键点在于Selector可以运行于一个单线程里，然后通过一个死循环（阻塞方法）来监听注册到选择器内的Channel的事件（注意这里，一个Channel的事件想要被选择器监听到，则要求该Channel必须注册到选择器里），这些事件上面也提到过包含：连接就绪、写就绪、读就绪等。这些动作全部由Channel自己完成，什么时候完成了通知选择器去进行相应的逻辑处理即可，而不必阻塞在IO交互上（也是与传统BIO不同的点），选择器工作如下图： 本篇简单介绍了下NIO，接下来将会介绍具体如何去使用","link":"/2019/03/05/Java%20NIO%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%B0%E5%BD%95%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E5%88%9D%E8%AF%86NIO/"},{"title":"Java NIO学习与记录（七）： Reactor单线程模型的实现","text":"一、Selector&amp;Channel1.1：各种channel写这个模型需要提前了解Selector以及Channel，之前记录过FileChannel，除此之外还有以下几种Channel： ServerSocketChannel：用于监听新的TCP连接的通道，负责读取&amp;响应，通常用于服务端的实现。 SocketChannel：用于发起TCP连接，读写网络中的数据，通常用于客户端的实现。 DatagramChannel：上述两个通道基于TCP传输协议，而这个通道则基于UDP，用于读写网络中的数据。 FileChannel：从文件读取数据。 本篇重点放在ServerSocketChannel和SocketChannel上，大部分客户端/服务端为了保证数据准确性，都是基于TCP传输协议实现的，由于使用Selector注册必须要求被注册的Channel是非阻塞模式的，因此FileChannel由于没有非阻塞模式（无法设置configureBlocking(false)），没办法和注册到selector。 1.2：selectorSelector是个通道注册器（用法会在程序里标注），是实现Reactor模型的关键，多个通道均可以注册到Selector，Selector负责监听每个Channel的几个事件：连接就绪、写就绪、读就绪，当某个channel注册感兴趣就绪事件到selector时，若发生兴趣事件就绪，则Selector.select()方法不再阻塞，返回兴趣事件集合（可能包含多个channel的），然后按照事件不同进行分发处理。 Selector返回对应的就绪事件，封装为SelectionKey，每个Channel对应一个SelectionKey，这个对象还可以通过attach方法附着处理类（Handler、Acceptor等）。 1.3：一个简单的例子先来看个简单使用Selector做处理的服务端实现，可以简单对Selector和SelectionKey的用法做个了解： 123456789101112131415161718192021222324252627282930313233343536373839public static void main(String[] args) throws IOException { Selector selector = Selector.open(); //打开选择器 ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); //打开通道 serverSocketChannel.configureBlocking(false); //设置通道为非阻塞模式 serverSocketChannel.bind(new InetSocketAddress(2333)); //绑定端口 serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); //注册channel到选择器，指定监听该Channel的哪些事件，初始化都是对连接事件监听（因为是入口） while (selector.select() &gt; 0) { // 若收到就绪事件select返回“感兴趣”事件集合，否则阻塞当前线程 Set keys = selector.selectedKeys(); //获取本次拿到的事件集合 Iterator iterator = keys.iterator(); while (iterator.hasNext()) { SelectionKey key = iterator.next(); iterator.remove(); if (key.isAcceptable()) { //当前就绪事件为连接事件 ServerSocketChannel skc = (ServerSocketChannel) key.channel(); //连接就绪触发，说明已经有客户端通道连了过来，这里需要拿服务端通道去获取客户端通道 SocketChannel socketChannel = skc.accept(); //获取客户端通道（连接就绪，说明客户端接下来可能还有别的动作，比如读和写） socketChannel.configureBlocking(false); //同样的需要设置非阻塞模式 System.out.println(String.format(\"收到来自 %s 的连接\", socketChannel.getRemoteAddress())); socketChannel.register(selector, SelectionKey.OP_READ); //将该客户端注册到选择器，感兴趣事件设置为读（客户端连接完毕，很肯能会往服务端写数据，因此这里要注册读事件用以接收这些数据） } else if (key.isReadable()) { //当前事件为读就绪 SocketChannel socketChannel = (SocketChannel) key.channel(); //能触发读就绪，说明客户端已经开始往服务端写数据，通过SelectionKey拿到当前客户端通道 ByteBuffer buffer = ByteBuffer.allocate(1024); int count = socketChannel.read(buffer); //从通道读入数据 if (count &lt; 0) { //若本次读就绪拿到-1，则认为客户端主动断开了连接 socketChannel.close(); //服务端关闭客户端通道 key.cancel(); //断连后就将该事件从选择器的SelectionKey集合中移除（这里说一下，这里不是真正意义上的移除，这里是取消，会将该key放入取消队列里，在下次select函数调用时才负责清空） System.out.println(\"连接关闭\"); continue; } System.out.println(String.format(\"收到来自 %s 的消息: %s\", socketChannel.getRemoteAddress(), new String(buffer.array()))); } keys.remove(key); } } } 代码块1 上面是一个简单的例子，接下来，就利用选择器、通道来实现Reactor单线程模型。 二、单Reactor单线程模型的服务端实现实现服务端，服务端负责接收客户端的连接，接收客户端的请求数据以及响应客户端。 把上一篇的结构图再拿过来展示下，看看需要做的有哪些模块： 通过上图，我们需要实现的模块有Reactor、Acceptor、Handler，下面来逐个编写： 2.1：Reactor核心模块该模块内部包含两个核心方法，select和dispatch，该模块负责监听就绪事件和对事件的分发处理： 123456789101112131415161718192021222324252627282930313233343536373839404142public class Reactor implements Runnable { private final Selector selector; private final ServerSocketChannel serverSocketChannel; public Reactor(int port) throws IOException { //Reactor初始化 selector = Selector.open(); //打开一个Selector serverSocketChannel = ServerSocketChannel.open(); //建立一个Server端通道 serverSocketChannel.socket().bind(new InetSocketAddress(port)); //绑定服务端口 serverSocketChannel.configureBlocking(false); //selector模式下，所有通道必须是非阻塞的 //Reactor是入口，最初给一个channel注册上去的事件都是accept SelectionKey sk = serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); //attach callback object, Acceptor sk.attach(new Acceptor(serverSocketChannel, selector)); } @Override public void run() { try { while (!Thread.interrupted()) { selector.select(); //就绪事件到达之前，阻塞 Set selected = selector.selectedKeys(); //拿到本次select获取的就绪事件 Iterator it = selected.iterator(); while (it.hasNext()) { //这里进行任务分发 dispatch((SelectionKey) (it.next())); } selected.clear(); } } catch (IOException e) { e.printStackTrace(); } } void dispatch(SelectionKey k) { Runnable r = (Runnable) (k.attachment()); //这里很关键，拿到每次selectKey里面附带的处理对象，然后调用其run，这个对象在具体的Handler里会进行创建，初始化的附带对象为Acceptor（看上面构造器） //调用之前注册的callback对象 if (r != null) { r.run(); } }} 代码块2 细节已标注。 2.2：实现Acceptor模块这个模块只负责处理连接就绪事件，有了这个事件就可以拿到客户单的SocketChannel，就可以继续完成接下来的读写任务了： 1234567891011121314151617181920212223242526public class Acceptor implements Runnable { private final Selector selector; private final ServerSocketChannel serverSocketChannel; Acceptor(ServerSocketChannel serverSocketChannel, Selector selector) { this.serverSocketChannel = serverSocketChannel; this.selector = selector; } @Override public void run() { SocketChannel socketChannel; try { socketChannel = serverSocketChannel.accept(); if (socketChannel != null) { System.out.println(String.format(\"收到来自 %s 的连接\", socketChannel.getRemoteAddress())); new Handler(socketChannel, selector); //这里把客户端通道传给Handler，Handler负责接下来的事件处理（除了连接事件以外的事件均可） } } catch (IOException e) { e.printStackTrace(); } }} 代码块3 细节已标注。 2.3：Handler模块的实现这个模块负责接下来的读写操作： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788public class Handler implements Runnable { private final SelectionKey selectionKey; private final SocketChannel socketChannel; private ByteBuffer readBuffer = ByteBuffer.allocate(1024); private ByteBuffer sendBuffer = ByteBuffer.allocate(2048); private final static int READ = 0; private final static int SEND = 1; private int status = READ; Handler(SocketChannel socketChannel, Selector selector) throws IOException { this.socketChannel = socketChannel; //接收客户端连接 this.socketChannel.configureBlocking(false); //置为非阻塞模式（selector仅允非阻塞模式） selectionKey = socketChannel.register(selector, 0); //将该客户端注册到selector，得到一个SelectionKey，以后的select到的就绪动作全都是由该对象进行封装 selectionKey.attach(this); //附加处理对象，当前是Handler对象，run是对象处理业务的方法 selectionKey.interestOps(SelectionKey.OP_READ); //走到这里，说明之前Acceptor里的建连已完成，那么接下来就是读取动作，因此这里首先将读事件标记为“感兴趣”事件 selector.wakeup(); //唤起select阻塞 } @Override public void run() { try { switch (status) { case READ: read(); break; case SEND: send(); break; default: } } catch (IOException e) { //这里的异常处理是做了汇总，常出的异常就是server端还有未读/写完的客户端消息，客户端就主动断开连接，这种情况下是不会触发返回-1的，这样下面read和write方法里的cancel和close就都无法触发，这样会导致死循环异常（read/write处理失败，事件又未被cancel，因此会不断的被select到，不断的报异常） System.err.println(\"read或send时发生异常！异常信息：\" + e.getMessage()); selectionKey.cancel(); try { socketChannel.close(); } catch (IOException e2) { System.err.println(\"关闭通道时发生异常！异常信息：\" + e2.getMessage()); e2.printStackTrace(); } } } private void read() throws IOException { if (selectionKey.isValid()) { readBuffer.clear(); int count = socketChannel.read(readBuffer); //read方法结束，意味着本次\"读就绪\"变为\"读完毕\"，标记着一次就绪事件的结束 if (count &gt; 0) { System.out.println(String.format(\"收到来自 %s 的消息: %s\", socketChannel.getRemoteAddress(), new String(readBuffer.array()))); status = SEND; selectionKey.interestOps(SelectionKey.OP_WRITE); //注册写方法 } else { //读模式下拿到的值是-1，说明客户端已经断开连接，那么将对应的selectKey从selector里清除，否则下次还会select到，因为断开连接意味着读就绪不会变成读完毕，也不cancel，下次select会不停收到该事件 //所以在这种场景下，（服务器程序）你需要关闭socketChannel并且取消key，最好是退出当前函数。注意，这个时候服务端要是继续使用该socketChannel进行读操作的话，就会抛出“远程主机强迫关闭一个现有的连接”的IO异常。 selectionKey.cancel(); socketChannel.close(); System.out.println(\"read时-------连接关闭\"); } } } void send() throws IOException { if (selectionKey.isValid()) { sendBuffer.clear(); sendBuffer.put(String.format(\"我收到来自%s的信息辣：%s, 200ok;\", socketChannel.getRemoteAddress(), new String(readBuffer.array())).getBytes()); sendBuffer.flip(); int count = socketChannel.write(sendBuffer); //write方法结束，意味着本次写就绪变为写完毕，标记着一次事件的结束 if (count &lt; 0) { //同上，write场景下，取到-1，也意味着客户端断开连接 selectionKey.cancel(); socketChannel.close(); System.out.println(\"send时-------连接关闭\"); } //没断开连接，则再次切换到读 status = READ; selectionKey.interestOps(SelectionKey.OP_READ); } }} 代码块4 细节已标注。 关键模块已实现，下面来启动服务端： 1new Thread(new Reactor(2333)).start(); 代码块5 三、客户端的编写接下来同样利用selector编写客户端，客户端需要做的事情就是发送消息到服务端，等待服务端响应，然后再次发送消息，发够10条消息断开连接： 3.1：Client入口模块1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class NIOClient implements Runnable { private Selector selector; private SocketChannel socketChannel; NIOClient(String ip, int port) { try { selector = Selector.open(); //打开一个Selector socketChannel = SocketChannel.open(); socketChannel.configureBlocking(false); //设置为非阻塞模式 socketChannel.connect(new InetSocketAddress(ip, port)); //连接服务 //入口，最初给一个客户端channel注册上去的事件都是连接事件 SelectionKey sk = socketChannel.register(selector, SelectionKey.OP_CONNECT); //附加处理类，第一次初始化放的是连接就绪处理类 sk.attach(new Connector(socketChannel, selector)); } catch (IOException e) { e.printStackTrace(); } } @Override public void run() { try { while (!Thread.interrupted()) { selector.select(); //就绪事件到达之前，阻塞 Set selected = selector.selectedKeys(); //拿到本次select获取的就绪事件 Iterator it = selected.iterator(); while (it.hasNext()) { //这里进行任务分发 dispatch((SelectionKey) (it.next())); } selected.clear(); } } catch (IOException e) { e.printStackTrace(); } } void dispatch(SelectionKey k) { Runnable r = (Runnable) (k.attachment()); //这里很关键，拿到每次selectKey里面附带的处理对象，然后调用其run，这个对象在具体的Handler里会进行创建，初始化的附带对象为Connector（看上面构造器） //调用之前注册的callback对象 if (r != null) { r.run(); } }} 代码块6 细节已标注。 3.2：Connector模块（建连）123456789101112131415161718192021222324public class Connector implements Runnable { private final Selector selector; private final SocketChannel socketChannel; Connector(SocketChannel socketChannel, Selector selector) { this.socketChannel = socketChannel; this.selector = selector; } @Override public void run() { try { if (socketChannel.finishConnect()) { //这里连接完成（与服务端的三次握手完成） System.out.println(String.format(\"已完成 %s 的连接\", socketChannel.getRemoteAddress())); new Handler(socketChannel, selector); //连接建立完成后，接下来的动作交给Handler去处理（读写等） } } catch (IOException e) { e.printStackTrace(); } }} 代码块7 细节已标注。 3.3：客户端Handler模块实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public class Handler implements Runnable { private final SelectionKey selectionKey; private final SocketChannel socketChannel; private ByteBuffer readBuffer = ByteBuffer.allocate(2048); private ByteBuffer sendBuffer = ByteBuffer.allocate(1024); private final static int READ = 0; private final static int SEND = 1; private int status = SEND; //与服务端不同，默认最开始是发送数据 private AtomicInteger counter = new AtomicInteger(); Handler(SocketChannel socketChannel, Selector selector) throws IOException { this.socketChannel = socketChannel; //接收客户端连接 this.socketChannel.configureBlocking(false); //置为非阻塞模式（selector仅允非阻塞模式） selectionKey = socketChannel.register(selector, 0); //将该客户端注册到selector，得到一个SelectionKey，以后的select到的就绪动作全都是由该对象进行封装 selectionKey.attach(this); //附加处理对象，当前是Handler对象，run是对象处理业务的方法 selectionKey.interestOps(SelectionKey.OP_WRITE); //走到这里，说明之前Connect已完成，那么接下来就是发送数据，因此这里首先将写事件标记为“感兴趣”事件 selector.wakeup(); //唤起select阻塞 } @Override public void run() { try { switch (status) { case SEND: send(); break; case READ: read(); break; default: } } catch (IOException e) { //这里的异常处理是做了汇总，同样的，客户端也面临着正在与服务端进行写/读数据时，突然因为网络等原因，服务端直接断掉连接，这个时候客户端需要关闭自己并退出程序 System.err.println(\"send或read时发生异常！异常信息：\" + e.getMessage()); selectionKey.cancel(); try { socketChannel.close(); } catch (IOException e2) { System.err.println(\"关闭通道时发生异常！异常信息：\" + e2.getMessage()); e2.printStackTrace(); } } } void send() throws IOException { if (selectionKey.isValid()) { sendBuffer.clear(); int count = counter.incrementAndGet(); if (count &lt;= 10) { sendBuffer.put(String.format(\"客户端发送的第%s条消息\", count).getBytes()); sendBuffer.flip(); //切换到读模式，用于让通道读到buffer里的数据 socketChannel.write(sendBuffer); //则再次切换到读，用以接收服务端的响应 status = READ; selectionKey.interestOps(SelectionKey.OP_READ); } else { selectionKey.cancel(); socketChannel.close(); } } } private void read() throws IOException { if (selectionKey.isValid()) { readBuffer.clear(); //切换成buffer的写模式，用于让通道将自己的内容写入到buffer里 socketChannel.read(readBuffer); System.out.println(String.format(\"收到来自服务端的消息: %s\", new String(readBuffer.array()))); //收到服务端的响应后，再继续往服务端发送数据 status = SEND; selectionKey.interestOps(SelectionKey.OP_WRITE); //注册写事件 } }} 代码块8 细节已标注。 下面启动客户端去连接之前的服务端： 12new Thread(new NIOClient(\"127.0.0.1\", 2333)).start();new Thread(new NIOClient(\"127.0.0.1\", 2333)).start(); 代码块9 上面模拟了两个客户端同时连到服务端，运行结果如下： 单线程Reactor模型有个致命的缺点，通过上述例子可以看出，整个执行流程都是线性的，客户端请求→服务端读取→服务端响应→客户端收到响应→客户端再次发送请求，那么在这个链路中，如果handler中某个位置存在性能瓶颈，比如我们可以改造下服务端的send方法： 1234567try { Thread.sleep(2000L); //响应2s} catch (InterruptedException e) { e.printStackTrace();}int count = socketChannel.write(sendBuffer); 代码块10 在响应客户端之前睡眠2s，当做是性能瓶颈点，同样的再次开两个客户端同时访问服务端，每个客户端发送10条消息，会发现，程序直接运行了40s，这是大多数情况下不愿意看到的，因此，就有了多线程Reactor模式，跟BIO为了提高性能将读操作放到一个独立线程处理一样，Reactor这样做，也是为了解决上面提到的性能问题，只不过NIO比BIO做异步有个最大的优势就是NIO不会阻塞一个线程，类似read这种操作状态都是由selector负责监听的，不像BIO里都是阻塞的，只要被异步出去，那么一定是非阻塞的业务代码（除非是人为将代码搞成阻塞），而BIO由于read本身阻塞，因此会阻塞掉整个业务线程，这也是同样是异步为什么NIO可以更加高效的原因之一。 那么单线程Reactor适用于什么情况呢？适用于那种程序复杂度很低的系统，例如redis，其大部分操作都是非常高效的，很多命令的时间复杂度直接为O(1)，这种情况下适合这种简单的Reactor模型实现服务端。","link":"/2019/03/27/Java%20NIO%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%B0%E5%BD%95%EF%BC%88%E4%B8%83%EF%BC%89%EF%BC%9A%20Reactor%E5%8D%95%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AE%9E%E7%8E%B0/"},{"title":"Java NIO学习与记录（三）： Scatter&Gather介绍及使用","text":"上一篇知道了Buffer的工作机制，以及FileChannel的简单用法，这一篇介绍下Scatter&amp;Gather 1.Scatter（分散）用于描述在Channel中读取的数据分散在不同的Buffer里。 接着上一篇的例子（rua文件内容为123456789），改造下代码： 1234567891011121314151617181920212223readFile = new RandomAccessFile(\"D:\\\\rua.txt\", \"r\");FileChannel readChannel = readFile.getChannel();ByteBuffer first = ByteBuffer.allocate(2); //第一块bufferByteBuffer second = ByteBuffer.allocate(2); //第二块bufferByteBuffer[] byteBuffers = {first, second};long bytesRead = readChannel.read(byteBuffers); //从通道里读取数据到Buffer内（最大不超过Buffer容积）while (bytesRead != -1) { //当读不到任何东西时返回-1 System.out.println(\"\\nheader里的数据------此时byteRead=\" + bytesRead); first.flip(); //切换到Buffer读模式，读模式下可以读取到之前写入Buffer的数据 while (first.hasRemaining()) { System.out.print(\"-\" + (char) first.get()); //第一块Buffer读出的数据用减号分割，用于跟第二块区分 } first.clear(); System.out.println(\"\\nbody里的数据------此时byteRead=\" + bytesRead); second.flip(); while (second.hasRemaining()) { System.out.print(\"+\" + (char) second.get()); //第二块Buffer读出的数据用加号分割，用于跟第一块区分 } second.clear(); // 切换回Buffer的写模式 System.out.println(\"\\n----------------------------------------------\"); bytesRead = readChannel.read(byteBuffers); //跟上面一样，再次从通道读取数据到Buffer中}System.out.print(\"\\n-----------程序结束\"); 代码块1 上面的代码开了两个Buffer，然后传给了Channel.read一个Buffer数组，运行结果如下： 12345678910111213141516171819header里的数据------此时byteRead=4-1-2body里的数据------此时byteRead=4+3+4----------------------------------------------header里的数据------此时byteRead=4-5-6body里的数据------此时byteRead=4+7+8----------------------------------------------header里的数据------此时byteRead=1-9body里的数据------此时byteRead=1---------------------------------------------------------程序结束 可以看到，文件里的内容被分段加载出来了，first buffer里首选读取一段，然后接着second buffer再接着读取接下来的一段。上面例子符合Scatter的描述。 看过网上一些文章，说的最多的例子就是协议头数据体分开处理的例子： 假设通过Channel获取到的数据存在固定长度的协议头，以及已知最大长度限制的数据体，就可以通过两个Buffer来接收，一个是header buffer，一个是body buffer， 但这个对数据要求很严苛，结合上面的例子，不难发现，想要做到准确无误的处理这个例子，就得要求事先必须知道header的长度，以及数据体的最大长度上限，为什么要这样呢？因为如果不知道header的长度，那么header buffer就可能会读到body buffer里的东西或者body buffer里读到header buffer里的东西，如果不知道body的上限长度，那么如果body数据长度超过了body buffer的长度，body里的数据就会再次读到header buffer中去（这个可以结合上面的例子理解）。 2.Gather（聚集）用于描述在将不同Buffer里的数据写到同一个Channel中去。 来看个例子： 1234567891011readFile = new RandomAccessFile(\"D:\\\\haha.txt\", \"rw\");FileChannel channel = readFile.getChannel();ByteBuffer first = ByteBuffer.allocate(5); //第一块bufferByteBuffer second = ByteBuffer.allocate(5); //第二块bufferfirst.put(\"aa\".getBytes());second.put(\"bb\".getBytes());first.flip();second.flip();ByteBuffer[] byteBuffers = {first, second};channel.write(byteBuffers);System.out.print(\"\\n-----------程序结束\"); 代码块2 运行结束后，haha.txt里的内容为： 1aabb 可以看到，最终写入的数据就是按照顺序把两个buffer里的内容传输进去了。 同样的，还是以网上的协议头数据体的例子说事儿，这个跟Scatter下的传输方式比较起来就不会那么严格了，看到上面，初始容积为5个字节，但实际写到文件里的每个buffer仍然是两个字节，因为Gather模式下，Channel读取Buffer数据的时候，只会读取position到limit间的数据（可读区域），因此这里不用像多Buffer读一样要求那么严格，我们可以随意定义header buffer的长度，只要大于协议头本身长度即可，body buffer的要求其实是同上，也是大于数据体的长度上限即可。 这就是Scatter和Gather的全部内容了~其实简单理解，就是多Buffer操作，以及对网上那个例子，进行了更详细一点的说明。","link":"/2019/03/07/Java%20NIO%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%B0%E5%BD%95%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9A%20Scatter&Gather%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BD%BF%E7%94%A8/"},{"title":"Java NIO学习与记录（二）：FileChannel与Buffer用法与说明","text":"上一篇简单介绍了NIO，这一篇将介绍FileChannel结合Buffer的用法，主要介绍Buffer 一、FileChannel例子上一篇说到，这个Channel属于文件通道，专门读取文件信息，NIO读取文件内容的简单的例子： 123456789101112131415161718192021222324252627public static void readFile() { RandomAccessFile file = null; try { file = new RandomAccessFile(\"D:\\\\rua.txt\", \"rw\"); FileChannel fileChannel = file.getChannel(); //获取文件通道 ByteBuffer buf = ByteBuffer.allocate(2); //分配容积为2字节的一块Buffer，用来读取数据 int bytesRead = fileChannel.read(buf); //从通道里读取数据到Buffer内（最大不超过Buffer容积） while (bytesRead != -1) { //当读不到任何东西时返回-1 buf.flip(); //切换到Buffer读模式，读模式下可以读取到之前写入Buffer的数据 while (buf.hasRemaining()) { //循环输出Buffer中的数据 System.out.print((char) buf.get()); } buf.compact(); //或者调用clear，切换回Buffer的写模式 bytesRead = fileChannel.read(buf); //跟上面一样，再次从通道读取数据到Buffer中 } } catch (IOException e) { e.printStackTrace(); } finally { try { if (file != null) { file.close(); } } catch (IOException e) { e.printStackTrace(); } } } 代码块1 rua.txt文件内容为：123456789 上述代码运行后输出如下： 1123456789 文件正常读取，可以结合上面的注释，来分析下过程，接下来要利用上面的例子介绍Buffer的一些概念。 二、Buffer的概念2.1：Buffer操作的步骤第一篇说过，Buffer是一个缓冲区，是一个容器，负责从通道读取数据或者写数据给通道，通过上面的例子，我们可以看到Buffer在读取通道数据时的几个步骤： step1：分配空间 1ByteBuffer.allocate(1024); //除此之外，还可以通过allocateDirector分配空间（具体不了解，先放一边，回头补） 代码块2 step2：从通道读取数据，写入Buffer 1int bytesRead = fileChannel.read(buf); 代码块3 step3：读取Buffer内的内容，切换回Buffer读模式 1buf.flip(); //切换到Buffer读模式，读模式下可以读取到之前写入Buffer的数据 代码块4 step4：循环执行读写操作，每取完一次Buffer中的值，都切换回写模式，再次从通道读取数据到Buffer 12345678while (bytesRead != -1) { //当读不到任何东西时返回-1 buf.flip(); //切换到Buffer读模式，读模式下可以读取到之前写入Buffer的数据 while (buf.hasRemaining()) { //循环输出Buffer中的数据 System.out.print((char) buf.get()); } buf.compact(); //或者调用clear，切换回Buffer的写模式 bytesRead = fileChannel.read(buf); //跟上面一样，再次从通道读取数据到Buffer中} 代码块5 2.2：Buffer读写流程详解2.2.1：重要属性的介绍Buffer具备的几个重要概念： capacity：缓冲区数组的总长度（容积） position：下一个需要操作的数据元素的位置 limit：缓冲区不可操作的下一个元素的位置，limit &lt;= capacity mark：用于记录position的前一个位置或默认是-1 2.2.2：Buffer内部的操作流程结合上面的概念，除了mark（再往下介绍），其余几个指标的操作变化如下图： 初始化一个容积为10的Buffer，初识位置limit = capacity，position位于第一个位置 当容器内写入了5个数据元素之后，position的位置变到了第6个位置，标记当前写入到哪里了 这时候不再写入数据了，开始切换回Buffer的读模式（flip），发生的变化如下： 发现，原先读模式下的position的位置被limit替换掉了，而position被重置为了第一个位置，这是因为现在读模式下想要读取之前写入的内容，为了保证读取的数据都是可读的（之前写入的），就需要有一个标记，来记录之前写模式下，操作到哪里了，position被重置为第一个位置，也很容易理解，因为切换了读模式，从头开始读取已写入的数据。 通过上面的描述，我们清楚了buffer是如何利用position、limit、capacity来完成读写操作的，下面我们来介绍下具体读写操作时Bufer发生的操作： Buffer切换读模式的方法有：flip Buffer切换写模式的方法有：clear、compact Buffer读数据：get 使用clear切换回写模式的时候，position会被置为0（也就是最初的位置），limit置为capacity（也就是最后的位置），意味着切换写模式之前未读的数据，将会被新一轮的写入覆盖，就再也找不回来了，所以除clear这个操作，Buffer还提供了compact方法来切换读模式，这个方法会把所有未读的数据拷贝到Buffer的起始位置，然后position指向最后一个未读数据的后一位，这样，下次开启读模式的时候，position操作同上，置为0，因此之前未读完被落下的数据也就在这时候被读到了。 下面我们来还原下这个转换过程： 走到上面的步骤后，我们切换成写模式，下面这个图分别表示了clear和compact两个方法下的两种操作： 根据图4和图5，结合上面的话，更容易理解clear和compact两种方式切换写模式所做的内部操作，以及为什么clear会丢数据，而compact不会。 下面通过一开始的例子，把中间读取数据的地方稍微做下修改： 12345678910ByteBuffer buf = ByteBuffer.allocate(2);int bytesRead = readChannel.read(buf);while (bytesRead != -1) { buf.flip(); char result = (char) buf.get(); //虽然读进来了2个字节，但这里只取一个 System.out.print(result); buf.clear(); // 使用clear切换回Buffer的写模式 bytesRead = readChannel.read(buf);}System.out.println(\"-----------程序结束\"); 代码块6 输出结果： 113579-----------程序结束 发现丢了一些数据，现在把clear改成compact，运行结果为： 112345678-----------程序结束 发现，除了9，都输出来了（至于9为啥没输出，因为每次只取了一个字节的数据呀~） 那么，如果切换到读模式，但是不读，然后切换回写模式继续写，会发生什么？ 改造上述代码如下： 12345678ByteBuffer buf = ByteBuffer.allocate(2);int bytesRead = readChannel.read(buf);while (bytesRead != -1) { buf.flip(); buf.clear(); // 不读，立刻切回写模式 bytesRead = readChannel.read(buf);}System.out.println(\"-----------程序结束\"); 代码块7 调用clear的情况下输出： 1-----------程序结束 而调用compact方法，却发生阻塞(死循环)了，结合之前的图，我们可以知道，如果不读，意味着在compact下会把未读的数据copy到Buffer里，如果一点都不读，那么意味着被copy的这批数据会占满整个Buffer，以至于position没有下一个位置可用，就会发生文件里的数据没办法被安排进缓冲区（意味着文件读不完），bytesRead一直不等于-1，发生死循环。 通过上面的图和例子，基本上可以理清楚读模式、写模式（包含不同的切换方式）下的Buffer内部处理方式。 2.3：Buffer的其他操作除了上面几种常规用法，Buffer还提供了其他的几个操作方法 2.3.1：rewind这个方法可以在读模式下，重置position的位置，也就是说在get执行后。position发生了位移，这个方法可以重置position的位置为初始位置，看例子： 12345678910ByteBuffer buf = ByteBuffer.allocate(2); //每次可读入两个字节int bytesRead = readChannel.read(buf);while (bytesRead != -1) { buf.flip(); System.out.print((char) buf.get()); buf.rewind(); //重置position System.out.print((char) buf.get());//这时候读到的数据跟上面是同一个 buf.clear(); bytesRead = readChannel.read(buf); } 代码块8 运行结果： 11133557799 可以看到，每次循环拿到两个字节，但两次获取的数据都是同一个，因为rewind把读取游标重置成初始位置了（也即是位置0） ⭐️ 这里说下，如果把上面的第二个get方法去掉，然后把clear模式改成compact模式同样也会发生死循环，因为rewind重置了游标，重置后又没有get方法再次读取，导致把本次的两个字节又复制进了Buffer，跟之前说的不读一样，会导致Buffer没有多余的空间放文件里的数据，导致一直读不完，发生死循环。 2.3.2：mark &amp; reset这两个方法放到一起说，因为mark跟reset不放在一起使用，没有任何意义。 mark：用于标记当前position的位置 reset：用于恢复被mark标记的position的位置 例子： 1234567891011ByteBuffer buf = ByteBuffer.allocate(2);int bytesRead = readChannel.read(buf);while (bytesRead != -1) { buf.flip(); buf.mark(); //标记当前位置，这里也就是初始位置 System.out.print((char) buf.get()); //读取到了初识位置数据 buf.reset(); //重置position到mark标记时那个值 System.out.print((char) buf.get()); //这里由于被reset了，因此输出的还是初识位置的数据 buf.clear(); bytesRead = readChannel.read(buf);} 代码块9 输出结果： 11133557799 会发现，上下两个打印都是是一样的数据。嘛，还是跟上面一样，再回顾一下，这里如果用compact会怎么操作？如果使用compact会打印如下语句： 11122334455667788 这个现在也很好理解了，因为重置了位置所以每个数据被打印了两次，由于mark的原因，每次实际上相当于只读了一个数据，所以剩下的一个数据被顺延到下次循环里打印，以此类推。 2.3.3：equals &amp; compareTo equals：用来比较两个Buffer是否相等，判等条件为 类型相同（byte、char等） 剩余元素个数相等 剩余元素相同 compareTo：比较两个Buffer中剩余元素的大小，如果满足如下条件，则认为buffer1小于buffer2： buffer1中第一个与buffer2不相等的元素小于buffer2的那个元素 所有元素相同，但是buffer1先比buffer2耗尽 三、实例：边读边写例子：将rua.txt里的内容在读的同时写入文件haha.txt里 12345678910111213readFile = new RandomAccessFile(\"D:\\\\rua.txt\", \"r\");writeFile = new RandomAccessFile(\"D:\\\\haha.txt\", \"rw\");FileChannel readChannel = readFile.getChannel(); //获取只读文件通道FileChannel writeChannel = writeFile.getChannel(); //获取写文件通道ByteBuffer readBuf = ByteBuffer.allocate(2); //分配容积为2字节的一块Buffer，用来读取数据int bytesRead = readChannel.read(readBuf); //从通道里读取数据到Buffer内（最大不超过Buffer容积）while (bytesRead != -1) { //当读不到任何东西时返回-1 readBuf.flip(); //切换到Buffer读模式，读模式下可以读取到之前写入Buffer的数据 writeChannel.write(readBuf); //将现在的buffer里的数据写到文件haha.txt里 readBuf.compact(); // 切换回Buffer的写模式 bytesRead = readChannel.read(readBuf); //跟上面一样，再次从通道读取数据到Buffer中} 代码块10 结果haha.txt里的内容为：123456789 四、Buffer的分类 类别 解释 ByteBuffer 支持存放字节类型数据，抽象类，有DirectByteBuffer、HeapByteBuffer、MappedByteBuffer两个子类，下面进行说明 CharBuffer 支持存放char类型数据 DoubleBuffer 支持存放double类型数据 FloatBuffer 支持存放float类型数据 IntBuffer 支持存放int类型数据 LongBuffer 支持存放long类型数据 ShortBuffer 支持存放short类型数据 表1 通过上表可以看到，Buffer有很多实现，其中大部分都对应一种基本类型，ByteBuffer比较特殊，下面介绍下它的两个子类。 ByteBuffer—-&gt;HeapByteBuffer 直接通过byte数组实现的在java堆上的缓冲区。 ByteBuffer—-&gt;DirectByteBuffer 直接在java堆外申请的一块内存，将文件映射到该内存空间，在大文件读写方面的效率非常高。 ByteBuffer—–&gt;MappedByteBuffer 同样写效率非常高。 关于这几个Buffer后续会专门整理一篇文章来写。","link":"/2019/03/05/Java%20NIO%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%B0%E5%BD%95%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9AFileChannel%E4%B8%8EBuffer%E7%94%A8%E6%B3%95%E4%B8%8E%E8%AF%B4%E6%98%8E/"},{"title":"Java NIO学习与记录（五）： 操作系统的I/O模型","text":"在开始介绍NIO Reactor模式之前，先来介绍下操作系统的五种I/O模型，了解了这些模型，对理解java nio会有不小的帮助。 前言：一次网络请求的流程先来看下一个服务端处理一次网络请求的流程图： 一、图1解析1.1：内核空间&amp;用户空间内核空间：指操作系统运行时用于程序调度、虚拟内存的使用或者连接硬件资源的程序逻辑。 用户空间：应用程序能够申请使用的空间。 操作系统采用虚拟存储器，操作系统核心是内核（Kernel），独立于普通应用程序，它既可以访问受保护的内存空间，又有访问底层硬件设备的所有权限，为了保证内核安全，使得用户进程不直接操作内核，因此操作系统将虚拟存储器分为两个部分：内核空间&amp;用户空间 1.2：网络请求流程根据图1，客户端发起一个请求到服务端，请求首先到达的是服务端网卡（步骤1），然后将请求数据copy到内核空间的内核缓冲区内（步骤2），到这一步，我们说一个数据报已经准备好了。 用户空间里的web服务进程（我们真正的业务程序）发起读取内核缓冲区里的数据，若内核缓冲区准备好了数据报，则会将数据报由内核缓冲区copy到用户空间的web服务进程内（步骤3），然后拿着这些数据进行逻辑处理（步骤4），然后将处理结果copy到内和缓冲区（步骤5），然后内核缓冲区将该数据copy到网卡（步骤6），然后远程传输给客户端（步骤7），这就完成了一次网络请求-响应处理。 这里需要指出步骤3下面这一步，这一步没有计入步骤，但这一步恰好是理解I/O是否发生阻塞的关键，下面介绍阻塞/非阻塞IO时会详细讲。 1.3：套接字(socket)&amp;文件描述符(fd)TCP用主机的IP地址加上主机上的端口号作为TCP连接的端点，这种端点就叫做套接字（socket），套接字提供了很多供应用程序使用的API，比如accept、read、write等。 文件描述符(fd)，Unix/Linux系统下，其作为一个socket的句柄，可以看做是一个文件，在socket上收发数据，相当于对一个文件进行读写，所以一个socket句柄，通常也用表示文件句柄的fd来表示。 二、I/O模型2.1：阻塞&amp;非阻塞调用阻塞与非阻塞的概念是针对调用方（一般指我们的业务程序，如图1中的web服务器进程）来说的。 阻塞调用：图1中步骤1、2执行期间，没有数据到达内核缓冲区，这个时候web服务器进程发起的获取数据的请求会被直接阻塞，当前相关线程会被挂起，直到步骤1、2完成，有数据写入内核缓冲区，这个时候才会唤醒线程执行步骤3和4. 非阻塞调用：与阻塞调用相反，当没有数据到达内核缓冲区时，web服务发起的获取数据的请求不会发生阻塞，相关线程可以选择做其他事情，然后轮询着查询请求结果即可，当某次轮询出结果，则进行步骤3和4的操作。 2.2：同步&amp;异步处理同步与异步的概念是针对被调用方（一般是指内核空间里的IO处理，如图1中的步骤1和2）来说的（一定要区分和理解阻塞/非阻塞、同步/异步这两个概念）。 同步处理：被调用方得到最终处理结果才返回给调用方。 异步处理：被调用方不用得到结果，只需返回一个状态给调用方，然后开始IO处理，处理完了就主动返回通知调用方。 2.3：数据输入的两个阶段一个网络输入流程包含下面两个阶段： 数据准备（步骤1、2）。 将准备好的数据从内核空间复制到用户空间（步骤3）。 2.4：阻塞IO模型我们从图1的步骤3下面的那次请求开始画图，阻塞式I/O模型处理流程如下： 从上图可以看出，阻塞IO模型是指从应用程序发起从socket获取数据（recvfrom）那一刻起，如果内核里没有准备好的数据报，则直接阻塞应用程序，导致应用程序无法去做别的任何事情，直到数据报准备好，被阻塞的程序才会被唤醒，继续处理下面拿到的数据报。 阻塞IO模型只允许一个线程处理一个连接请求，因此当并发量大的时候，会创建大量线程，线程切换开销很大，导致程序处理性能低下。具体参考BIO模式的服务端实现：SocketChannel与BIO服务器 2.5：非阻塞IO模型同样从应用程序发起获取数据的地方开始画图，非阻塞式I/O模型处理流程如下： 从上图可以看出，非阻塞模式也是相对于调用者的，调用者在发送获取数据的请求时会将对应套接口设置为非阻塞，这样在数据报还未准备好的时候，应用程序就不会被阻塞了，然后应用程序再通过轮询的方式进行询问数据报是否已经准备好，当准备好后停止轮询，接下来的逻辑跟阻塞IO一致。对比可以发现，阻塞与非阻塞都是以调用方的角度看的，而且阻塞与否全在第一个阶段，第二个阶段都是一致的。非阻塞IO虽然不会阻塞应用程序，但是因为需要长时间的轮询，对于CPU来说，将会进行大量无意义的切换，资源利用率较低。 2.6：非阻塞IO-多路复用模型2.6.1：模型介绍IO多路复用模型处理流程如下： 从上图可以看出，IO多路复用，其实是找了个代理select，帮助监听多个IO通道的状态，某个通道有新状态产生，才触发recvfrom操作，没有新的状态产生，则select会阻塞。注意这里的阻塞，与阻塞IO模型里的不同，阻塞IO模型是指一个IO操作发生的阻塞行为，而这里select可以同时阻塞多个IO通道，也就是说select可能会监听到一个以上的IO通道的状态，直到有数据可读、可写时，才真正触发IO操作的函数。 🌿 多路复用 图4里的多路复用是说利用某个IO函数（这里是指select）同时监听多个IO通道的状态变更，这样应用程序就可以通过一个函数同时监听多个通道的就绪状态（如连接就绪、读就绪），多路复用跟后面要讲的NIO不是同一个概念，它只是一种处理模型，而NIO是一组API，它提供的select函数恰好可以实现这种数据处理模型。 另外一种多路复用是指基于传输层协议（如TCP）的特性来实现的数据流传输方式，根据TCP特性，同一个TCP连接可以同时传输多条数据和接收多条数据，而实现这种多路复用的方式取决于应用层协议（全双工通信的应用层协议，比如HTTP2）。多路是指多个数据流，复用是指复用同一个资源（这个资源放到图4就是指select函数，放到通信方式里就是指TCP连接），可以参考其原始概念：多路复用-百度百科。以及这篇知乎上的回答：IO 多路复用是什么意思？ 2.6.2：select、poll、epoll函数上述三个函数均提供IO多路复用的解决方案，但是它们之间存在差异性，下面会介绍具体的区别： select： select 函数监视的fd分为writefds、readfds、exceptfds三类，调用后select函数会阻塞，直到有fd就绪（可读、可写、或except），或超时（指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以通过遍历fdset，来找到已经就绪的fd。 优点：跨平台支持，目前几乎所有的平台都支持。 缺点：单个进程内其监视的fd存在最大限制，一般为1024个（linux32）或者2048个（linux64）。另外一个缺点就是其会不断的轮询fdset，不管存不存在活跃的socket，它都会全部遍历一遍fdset来查找就绪的fd，导致浪费许多CPU的时间去做这件事。最后一个缺点是其可能会维护一个存放大量fd的数据结构，这样会使用户空间和内核空间在传递该结构时复制开销过大。 poll： 本质上和select没有区别，但是它解决了select监视fd个数的限制。 优点：对于监视的fd，采用链表结构存储，无个数限制。 缺点：基本上select有的缺点它都有，其次它还有个特点：水平触发，也就是说poll到的fd没有被处理掉，下次依旧能被poll到。 select和poll一样，在大量客户端连接进来时，它们的效率会随着客户端数量而线性下降。 epoll： Linux2.6开始支持的一个函数，是对select和poll的增强版本。 优点：没有监视fd个数的限制，主动通知（回调）机制，只关注活跃的fd，不用像select和poll那样全量遍历去找就绪的fd，因而也不存在随着客户端数量的增多而性能下降的问题。最后是内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递，即epoll使用mmap减少复制开销。 缺点：在大量客户端连接，并且大量活跃的fd时，其性能可能还不如select/poll。 2.7：信号驱动式IO模型信号驱动IO模型处理流程如下： 通过上图，在信号驱动 IO 模型中，应用程序使用套接口进行信号驱动 IO，并安装一个信号处理函数，进程继续运行并不会发生阻塞； 当数据准备好时，进程会收到一个 SIGIO 信号，可以在信号处理函数中调用 IO 操作函数处理数据。 这种模式下在大量IO操作时可能会发生信号队列溢出而导致无法通知。在TCP下，该模式几乎没用，TCP下可通知的条件过多，每一个都进行判断会消耗掉大量的资源。 2.8：异步IO模型（AIO）上面介绍的几种IO模型，对于IO处理本身而言，都是同步的，只有这个模型，针对IO处理本身来讲，是异步的。 下面来看看流程图： 由上图看出，此模型下首先由应用程序告知内核启动某个操作，并让内核在整个操作包括将数据从内核拷贝到应用程序的缓冲区的过程中，完成后通知应用程序。 这跟上面的信号驱动IO模型有所不同，这个模型通知给应用程序时，IO操作已经全部完成，应用程序直接拿数据就好，无需再做任何IO操作（这就是此模型叫异步IO处理的原因），而信号驱动通常是返回给应用程序一个数据报准备状态，真正的IO操作仍需要应用程序进行。 目前AIO并不完善，最常用的高性能IO模型仍然是IO多路复用模型。 三、总结这几种模型除了AIO属于异步IO以外，其余的几种全都是同步IO（即需要应用程序主动进行IO操作），而是否阻塞应用程序取决于第一个阶段的处理方式，前几种IO模型的区别全在于第一阶段的处理。 本文参考：https://zhuanlan.zhihu.com/p/43933717","link":"/2019/03/19/Java%20NIO%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%B0%E5%BD%95%EF%BC%88%E4%BA%94%EF%BC%89%EF%BC%9A%20%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84IO%E6%A8%A1%E5%9E%8B/"},{"title":"Java NIO学习与记录（八）： Reactor两种多线程模型的实现","text":"注：本篇文章例子基于上一篇进行：Java NIO学习与记录（七）： Reactor单线程模型的实现 前言：单线程Reactor模型的缺点紧接着上篇Reactor单线程模型的例子来，假设Handler的read那里的处理方式延迟5s，当做是业务性能瓶颈，改变下原来的Handler，让其read方法在处理时延迟5s： 1234567891011121314151617181920212223private void read() throws IOException { if (selectionKey.isValid()) { System.out.println(\"服务端读取数据前\"); readBuffer.clear(); int count = socketChannel.read(readBuffer); if (count &gt; 0) { try { Thread.sleep(5000L); //读取信息后睡眠5s当做业务处理瓶颈 } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(String.format(\"收到来自 %s 的消息: %s\", socketChannel.getRemoteAddress(), new String(readBuffer.array()))); status = SEND; selectionKey.interestOps(SelectionKey.OP_WRITE); } else { selectionKey.cancel(); socketChannel.close(); System.out.println(\"read时-------连接关闭\"); } } } 代码块1 现在同样开启两个客户端同时连接到该服务端，然后请求--&gt;收到响应--&gt;再次请求的流程走10次，会发现，客户端每收到一次响应需要10s，同样的如果开启3个客户端，则需要15s，因为单线程的Reactor模型是串行的，业务处理的瓶颈可以影响到全局的事件分发，这种模型下，如果存在类似例子中的瓶颈点是致命的（例子的5s是夸张处理），因为新进来的连接也会排队，整个select都会被Handler的处理给阻塞掉，举个实际点的例子，redis在使用时大部分时候会避免使用类似keys这种重操作，为什么呢？就是因为redis是单线程，这里说的单线程其实并不是说redis服务端就一个线程，而是说redis采用的NIO Reactor模型就是单线程的Reactor模型，跟上面代码里做的改动一样，5s可以理解成重操作，影响整个模型的正常运作，redis之所以采用单线程模式，是因为redis大部分操作实在是太快了，快到使用这种模式也可以提供近十万/秒的并发能力，单线程模型实现起来简单且可控性强，所以redis很自然的选择了这种模式。回到问题本身，我们自己的业务可能并没有redis那样高的处理能力，搞不好几个网络请求就可以造成性能瓶颈，拖慢甚至拖垮整个处理模型，所以大部分RPC框架和web容器并不会采用单线程的Reactor模型实现，那么有没有什么方法可以优化这种模型呢？比如，把这个瓶颈点利用独立线程异步出去处理，这样可以保证不影响select的执行，也就很好的避免了上面的问题了，下面介绍两种多线程异步的Reactor模型。 一、单Reactor多线程模型模型图： 上图与单线程Reactor模型对比可以看出，读入数据后，对数据的业务处理部分被线程池做了异步处理，也就是说，上述5s的那段瓶颈被放到了子线程去处理，select的执行不会受到任何影响，因此对新的连接处理、多个客户端的响应速度都应该可以得到保障。 现在来改写下前篇文章里的单线程处理模式的Handler，更名为AsyncHandler： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118public class AsyncHandler implements Runnable { private final Selector selector; private final SelectionKey selectionKey; private final SocketChannel socketChannel; private ByteBuffer readBuffer = ByteBuffer.allocate(1024); private ByteBuffer sendBuffer = ByteBuffer.allocate(2048); private final static int READ = 0; //读取就绪 private final static int SEND = 1; //响应就绪 private final static int PROCESSING = 2; //处理中 private int status = READ; //所有连接完成后都是从一个读取动作开始的 //开启线程数为5的异步处理线程池 private static final ExecutorService workers = Executors.newFixedThreadPool(5); AsyncHandler(SocketChannel socketChannel, Selector selector) throws IOException { this.socketChannel = socketChannel; this.socketChannel.configureBlocking(false); selectionKey = socketChannel.register(selector, 0); selectionKey.attach(this); selectionKey.interestOps(SelectionKey.OP_READ); this.selector = selector; this.selector.wakeup(); } @Override public void run() { //如果一个任务正在异步处理，那么这个run是直接不触发任何处理的，read和send只负责简单的数据读取和响应，业务处理完全不阻塞这里的处理 switch (status) { case READ: read(); break; case SEND: send(); break; default: } } private void read() { if (selectionKey.isValid()) { try { readBuffer.clear(); int count = socketChannel.read(readBuffer); if (count &gt; 0) { status = PROCESSING; //置为处理中，处理完成后该状态为响应，表示读入处理完成，接下来可以响应客户端了 workers.execute(this::readWorker); //异步处理 } else { selectionKey.cancel(); socketChannel.close(); System.out.println(\"read时-------连接关闭\"); } } catch (IOException e) { System.err.println(\"处理read业务时发生异常！异常信息：\" + e.getMessage()); selectionKey.cancel(); try { socketChannel.close(); } catch (IOException e1) { System.err.println(\"处理read业务关闭通道时发生异常！异常信息：\" + e.getMessage()); } } } } void send() { if (selectionKey.isValid()) { status = PROCESSING; //置为执行中 workers.execute(this::sendWorker); //异步处理 selectionKey.interestOps(SelectionKey.OP_READ); //重新设置为读 } } //读入信息后的业务处理 private void readWorker() { try { Thread.sleep(5000L); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(String.format(\"收到来自客户端的消息: %s\", new String(readBuffer.array()))); status = SEND; selectionKey.interestOps(SelectionKey.OP_WRITE); //注册写事件 this.selector.wakeup(); //唤醒阻塞在select的线程，因为该interestOps写事件是放到子线程的，select在该channel还是对read事件感兴趣时又被调用，因此如果不主动唤醒，select可能并不会立刻select该读就绪事件（在该例中，可能永远不会被select到） } private void sendWorker() { try { sendBuffer.clear(); sendBuffer.put(String.format(\"我收到来自%s的信息辣：%s, 200ok;\", socketChannel.getRemoteAddress(), new String(readBuffer.array())).getBytes()); sendBuffer.flip(); int count = socketChannel.write(sendBuffer); if (count &lt; 0) { selectionKey.cancel(); socketChannel.close(); System.out.println(\"send时-------连接关闭\"); } else { //再次切换到读 status = READ; } } catch (IOException e) { System.err.println(\"异步处理send业务时发生异常！异常信息：\" + e.getMessage()); selectionKey.cancel(); try { socketChannel.close(); } catch (IOException e1) { System.err.println(\"异步处理send业务关闭通道时发生异常！异常信息：\" + e.getMessage()); } } }} 代码块2 可以看到，read里、send里的逻辑处理被异步出去执行，新增了中间状态“执行中”，主要用来防止事件重复触发，重复执行异步逻辑，当异步逻辑处理完毕才会更改状态值，这时候可以继续处理接下来的事件（读或写）。 把Accptor类里的实现换成AsyncHandler，运行服务端和客户端会发现，两个客户端的响应均为5s，也不会阻塞新增的连接，新增至三个或者更多的客户端基本可以保持客户端响应均为5s（说明：这里5s是夸张比喻，正常瓶颈没这么夸张，若开了n多客户端，每个都阻塞5s，那么线程池也会发生排队，因为子线程个数有限，处理不过来，最后还是阻塞，一定会远超过5s）。 通过多线程Reactor模型，降低了业务代码瓶颈导致影响整个Reactor执行链路的风险，但是即便如此，read、send操作仍然和接收请求（accept）处于同一个线程，这就意味着read、send的处理可能会影响到对客户端连接的接收能力，那么有没有一种办法，可以把读写流程彻底异步出去，负责连接的线程就只负责接收连接？于是多Reactor多线程模型就产生了，这种模型也叫主从Reactor模型，该模型下可以分为一个主Reactor专门处理连接事件，而多个从Reactor负责读写、业务处理等，这样服务端可以接收并处理更多的请求，提升服务端的吞吐能力（该模型或者说所有基于NIO的Reactor模型，都是以提升服务端处理能力为基础的，NIO在某些情况下不一定会比BIO处理速度快，但一定比BIO稳，就像NIO可以利用很少的线程处理大量的客户端请求，而BIO在大量客户端请求过来的情况下，由于各种操作均会阻塞线程，会处理不过来）。 二、主从Reactor模型还是把之前文章的图拿来展示下这种模型的流程，可以与上面图1进行对比，看看发生了哪些变化： 上图就是主从Reactor模型的一个流程，看下与图1的不同之处，多了SubReactor这样一个角色，这个角色就是用来处理读写操作的Reactor，现在仍然基于之前的例子，进行改写，明确需要改写的点： 新增SubReactor Acceptor那里进行初始化一批SubReactor，进行分发处理 为了区分客户端分别是被哪个SubReactor处理的读写操作，还需要改写下AsyncHandler，在里面加上SubReactor的序号，打印信息时进行区分。 ok，总结完改动点，现在基于上面的代码（代码初代目版本：Reactor单线程模型的实现）改写一下这几个类： step1.首先新增SubReactor类1234567891011121314151617181920212223242526272829303132333435363738394041424344public class SubReactor implements Runnable { private final Selector selector; private boolean register = false; //注册开关表示，为什么要加这么个东西，可以参考Acceptor设置这个值那里的描述 private int num; //序号，也就是Acceptor初始化SubReactor时的下标 SubReactor(Selector selector, int num) { this.selector = selector; this.num = num; } @Override public void run() { while (!Thread.interrupted()) { System.out.println(String.format(\"%d号SubReactor等待注册中...\", num)); while (!Thread.interrupted() &amp;&amp; !register) { try { if (selector.select() == 0) { continue; } } catch (IOException e) { e.printStackTrace(); } Set selectedKeys = selector.selectedKeys(); Iterator it = selectedKeys.iterator(); while (it.hasNext()) { dispatch(it.next()); it.remove(); } } } } private void dispatch(SelectionKey key) { Runnable r = (Runnable) (key.attachment()); if (r != null) { r.run(); } } void registering(boolean register) { this.register = register; }} 代码块3 这个类负责Acceptor交给自己的事件select（例子中实际上就是read、send）。 step2.Acceptor类的更改1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class Acceptor implements Runnable { private final ServerSocketChannel serverSocketChannel; private final int coreNum = Runtime.getRuntime().availableProcessors(); // 获取CPU核心数 private final Selector[] selectors = new Selector[coreNum]; // 创建selector给SubReactor使用，个数为CPU核心数（如果不需要那么多可以自定义，毕竟这里会吞掉一个线程） private int next = 0; // 轮询使用subReactor的下标索引 private SubReactor[] reactors = new SubReactor[coreNum]; // subReactor private Thread[] threads = new Thread[coreNum]; // subReactor的处理线程 Acceptor(ServerSocketChannel serverSocketChannel) throws IOException { this.serverSocketChannel = serverSocketChannel; // 初始化 for (int i = 0; i &lt; coreNum; i++) { selectors[i] = Selector.open(); reactors[i] = new SubReactor(selectors[i], i); //初始化sub reactor threads[i] = new Thread(reactors[i]); //初始化运行sub reactor的线程 threads[i].start(); //启动（启动后的执行参考SubReactor里的run方法） } } @Override public void run() { SocketChannel socketChannel; try { socketChannel = serverSocketChannel.accept(); // 连接 if (socketChannel != null) { System.out.println(String.format(\"收到来自 %s 的连接\", socketChannel.getRemoteAddress())); socketChannel.configureBlocking(false); // reactors[next].registering(true); // 注意一个selector在select时是无法注册新事件的，因此这里要先暂停下select方法触发的程序段，下面的weakup和这里的setRestart都是做这个事情的，具体参考SubReactor里的run方法 selectors[next].wakeup(); // 使一個阻塞住的selector操作立即返回 SelectionKey selectionKey = socketChannel.register(selectors[next], SelectionKey.OP_READ); // 当前客户端通道SocketChannel向selector[next]注册一个读事件，返回key selectors[next].wakeup(); // 使一個阻塞住的selector操作立即返回 reactors[next].registering(false); // 本次事件注册完成后，需要再次触发select的执行，因此这里Restart要在设置回false（具体参考SubReactor里的run方法） selectionKey.attach(new AsyncHandler(socketChannel, selectors[next], next)); // 绑定Handler if (++next == selectors.length) { next = 0; //越界后重新分配 } } } catch (IOException e) { e.printStackTrace(); } }} 代码块4 可以跟以前的Acceptor做个对比，做了如下改动： 接受到连接后不再直接触发handler了 初始化一堆SubReactor（从反应堆），每个交给一个线程处理，注册读事件后顺序分配给不同的SubReactor去处理自己的selector监听。 以上，就可以把读写处理+业务处理与接受连接的Reactor彻底分开了，接受连接的事件不再受任何读写、业务相关的影响，只负责接收，目前即便是业务线程池用光线程发生排队，也不会影响到连接的接收，很大程度上降低了服务端的接收能力遭遇瓶颈的风险。 step3.改写AsyncHandler的打印这里就不po代码了，具体就是把SubReactor的序号传给handler，标记触发Handler的Reactor是哪个。 同样的，启动下服务端，再开启两个客户端（跟之前一样，每个客户端发10条消息终止连接），运行结果如下： 服务端： 1234567891011121314151617181920212223242526272829301号SubReactor等待注册中...3号SubReactor等待注册中...0号SubReactor等待注册中...2号SubReactor等待注册中...收到来自 /127.0.0.1:60407 的连接0号SubReactor等待注册中...收到来自 /127.0.0.1:60410 的连接1号SubReactor等待注册中...1号SubReactor触发：收到来自客户端/127.0.0.1:60410的消息: 客户端发送的第1条消息0号SubReactor触发：收到来自客户端/127.0.0.1:60407的消息: 客户端发送的第1条消息0号SubReactor触发：收到来自客户端/127.0.0.1:60407的消息: 客户端发送的第2条消息1号SubReactor触发：收到来自客户端/127.0.0.1:60410的消息: 客户端发送的第2条消息0号SubReactor触发：收到来自客户端/127.0.0.1:60407的消息: 客户端发送的第3条消息1号SubReactor触发：收到来自客户端/127.0.0.1:60410的消息: 客户端发送的第3条消息1号SubReactor触发：收到来自客户端/127.0.0.1:60410的消息: 客户端发送的第4条消息0号SubReactor触发：收到来自客户端/127.0.0.1:60407的消息: 客户端发送的第4条消息1号SubReactor触发：收到来自客户端/127.0.0.1:60410的消息: 客户端发送的第5条消息0号SubReactor触发：收到来自客户端/127.0.0.1:60407的消息: 客户端发送的第5条消息1号SubReactor触发：收到来自客户端/127.0.0.1:60410的消息: 客户端发送的第6条消息0号SubReactor触发：收到来自客户端/127.0.0.1:60407的消息: 客户端发送的第6条消息1号SubReactor触发：收到来自客户端/127.0.0.1:60410的消息: 客户端发送的第7条消息0号SubReactor触发：收到来自客户端/127.0.0.1:60407的消息: 客户端发送的第7条消息0号SubReactor触发：收到来自客户端/127.0.0.1:60407的消息: 客户端发送的第8条消息1号SubReactor触发：收到来自客户端/127.0.0.1:60410的消息: 客户端发送的第8条消息0号SubReactor触发：收到来自客户端/127.0.0.1:60407的消息: 客户端发送的第9条消息1号SubReactor触发：收到来自客户端/127.0.0.1:60410的消息: 客户端发送的第9条消息0号SubReactor触发：收到来自客户端/127.0.0.1:60407的消息: 客户端发送的第10条消息1号SubReactor触发：收到来自客户端/127.0.0.1:60410的消息: 客户端发送的第10条消息0号SubReactor触发：read时-------连接关闭1号SubReactor触发：read时-------连接关闭 客户端： 12345678910111213141516171819202122已完成 /127.0.0.1:2333 的连接已完成 /127.0.0.1:2333 的连接收到来自服务端的消息: 0号SubReactor触发：我收到来自/127.0.0.1:60407的信息辣：客户端发送的第1条消息, 200ok;收到来自服务端的消息: 1号SubReactor触发：我收到来自/127.0.0.1:60410的信息辣：客户端发送的第1条消息, 200ok;收到来自服务端的消息: 0号SubReactor触发：我收到来自/127.0.0.1:60407的信息辣：客户端发送的第2条消息, 200ok;收到来自服务端的消息: 1号SubReactor触发：我收到来自/127.0.0.1:60410的信息辣：客户端发送的第2条消息, 200ok;收到来自服务端的消息: 1号SubReactor触发：我收到来自/127.0.0.1:60410的信息辣：客户端发送的第3条消息, 200ok;收到来自服务端的消息: 0号SubReactor触发：我收到来自/127.0.0.1:60407的信息辣：客户端发送的第3条消息, 200ok;收到来自服务端的消息: 1号SubReactor触发：我收到来自/127.0.0.1:60410的信息辣：客户端发送的第4条消息, 200ok;收到来自服务端的消息: 0号SubReactor触发：我收到来自/127.0.0.1:60407的信息辣：客户端发送的第4条消息, 200ok;收到来自服务端的消息: 1号SubReactor触发：我收到来自/127.0.0.1:60410的信息辣：客户端发送的第5条消息, 200ok;收到来自服务端的消息: 0号SubReactor触发：我收到来自/127.0.0.1:60407的信息辣：客户端发送的第5条消息, 200ok;收到来自服务端的消息: 1号SubReactor触发：我收到来自/127.0.0.1:60410的信息辣：客户端发送的第6条消息, 200ok;收到来自服务端的消息: 0号SubReactor触发：我收到来自/127.0.0.1:60407的信息辣：客户端发送的第6条消息, 200ok;收到来自服务端的消息: 1号SubReactor触发：我收到来自/127.0.0.1:60410的信息辣：客户端发送的第7条消息, 200ok;收到来自服务端的消息: 0号SubReactor触发：我收到来自/127.0.0.1:60407的信息辣：客户端发送的第7条消息, 200ok;收到来自服务端的消息: 1号SubReactor触发：我收到来自/127.0.0.1:60410的信息辣：客户端发送的第8条消息, 200ok;收到来自服务端的消息: 0号SubReactor触发：我收到来自/127.0.0.1:60407的信息辣：客户端发送的第8条消息, 200ok;收到来自服务端的消息: 0号SubReactor触发：我收到来自/127.0.0.1:60407的信息辣：客户端发送的第9条消息, 200ok;收到来自服务端的消息: 1号SubReactor触发：我收到来自/127.0.0.1:60410的信息辣：客户端发送的第9条消息, 200ok;收到来自服务端的消息: 0号SubReactor触发：我收到来自/127.0.0.1:60407的信息辣：客户端发送的第10条消息, 200ok;收到来自服务端的消息: 1号SubReactor触发：我收到来自/127.0.0.1:60410的信息辣：客户端发送的第10条消息, 200ok; 到这里，主从Reactor模型就被改写完成了，上面的例子只是简单演示了下这个模型，所有的例子都是从单线程Reactor模型一点点改写来的，客户端没变过，为的是更好的测试服务端在不同模型下的表现。主从Reactor模型应用的比较多，比如著名NIO框架Netty底层模型也是基于主从Reactor模型来实现的。 到这里java nio的东西已经差不多记录完了，后续会开始netty的学习记录，当然上述例子弱化了buffer的使用，而且例子中不存在粘包拆包的问题（因为都是请求+应答的方式进行），如果把上面的例子改成客户端在未收到响应时就连续发送几条信息，服务端这时再次由写模式切换到读模式，就会从Channel里连续拿到这几条消息，这就导致了粘包问题，那么如何解决类似的问题呢？通常是定义一种协议，来区分消息头和尾，中间的消息体是我们真正需要的数据，这种协议也就是我们常说的应用层协议，比如HTTP、FTP等，这里不做赘述，之后会通过一个例子来完成这部分的补充说明。 代码地址 单线程Reactor模型：https://github.com/exceting/DemoAll/tree/master/jdk/src/main/java/demo/jdk/reactor/simple 多线程Reactor模型：同上，Acceptor里的Handler改成AsyncHandler即可 主从多线程Reactor模型：https://github.com/exceting/DemoAll/tree/master/jdk/src/main/java/demo/jdk/reactor/mainsub","link":"/2019/04/01/Java%20NIO%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%B0%E5%BD%95%EF%BC%88%E5%85%AB%EF%BC%89%EF%BC%9A%20Reactor%E4%B8%A4%E7%A7%8D%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AE%9E%E7%8E%B0/"},{"title":"Java NIO学习与记录（六）： NIO线程模型","text":"上一篇说的是基于操作系统的IO处理模型，那么这一篇来介绍下服务器端基于IO模型和自身线程的处理方式。 一、基于BIO下的线程处理模式这种处理模型是基于阻塞IO进行的，上一篇讲过，阻塞IO会阻塞每一个IO操作，直到事件就绪，下面来看下阻塞IO下的服务端线程模型： 如上图所示，该线程模型基于阻塞IO模型实现，针对每个请求都需要抽出来一个线程进行处理读入数据、业务处理数据、返回响应结果给客户端，这个过程中读、写操作均会阻塞，且跟业务处理串行执行，该模式下，并发量过大时会大量创建线程，发生的大量上下文切换，从而导致CPU资源占用过大，当连接建立后，若当前线程暂无可读数据，则线程会一直阻塞在读操作上，造成线程资源浪费，即便使用线程池进行优化，虽然避免了大量创建线程，但也会出现线程资源浪费的问题，高并发下可能会造成排队、响应不及时的问题。 具体BIO服务器的实现参考：SocketChannel与BIO服务器 二、基于NIO下的Reactor线程模型利用操作系统NIO的API实现，Java对其API的调用进行了封装（select等），这里先不探讨怎么利用java的api去调用，先来看看它的基本流程是怎样的，Reactor模式下的线程模型又会根据线程数量、线程池数量的不同，细分了三种线程模型。 2.1：单Reactor单线程模型这是最简单的Reactor模型，整个过程中的事件处理全部发生在一个线程里： 上图示意就是个简单的NIO单Reactor单线程处理模型，流程如下： Reactor对象通过select监听客户端的请求事件，收到事件消息后通过dispatch进行任务分发。 如果是建连请求，则交由Acceptor对象处理连接请求，然后创建一个Handler对象继续完成后续处理 若不是建连请求，则dispatch会调用对应连接的Handler进行处理，Handle负责完成连接成功后的后续处理（读操作、写操作、业务处理等） 此模型很简单，易于理解，但是存在一定的问题，比如单线处理程模型下，无法发挥多核CPU的性能，如果Handler上的业务处理很慢，则意味着整个程序无法处理其他连接事件，造成性能问题。适用于业务处理快速、客户端连接较少的情况。 2.2：单Reactor多线程模型相较于上面的模型，对业务处理模块进行了异步处理，流程图如下： 上图示意属于单Reactor多线程处理模型，流程如下： Reactor对象通过select监听客户端的请求事件，收到事件消息后通过dispatch进行任务分发。 如果是建连请求，则交由Acceptor对象处理连接请求，然后创建一个Handler对象继续完成后续处理 若不是建连请求，则dispatch会调用对应连接的Handler进行处理，Handle负责完成连接成功后的读操作，读出来数据后的业务处理部分交由线程池异步处理，业务处理完成后发送给Handler处理完成的消息，然后再由Handler发送处理响应信息给对应的Client。 本模型充分利用了多核CPU的处理能力，降低了由业务处理引起的性能问题，Reactor线程仅负责接收连接、读写操作。但是Reactor除了负责连接处理外仍然负责读写操作，大量的请求下仍然可能仍然存在性能问题。 2.3：主从Reactor多线程模型这个模型中将会独立出另一个Reactor对象来处理非连接处理的其他处理，命名为从Reactor（SubReactor），流程图如下： 上图示意属于主从Reactor多线程处理模型，流程如下： 主Reactor对象（MainReactor）通过select监听客户端的连接事件，收到连接事件后交由Acceptor处理。 Acceptor处理完成后，MainReactor将此连接分配给SubReactor处理，SubReactor将此连接加入连接队列进行事件监听并建立Handler进行后续的各种操作，同上面的模型一致，SubReactor会监听新的事件，如果有新的事件发生，则调用Handler进行相应的处理。 Handler读出来数据后的业务处理部分交由线程池异步处理，业务处理完成后发送给Handler处理完成的消息，然后再由Handler发送处理响应信息给对应的Client。 该模型存在两个线程分别处理Reactor事件，主线程只负责处理连接事件，子线程只负责处理读写事件，这样主线程可以处理更多的连接，而不用关心子线程里的读写处理是否会影响到自己。目前这种模型被广泛使用在各种项目中（如Netty、Memcached等）。 以上的线程模型都是基于同步IO，异步IO这里不作说明，目前大部分项目都采用NIO的API进行实现（该模式下又分成了上述3种线程处理模型）。 下一篇将会针对NIO下的三种线程处理模型，介绍下Selector，以及利用Selector来写一下具体的实现代码。","link":"/2019/03/20/Java%20NIO%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%B0%E5%BD%95%EF%BC%88%E5%85%AD%EF%BC%89%EF%BC%9A%20NIO%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/"},{"title":"Kingdom Rush Origins","text":"中学时玩的一款游戏，当时玩的应该是初版，今天下午在steam下载了最新版-起源，感觉游戏画面很舒服，风格也是以前的样子，一款休闲的塔防游戏 Kingdom Rush发展史： Kingdom Rush Origins游戏截图：","link":"/2019/04/13/Kingdom%20Rush%20Origins/"},{"title":"Java NIO学习与记录（四）： SocketChannel与BIO服务器","text":"SocketChannel可以创建连接TCP服务的客户端，用于为服务发送数据，SocketChannel的写操作和连接操作在非阻塞模式下不会发生阻塞，这篇文章里的客户端采用SocketChannel实现，利用线程池模拟多个客户端并发访问服务端的情景。服务端仍然采用ServerSocket来实现，主要用来看下阻塞模式下的服务端在并发访问时所做出的的处理。 一、使用SocketChannel实现一个客户端1234567891011121314151617181920212223242526272829303132333435363738394041424344private static ExecutorService ctp = Executors.newCachedThreadPool(); public static void main(String[] args) { for (int i = 0; i &lt; 10; i++) { ctp.submit(IOTest::client); //并发十个客户端连接过去 } } public static void client() { ByteBuffer buffer = ByteBuffer.allocate(1024); //定义缓冲区 SocketChannel socketChannel = null; try { socketChannel = SocketChannel.open(); //打开SocketChannel socketChannel.configureBlocking(false); //设置为非阻塞模式 socketChannel.connect(new InetSocketAddress(\"127.0.0.1\", 2333)); //连接服务 while (true) { if(socketChannel.finishConnect()){ //这里的finishConnect是尝试连接，有可能返回false，因此使用死循环进行连接检查，确保连接已经正常建立。 System.out.println(\"客户端已连接到服务器\"); int i = 0; while (i &lt; 5) { TimeUnit.SECONDS.sleep(1); //隔一秒钟写一条 String info = \"来自客户端的第\" + (i++) + \"条消息\"; buffer.clear(); buffer.put(info.getBytes()); buffer.flip(); while (buffer.hasRemaining()) { socketChannel.write(buffer); //给服务写消息 } } break; } } } catch (IOException | InterruptedException e) { e.printStackTrace(); } finally { try { if (socketChannel != null) { System.out.println(\"客户端Channel关闭\"); socketChannel.close(); } } catch (IOException e) { e.printStackTrace(); } } 代码块1 上面会同时产生10个客户端去连接服务端 二、使用ServerSocket实现一个BIO的TCP服务12345678910111213141516171819202122232425262728293031323334ServerSocket serverSocket = null; int recvMsgSize = 0; InputStream in = null; try { serverSocket = new ServerSocket(2333); //开一个监听2333端口的TCP服务 byte[] recvBuf = new byte[1024]; while (true) { Socket clntSocket = serverSocket.accept(); //探听有没有新的客户端连接进来，没有就阻塞 SocketAddress clientAddress = clntSocket.getRemoteSocketAddress(); //通过跟服务连接上的客户端socket，拿到客户端地址 System.out.println(\"连接成功，处理客户端：\" + clientAddress); in = clntSocket.getInputStream(); //数据流 while ((recvMsgSize = in.read(recvBuf)) != -1) { //读取发送的数据，当客户端未断开连接，且不往服务端发数据的时候，说明一直处于准备读的状态，会一直阻塞下去，直到有数据写入（读就绪） byte[] temp = new byte[recvMsgSize]; System.arraycopy(recvBuf, 0, temp, 0, recvMsgSize); System.out.println(\"收到客户端\" + clientAddress + \"的消息内容：\" + new String(temp)); //打印消息 } System.out.println(\"-----------------------------------\"); } } catch (IOException e) { e.printStackTrace(); } finally { try { if (serverSocket != null) { System.out.println(\"socket关闭！\"); serverSocket.close(); } if (in != null) { System.out.println(\"stream连接关闭！\"); in.close(); } } catch (IOException e) { e.printStackTrace(); } } 代码块2 运行上面的代码，服务端打印如下： 12345678910111213141516171819202122232425262728293031323334连接成功，处理客户端：/127.0.0.1:54688收到客户端/127.0.0.1:54688的消息内容：来自客户端的第0条消息收到客户端/127.0.0.1:54688的消息内容：来自客户端的第1条消息收到客户端/127.0.0.1:54688的消息内容：来自客户端的第2条消息收到客户端/127.0.0.1:54688的消息内容：来自客户端的第3条消息收到客户端/127.0.0.1:54688的消息内容：来自客户端的第4条消息-----------------------------------连接成功，处理客户端：/127.0.0.1:54680收到客户端/127.0.0.1:54680的消息内容：来自客户端的第0条消息来自客户端的第1条消息来自客户端的第2条消息来自客户端的第3条消息来自客户端的第4条消息-----------------------------------连接成功，处理客户端：/127.0.0.1:54689收到客户端/127.0.0.1:54689的消息内容：来自客户端的第0条消息来自客户端的第1条消息来自客户端的第2条消息来自客户端的第3条消息来自客户端的第4条消息-----------------------------------连接成功，处理客户端：/127.0.0.1:54682收到客户端/127.0.0.1:54682的消息内容：来自客户端的第0条消息来自客户端的第1条消息来自客户端的第2条消息来自客户端的第3条消息来自客户端的第4条消息-----------------------------------连接成功，处理客户端：/127.0.0.1:54683收到客户端/127.0.0.1:54683的消息内容：来自客户端的第0条消息来自客户端的第1条消息来自客户端的第2条消息来自客户端的第3条消息来自客户端的第4条消息-----------------------------------连接成功，处理客户端：/127.0.0.1:54684收到客户端/127.0.0.1:54684的消息内容：来自客户端的第0条消息来自客户端的第1条消息来自客户端的第2条消息来自客户端的第3条消息来自客户端的第4条消息-----------------------------------连接成功，处理客户端：/127.0.0.1:54685收到客户端/127.0.0.1:54685的消息内容：来自客户端的第0条消息来自客户端的第1条消息来自客户端的第2条消息来自客户端的第3条消息来自客户端的第4条消息-----------------------------------连接成功，处理客户端：/127.0.0.1:54681收到客户端/127.0.0.1:54681的消息内容：来自客户端的第0条消息来自客户端的第1条消息来自客户端的第2条消息来自客户端的第3条消息来自客户端的第4条消息-----------------------------------连接成功，处理客户端：/127.0.0.1:54686收到客户端/127.0.0.1:54686的消息内容：来自客户端的第0条消息来自客户端的第1条消息来自客户端的第2条消息来自客户端的第3条消息来自客户端的第4条消息-----------------------------------连接成功，处理客户端：/127.0.0.1:54687收到客户端/127.0.0.1:54687的消息内容：来自客户端的第0条消息来自客户端的第1条消息来自客户端的第2条消息来自客户端的第3条消息来自客户端的第4条消息----------------------------------- 可以看到，消息是按照顺序，一个一个连接进来，然后完成处理的，至于后面的消息为什么会被合并成一个，也是这个原因，因为阻塞，所以等第一个连接逐条输出完成后，第二个连接进来，这时很可能客户端的SocketChannel已经将十条消息全部写入channel，等第一个连接处理完成后，接到第二条消息时就已经是全部的消息了，因此一次性输出，后面的合并也是这个原因（主要客户端使用NIO实现，因此写和连接服务不会发生阻塞，因此在第次个请求服务端还在处理时，其余的客户端数据也在执行并写入通道，最终服务端处理完第一个连接，然后继续接收第二个连接时，数据便是完整的5条数据了）。 上面的服务端是一个典型的阻塞IO的服务，accept在没有连接进来时会发生阻塞，read在客户端连接没关闭，且不再写消息时，服务端的read将一直处于读等待状态并阻塞，直到收到新的消息转为读就绪才会继续往下执行（这就是上面例子里第一个进来的连接可以逐条输出的原因），完全串行化，过程如下图： 下面，来改造下服务端，让其处理能力更好一些，除了accept，下面的处理逻辑全部交给线程池处理： 1234567891011121314151617181920212223while (true) { Socket clntSocket = serverSocket.accept(); //探听有没有新的客户端连接进来，没有就阻塞 SocketAddress clientAddress = clntSocket.getRemoteSocketAddress(); //通过跟服务连接上的客户端socket，拿到客户端地址 System.out.println(\"连接成功，处理客户端：\" + clientAddress); ctp.execute(() -&gt; { int recvMsgSize = 0; InputStream in = null; //数据流 try { in = clntSocket.getInputStream(); while ((recvMsgSize = in.read(recvBuf)) != -1) { //读取发送的数据，当客户端未断开连接，且不往服务端发数据的时候，说明一直处于准备读的状态，会一直阻塞下去，直到有数据写入（读就绪） byte[] temp = new byte[recvMsgSize]; System.arraycopy(recvBuf, 0, temp, 0, recvMsgSize); System.out.println(\"收到客户端\" + clientAddress + \"的消息内容：\" + new String(temp)); //打印消息 } System.out.println(\"-----------------------------------\"); } catch (IOException e) { e.printStackTrace(); } }); } 代码块3 运行结果： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970连接成功，处理客户端：/127.0.0.1:55259连接成功，处理客户端：/127.0.0.1:55265连接成功，处理客户端：/127.0.0.1:55266连接成功，处理客户端：/127.0.0.1:55257连接成功，处理客户端：/127.0.0.1:55260连接成功，处理客户端：/127.0.0.1:55258连接成功，处理客户端：/127.0.0.1:55261连接成功，处理客户端：/127.0.0.1:55262连接成功，处理客户端：/127.0.0.1:55263连接成功，处理客户端：/127.0.0.1:55264收到客户端/127.0.0.1:55265的消息内容：来自客户端的第0条消息收到客户端/127.0.0.1:55266的消息内容：来自客户端的第0条消息收到客户端/127.0.0.1:55258的消息内容：来自客户端的第0条消息收到客户端/127.0.0.1:55257的消息内容：来自客户端的第0条消息收到客户端/127.0.0.1:55261的消息内容：来自客户端的第0条消息收到客户端/127.0.0.1:55262的消息内容：来自客户端的第0条消息收到客户端/127.0.0.1:55263的消息内容：来自客户端的第0条消息收到客户端/127.0.0.1:55260的消息内容：来自客户端的第0条消息收到客户端/127.0.0.1:55259的消息内容：来自客户端的第0条消息收到客户端/127.0.0.1:55264的消息内容：来自客户端的第0条消息收到客户端/127.0.0.1:55265的消息内容：来自客户端的第1条消息收到客户端/127.0.0.1:55266的消息内容：来自客户端的第1条消息收到客户端/127.0.0.1:55258的消息内容：来自客户端的第1条消息收到客户端/127.0.0.1:55257的消息内容：来自客户端的第1条消息收到客户端/127.0.0.1:55261的消息内容：来自客户端的第1条消息收到客户端/127.0.0.1:55260的消息内容：来自客户端的第1条消息收到客户端/127.0.0.1:55262的消息内容：来自客户端的第1条消息收到客户端/127.0.0.1:55263的消息内容：来自客户端的第1条消息收到客户端/127.0.0.1:55259的消息内容：来自客户端的第1条消息收到客户端/127.0.0.1:55264的消息内容：来自客户端的第1条消息收到客户端/127.0.0.1:55266的消息内容：来自客户端的第2条消息收到客户端/127.0.0.1:55262的消息内容：来自客户端的第2条消息收到客户端/127.0.0.1:55261的消息内容：来自客户端的第2条消息收到客户端/127.0.0.1:55260的消息内容：来自客户端的第2条消息收到客户端/127.0.0.1:55263的消息内容：来自客户端的第2条消息收到客户端/127.0.0.1:55257的消息内容：来自客户端的第2条消息收到客户端/127.0.0.1:55265的消息内容：来自客户端的第2条消息收到客户端/127.0.0.1:55258的消息内容：来自客户端的第2条消息收到客户端/127.0.0.1:55259的消息内容：来自客户端的第2条消息收到客户端/127.0.0.1:55264的消息内容：来自客户端的第2条消息收到客户端/127.0.0.1:55258的消息内容：来自客户端的第3条消息收到客户端/127.0.0.1:55266的消息内容：来自客户端的第3条消息收到客户端/127.0.0.1:55257的消息内容：来自客户端的第3条消息收到客户端/127.0.0.1:55262的消息内容：来自客户端的第3条消息收到客户端/127.0.0.1:55261的消息内容：来自客户端的第3条消息收到客户端/127.0.0.1:55263的消息内容：来自客户端的第3条消息收到客户端/127.0.0.1:55265的消息内容：来自客户端的第3条消息收到客户端/127.0.0.1:55260的消息内容：来自客户端的第3条消息收到客户端/127.0.0.1:55264的消息内容：来自客户端的第3条消息收到客户端/127.0.0.1:55259的消息内容：来自客户端的第3条消息收到客户端/127.0.0.1:55266的消息内容：来自客户端的第4条消息收到客户端/127.0.0.1:55265的消息内容：来自客户端的第4条消息-----------------------------------收到客户端/127.0.0.1:55263的消息内容：来自客户端的第4条消息收到客户端/127.0.0.1:55261的消息内容：来自客户端的第4条消息-----------------------------------收到客户端/127.0.0.1:55260的消息内容：来自客户端的第4条消息-----------------------------------收到客户端/127.0.0.1:55262的消息内容：来自客户端的第4条消息-----------------------------------收到客户端/127.0.0.1:55257的消息内容：来自客户端的第4条消息----------------------------------------------------------------------收到客户端/127.0.0.1:55258的消息内容：来自客户端的第4条消息----------------------------------------------------------------------收到客户端/127.0.0.1:55264的消息内容：来自客户端的第4条消息-----------------------------------收到客户端/127.0.0.1:55259的消息内容：来自客户端的第4条消息----------------------------------- 消息被分开了，接收连接虽然仍然是串行，但实际的处理速度在多线程的帮助下已经比之前快很多了，流程如下图： 三、BIO总结综合看下来，传统的阻塞IO，按照图2的方式进行，虽然利用多线程避免了read等操作的阻塞对accept的影响，提高了处理效率，但想象下，如果现在存在高并发的情况，图2的模型如果不使用线程池，就会创建大量线程，会发生大量的线程上下文切换，影响整体效率，并且会影响新的线程，如果使用线程池，虽然某种程度上避免了线程的创建和上下文切换的量级，但是在大量并发的场景下，会发生排队，一旦发生排队，紧接着就会影响到accept。","link":"/2019/03/08/Java%20NIO%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%B0%E5%BD%95%EF%BC%88%E5%9B%9B%EF%BC%89%EF%BC%9A%20SocketChannel%E4%B8%8EBIO%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"title":"LV1-1：安装java环境&第一个java程序","text":"一、java环境组成 JRE：java运行时环境，包含了java虚拟机，java基础类库。是使用java语言编写的程序运行所需要的软件环境，简单来说，如果你只是想运行你的java程序，只安装JRE就行了。 JDK：java开发工具包，提供了全套JRE、编译器、一些开发工具包，如果你想要开发java程序，需要安装一个JDK。 二、java环境安装上网查，太多了 暂时这个吧~https://www.jianshu.com/p/efef80171a4a 三、第一个java程序java程序的入口，都是从main方法开始的，所以在初期做实验的时候，至少要定义一个public类，里面放入一个main方法（不理解啥是类？啥是方法？不要紧，先记住下面的写法即可，反正后面都会介绍到）： 图里可能要素过多，目前了解即可，等学完类和方法部分的内容，再翻过来看这个图，就会很容易理解了。 经过第二步，假设我们已经安装好了java环境，并且配置好了环境变量，现在在终端执行下这个指令： 代码块11java -version 就会打印出java的版本号信息，一旦打印出版本号信息，说明你安装的java环境是没有问题的： 代码块2123java version \"11.0.2\" 2019-01-15 LTSJava(TM) SE Runtime Environment 18.9 (build 11.0.2+9-LTS)Java HotSpot(TM) 64-Bit Server VM 18.9 (build 11.0.2+9-LTS, mixed mode) 现在来写一个最基本的程序： 代码块312345public class Test{ public static void main(String[] args){ System.out.println(\"Hello world!\"); }} 新建一个叫Test.java的文件，将这段代码拷贝进去。 然后现在输入这个指令，用来编译代码： 代码块41javac Test.java 然后你就得到了一个字节码文件：Test.class 字节码文件才可以被java直接运行，通过下面这个指令（注：.class后缀是可以省略不写的）： 可以看到，已经成功运行了。 通过本例子可以知道，java想要执行一个java程序，需要将java源代码文件（例子中的Test.java），通过javac指令编译成字节码文件（例子中的Test.class），然后通过java指令运行对应的字节码文件即可。","link":"/2020/02/25/LV1-1%EF%BC%9A%E5%AE%89%E8%A3%85java%E7%8E%AF%E5%A2%83&%E7%AC%AC%E4%B8%80%E4%B8%AAjava%E7%A8%8B%E5%BA%8F/"},{"title":"LV1-2：java中的变量类型","text":"一、基础变量类型1.1：整型即整数类型，如1，2，0，-1，-2这种。 整型变量在java中的声明方式如下： 代码块112int a; //声明名称为a的整型变量（默认值为0）int b = 5; //声明名称为b的整型变量（初始化值为5） 整型变量在内存中占据32个bit位（4字节），每个bit位可存储0和1，通常第一位为符号位（±），所以有效数字部分就占了31位，如图（图中表示十进制数字+6）： 按照这个特性，整型的取值范围为： (-2^31) ~ (2^31)-1 即：-2147483648 ~ 2147483647 除了浮点型，其余只要有符号位的类型，都符合这个范围规则。 为什么负数的数值位比正数多1，计算机是如何做减法运算的？请参考：JAVA有关位运算的全套梳理 1.2：长整型长整型变量在java中的声明方式如下： 代码块212long a; //声明名称为a的长整型变量（默认值为0）long b = 5; //声明名称为b的长整型变量（初始化值为5） 这种类型所表示的数值范围相比整型的位数，多了一倍，占据64个bit位（8字节），因此其取值范围为： (-2^64) ~ (2^64)-1 即：-9223372036854775808 ~ 9223372036854775807 1.3：短整型短整型变量在java中的声明方式如下： 代码块312short a; //声明名称为a的长整型变量（默认值为0）short b = 5; //声明名称为b的长整型变量（初始化值为5） 这种类型所表示的数值范围相比整型的位数，少了一倍，只占据16个bit位（2字节），取值范围为： (-2^15) ~ (2^15)-1 即：-32768 ~ 32767 巩固： 这里说明下，short、int、long本质上都表示整数，因此像下面这种写法都是ok的： short a = 1; int a = 1; long a = 1; 那为什么要如此区分呢？这就存在一个取值范围的问题，因为这三种类型的二进制位数不一样，所以他们所能容下的数值范围也不同，具体参考下图： 所以今后在写程序时，需要严格推断数值的极端可能性，然后设计出合理接收数据的类型。 举个反例：比如某个系统的id，id增长特别迅速，开始设计用int类型接收id，后来id值超过了int表示数据的最大范围，就会出现很严重的问题。 1.4：单精度浮点型浮点型变量在java中的声明方式如下： 代码块412float a; //声明名称为a的单精度浮点型变量（默认值为0.0）float b = 5.0f; //声明名称为b的单精度浮点型变量（初始化值为5.0） 单精度浮点型变量在内存中占据32个bit位（4字节），相比整型，它存在指数位，分布如下： 取值范围为：-2^128 ~ 2^127 即：-3.40E+38 ~ +3.40E+38 注：java中如果单独写一个类似0.1这样的小数，默认是双精度，如果用float接收，会报错，一般需要在小数后面加个f修饰符（隐式类型转换）。 1.5：双精度浮点型双精度变量在java中的声明方式如下： 代码块512float a; //声明名称为a的浮点型变量（默认值为0.0）float b = 5.0; //声明名称为b的浮点型变量（初始化值为5.0） 双精度浮点型变量在内存中占据64个bit位（8字节），相比单精度浮点型数据，它用来存放指数和尾数的位数明显更多，分布如下： 1.6：字符型字符变量在java中的声明方式如下： 代码块612char a; //声明名称为a的字符型变量（默认值为0，对应的字符为空字符，BLANK）char b = '我'; //声明名称为b的字符型变量（初始化值为汉字'我'，对应的Unicode码为25105） 字符型变量在内存中占据16个bit位（2字节），java语言的字符基于Unicode，无论是数字、字母，还是汉字，均占2个字节。 按照16位的保存方式，char的数字取值区间为：0 ~ 65535 1.7：字节字节变量在java中的声明方式如下： 代码块712byte a; //声明名称为a的字节变量（默认值为0）byte b = 5; //声明名称为b的字符型变量（初始化值为5） 字节变量在内存中占据8个bit位 取值区间为：(-2^7) ~ (2^7)-1 即：-128~127 一个字节就是一个数字，字节存储的数字聚合在一起就变成了字节流（byte[]）字节流可以被不同的编码方式解码成具体某一个字符或者某一段语句，现有的文本信息，在计算机中以字节的方式进行存储，存储前通过某种编码方式编码，获取到时通过同样的编码方式解码即可获取到具体的文本信息。 1.8：布尔值布尔类型的变量在java中的声明方式如下： 代码块812boolean a; //声明名称为a的布尔变量（无初始化值时，默认值为false）boolean b = true; //声明名称为b的布尔变量（初始化值为true） 这种类型的变量只有true或false两种值，用来表示真或假。 布尔变量在内存中占据8个bit位（1个字节，存在争议，JVM规范中提到应占4个字节）。 二、字符串类型&amp;引用变量上面所有的类型，均为java的基本类型，除了基本类型变量，其他的所有变量均为引用变量，这里介绍一种引用变量：String String相比char只能表示一个字符来说，它可以用来表达一段话，它的声明方式如下： 代码块9123String a; //声明名称为a的String类型变量（由于其非基本类型，因此a属于引用变量，引用类型变量在不赋值的情况下默认值为null）String b = \"这是一段话\"; //声明名称为b的String类型变量（初始值为：这是一段话），常用的声明字符串的方式String c = new String(\"这是一段话\"); //声明名称为c的String类型变量（初始值为：这是一段话）这种写法不建议 字符串的拼接也很简单： 代码块10123String a = \"哔哩哔哩 \";String b = \"乾杯~\";String c = a + b; //c最终的结果为：哔哩哔哩 乾杯~ 三、基本类型转换我们按照基本类型所能表示的数值范围来区分它们的大小，现可以做出如下排序： 所谓类型转换，就是java语法里为了程序严谨性所做的一层保护，举个例子，一个比较大的类型long，声明了一个变量，我们记为α，现在用一个比较小的类型int来接收α，这在java的语法里是不允许的，因为你不知道α的大小是不是已经超出int型所能表达的范围值了，但是相反的，如果现在声明一个int型的变量，我们记为β，这时使用long型接收β在java的语法里是允许的，因为int型的数顶天了也不可能超过long型所能表达的范围，所谓基本类型的转换就是这么回事，下面来看看具体的场景。 注：布尔类型是不参与类型转换的 4.1：强制转换通过上面简短的介绍，已经知道了java为什么要做一些类型转换的操作，那么哪些情况下需要做强制类型转换呢？ 按照类型大小排列，long型可以接收int型数据，而int型要想接收long型数据，就需要做强转，语法如下： 代码块1012345long γ = 1; //声明long型的变量γint λ = (int) γ; //声明int型的变量λ，由于int型表示范围比long型小，因此有超范围的风险，因此java要求必须做一层强转 int α = 1; //声明int型的变量αlong β = α; //声明long型的变量β，使其值等于α，由于long型表示范围比int型大，因此α不需要做类型强转 比较特殊的就是short和char型变量，它们俩由于位数相同，虽然表达的取值范围不同，但是其类型大小在java眼里是相同的，所以它们俩需要互转，不存在谁比谁大的情况： 代码块11123456//short和char不管由谁接收谁，均需要强转short γ = 1;char λ = (char) γ; char α = 1;short β = (short) α; 这个规则放到方法传参时同样是适用的： 代码块121234567891011public static void main(String[] args) { short param1 = 1; method(param1); //method接收的参数是int型，声明的参数值却是short型，short比int表达范围小，因此调用method时，不需要强转 long param2 = 1; method((int) param2); //method接收的参数是int型，声明的参数值却是long型，调用method时，需要强转}//这是一个接收int型参数的方法public static void method(int param) { //方法逻辑省略...} 4.2：自动转换自动转换就是指取值范围小的数据类型可以自动转换成取值范围大的数据类型。 需要结合4.1理解，4.1介绍了强制类型转换，例子中不需要强转的统统都是自动转换的，如代码块10中的α和β的类型转换： 代码块1312int α = 1; //声明int型的变量α，值为1long β = α; //声明long型的变量β，使其值等于α的值，由于long型表示范围比int型大，因此α的值不需要做类型强转，但其实是α的值类型已经自动转成long了 四、小结通过本节，我们知道了java里的基本数据类型，字符串类型，以及引用变量的简单介绍。 下一节将会介绍java中的运算符，让本节里的数据通过运算”活起来“。","link":"/2020/02/26/LV1-2%EF%BC%9Ajava%E4%B8%AD%E7%9A%84%E5%8F%98%E9%87%8F%E7%B1%BB%E5%9E%8B/"},{"title":"LV1-4：条件语句&循环语句","text":"通过前面的介绍，我们已经了解了变量和运算符，通过运算符可以将多个变量进行不同的运算，这已经可以做出一个计算器了，可是一段具备各种逻辑的程序，仅靠简单的运算是无法完成的，于是，我们便有了各种条件语句和循环语句，用来组合运算逻辑，从而实现更为复杂的业务逻辑。 .heimu { color: #000; background-color: #000; } .heimu:hover { color: #fff; } 一、条件语句1.1：if、else if、else先来看一个例子： 代码块112345678910111213141516171819202122public static void main(String[] args) { int a = 1; if (a == 1) { //这里放a等于1时的逻辑代码 } else if (a == 2) { //这里放a等于2时的逻辑代码 } else if (a == 3) { //这里放a等于3的逻辑代码 } else { //如果a不满足上面任意一个条件，则走这里的逻辑 }} 这就是if条件语句的基本用法，它一定是以if开头的，如果除了if头的条件不满足，还需要别的判断条件，则使用else if，如果没有任何满足的条件时需要做进一步处理，则使用else，条件语句括号内的语句，一定是一个关系运算式，结果为true或false，结果为true，则走对应的代码块，它的运行模式如下： 由图知：if语句从上到下开始判断，一旦碰到条件满足的，就执行满足条件的代码块，其余代码块不再运行，思考，下方哪个代码块会执行？ 代码块21234567891011121314public static void main(String[] args) { int a = 3; if (a == 1) { //代码块1 } else if (a == 2 || a == 3) { //代码块2 } else if (a == 3) { //代码块3 } else { //代码块4 }} 首先，第二个条件语句（a == 2 || a == 3）和（a == 3）都是true，那么究竟是执行代码块2还是执行代码块3呢？答案是代码块2，因为上面已经说过了，判断时只要遇到一个true，就直接执行对应的代码块了，其余的代码块都不会生效。 ok，看完上面的案例，再来说下if语句本身，if语句的else或者else if是可以不存在的，比如我现在仅做一个最基本的判断： 代码块31234567int a = 3; if (a == 1) { //代码块1} //其它代码 这段代码的意思是说，只要a的值为1，就会执行代码块1，其它不需要做任何判断，同样的，if可以跟一个else使用： 代码块4123456789int a = 3; if (a == 1) { //代码块1} else { //代码块2} //其它代码 这段代码的意思是说，如果a的值为1，则运行代码块1，如果a的值不等于1，则运行代码块2. if也可以单独跟一个或多个else if一块使用： 代码块512345678910int a = 3; if (a == 1) { //代码块1} else if(a == 2) { //代码块2} //其它代码 这段代码的意思是说，如果a的值为1，则运行代码块1，如果a的值为2，则运行代码块2。 1.2：switch、case语法如下： 代码块6123456789101112131415161718public static void main(String[] args) { int a = 2; switch (a){ case 1: //代码块1 break; case 2: //代码块2 break; case 3: //代码块3 break; default: //代码块4 }} 语法规范：switch括号内的类型只能是基本类型、枚举类、String，一个switch里可以包含多个case，default可以写也可以不写。 它是用来做什么的呢？ 其实它有些像if语句，用来匹配符合规则的代码块，以代码块6为例，它的执行流程如下： 可以看到，switch也是自上到下根据条件判断出需要执行的代码块，那么这个break又是什么意思呢？根据图2可以发现它是用来终止程序用的，如果少了break会发生什么？如下图，现在我们把程序里的break去掉： 可以看到，如果在case2的代码里没有做程序终止，则从case2开始往下的每一项都会触发执行。 那么，default这一项是干嘛的？这个其实跟if里的else类似，就是switch内的值在case内没有任何匹配项的时候，默认触发的代码块，此外switch是允许不定义此项的。 ok，了解了switch的执行流程，那么请思考一下下方这个结果应该输出多少？ 代码块71234567891011121314int a = 2; switch (a){ case 1: System.out.println(1); break; case 2: System.out.println(2); case 3: System.out.println(3); break; default: System.out.println(\"default\");} 答案：输出2和3 那么下面这个输出什么呢？ 代码块8123456789101112131415int a = 233; //注意这里a的值变了 switch (a){ case 1: System.out.println(1); break; case 2: System.out.println(2); break; case 3: System.out.println(3); break; default: System.out.println(\"default\");} 答案：default 二、循环语句2.1：for循环语句语法如下： 代码块91234567public static void main(String[] args) { for (int i = 0; i &lt; 10; i++) { System.out.println(i + \"哔哩哔哩干杯\"); } } 上面这个程序会输出10个字符串，即：0哔哩哔哩干杯 ~ 9哔哩哔哩干杯，for循环是如何运行的？它是以什么为依据运行10遍的？下面我们来拆解下它的语法： 如图4，根据对括号内的了解，我们来梳理下代码块9里的执行过程： 请仔细阅读图5中的流程，这是推动for循环执行的流程。 学完了if语句和for循环，我们来写一个程序，程序要求：输出0~9里的奇数和偶数，最后将它们按照空格分开打印出来： 代码块101234567891011121314151617public static void main(String[] args) { String odd = \"\"; //声明存放奇数数据的字符串 String even = \"\"; //声明存放偶数数据的字符串 for (int i = 0; i &lt; 10; i++) { //循环运行，每次i+1，一共循环10次，i的赋值范围为0~9 if (i % 2 == 0) { even += i + \" \"; //如果被2整除，则说明是偶数，加空格后拼在even后面 } else { odd += i + \" \"; //如果不能被2整除，则说明是奇数，加空格后拼在odd后面 } } System.out.println(\"0~9中的奇数为：\" + odd); System.out.println(\"0~9中的偶数为：\" + even); } 输出结果为： 代码块11120~9中的奇数为：1 3 5 7 90~9中的偶数为：0 2 4 6 8 2.2：while、do whilewhile循环的语法如下： 代码块1212345678910public static void main(String[] args) { int i=0; while (i&lt;10){ System.out.println(i + \"哔哩哔哩干杯\"); i++; } } 这个跟代码块9输出一样，也是：0哔哩哔哩干杯 ~ 9哔哩哔哩干杯，先来说下while这个单词本身的意思，它的意思是“当….的时候”，所以while(i&lt;10)这句话就很好理解了，就是当i的值小于10的时候，运行while循环体里的代码，相比for循环，while理解起来相对简单，它的运行流程图不再画。 do while跟while类似，将代码块12里的代码利用do while改造一下： 代码块1312345678910public static void main(String[] args) { int i = 0; do { System.out.println(i + \"哔哩哔哩干杯\"); i++; } while (i &lt; 10); } 输出结果跟while一致，那你可能要问了，while和do while有啥区别？ 来看下它们的执行流程图： 这就是它们的区别，while上去就会判断条件是否满足，从而决定是否走下去，而do while往往上去就会触发一次循环体，然后才做判断决定是否再次触发循环体。 按照代码块13的逻辑来说，while和do while确实没差别，因为i一开始确实小于10，所以第一次的时候无论如何都会触发一次循环体里的逻辑，是否先判断条件已经无所谓了，我们来举一个不一样的例子： 代码块1412345678910public static void main(String[] args) { int i = 10; do { i--; System.out.println(i + \"哔哩哔哩干杯\"); } while (i &gt; 0 &amp;&amp; i &lt; 10); } 这段代码输出为：9哔哩哔哩干杯 ~ 0哔哩哔哩干杯 我们现在用while改造一下： 代码块1512345678910public static void main(String[] args) { int i = 10; while (i &gt; 0 &amp;&amp; i &lt; 10) { i--; System.out.println(i + \"哔哩哔哩干杯\"); } } 这段代码啥也不会输出，因为while会先判断循环条件是否成立，再决定走不走循环体，而需要i&lt;10成立的i–操作却在循环体内，因此代码块14成功执行，而代码块15未成功。 三、数组&amp;for增强3.1：数组是什么？我们前面讲基本类型变量时说过，设置一个变量的步骤是：①声明、②赋值、③使用，但是当时的变量都是我们一个个声明的，有没有一种方式可以一次性声明n个变量呢？数组就是这样一种结构，它允许一次性声明n个变量，并且支持逐个赋值，数组跟基本类型一样，也需要声明，声明方式为： 代码块1612int[] nums = new int[10]; //这种声明方式只是简单的定义了一个容量为10的int型数组，并未给内部的元素赋值int[] nums2 = {1, 222, 334, 566, 256}; //这种声明方式就是连带着初始值给每个元素都赋上了，这里是指从0~5的下标的元素值分别为：1, 222, 334, 566, 256 上述的代码的第一段就是声明了一个同时声明了10个int型变量的数组变量（套娃中…），也是常用的数组声明方式，那么之前也说过了，java除了基本变量之外，其余全都是引用变量，因此，数组类型也是一种引用变量，引用变量的原理性质的东西到讲类的时候会细说。 数组到底是什么？代码块16那样的做法会发生什么？ 先说下数组的结构，数组就是包含了多个元素的集合，例如代码中的nums，本身就一次性声明了10个int型元素，那么我们知道int型如果不给赋值的话，它的默认值是0，如何给数组里的元素赋值呢？这里就要引出一个叫做下标的东西，下标的含义就是指元素本身在数组中的位置，下标从0开始计算，nums在完成声明后的结构如下： 那么现在我如果要给下标5的数赋值为256，该如何操作呢？看代码： 代码块171nums[5] = 256; 利用数组变量，将下标值放进去，即认为操作的就是对应元素本身，因此利用等号赋值即可，赋完值的nums如下： 下标为5的int型数据元素已经被成功赋值了。 那么如何批量赋值呢？这样一个个的赋值太麻烦了，如果现在有一个size为10000的数组，这样一个个赋值会死人的~还记得本节所学的内容吗？循环啊，就不能利用循环赋值吗？比如for循环，完全可以把循环体里的i变量当成下标访问数组里的元素哇，现在我们利用循环操作，来给nums这个数组的每个元素都赋上256： 代码块18123456789public static void main(String[] args) { int[] nums = new int[10]; for (int i = 0; i &lt; 10; i++) { nums[i] = 256; //利用i当做nums的下标来访问它里面的元素 } } 这样nums里面的每一个元素的值就都是256了~ 再思考一个问题，这里因为我们事先知道了nums的元素个数是10个，下标是0~9，所以for循环里的i初始化为0，每次自增1，且自增至9终止循环，正好把nums里的每个元素赋值一遍，那如果我们事先不知道数组大小该怎么办？这时可以利用数组变量自带的方法length来获取数组的大小： 代码块19123for (int i = 0; i &lt; nums.length; i++) { //nums.length返回的就是数组大小，本例中就是10 nums[i] = 256;} 我们现在知道了根据数组的下标可以访问数组内具体的元素，通过循环体可以按照循环自增的i值快速访问整个数组（这个过程叫做“遍历”），那么现在我想要输出整个数组里每一个元素的值就变得很简单了，依然是for循环： 代码块20123for (int i = 0; i &lt; nums.length; i++) { System.out.println(nums[i]); //仍然是i当下标，将对应的数值输出即可} 3.2：for增强遍历数组其实除了上述的方式之外，还有一种增强方式，写法如下： 代码块21123for (int num : nums) { System.out.println(num);} 可以看到，for增强连下标都省去了，直接使用数组的基本类型接收都行，它是用来简化数组遍历的一种方式。 3.3：二维数组&amp;for嵌套上面介绍了数组，数组就是简单一批数据，那么二维数组又是啥？ 相比一维数组，二维数组跟它的名字一样，具有横竖两个维度的元素，它的结构如下： 可见，相比一维数组，二维数组定位到一个元素需要两个下标，那么给二维数组里的每一个元素赋值就不能用一个for循环来进行了，这时需要借助我们的for嵌套： 代码块221234567891011121314151617181920212223public static void main(String[] args) { int[][] a = new int[5][5]; //获取横向的长度 int lenX = a.length; //获取纵向的长度 int lenY = a[0].length; for (int i = 0; i &lt; lenX; i++) { for (int j = 0; j &lt; lenY; j++) { a[i][j] = 1; } } //遍历与打印 for (int i = 0; i &lt; lenX; i++) { for (int j = 0; j &lt; lenY; j++) { System.out.print(a[i][j]); } //每遍历完一遍横轴的元素，则换一次行 System.out.println(); }} ❓ 思考：请仔细阅读上面的代码，根据自己学过的for循环，想象一下for嵌套的执行顺序。","link":"/2020/03/02/LV1-4%EF%BC%9A%E6%9D%A1%E4%BB%B6%E8%AF%AD%E5%8F%A5&%E5%BE%AA%E7%8E%AF%E8%AF%AD%E5%8F%A5/"},{"title":"LV1-3：java中的运算符","text":".heimu { color: #000; background-color: #000; } .heimu:hover { color: #fff; } 一、运算符1.1：算术运算符算术运算符主要包含： 运算符 说明 示例 备注 + 加法 a + b 计算变量间的和 - 减法 a - b 计算变量间的差 * 乘法 a * b 计算变量间的积 / 除法 a / b 计算变量间的商 % 取余 a % b 计算变量间的余 ++ 自增1 a++ 或 ++a 等效于：a = a + 1; 或者 a += 1;(+=在下面赋值运算符会介绍)++放变量前面和后面，是有区别的，具体请参考第二部分的例3 – 自减1 a-- 或 --a 等效于：a = a - 1; 或者 a-=1;(-=在下面赋值运算符会介绍)跟++一样，也有前后之分。 表1 1.2：位运算符位运算符包含： 运算符 说明 示例 特性 &amp; 与运算 a &amp; b 1&amp;1=1、1&amp;0=0、0&amp;1=0、0&amp;0=0 | 或运算 a | b 1|1=1、 1|0=1、 0|1=1、 0|0=0 ~ 取反 ~a ~1=0、~0=1 ^ 异或运算 a ^ b 1^1=0、1^0=1、0^1=1、0^0=0 &gt;&gt;&gt; 无符号右移 a &gt;&gt;&gt; b 参考注1 &gt;&gt; 右移运算 a &gt;&gt; b 参考注1 &lt;&lt; 左移运算 a &lt;&lt; b 参考注1 表2 ⚜️ 注1： 关于位运算的一切，请参考：JAVA有关位运算的全套梳理 1.3：赋值运算符赋值运算符主要包含： 运算符 说明 示例 备注 = 赋值 a = 1 让等号左边的值等于右边的值，这在之前的示例代码里已经体现过很多次了，简单一个变量声明的初始化值都需要用到赋值运算符：int a = 1; += 做加法操作后并且赋值给自身 a += 2 等效于：a = a + 2这种等式一般是从右往左执行，所以该表达式的意思是：先让a自身加上2，然后再把这个结果重新赋值给a。 -= 做减法操作后并且赋值给自身 a -= 2 同上，只不过换成减法 *= 做乘法操作后并且赋值给自身 a *= 2 同上，只不过换成乘法 /= 做除法操作后并且赋值给自身 a s/= 2 同上，只不过换成除法 %= 做取余运算并且赋值给自身 a %= 2 同上，只不过换成取余运算 &lt;&lt;= 做左移运算并且赋值给自身 a &lt;&lt;= 2 等同于：a = a &lt;&lt; 2 &gt;&gt;= 做右移运算并且赋值给自身 a &gt;&gt;= 2 等同于：a = a &gt;&gt; 2 &gt;&gt;&gt;= 做无符号左移运算并且赋值给自身 a &gt;&gt;&gt;= 2 等同于：a = a &gt;&gt;&gt;2 &amp;= 做与运算并且赋值给自身 a &amp;= 2 等同于：a = a &amp; 2 |= 做或运算并且赋值给自身 a |= 2 等同于：a = a | 2 ^= 做异或运算并且赋值给自身 a ^= 2 等同于：a = a ^ 2 表3 1.4：关系运算符关系运算符用来运算两个值的大小、是否相等等关系，经过关系运算符运算后的两个值的结果一定是boolean类型的，结果只有真或假。 关系运算符主要包含： 运算符 说明 示例 备注 &gt; 大于 a &gt; b 参考注2 &gt;= 大于等于 a &gt;= b 同上，判断关系为大于等于 &lt;= 小于等于 a &lt;= b 同上，判断关系为小于等于 &lt; 小于 a &lt; b 同上，只不过判断关系为小于 == 等于 a == b 参考注3 != 不等于 a != b 参考注4 表4 ⚜️ 注2： 用于判断两个值大小，需要注意的是，比较大小的关系运算符无法用来比较大部分的引用变量，因此不存在cat1 &gt; cat2这种代码。 代码块1123char a = '我';int b = 25105;boolean d = a &gt; b; 上面结果为false ⚜️ 注3： 用来判断两个变量是否相等： 代码块21234567//声明a、b、c，并为它们赋初始值int a = 1;int b = 1;int c = 2;//运算符==返回的是布尔型数据，因为其判定结果只有真或假两种状态boolean d = a == b;boolean e = a == c; 如上代码，d的结果为true，e的结果为false 简单的基本类型，判等方式是很简单的，值一样，就相等，哪怕类型不一致： 代码块3123char a = '我';int b = 25105;boolean d = a == b; d的结果值依然是true，因为汉字“我”对应的Unicode码值就是25105。 通过上面两个例子，可以发现基本类型的判等很单纯，就是看数值是否相等而已。 ⚠️下面的内容建议看完LV3-1后再来阅读 既然==是用来为变量判等的，那它是否也能用来判断复杂的引用变量是否相等呢？ 现在让我们回忆一下LV3-1里的那只猫，通过那只猫的例子，我们知道了引用变量其实是一个保存了某个内存地址的变量，它并不是一个实际的对象，它只是保存了实际对象的地址，方便通过它在内存中访问到那块对象数据，我们还知道，当一个类利用其构造方法被new出来的时候，它就产生了一个对象，对象就会存在一块内存区域内，此时对象自然就有了对应的内存地址，而将该地址赋值给对应的引用变量，这样就可以通过此引用变量访问具体的对象内容了，如果还是不太熟悉这个过程，请再次翻看LV1-2中的图7。 现在我们仍然用那个猫类来说明问题： 代码块4123456789101112public static void main(String[] args) { int gender = 1; int age = 5; int color = 1; String name = \"加菲\"; Cat cat1 = new Cat(gender, age, color, name); Cat cat2 = new Cat(gender, age, color, name); boolean result = cat1 == cat2; System.out.println(result);} 由上面的代码可知，我们造出来了两只猫，它们的各项属性全部一致，那么现在请思考一下，引用变量cat1和引用变量cat2是否相等呢？上面的结果应该是true还是false？ 输出结果为false。 为什么呢？它们明明什么都一样！！回忆一下我们在上一节有关引用变量的解释，引用变量保存的是内存地址，而我们这个例子中，造出了两只猫，尽管它们啥都一致，但事实上，这种一致你可以理解成“巧合”，碰巧有两只名字都叫加菲的5岁黑色公猫， 所以实际上它们是不同的两个对象，它们在地球上所处的位置不可能穿透对方的身体重合存在，抽象到计算机层面，它们需要存储在不同的存储单元内，存储单元不同，自然存储地址不同，那么cat1和cat2又怎么会相等呢。 那么现在再思考下，如何让cat1和cat2相等？ 现在让我们改造下上面的代码： 代码块5123456789101112public static void main(String[] args) { int gender = 1; int age = 5; int color = 1; String name = \"加菲\"; Cat cat1 = new Cat(gender, age, color, name); Cat cat2 = cat1; //这里把cat1直接赋值给cat2 boolean result = cat1 == cat2; System.out.println(result);} 这时结果就为true，这里应该都理解为什么了，因为cat1本身是引用变量，保存的是new出来那个对象的内存地址，现在直接把它的值赋值给cat2，因此cat2里保存的地址跟cat1中是一样的，所以它们一定是相等的。 ⚜️ 注4： 跟==性质一样，只不过它用来表示不等于，运算方式跟==相反。 所以： 代码块6123char a = '我';int b = 25105;boolean d = a != b; 这个例子把==换成!=后，输出结果就为false了，引用变量就不举例了。 1.5：逻辑运算符讲完了关系运算符，现在再来认识下逻辑运算符，逻辑运算符主要用来运算两个或多个布尔值间的真假，因此逻辑运算符两边连接的变量必须是boolean类型的数据。 运算符 说明 示例 备注 &amp; 与运算 a &amp; b 参考注5 | 或运算 a | b 同注5，作为逻辑运算符来讲，逻辑同“或” ^ 异或 a ^ b 同上，只是逻辑同“异或” ! 非 !a 参考注6 &amp;&amp; 短路与 a &amp;&amp; b 参考注7 || 短路或 a || b 跟或运算的区别跟上述短路与和与运算的区别一致，即条件1如果成立(true)，则不再进行后续条件的执行与判断，因为true跟任意boolean值相或，结果一定是true。 表5 ⚜️ 注5： 没错，又是这个符号，我们在1.2里的位运算符里已经碰到过了，只不过1.2里它连接两个非boolean类型的变量，用来表示两个变量的二进制数的与运算， 这里它被用来连接两个boolean类型的变量时，由于boolean类型的数据仅有真和假两种状态，因此它仅用来做简单的与门转换： 代码块7123456boolean a = true;boolean b = false; boolean c = a &amp; b; //a和b相与 System.out.println(c); 结果为false，因为true &amp; false = false 结合1.4里的关系运算符，可以知道任意关系运算符连接的式子，其结果一定是一个boolean值，那么我们可以写更为复杂的相与代码： 代码块8123456789int a = 1;int b = 1; int c = 5;int d = 6; boolean r = (a == b) &amp; (c != d); System.out.println(r); 结果为true，因为使用关系运算符==连接的a、b结果为true，而用!=连接的c、d的结果也为true，那么最终符号&amp;连接的boolean值就被简化成了：true &amp; true 结果自然是true，利用这种特性我们后续在java程序里可以做很多逻辑判定，比如我们之前举得Cat类里的run方法： 代码块91234567public void run() { if (age &gt; 10) { //这里就是一个逻辑判定，利用关系运算符&gt;连接两个数，当age大于10的时候条件成立为true，输出10km/h，否则输出下面的15km/h System.out.println(\"奔跑速度：10km/h\"); } else { System.out.println(\"奔跑速度：15km/h\"); }} ⚜️ 注6： 类似位运算里的按位取反~，即让自己的结果值反过来，例如： 代码块10123456int a = 1;int b = 1; boolean c = !(a == b); System.out.println(c); a == b这个关系语句的结果肯定是true，但是它在外层加了!，意味着结果要跟实际值反过来，因此c的结果为false。 ⚜️ 注7： 相比&amp;，短路与更加“智能”，如果第一个条件不成立，则直接返回结果，这么说不容易理解，下面通过一个例子来说明： 代码块111234567891011int a = 1;int b = 1; int c = 5;int d = 6; boolean r1 = (a != b) &amp; (c != d);boolean r2 = (a != b) &amp;&amp; (c != d); System.out.println(r1);System.out.println(r2); 上面r1和r2的执行结果是一致的，都是false，但执行的方式却不一样： 上述就是短路与和正常与参与运算时的区别，但是如果第一个条件成立(true)，仍然需要进行后续条件的判断，这时与&amp;无异，但短路与总是尽可能的减少关系运算的次数。 一般建议使用短路与做与逻辑运算。 1.6：三元运算符通过对上面关系运算符的了解后，现在来了解一种特殊的运算符：三元运算符（xx ? yy : zz）。 三元运算符会结合赋值运算符和关系运算符合计使用，旨在挑选符合自己预期的值（其实跟后面要讲的条件语句if/else有些像）。 现在来简单了解下其结构： 上图展示了一个三元表达式以及其组成部分。 最终s的值为11； 我们还可以嵌套三元表达式： 代码块1212345678//声明变量&amp;赋值int a = 1;int b = 2;int c = 5;int d = 6; int s = (a &gt; b) ? 10 : ((c &lt; d) ? 66 : 77); 首先判断a&gt;b是否成立，由a和b的值可知是不成立的，所以会跳过10这个结果，选取冒号后面的值，而冒号后面仍然是一个三元表达式，这个三元表达式的值为66，因此s最终等于66。理论上java允许你无限套娃，但为保证代码可读性，不建议嵌套三元表达式 二、运算符间的优先级2.1：运算顺序猜想我们在之前的示例代码里经常会看到类似下面这样的代码： 代码块13123int a = 1; //声明变量a，并通过赋值运算符为其赋值int b = 2; //声明变量b，并通过赋值运算符为其赋值int c = a + b; //声明变量c，然后通过赋值运算符为其赋值，值为a和b通过算术运算符”+“运算后的结果值 那么类似int c = a + b;这种语句，它的执行顺序为什么不是直接给c通过”=“运算符赋上a的值，然后再计算a和b的”+“运算呢？即： 如图，如果我们把int c = a + b;这种语句按照上图的拆分方式进行运算，那么这段代码的最终运行结果将是c等于a的值，其余无事发生，然而经过前面那么多示例，我们知道这是不对的，c的值应该等于a+b的运行结果才对，那么这就意味着加法运算发生在赋值运算之前，即： 真正的执行过程应该是图4中的过程，这样的结果似乎在告诉我们，运算符之间存在着某种等级，等级高的先执行，等级低的往后稍稍，这就是运算符之间的执行优先级，通过我们对int c = a + b;这种语句的了解，我们至少已经知道了”+“应该发生在”=“之前，即算术运算符应发生在赋值运算符之前执行。 2.2：运算符的优先级列表那么我们现在就来列一下所有运算符的执行优先级： 优先级（从高至低排序） 运算符 结合性 1 ( ) [ ] . 左→右 2 ! ~ ++ – 右→左 3 * / % 左→右 4 + - 左→右 5 &lt;&lt; &gt;&gt; &gt;&gt;&gt; 左→右 6 &lt; &lt;= &gt; &gt;= instanceof 左→右 7 == != 左→右 8 &amp; 左→右 9 ^ 左→右 10 | 左→右 11 &amp;&amp; 左→右 12 || 左→右 13 ? : 右→左 14 = += -= *= /= &amp;= |= ^= ~= &lt;&lt;= &gt;&gt;= &gt;&gt;&gt;= 右→左 表6 2.3：实例结合上面的表，我们通过几个例子来固化一下我们的记忆： 例1：括号的运算等级是最高的代码块14123int a = 1;int b = (a + 1) * 2; //这里由于括号运算符的优先级高于一切，所以括号内的内容a+1先被执行int c = (a + b) + (22 + 5); //如果有多个括号，则依据\"结合性\"可知，应该由左至右执行，因此这里的执行顺序为先执行a+b，再执行22+5 这个符合数学里的运算规则，例如： 乘除法的优先级高于加减法，所以类似“int c = a + b * 2”，首先计算的是b2的值，然后再拿着b2的结果跟a相加，但是如果改成“int c = (a + b) *2”的话，就变成先执行括号内的加法运算，然后拿着和去和2相乘。 例2：括号、非运算、与运算、或运算结合普通非运算+括号： 代码块151234//非int a = 1;int b = 2;boolean s = !(a &lt; b); // 按照优先级，括号内的先运算，a&lt;b结果为true，然后再运算仅次于括号的运算符!，最后赋值给s，s的值为false 嵌套非运算： 代码块16123456int a = 1;int b = 2; boolean s = !!(a &lt; b);// ↑首先计算优先级高的括号内的值，为true，然后同级非运算的结合性按照从右到左，因此右侧的\"!\"首先参与运算，// 结果为false，然后拿着结果再用最外侧的\"!\"参与运算，结果为true 括号、嵌套非运算、与、或运算结合： 代码块17123456int a = 1;int b = 2;boolean c = false;boolean d = true;boolean e = true;boolean s = !!(a &lt; b) &amp; c &amp; d | !!!e; 这个看起来很复杂，我们借助流程图来梳理下： 例3：i++、++i问题由表6可知++运算符优先级仅次于括号。 类似这种++的方式，有两种写法：a++和++a ++位于变量的前面和后面最终变量的结果都是一样的： 代码块18123456789//声明变量a和b，它们的值都是1int a = 1;int b = 1; a++; //a自增1，++放其后面++b; //b自增1，++放其前面 System.out.println(a);System.out.println(b); 最终输出结果都是2，那么++放前面和放后面有何区别呢？ 代码块1912345678910111213//声明变量a和b，它们的值都是1int a = 1;int b = 1; int c = a++; //a自增1，++放其后面，将a的值赋值给cint d = ++b; //b自增1，++放其前面，将b的值赋值给d System.out.println(a);System.out.println(b); System.out.println(c);System.out.println(d); 上面输出结果，a和b自然还是等于2，但是c和d却不相同： c最终等于1，d最终等于2. 首先我们知道++操作相当于变量自增，a++相当于a = a+1，所以类似这种语句： int c = a++; 相当于有两个赋值运算符： 先记住这个流程，下面来看下++放到变量后面和前面的区别： 所以 int c = a ++;这段代码是先执行的赋值运算符，因此c的值等于还没完成自增前的a。相反的，如果++放到自增变量前面，则意味着它的执行优先级高于赋值运算符，所以 int c = ++ a;这段代码是先执行++操作，然后再将++后的值赋值给c。 ❓ 思考：请问下方的a、b、c的最终值分别等于多少？ 代码块2012345int a = 1;int b = a++ + 1;int c = ++b + 1;System.out.println(b);System.out.println(c); 答案：a=2，b=3，c=4 三、运算符下的自动转型我们通过LV-2-四可以知道基本类型是会区分按照取值范围来区分大小的，我们再次把它们的大小等级贴出来： 我们还知道了小类型不可以接收大类型的数据，如必须要接收，需要做强转，而如果使用一个大类型接一个小类型的值，则这个小类型的值会自动转换成对应的大类型，这种类型的转换叫类型自动转换，贴一下当时的例子。 例1：代码块2112int α = 1; //声明int型的变量α，值为1long β = α; //声明long型的变量β，使其值等于α的值，由于long型表示范围比int型大，因此α的值不需要做类型强转，但其实是α的值类型已经自动转成long了 现在结合本节的运算符知识再来看下这个类型自动转换是如何发生的： 首先声明的α是一个int型，然后使用大类型的β接收，此时α的值（也就是1）已经自动转成了long型，这就是运算符导致了类型的转换，在本例中，=就是这个运算符（赋值运算符），因为α的值被赋给了β，因此α值的类型自动提升为long。 结论：运算符可以导致某些数据变量值的类型转换。 例2：代码块22123int a = 1;float b = 1;int s = a + b; //这是不允许的，经过加法运算，a的值已经被自动提升为float型，因此a+b的值是一个float型，较小的int是不能接收较大的float型的 上述注释内的内容用下图来描述： 其实最终都要回归到强制类型转换那一部分内容来。 现在改一下代码，解决上述问题： 代码块23123456int a = 1;float b = 1; float s = a + b; //这种改法就是直接用大类型接收或：int s = a + (int)b; //这种改法就是将大类型强转成小类型，这样它们经过加法运算后类型不会提升，还是int 参考注释，最终还是回归到要么用大类型接收小类型，要么强转的解决方法上来，针对例1，我们可以说是“=”运算符让变量α的值类型提升，而在本例，我们可以说是“+”运算符让a的值类型得到提升。 为了巩固这块的知识，再让我们改造下上面的代码： 代码块24123456int a = 5;int b = 2; float s = a / b; System.out.println(s); 这个结果是2.5吗？答案并不是，最终结果是2. 为什么？？明明5/2是2.5啊，这里结合前面的例子，你只需要稍微思考一下就可以得到答案： ❓ 思考：那如何才能得到自己想要的2.5呢？ 答案：很简单，只需要提升a+b的类型就行了，即：(float)a+b 或 a+(float)b，当然，两个都强转也行：(float)a+(float)b，这样在上图①处在除法运算时就会将a/b的结果提升为float，自然就不会失精。","link":"/2020/02/28/LV1-3%EF%BC%9Ajava%E4%B8%AD%E7%9A%84%E8%BF%90%E7%AE%97%E7%AC%A6/"},{"title":"LV2-1：类&引用变量的简单介绍","text":"一、类的简单介绍、什么是引用变量前面讲述完基本变量类型，现在说下引用变量类型，这里先简单介绍下java里非常重要的一个概念：类 1.1：什么是类？java是一个面向对象语言，那么什么是对象？类又和对象有什么关系呢？ 之前了解了所有的基础类型数据，我们可以用它们来搞个事情，现在，让我们用这些基本类型造只猫。 那么，我们现在需要提炼出来猫所具备的一些属性，比如，每只猫都有自己的生理性别，那么性别就可以是一个属性，每只猫可能还会有一个昵称，每只猫还会有它的年龄，当然，随便什么属性都可以，自己喜欢就好，都可以加进你的设计里，前提是这些属性是客观存在的事实。除了一些属性，猫还会有一些行为，比如吃饭、奔跑、叫、无法归类的迷惑行为等，把属性加上这些行为，一个猫类就被我们抽象出来了： 如上图所示，抽象后的数据结构，被我们称作一个类，类在java中无处不在，类内按照特性分为了两类，上方红色部分，我们称它为类的属性，属性主要用来描述一些客观存在的事实，比如猫确实有年龄，猫确实有生理性别等，而猫会叫，会跑等这些含主观意识构成的特性，我们管它叫类的方法，类方法可以用来描述这个类里所具备的具体功能，比如例子里的猫，具备吃饭的功能，具备跑的功能等，而很多时候，这些功能特性还会依赖自己的属性来决定功能的运行方式，比如猫在奔跑的时候可能会依赖自己的年龄，年龄大的猫奔跑速度可能赶不上年龄小的猫，这个时候奔跑这个功能便会受猫的年龄属性的影响。 这里简单了解下方法在java中的定义方式：类里的方法又叫函数（function），它的基本定义结构如下： 上面是一个简单的求两个数之和的方法（函数），它的逻辑是，计算输入的两个参数的和，并将其返回出去。 1.2：什么是对象？通过对1.1的理解，我们知道了类的基本概念，那么类就跟它的名字一样，属于对一类事物的描述，比如猫，猫是一个种群，因为猫都具备图1中的特性，所以猫这个种群可以用Cat类来描述，但是既然是种群，肯定存在个体差异，比如，你家的猫是母猫，他家的猫是公猫，你家的是白猫，他家的是黑猫，这种个体的差异没有越过类的描述，不管是公还是母，本质上都是一种生理性别（gender），那么如何解决这种细微的个体差异性呢？ 这时对象就出来了，我们来看下下面这个图： 如上图所示，利用Cat这个类的信息，对其内部属性赋值，就可以造出各种各样“符合类规则”的猫了，产生的这只猫，就叫做类的对象，每个类都可以产生许多许多个对象，这些对象符合类的基本定义，但是却各不相同。 1.3：利用java实现一个类、认识并理解引用变量 本篇文章旨在简单介绍java类是什么，重点介绍引用变量，主要结合图片理解，可以对类可以有个基本的认识以及更深层次的理解引用变量。 通过前面所有内容的了解，我们利用java代码来实现下Cat： 代码块112345678910111213141516171819202122232425262728293031323334353637383940//猫类的定义public class Cat { //性别：0雌，1雄 private int gender; //年龄 private int age; //毛色：1黑，2白 private int color; //昵称 private char name; //构造器：关键方法，用来制造对象，传入的这些属性值得以赋值到对象内部 public Cat(int gender, int age, int color, char name) { this.gender = gender; this.age = age; this.color = color; this.name = name; } //叫 public void cry() { //猫叫声的实现 System.out.println(\"喵喵喵~\"); } //吃 public void eat() { System.out.println(\"要恰饭的嘛\"); } //无法归类的迷惑行为 public void emm() { System.out.println(\"猪肉卷和千层面不存在二选一，我全都要！\"); } public void run() { if (age &gt; 10) { //假如奔跑速度跟年龄有关，年龄超过10岁，则速度变慢 System.out.println(\"奔跑速度：10km/h\"); } else { System.out.println(\"奔跑速度：15km/h\"); } }} 经过上述代码，我们已经完成了1.1中，有关猫类的抽象。 接下来，我们来完成1.2中的造对象过程，现在新造一个Test类用于测试（注：java所有的程序，都是以一个main方法开始的，这里通过Test类里的main方法来开始测试）： 代码块21234567891011121314public class Test { public static void main(String[] args) { //下面都是基本类型 int gender = 1; int age = 5; int color = 1; char name = 'A'; //这里将上方赋好值的数据，送入构造器，然后构造器构造出来对应的对象 Cat cat = new Cat(gender, age, color, name); cat.run(); //利用这个对象，调用它自身的run方法 }} 例子中通过new构造器来构造一个具体的对象，命名为cat，这个cat是一个变量，这种非基本类型的变量，叫做引用变量，引用变量相比基本类型，较为复杂，它内部其实存储的是一段地址，这段地址指向了具体的对象体，例子里就是通过构造器构造出来的对象本身，而cat.run()就是在利用这个引用变量cat访问具体的对象的run方法，通过代码块1，可以知道在age&lt;=10的时候，输出应该是15km/h，事实上运行一下这段代码确实是这个结果： 1奔跑速度：15km/h 目前做简单了解就好，后面会仔细讲，这个过程可以用下方流程图简单说明一下： 需要注意的是，与基本变量不同，引用变量不存在默认值，如果一个引用变量不进行赋值操作，那么它的“默认值”是null，即引用变量并没有指向任何对象实体，如果之前有听说过java鼎鼎大名的空指针异常（或称npe异常），那么空指针异常在多数情况下都是因为使用了一个值为null的引用变量去访问某个对象本体导致的。 通过上述的例子会发现，猫的名字是char类型，但是char类型仅能保存一个字符，如果我的猫名字叫“加菲”，对于Cat类，就是一件很棘手的事情了，因为“加菲”是由两个汉字字符组成的词语，那么这时候有没有一种类型可以用来接收它呢？ 字符串类型String就是用来做这个的，LV1-2里说过，它并非基本类型，它的声明方式如下： 代码块3123String a; //声明名称为a的String类型变量（由于其非基本类型，因此a属于引用变量，不赋值的情况下默认值为null）String b = \"加菲\"; //声明名称为b的String类型变量（初始值为：加菲）String c = new String(\"加菲\"); //不建议的写法，声明名称为c的String类型变量（初始值为：加菲） 这样，将Cat类改造下，将其内部的name改成String类型： 代码块41234567891011121314public class Cat { private int gender; private int age; private int color; private String name; //改成String类型 public Cat(int gender, int age, int color, String name) { //接收name参数时使用String类型接收 this.gender = gender; this.age = age; this.color = color; this.name = name; } ...方法省略，参考代码块1...} 此时的main方法改成如下： 代码块51234567int gender = 1;int age = 5;int color = 1;String name = \"加菲\"; //声明一个叫name的字符串，初始化值为”加菲“ Cat cat = new Cat(gender, age, color, name);cat.run(); 由于name也变成了一个引用变量，所以图4就变成了下方的流程： String为java自带的原生类，而Cat是我们自己定义的类，本质上都是类，未来编写java程序时，会用到很多类似String这样的java现成的类，自己实现一些业务逻辑时，需要创造自己的类，自己的类里也可以使用别的类，类似上述例子中，Cat类就是用了String类，只要是类产生的对象，对应它的变量一定是一个引用变量，引用变量永远是一段访问实际对象时的内存地址，如果一个对象在内存里失去了变量引用，则认为该对象废弃，这时JVM就会将其回收，这就是java的垃圾回收机制，这里不需要知道太多，反正后面都会讲，先了解下即可。","link":"/2020/03/02/LV2-1%EF%BC%9A%E7%B1%BB&%E5%BC%95%E7%94%A8%E5%8F%98%E9%87%8F%E7%9A%84%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D/"},{"title":"LV2-2：包的定义、类的基本组成、访问权限修饰符","text":"一、包包说白了就是一个个的文件夹，在java中，所有的类按照其特点，以包的形式进行做区分，包的目录层级命名规则一般是公司的网址倒过来，例如： 如上图所示，.java文件内就是存放的java代码，例如Cat.java文件里面放的就是上一节里那只猫的Cat类的代码，由于现在Cat类有了目录，所以它就需要在头部加上一句话： 代码块112345package com.bilibili.pet; //这句话位于代码首部，用于标识当前类的java文件在哪个目录下public class Cat { //代码省略..} 因为Cat有了相对目录，这里就需要加上package来标记自己所在的目录层级，否则报错。 再回到图1中，我们看下分包的目的是什么，从图1可以看到，基础包为com.bilibili（这里提一下，java代码里的包目录引用都是以“.”做分隔的，而不是斜杠），然后基础包下细分了俩包，一个是pet（宠物），一个是human（人类），这俩包下分别有两个java文件，pet下放的是Cat和Dog，而human下放的是Boy和Girl，所以其实包就是用来给类分类的（套娃警告），这里可能会晕，因为之前说过，类是用来描述一类事物的单元，那么既然这样，为啥还需要用目录再分割一层做分类呢？这其实是一个分类大小方向的划分，例如，粗略划分人类包下的类可以包含男生、女生、学生、老师，但是像猫狗明显和人类不是一回事，这时候就需要用一种更高层级的东西来做隔离，包就这样产生了，当然这个是没有绝对标准的，只要你喜欢，可以按照你的方式做分包，比如，你仍然可以认为，pet和human两个包可以合并为biology（生物），因为不管你是人类还是宠物，都是生物，所以对于包的划分，是个“哲学”问题，不过先不用担心，等写的多了，自然就会划分了，这一部分你只需要知道包是个什么东西，以及在存在包目录的情况下类要加package声明头即可。 二、如何使用代码定义一个类？2.1：类的定义和java文件上一节已经知道Cat类的代码了，只是没有细说一个类该如何定义，这次我们来讲下类是如何定义的，以及它和java文件是什么关系。 首先，新建一个叫Cat.java的文件，然后在这个文件里写入以下代码： 代码块2123public class Cat { } 保存，这样一个Cat类就就建好了，诶？？就这？ 是的，我们来拆解和分析一下这段代码： public是一种权限修饰符，可以控制被修饰内容的访问权限，在介绍完类的所有概念之前，不会涉及它的概念，这里只需要记住，一个java文件允许定义多个class，但只允许有一个public类，而且这个public的类名字一定要和这个java文件的命名一致，比如例子里的public的Cat类就定义在Cat.java里，我们还可以在一个java文件里加多个class，但是public的只能有一个。 代码块2里只是定义了一个空类，通过上一节内容，我们可以知道一个类所包含的内容大概有两大类，一个是属性，一个是方法（也叫函数，我们后面统称方法），所有的类都符合这个结构，类可以不定义任何属性，也可以不定义任何方法，这个没有硬性要求。 2.2：类的属性和方法上一节介绍过，这一节细分析下。 通过上一节的Cat我们会发现类的属性其实也是各种变量组成的，这种变量在类定义里叫做类的属性（之前也说过，类本身是一种信息模板，而类产生的对象才是我们需要访问的实际数据），而在类产生的对象里叫做对象的成员变量，成员变量在对象内部是可以在任意地方随意访问的，比如Cat类里所有方法都是可以直接访问到对象内的成员变量的。成员变量的作用域就是整个类对象，如果别的地方需要用到它们，则需要通过其对应的引用变量进行访问。 我们现在再把Cat类改造下： 代码块31234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677//猫类的定义public class Cat { //性别：0雌，1雄 private int gender; //年龄 private int age; //毛色：1黑，2白 private int color; //昵称 private String name; //构造方法，用于构造一个类对象 public Cat(int gender, int age, int color, String name) { //通过传入的参数，初始化自己对象内的每一个成员变量 this.gender = gender; this.age = age; this.color = color; this.name = name; } public void cry() { if (this.tooOld()) { //通过本类的私有方法来判断当前这只猫是否年龄太大了 System.out.println(\"叫不动了...\"); } else { System.out.println(\"喵喵喵~\"); } } public void eat() { System.out.println(\"要恰饭的嘛\"); } public void emm() { if (this.tooOld()) { System.out.println(\"骚不动了...\"); } else { System.out.println(\"猪肉卷和千层面不存在二选一，我全都要！\"); } } public void run() { if (tooOld()) { System.out.println(\"跑不动了...\"); } else if (age &gt; 10) { System.out.println(\"奔跑速度：10km/h\"); } else { System.out.println(\"奔跑速度：15km/h\"); } } //这个方法用来介绍自己 public String intro() { String gender = this.gender == 0 ? \"母\" : \"公\"; String color = this.color == 1 ? \"黑色\" : \"白色\"; //将这些属性值拼成一句间接返回出去 String result = \"我是一只名叫\" + name + \"有着\" + color + \"皮毛的\" + age + \"岁\" + gender + \"猫\"; return result; } //给猫加年龄的方法 public void plusAge(int plusCount) { this.age += plusCount; } //返回猫当前的年龄 public int getCurrentAge() { return this.age; } //private修饰的私有方法，私有方法仅允许本类内访问 private boolean tooOld() { return this.age &gt; 15; //如果年龄超过15岁，则返回true }} 我们改造了之前的旧方法，让猫的行为根据自己的年龄的不同再次发生改变，此外新增了intro方法用来返回出去自己的简介，plusAge用来增加猫的年龄，getCurrentAge用来返回猫当前的年龄，tooOld使用了private修饰，跟public一样属于访问权限，加了这个访问权限意味着在别的地方通过对象无法调用该方法，只能由对象内部触发调用，后面会着重介绍访问权限修饰符。此外，方法又分为两种，一种是有返回值的，比如getCurrentAge，一种是没有返回值的，比如plusAge，它们的区分方式在于访问权限修饰符public后面是void还是其它类型，如果是void则说明此方法没有返回值，否则就是返回值对应的类型（如int、long，返回结果为引用变量的话，则为对应的类，例如String、Cat等）。 现在拿着这个Cat类来做个试验，我们之前有说过，访问对象里面的方法或者属性时，需要通过引用变量来进行访问，引用变量又是通过初始化类对象来的，初始化类对象之前说过，通过new后面加上构造方法来进行构造一个类对象： 代码块41234567891011121314151617181920212223242526272829303132public static void main(String[] args) { //造出两只猫，现在我们有了两个引用变量，可以利用它们访问对象实体了 Cat cat1 = new Cat(0, 1, 0, \"咲川\"); Cat cat2 = new Cat(1, 5, 1, \"龟田志斌\"); String cat1Into = cat1.intro(); //这个方法会返回对应猫咪的简介，这里用一个变量接收 String cat2Into = cat2.intro(); System.out.println(cat1Into); //打印第一只猫的简介 System.out.println(cat2Into); //打印第二只猫的简介 System.out.println(\"------------------------------------\"); //为方便观察，这里用分割线隔开 cat1.emm(); //由于这里cat1对应的猫对象里的age为1，因此这里仍然可以打印迷惑语录 cat2.emm(); //由于这里cat2对应的猫对象里的age为5，因此这里仍然可以打印迷惑语录 System.out.println(\"------------------------------------\"); cat1.plusAge(15); //让川桑老15岁，由于plusAge的逻辑为原age加上传入的年龄增量，所以现在的咲川应为16岁 cat2.plusAge(6); //让龟田老6岁，由于plusAge的逻辑为原age加上传入的年龄增量，现在的龟田志斌应为11岁 //通过getCurrentAge把二位的年龄拿到 int cat1Age = cat1.getCurrentAge(); int cat2Age = cat2.getCurrentAge(); System.out.println(\"咲川当前年龄为：\" + cat1Age + \" \" + \"龟田志斌当前年龄为：\" + cat2Age); //这里再次打印出二位当前的年龄值 System.out.println(\"------------------------------------\"); //再触发一下它们的迷惑行为 cat1.emm(); //由于咲川现在为16岁，符合tooOld为true，因此这里打印骚不动了... cat2.emm(); //由于龟田志斌现在为11岁，符合tooOld为false，因此这里仍然打印迷惑语录} 上方代码块打印： 代码块512345678910我是一只名叫咲川有着白色皮毛的1岁母猫我是一只名叫龟田志斌有着黑色皮毛的5岁公猫------------------------------------猪肉卷和千层面不存在二选一，我全都要！猪肉卷和千层面不存在二选一，我全都要！------------------------------------咲川当前年龄为：16 龟田志斌当前年龄为：11------------------------------------骚不动了...猪肉卷和千层面不存在二选一，我全都要！ 通过这个例子我们会发现： 类在产生对象以后，可以利用引用变量来操纵它，具体引用变量可以调用对象的方法，甚至可以直接访问它的属性（能不能访问具体看访问权限修饰符，public或private等，后面讲） 类在产生对象后，每个对象都持有自己的属性和方法，互不干扰 对象内的方法可以访问对象内的任意成员变量以及其他方法（无视访问权限修饰符） 对象内某些方法可以改变成员变量的值，比如plusAge，它会重新给自己的成员变量赋值，而有些方法则不会，例如intro，它仅仅是拼接自己内部的成员变量 2.3：构造器构造器是类里的一个特殊的方法，注意，它也是一个方法，构造器特殊的原因在于它有且仅被触发一次，就是在类构造类对象的时候，一般你定义了一个类如果不写构造器，那就会默认一个构造器，例如代码块2里，虽然是个空类，但它有一个隐藏的构造器，即： 代码块6123456public class Cat { public Cat() { //不定义构造器，则默认有这样一个构造器，由于它并没有什么实际意义（因为{}内没有任何实质性的逻辑代码），所以java语法里允许不写 }} 而在代码块4里的构造器没有省略，因为它是有实际意义的，它的意义在于给成员变量赋值： 代码块712345678//构造方法，用于构造一个类对象public Cat(int gender, int age, int color, String name) { //通过传入的参数，初始化自己对象内的每一个成员变量 this.gender = gender; this.age = age; this.color = color; this.name = name;} 通过上面的代码我们可以发现构造器的特点，名称和类名一致，没有标记返回结果的修饰符（void关键词或其他返回类型），且在构造一个对象时必须要通过调用构造方法完成。 三、访问权限修饰符3.1：访问权限符介绍在前面所介绍的类定义、类属性定义、类方法的定义的最前端，都会有类似public、private这种修饰符，它们的意义和作用是什么呢？ 首先我们来介绍一下它们，它们是用来控制访问权限的修饰符，是编译器做访问语法检查时所做的判断依据，一般放到代码首部，可以用来修饰类、类的属性变量、类的方法，用来约定它们的访问权限。 关于表里父子类相关内容需要了解过继承后再去看 ps：这个访问权限，仅仅是根据类定义的上下文来判定的。 单看表和描述是很难发现它们的区别的，现在我们来举个具体的例子，我们现在再来改造下Cat类（修改了一些内容的访问权限，顺带精简了下代码）： 代码块812345678910111213141516171819202122232425262728293031323334353637383940414243public class Cat { public int gender; //gender字段改为public访问权限 protected int age; //age字段改为protected访问权限 int color; //color字段改成默认（default关键字可以省略不写）的访问权限 private String name; //name仍然是private访问权限 public Cat(int gender, int age, int color, String name) { this.gender = gender; this.age = age; this.color = color; this.name = name; } public void eat() { //eat方法仍为public访问权限 System.out.println(\"要恰饭的嘛\"); } protected void emm() { //emm方法改为protected访问权限 if (this.tooOld()) { System.out.println(\"骚不动了...\"); } else { System.out.println(\"猪肉卷和千层面不存在二选一，我全都要！\"); } } void run() { //run方法改为默认访问权限 if (tooOld()) { System.out.println(\"跑不动了...\"); } else if (age &gt; 10) { System.out.println(\"奔跑速度：10km/h\"); } else { System.out.println(\"奔跑速度：15km/h\"); } } private boolean tooOld() { //tooOld方法仍为private访问权限 return this.age &gt; 15; //如果年龄超过15岁，则返回true }} 3.2：举例说明：同一个类ok，现在让我们基于改造好的Cat类，从第1列的内容试起： 我们在写代码的时候也发现了，同一个类内部的所有属性、方法无视其访问权限，直接获取&amp;访问即可，现在再来试试这样： 由上图可以看到，同一个类定义内，如果存在另外一个相同类产生的对象，仍然可以通过其引用变量无视访问权限进行访问，因为它们属于同一个类，分析如下： 首先cry是Cat类的方法，接收的参数是Cat类产生的引用变量，因此在cry内可以无视访问权限，直接通过cat这个变量访问到所有的内容。 3.3：举例说明：同一个包我们现在再在同一个包创建一个Test类，在其main方法里做实验： 这是符合预期的，Test和Cat不属于同一个类定义，但它们在同一个包内，因此除了private的内容，均可访问。 3.4：举例说明：同包/不同包的父子类后面讲继承的时候会讲。 3.5：举例说明：不同包的类跟3.3相反，我们现在新建一个跟Cat不同包的Test类，然后用其main方法做实验： 这是符合预期的，Test和Cat不属于同一个类定义，且它们不在同一个包内，因此除了public的内容，均不可访问。","link":"/2020/03/05/LV2-2%EF%BC%9A%E5%8C%85%E7%9A%84%E5%AE%9A%E4%B9%89%E3%80%81%E7%B1%BB%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90%E3%80%81%E8%AE%BF%E9%97%AE%E6%9D%83%E9%99%90%E4%BF%AE%E9%A5%B0%E7%AC%A6/"},{"title":"LV2-3：变量的作用域","text":"通过对前面很多代码的了解，我们发现变量的声明通常发生在一个大括号内，被声明在某个大括号内的变量，它的作用域就对应的大括号内，不够直观？我们来通过一张图来说明一下： 如图所示，一个类定义代码，请仔细按照从上到下的顺序仔细阅读每一段说明。 每一个”{}”看做一个域，变量在哪个域做的声明，则在哪个域生效，上图已经按照颜色标明不同的域了。除此之外，变量的声明是在同域内不允许重名的，上述的loopTest的方法域里的age跟类域里的age重名，但是程序并不会报错，因为他俩作用域不一样。","link":"/2020/03/05/LV2-3%EF%BC%9A%E5%8F%98%E9%87%8F%E7%9A%84%E4%BD%9C%E7%94%A8%E5%9F%9F/"},{"title":"LV2-4：类的特性、关系","text":"一、继承和多态1.1：一个例子参考之前的Cat类，如果我现在让你设计一个Dog类，它仍然具备眼睛、性别等属性，也会跑、吃等动作，这个时候你一定会发现，单独再为Dog搞一套跟Cat差不多的类定义吗？就没有更聪明的办法吗？ 此时java里允许的类继承就可以起到作用了，想想我们的目标，我们的目标是让这些重复的属性不再重复定义一遍，那么像眼睛、毛色这种属性，或者跑、吃饭这类的操作就可以再拆出一个类：动物类 现在我们来定义下动物类： 代码块1123456789101112131415161718192021222324public class Animal { private String name = \"xx\"; //动物学名，动物们都有学名，这里默认为xx，因为动物类是用来描述动物的，动物有学名，但你并不知道是那种动物，name只能未知 private int age; //动物们的年龄 public void cry() { //控制叫声的方法 System.out.println(\"叫声为：未知\"); } public void eat() { //负责吃饭的方法 System.out.println(name + \"正在吃东西\"); } //用来给name赋值的方法 public void setName(String name) { this.name = name; } //用来给age赋值的方法 public void setAge(int age) { this.age = age; } } 然后再定义一下Cat和Dog类： 代码块2123public class Cat extends Animal { //让Cat类继承Animal类 } 代码块3123public class Dog extends Animal { //让Dog类继承Animal类 } Cat和Dog都是一个”空“类，但是分别利用extends关键词继承了Animal类，现在让我们进行如下测试： 代码块412345678910111213141516171819202122232425public static void main(String[] args) { //造一只9岁的猫 Cat cat = new Cat(); cat.setAge(9); cat.setName(\"猫\"); //让这只猫叫一声，再吃一口东西 cat.cry(); cat.eat(); //造一只10岁的狗 Dog dog = new Dog(); dog.setAge(10); dog.setName(\"狗\"); //让这只狗叫一声，再吃一口东西 dog.cry(); dog.eat(); //造一只10岁的狗，但不设置学名 Dog dog2 = new Dog(); dog2.setAge(10); //让这只狗叫一声，再吃一口东西 dog2.cry(); dog2.eat();} 上述程序输出结果如下： 代码块5123456叫声为：未知猫正在吃东西叫声为：未知狗正在吃东西叫声为：未知xx正在吃东西 可以看到，Cat和Dog虽然啥都没定义，但仍然可以使用Animal类里的方法，我们此时管Cat和Dog叫做Animal的子类，相反的Animal叫做Cat和Dog的父类。 可以通过这个例子发现，子类通过继承，可以得到父类的一些功能，需要确认的一个点是：在初始化完成一个子类初始化的同时其父类信息也会自动加载进子类，然后子类可以共享父类里的方法和属性。 这里说一下this关键词，它表示的是本类所产生的具体对象对其内部内容做访问时用的一个标识，你甚至可以省略不写。 1.2：父类方法覆盖通过上面的输出，我们发现，猫狗的cry方法输出的是Animal默认的内容，这时我们需要猫和狗能有自己的叫声，那么这时就可以选择重写父类的方法： Cat类重写父类的cry方法： 代码块61234567public class Cat extends Animal { @Override //加上@Override标识为方法重写 public void cry() { System.out.println(\"喵喵喵~\"); //这里重新定义方法的实现 }} Dog类重写父类cry方法： 代码块712345678public class Dog extends Animal { @Override public void cry() { System.out.println(\"汪汪汪~\"); } } 现在再运行下测试代码输出如下： 代码块81234喵喵喵~猫正在吃东西汪汪汪~狗正在吃东西 通过这个例子，我们可以知道，如果子类不想要父类里的实现，那么可以通过重写的方式重新设计对应的方法，例子中通过重写cry方法，让Cat和Dog都拥有了自己的cry方法。 1.3：子类方法扩展经过上面一步，我们知道猫和狗都是动物，所以它们离不开动物类里定义的属性和方法，但是猫和狗仍存在一些不太一样的地方，比如猫具有捕鼠的能力，但不具备看家的能力，而狗具有看家能力，却没有捕鼠的能力，这种相对比较独立的能力就可以用来扩展： Cat类新增捕鼠方法 代码块9123456789101112public class Cat extends Animal { @Override //加上@Override标识为方法重写 public void cry() { System.out.println(\"喵喵喵~\"); //这里重新定义方法的实现 } public void catchMice() { //扩展方法：捕鼠 System.out.println(\"我会捉老鼠\"); } } Dog类新增看家方法： 代码块10123456789101112public class Dog extends Animal { @Override public void cry() { System.out.println(\"汪汪汪~\"); } public void houseKeeping() { //扩展方法：看家 System.out.println(\"我会看家\"); }} 通过本例我们知道，子类是可以自由扩展的，通过子类的引用变量依然可以完成调用： 代码块1112345678public static void main(String[] args) { Cat cat = new Cat(); cat.catchMice(); Dog dog = new Dog(); dog.houseKeeping();} 输出： 代码块1212我会捉老鼠我会看家 1.4：多态现在来介绍下多态，多态是一种类和类之间的一种引用关系，因为有了继承，才有了多态这种特性，我们现在来改造下代码块4： 代码块131234567891011121314151617public static void main(String[] args) { Animal cat = new Cat(); //声明变量时，改成父类类型 cat.setAge(9); cat.setName(\"猫\"); cat.cry(); cat.eat(); Animal dog = new Dog(); //声明变量时，改成父类类型 dog.setAge(10); dog.setName(\"狗\"); dog.cry(); dog.eat(); } 运行如下： 代码块141234喵喵喵~猫正在吃东西汪汪汪~狗正在吃东西 仍然可以正常运行，并且被重写的方法cry仍然执行的是子类里的那个。 这就是多态，如果不太好理解，我们可以通过下图来加深一下记忆： 这种使用父类修饰的引用变量，可以指向其任意子类对象的行为，我们称为类的多态，可以发现父类接收的子类对象无法访问扩展内容，但仍然可以访问父类所具备的内容，哪怕被重写的方法cry，但这时由于父类指向的还是子类对象，因此所触发的内容均属于子类，这里先不探讨多态的好处，你只需要加深对代码块13和图1的理解类的这种特性即可。 ❓ 疑问点1：为什么通过Animal的引用变量指向的Cat对象，无法调用其catchMice方法？为什么cry方法可以调用触发的却是Cat里的cry方法？ 1.5：如何直接访问父类的内容？1.5.1：直接new父类也是一个普通的类嘛，要想不受子类的任何影响，直接new不就完事儿了。但一般父类都不太可能直接new，在多子类的情况下，又该怎样直接访问自己的资源呢？来接着往下看1.5.2吧。 1.5.2：super关键词通过上面的介绍，我们了解了类的继承和多态，子类在继承了父类的功能和属性之后，可以自定义方法实现对父类的扩展，针对实现不合子类要求的方法，子类也可以通过方法重写来覆盖原父类方法，然后就是多态，多态简单来说就是通过一个父类引用变量直接指向一个子类对象，还是结合图1理解。 那么我们现在再来做一个实验，现在我想让Cat和Dog在吃饭的时候自带叫声，现在我们来继续改造下这些类： 首先把Animal里的eat方法改造下，让它的逻辑执行之前，先调用下cry方法： 代码块151234567891011121314151617181920212223public class Animal { private String name = \"xx\"; private int age; public void cry() { System.out.println(\"叫声为：未知\"); } public void eat() { this.cry(); //吃饭之前先叫两嗓子 System.out.println(name + \"正在吃东西\"); } public void setName(String name) { this.name = name; } public void setAge(int age) { this.age = age; } } 别的代码不动，单独测试下eat方法： 代码块161234567public static void main(String[] args) { Animal cat = new Cat(); cat.eat(); Animal dog = new Dog(); dog.eat();} 最终输出： 代码块171234喵喵喵~xx正在吃东西汪汪汪~xx正在吃东西 这里说一下，即便代码块16直接用Cat和Dog接收对应的类对象，结果都是一致的。 🦩 结论：new出来具体的子类之后，父类里即便使用this调用它内部的被子类重写的方法，实际触发的仍然是子类的方法。 ❓ 疑问点2：为什么呢？我明明是在Animal对象里调用的this.cry，为什么执行的却是子类的？ ok，那我们怎么直接访问父类里的方法呢？借助super关键词即可，同this关键词一样用来描述类对象内部引用的，与this不同的是，子类利用super可以调用父类资源，注意，这里说了，想用super，就得在某子类内，我们现在如果想调用Animal本身的cry方法，那么就需要在Cat或Dog里，通过super触发： 首先把Animal里面的eat方法还原： 代码块181234567891011public class Animal { ...省略... public void eat() { //负责吃饭的方法 System.out.println(name + \"正在吃东西\"); } ...省略...} 然后改造下Cat类，让它重写eat方法，我们目标是让这个eat方法先调用一遍父类原始的cry方法，再调用一次父类原始的eat方法： 代码块1912345678910111213public class Cat extends Animal { ...省略... @Override public void eat() { //这里重写eat，同时使用super直接调用父类的cry和eat方法 super.cry(); super.eat(); } ...省略... } 现在再次调用eat方法，输出结果如下： 代码块2012叫声为：未知xx正在吃东西 你会发现，现在的调用就是父类里面原生的方法。 现在，让我们把代码块19里的cry的super关键词去掉（之前说过，去掉相当于使用this关键词调用）： 代码块2112345678910111213public class Cat extends Animal { ...省略... @Override public void eat() { cry(); //这里把super去掉 super.eat(); //等看完这一块的内容之后，结合Cat类的代码，分析一下这里eat的super关键词去掉会发生什么？ } ...省略... } 然后调用eat的结果如下： 代码块2212喵喵喵~xx正在吃东西 可见，Cat里使用this调用cry方法，当然是调用的它自己的咯。 ❓ 疑问点3：为什么父类的被子类重写过的方法可怜到只能通过子类的super关键词才能触发？为什么父类里也有的方法要优先执行子类里重写后的？不管在父类还是子类，用this关键词调用的资源都是优先以子类为准吗？找不到的资源才去考虑找父类吗？ 1.6：继承链首先请记住现在的Animal类： 代码块2312345678910111213141516171819202122232425public class Animal { private String name = \"xx\"; //动物学名，动物们都有学名，这里默认为xx，因为动物类是用来描述动物的，动物有学名，但你并不知道是那种动物，name只能未知 private int age; //动物们的年龄 public void cry() { //控制叫声的方法 System.out.println(\"叫声为：未知\"); } public void eat() { //负责吃饭的方法 System.out.println(name + \"正在吃东西\"); } //用来给name赋值的方法 public void setName(String name) { this.name = name; } //用来给age赋值的方法 public void setAge(int age) { this.age = age; } } Cat类清理一下之前的测试代码，记住现在的Cat类： 代码块24123456789101112public class Cat extends Animal { @Override //加上@Override标识为方法重写 public void cry() { System.out.println(\"喵喵喵~\"); //这里重新定义方法的实现 } public void catchMice() { //扩展方法：捕鼠 System.out.println(\"我会捉老鼠\"); } } java语法里，只允许一个类继承一个类，也就是说，extends关键词只能在一个类定义里出现一次，根据这个规则，父类也是一个类，类允许继承一个别的类（套娃警告），描述起来是越来越乱，不如再改造下前面的例子来说明问题；现在我们发现Cat也只是定义了猫的基本概念，包括被它重写后的cry，确实，猫都是喵喵喵的叫，猫都会捕鼠，但是不同品种的猫，也存在差异，例如相比其它猫，橘猫的食量惊人，它还可以扮猪，如果这时定义一个橘猫类，首先它也是猫，那就让它继承Cat类，那么eat这个方法就可以单独拎出来再被重写一次，以显示橘猫特有的食量，其次应该单独加一个橘猫特有技能：扮猪，看代码： 代码块25123456789101112public class OrangeCat extends Cat { @Override public void eat() { //重写eat方法 System.out.println(\"我寻思你不能因为我吃的多就专门为我量身定做一个eat方法吧？。。。。。。艾玛真香~\"); } //假装自己是头猪 public void playAPig() { System.out.println(\"我说我是🐷，你能怎么办？（🤪）\"); }} ok，至少通过橘猫类，我们知道了，java虽然不允许一个类继承多个类，但可以间接继承多个类，现在的继承链为： 那么一样的，我们前面了解了java的继承和多态，这种继承链也是符合上述所有的继承相关的特性，比如我们来利用OrangeCat做个试验： 代码块26123456789101112131415public static void main(String[] args) { //继承链仍符合多态规则，看下方的代码，我用Animal和Cat都可以接收OrangeCat对象，因为它们俩都是OrangeCat的父类 Animal orangeCat1 = new OrangeCat(); Cat orangeCat2 = new OrangeCat(); OrangeCat orangeCat3 = new OrangeCat(); orangeCat1.cry(); orangeCat1.eat(); orangeCat2.cry(); orangeCat2.eat(); orangeCat3.cry(); orangeCat3.eat();} 结果如下： 代码块27123456喵喵喵~我寻思你不能因为我吃的多就专门为我量身定做一个eat方法吧？。。。。。。艾玛真香~喵喵喵~我寻思你不能因为我吃的多就专门为我量身定做一个eat方法吧？。。。。。。艾玛真香~喵喵喵~我寻思你不能因为我吃的多就专门为我量身定做一个eat方法吧？。。。。。。艾玛真香~ 可以看到，不管用谁去接收OrangeCat对象，最终输出结果都是正确的，首先OrangeCat没有重写cry方法，因此触发的是父类Cat里的cry方法，又因为自己重写了eat对象，所以eat调用时就直接触发了自己的eat方法。 同样的，playAPig方法属于OrangeCat自定义的扩展方法，它只能由OrangeCat类型的引用变量触发，因此代码块26里，只有orangeCat3可以调用这个方法，由于OrangeCat继承了Cat，所以它也会捕鼠（catchMice）了。 我们再来看看OrangeCat具备了哪些能力： 代码块28123456789public static void main(String[] args) { OrangeCat orangeCat3 = new OrangeCat(); orangeCat3.setAge(9); //其直系父类Cat继承了Animal，因此它也可以调用Animal的setAge方法 orangeCat3.setName(\"橘猫\"); //同上 orangeCat3.cry(); //其直系父类Cat有cry方法（虽然是重写Animal的cry来的），因此这里触发的是Cat里那个cry方法 orangeCat3.eat(); //因为自己有eat方法，因此这里触发的是自己的eat方法 orangeCat3.catchMice(); //其直系父类Cat有catchMice方法，因此这里触发的是Cat里那个catchMice方法 orangeCat3.playAPig(); //这是OrangeCat特有的方法，自然可以调用} 看到了吗，经过一层层的继承，OrangeCat拥有的技能要比俩父类加起来还多，这是因为继承的特性，就是父类所有的东西都是可以给子类的（当然能不能访问就是另一回事了，下面会说访问权限相关的内容），而子类又可以重写父类的方法，如果不重写，则按照就近原则触发对应的方法，比如例子里虽然OrangeCat没有重写cry方法，但它调用cry的输出结果却是Cat类里的那个，因此，在重写方法调用上，一般遵循就近原则，此外子类也可以扩展自己的内容，比如Cat相比Animal，可以捕鼠，再比如OrangeCat相比Cat和Animal，可以扮猪。 1.7：巩固继承&amp;多态前面讲了那么多，现在我们通过画图的方式，系统的解释一遍继承和多态。 1.7.1：继承关系下，重复方法的就近调用规则先看下我们在前面留下的3个问题： ❓ 疑问点1：为什么通过Animal的引用变量指向的Cat对象，无法调用其catchMice方法？为什么cry方法可以调用触发的却是Cat里的cry方法？ ❓ 疑问点2：为什么呢？我明明是在Animal对象里调用的this.cry，为什么执行的却是子类的？ ❓ 疑问点3：为什么父类的被子类重写过的方法可怜到只能通过子类的super关键词才能触发？为什么父类里也有的方法要优先执行子类里重写后的？不管在父类还是子类，用this关键词调用的资源都是优先以子类为准吗？找不到的资源才去考虑找父类吗？ 先不用急着看问题，我们先来分析下一个类方法或属性在调用时，都经历了些什么。 在LV2-1的时候，我们就知道了，对象实际上就是一个整体，被保存在了内存里，然后通过一个引用变量来指向它，然后就可以利用这个引用变量来操纵它了，现在我们来看下，正常没有继承任何类的类，是如何访问方法的： 🦜 这里说明一下，下面的流程图只是为了便于让大家理解并记住java继承关系下的访问规则，真实的java对象在内存里并不长这样（虽然确实包含属性值），方法的调用在java底层也很复杂，这些都要对jvm有深入了解才行。 如果一个类没有任何父类，那么它的方法调用就很纯粹，没有任何悬念，现在让我们的看看Cat类： 让我们再来看看更复杂的橘猫： 我们仍然可以找到一些规则，来说明在继承里方法的调用和最终触发哪个方法的问题。 好的，截止目前，集合图4和图5，我们解决了疑问点2和疑问点3，通过图4，我们知道了this关键词取决于当前的对象究竟属于哪个类，仍然符合就近调用规则，例如Animal里面使用this.cry调用cry，如果当前对象是Animal自己，那么毫无疑问，最终触发的会是它自己的cry方法，但如果当前对象是Cat，那么this调用cry时就遵循就近规则，优先触发自己所属类（也就是Cat类）里的cry方法。 图4告诉我们，super关键字在子类里可用来直接调用其父类里的方法： 这个可以解答疑问点3. 现在让我们解答下疑问点1，为什么父类引用变量可以接收子类对象？ 还记得讲基本类型时，存在大类型和小类型吗？大类型可以自动接收小类型，而小类型想要变成大类型就得强转，类同样拥有类似的规则，比如你可以把父类理解成比较大的类，子类是比较小的类，那么父类当然可以自动接收子类咯，只不过类有不一样的地方，一个子类被父类接收以后，访问域就受父类限制了： 既然规则跟基本类型差不多，当然也有类型强转啦： 代码块2912Animal cat = new Cat();Cat cat2 = (Cat)cat; 看吧，连写法都跟基本类型的强转一样，括号里加上要转的目标类型即可。 但是需要注意的是，别瞎转，比如你知道这个Animal的确是一个Cat，然后像代码块29里那样转成Cat类型即可，但如果对象并不是Cat，那样强转语法里是允许的，但是运行时会报类型转换错误，比如下面这样： 代码块3012Animal dog = new Dog();Cat cat = (Cat)dog; 上面的代码在语法里不会有问题，但实际上运行时便会报错，即类型转换错误。 到目前为止，有关问题1、2、3都说完了，继承和多态这一块确实很复杂，最好能结合本节流程图记下来这个规则，以后做分析时就不会乱了。 1.7.2：属性在继承关系下的访问规则上面只是说了方法的调用规则，却没有说属性，我们来做个试验： 现在让Cat类里也有一个叫age的属性： 代码块3112345678910111213141516public class Cat extends Animal { public int age = 12; //新增一个跟父类一样的属性，初始值为12 @Override public void cry() { System.out.println(this.age); //通过this关键词访问age System.out.println(super.age); //通过super关键词访问父类里的age System.out.println(\"喵喵喵~\"); } public void catchMice() { //扩展方法：捕鼠 System.out.println(\"我会捉老鼠\"); } } 然后让父类里的age访问权限变成public（详细看下方1.8，这里改成public的目的是为了让Cat可以直接访问这个属性），然后让其初始值为15，并且在其eat方法里使用this关键词访问age： 代码块321234567891011121314public class Animal { ...省略... public int age = 15; //动物们的年龄，初始值为15 public void eat() { System.out.println(this.age); //输出age System.out.println(this.name + \"正在吃东西\"); } ...省略...} 现在让我们来测试下： 代码块3312345public static void main(String[] args){ Animal cat = new Cat(); cat.cry(); cat.eat();} 输出如下： 代码块34123451215喵喵喵~15xx正在吃东西 🎑 结论：由运行结果我们可以知道，与方法的重写不同，类的属性本身该属于哪个类还是属于哪个类，记住这个规则。 好了，上面的这个试验有画蛇添足的嫌疑，因为age父类里就有，为什么Cat里还要加上一个同名的age呢？是的，真实设计类的时候没人会这样设计的，我们需要明确一个点，方法是行为，方法在继承关系里允许各种重写，但是属性作为一种没有任何行为方式的东西，你重复定义它的意义大吗？显然是不大的，而且极易跟父类混淆，所以我们说子类可以重写父类的方法，继承关系里，方法调用符合以对象所属类为参照就近调用的规则，子类还可以自己拓展父类里没有的方法，子类的对象还可以被父类引用变量接收，只是这样会影响子类对象的访问域（图7），子类还可以拓展父类里没有的属性，但不建议子类覆盖父类的属性，这种覆盖是没有意义的，通过上面的例子我们也发现了，同名属性在类继承链里是相互隔离的。 1.8：访问权限通过1.7，你应该知道了某种类与父类访问规则，但是我们在LV2-2的访问权限符的介绍里，介绍了访问权限修饰符以及被它们修饰了的资源的访问权限，也就是说理想状态下1.7的流程图都是成立的，但是你有没有发现，这些方法的权限修饰符都是public的？是的，public表示资源公开，比如Animal类里的age和name两个属性都是private类型的，子类可以通过super直接访问这俩属性吗？显然是不行的，必须得通过public的setName和setAge俩方法完成对name和age的赋值，这就是访问权限符的意义了，至于怎么区分能不能访问呢？我们再把那张表里有关修饰符访问等级的表贴来： 只需要记住，如果俩类为继承关系，则protected关键词无视包目录，均可访问，其余规则全部跟普通类一样，由于之前讲过权限修饰符，因此这里不再做详细介绍。 1.9：继承和多态的好处通过前面对继承和多态的了解，我们大体上对这俩特性有了一个认识，首先继承是为了解决什么问题的？ 回归到我们的例子上，Animal里定义了符合动物特性一些行为和属性，Cat是一种动物，符合Animal定义的行为和属性，它们俩建立起父子关系后，Cat就可以直接使用父类里定义的属性和方法了，这样像eat这种方法，Cat和Dog都不需要自己定义了，这样会让我们的代码看起来很简洁，而且同样的代码逻辑块，不需要重复定义多次，有需要可以重写，子类还可以自定义自己的行为方法。 多态呢？它有什么好处？ 多态就是指使用一个父类引用变量，可以接收子类对象并允许触发它内部的方法，参见图1，那么这样的一种特性的好处究竟是什么呢？我们本节先不会涉及，之后讲JDBC时可以提一嘴，现在你要做的是，牢记java的这种机制。 1.10：抽象类了解完了继承和多态，我们再来了解一种特殊的类：抽象类 什么是抽象类？让我们来改造下Animal方法，不知道你有没有发现，由Animal派生出来的子类Cat和Dog都重写了cry方法，说明大部分时候，Animal里的cry方法都不会主动生效，因为意义不大，这时我们认为cry方法在绝大多数情况下都是需要被重写的，像这种方法，我们就可以把它定义成一个抽象方法，包含抽象方法的类被称作抽象类，普通的类是不能有抽象方法的，因此想要cry变成抽象方法，首先要把Animal变成抽象类： 代码块351234567891011121314151617181920212223//利用abstract修饰的class，被称为抽象类public abstract class Animal { private String name = \"xx\"; //动物学名，动物们都有学名，这里默认为xx，因为动物类是用来描述动物的，动物有学名，但你并不知道是那种动物，name只能未知 public int age = 15; //动物们的年龄 //被abstract修饰的方法被称为抽象方法 public abstract void cry(); //动物会叫，但每个动物的叫声都完全不一样，有的甚至不会叫，那\"叫\"就应该是一个标准，作为动物的标准，动物本身只要定义好这个标准就好了，其余交给具体的动物（子类）去实现 public void eat() { //负责进食的方法 System.out.println(this.name + \"正在进食\"); } public void setName(String name) { this.name = name; } public void setAge(int age) { this.age = age; } } 我们可以看到，抽象方法没有任何实现，所以称它为一个标准，所有直系子类都必须实现这个标准，这时Cat类继承了Animal类，如果不实现cry方法，语法上就会报错： 现在我们只能让Cat类实现这个抽象方法： 这就相当于强制让子类去重写cry方法，事实上确实需要每个动物都实现自己的cry方法，但是像eat这种方法就没有必要这样做，因为大部分动物都需要进食且都是用嘴进食的，大同小异，如果真的存在不一样的吃东西的方法，那么就跟之前一样重写就好了，但大部分动物都不需要重写eat方法，父类Animal里的已经够用了，这是在告诉你什么时候需要搞抽象方法，什么时候不需要。 现在你知道了，有的方法需要被抽象，那就定义抽象方法，因为存在抽象方法，所以类必须被声明为抽象类（abstract关键词）。 抽象类的特点： 抽象类不能被实例化（也就是说不可以利用new关键词实例化一个抽象类） 由于1的特性，我们认为，抽象类是为继承而生的，如果你定义了一个抽象类，而它没有任何子类，那么这个抽象类就没有任何意义 抽象类不一定有抽象方法，但有抽象方法的类一定是抽象类 抽象类可以继承抽象类，当继承了抽象类时，子类抽象类也可以不实现其父类的抽象方法，全部交给非抽象的子类去做 抽象类也可以继承普通类，也可以选择重写普通类的方法，更神奇的是，它还可以让通过重写，让普通类的方法变成一个抽象方法 抽象类虽然不可以被实例化，但是它仍然存在构造器（这是句废话，抽象类是天生的父类，父类构造器在子类被实例化的时候会自动调用一次，所以作为天生的父类，它必有构造器） 🌵 思考： 现在Animal定义如下： Cat类是它的子类，定义如下： 结合前面对继承和多态以及本部分对抽象类的理解，请问如下测试代码输出结果是什么？ 1.11：万类の父-Object不知道你有没有发现，任何对象都自动有这些方法： 这是因为类被定义出来，就隐藏继承了一个父类，名叫Object，这是java自带的类，不需要显式的extends出来。 二、封装封装充满我们代码，还是以前面的例子为准，我们认为对一类操作使用一个方法定义来圈起来，就是封装，比如eat、cry等方法，例子里面很简单，只打印了一句话，但实际开发中，一个方法可能会完成很复杂的操作，这里拿之前一个例子来说明问题： 代码块36123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class Cat { public int gender; protected int age; int color; private String name; public Cat(int gender, int age, int color, String name) { this.gender = gender; this.age = age; this.color = color; this.name = name; } public void cry(Cat cat) { if (this.tooOld()) { //通过tooOld来判断当前这只猫是否年龄太大了 System.out.println(\"叫不动了...\"); } else { System.out.println(\"喵喵喵~\"); } } public void eat() { System.out.println(\"要恰饭的嘛\"); } protected void emm() { if (this.tooOld()) { //通过tooOld来判断当前这只猫是否年龄太大了 System.out.println(\"骚不动了...\"); } else { System.out.println(\"猪肉卷和千层面不存在二选一，我全都要！\"); } } void run() { if (tooOld()) { //通过tooOld来判断当前这只猫是否年龄太大了 System.out.println(\"跑不动了...\"); } else if (age &gt; 10) { System.out.println(\"奔跑速度：10km/h\"); } else { System.out.println(\"奔跑速度：15km/h\"); } } ...省略... //被拆出来的逻辑块，因为这段逻辑会出现在多个方法里，因此单拆出来封装成一个方法，这种方法建议设置成private权限的，因为仅限本类内调用 private boolean tooOld() { return this.age &gt; 15; //经过本层封装，只要需要这段逻辑的地方，直接调用下这个方法即可，本例太简单，因为只做了age大小判断，实际开发里可以把更复杂的且重复度过高的代码块像这样拆出来，封装成一个方法提供服务 }} 通过本例，我们知道了封装的目的是减少代码的重复度，提高复用率，这点是不是跟继承也很像？继承的意义之一也是为了解决代码重复度的。 封装仅仅只是为了解决重复度吗？并不是，通过之前的Animal的例子，我们发现像age、name这种属性的赋值操作也被封装成了一个个方法（setName和setAge），而Animal里的name和age全是private的，这是为什么呢？为什么不让age和name变成protected或public这种权限呢？让别的类直接赋值不是更好？为啥还要多此一举搞俩专门赋值的方法？ 这就体现了封装的另外一层意义：隔离 现在我们试着将Animal里的age变成public的，来看看下面： 代码块3712Animal animal = new Animal();animal.age = 10000; //由于Animal的age变成public公开了，因此在外界可以随意对其赋值 但是Animal这时不干了，你见过能活10000岁的生物吗？？因此Animal把自己的age封了起来，首先把访问权限变成private，然后提供一个setAge方法用来给age赋值，setAge就是Animal对外封装的一个专门给age赋值的方法，这个时候Animal就由之前的被动状态变成主动状态了，如果你不想让别人设置的age太过分，就可以在setAge里做限制，反正是自己的方法嘛，还不是想怎么设计怎么设计，让我们来改一下Animal里setAge的逻辑： 代码块381234567public void setAge(int age) { if (age &gt; 10000) { //当传入的age超过1w时，输出这句话反问对方 System.out.println(\"这种生物你给我找来个康康？\"); } else { //否则的话就给自己的age赋值 this.age = age; }} 看看，这样age的赋值就完全被隔离进本类内了，外界进行赋值时就不敢那么放肆了~ 封装的意义： 封装的意义在于保护或者防止代码（数据）被我们无意中破坏。 保护成员属性，不让类以外的程序直接访问和修改； 隐藏方法细节 这也是为啥我们在定义一个类的时候，属性经常被设置成private访问级别的，然后通过定义赋值方法来让外界给自己的属性赋值。 关于对象封装的原则: 内聚：内聚是指一个模块内部各个部分之间的关联程度 耦合：耦合指各个模块之前的关联程度 封装原则：隐藏对象的属性和实现细节，仅对外公开访问方法，并且控制访问级别 在面向对象方法中，用类来实现上面的要求。用类实现封装，用封装来实现高内聚，低耦合。 ↑上面的话先读一下，做多了东西自然就懂了，我们做开发时所作的封装、多态等，都是为了这一个目标：高内聚、低耦合来进行的。","link":"/2020/03/10/LV2-4%EF%BC%9A%E7%B1%BB%E7%9A%84%E7%89%B9%E6%80%A7%E3%80%81%E5%85%B3%E7%B3%BB/"},{"title":"Redis小记-内存解析&内存消耗篇","text":"前置：redis内存指标 注：本文默认读者已初步学会使用redis了。 首先我们通过info命令查看相关指标，其中几个memory的重要指标整理出来如下： 属性 解释 used_memory redis内部存储的所有数据的内存总占用量（自身内存+对象内存+缓冲内存） used_memory_ress redis进程占用的总物理内存 mem_fragmentation_ratio used_memory_ress与used_memory的比值，即为内存碎片率 mem_allocator 内存分配器，默认为jemalloc 表1 一、碎片率 当内存碎片率 &gt; 1时，说明redis进程占用物理内存的总量大于Redis实际存储数据（表1第一行）的内存占用量，溢出来的部分内存被内存碎片消耗，如果溢出部分过大，则说明内存碎片率严重。 相反的，如果碎片率 &lt; 1时，则说明Redis存储的数据总量已经超出了redis进程占用内存的总量，造成这种情况是因为操作系统把Redis内存交换至硬盘导致（swap），由于硬盘读取速度远远慢与内存，因此这种情况下redis性能极差，可能出现僵死。 二、redis内存消耗的几个来源2.1：自身内存redis启动后自身运行所需内存； 2.2：对象内存内存占用最大的一部分，这里面存储的就是用户自身的数据（业务数据），数据以key-value类型存储，内存消耗可表示为：key内存+value内存。 2.3：缓冲内存主要由客户端缓冲区+复制积压缓冲区+AOF缓冲区组成，具体解释如下： 客户端缓冲区指的是所有接入redis服务器的TCP连接的输入和输出缓冲，输入缓冲无法被控制，最大空间为1G，超过立即断开连接，输出缓冲通过client-output-buffer-limit控制。 复制积压缓冲区指的是redis在2.8版本以后提供了一块可以重复利用的固定大小的缓冲区，用来实现部分复制功能，使用repl-backlog-size参数控制，默认1MB（主从结构下，主节点只存在一个该缓冲区，从节点共用，那时可以设置较大的缓冲区空间），该缓冲区可以避免全量复制。 AOF缓冲区用于存储在redis重写期间保存最近的写入命令，无法控制，通常取决于AOF重写时间以及写入命令量，一般情况下很小。 2.4：内存碎片redis默认的内存分配器是jemalloc，可选的还有glibc和tcmalloc；内存分配器为了更好的管理以及重复利用内存，分配策略一般采用固定范围的内存块进行分配；因此，我们在存储一块5kb的内容时，内存分配器可能会为我们分配8kb的块存储，剩下的3kb不能再次分配给其他对象存储，因而沦为了内存碎片；jemalloc对碎片化问题做了优化，一般来讲碎片化率保持在1.03左右。 可能造成内存碎片率过高的场景： 频繁的更新操作，例如频繁对已存在的键做append、setrange等操作； 大量过期键删除，键对象过期删除后释放的空间无法得到充分的利用，导致碎片率上升。 解决办法： 数据对齐，尽量采用数字类型或固定长度的字符串（大部分业务场景不满足这种方式）； 重启，重启节点可以使内存重整理，利用高可用的结构（节点集群+主从结构），将碎片率过高的节点主节点转换为从节点，然后进行安全重启。 2.5：子进程内存消耗子进程内存消耗指的是执行AOF/RDB重写时redis创建的子进程内存消耗；redis执行fork操作产生的子进程内存占用量对外表现为与父进程相同，理论上需要一倍的物理内存来完成重写的操作。但是linux具备写时复制技术（copy-on-write），父子进程会共享相同的物理内存页，当父进程处理写请求时会对需要修改的页复制出一份副本来完成写操作，而子进程依然读取fork时整个父进程的内存快照，总结： 子进程并不需要消耗一倍的父进程内存，实际消耗根据期间写入命令量决定，但依然要预留出一些内存防止溢出； 需要设置sysctl vm.overcommit_memory = 1允许内核可以分配所有的物理内存，防止redis进程执行fork时因剩余内存不足导致失败； 排查当前系统是否支持开启THP，如果开启建议关闭，防止copy-on-write期间内存过度消耗。","link":"/2017/08/12/Redis%E5%B0%8F%E8%AE%B0-%E5%86%85%E5%AD%98%E8%A7%A3%E6%9E%90&%E5%86%85%E5%AD%98%E6%B6%88%E8%80%97%E7%AF%87/"},{"title":"ThreadLocal系列（一）-ThreadLocal的使用及原理解析","text":"项目中我们如果想要某个对象在程序运行中的任意位置获取到，就需要借助ThreadLocal来实现，这个对象称作线程的本地变量，下面就介绍下ThreadLocal是如何做到线程内本地变量传递的， 一、基本使用先来看下基本用法： 1234567891011121314private static ThreadLocal tl = new ThreadLocal&lt;&gt;();public static void main(String[] args) throws Exception { tl.set(1); System.out.println(String.format(\"当前线程名称: %s, main方法内获取线程内数据为: %s\", Thread.currentThread().getName(), tl.get())); fc(); new Thread(ThreadLocalTest::fc).start();}private static void fc() { System.out.println(String.format(\"当前线程名称: %s, fc方法内获取线程内数据为: %s\", Thread.currentThread().getName(), tl.get()));} 代码块1 运行结果： 123当前线程名称: main, main方法内获取线程内数据为: 1当前线程名称: main, fc方法内获取线程内数据为: 1当前线程名称: Thread-0, fc方法内获取线程内数据为: null 可以看到，main线程内任意地方都可以通过ThreadLocal获取到当前线程内被设置进去的值，而被异步出去的fc调用，却由于替换了执行线程，而拿不到任何数据值，那么我们现在再来改造下上述代码，在异步发生之前，给Thread-0线程也设置一个上下文数据： 12345678910111213141516171819private static ThreadLocal tl = new ThreadLocal&lt;&gt;(); public static void main(String[] args) throws Exception { tl.set(1); System.out.println(String.format(\"当前线程名称: %s, main方法内获取线程内数据为: %s\", Thread.currentThread().getName(), tl.get())); fc(); new Thread(()-&gt;{ tl.set(2); //在子线程里设置上下文内容为2 fc(); }).start(); Thread.sleep(1000L); //保证下面fc执行一定在上面异步代码之后执行 fc(); //继续在主线程内执行，验证上面那一步是否对主线程上下文内容造成影响 } private static void fc() { System.out.println(String.format(\"当前线程名称: %s, fc方法内获取线程内数据为: %s\", Thread.currentThread().getName(), tl.get())); } 代码块2 运行结果为： 1234当前线程名称: main, main方法内获取线程内数据为: 1当前线程名称: main, fc方法内获取线程内数据为: 1当前线程名称: Thread-0, fc方法内获取线程内数据为: 2当前线程名称: main, fc方法内获取线程内数据为: 1 可以看到，主线程和子线程都可以获取到自己的那份上下文里的内容，而且互不影响。 二、原理分析ok，上面通过一个简单的例子，我们可以了解到ThreadLocal（以下简称TL）具体的用法，这里先不讨论它实质上能给我们带来什么好处，先看看其实现原理，等这些差不多了解完了，我再通过我曾经做过的一个项目，去说明TL的作用以及在企业级项目里的用处。 我以前在不了解TL的时候，想着如果让自己实现一个这种功能的轮子，自己会怎么做，那时候的想法很单纯，觉得通过一个Map就可以解决，Map的key设置为Thread.currentThread()，value设置为当前线程的本地变量即可，但后来想想就觉得不太现实了，实际项目中可能存在大量的异步线程，对于内存的开销是不可估量的，而且还有个严重的问题，线程是运行结束后就销毁的，如果按照上述的实现方案，map内是一直持有这个线程的引用的，导致明明执行结束的线程对象不能被jvm回收，造成内存泄漏，时间久了，会直接OOM。 所以，java里的实现肯定不是这么简单的，下面，就来看看java里的具体实现吧。 先来了解下，TL的基本实现，为了避免上述中出现的问题，TL实际上是把我们设置进去的值以k-v的方式放到了每个Thread对象内（TL对象做k，设置的值做v），也就是说，TL对象仅仅起到一个标记、对Thread对象维护的map赋值的作用。 先从set方法看起： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public void set(T value) { Thread t = Thread.currentThread(); //获取当前线程 ThreadLocal.ThreadLocalMap map = getMap(t); //获取到当前线程持有的ThreadLocalMap对象 if (map != null) map.set(this, value); //直接set值，具体方法在下面 else createMap(t, value); // 为空就给当前线程创建一个ThreadLocalMap对象，赋值给Thread对象，具体方法在下面 } ThreadLocal.ThreadLocalMap getMap(Thread t) { return t.threadLocals; //每个线程都有一个ThreadLocalMap，key为TL对象（其实是根据对象hash计算出来的值），value为该线程在此TL对象下存储的内容值 } private void set(ThreadLocal&lt;?&gt; key, Object value) { ThreadLocal.ThreadLocalMap.Entry[] tab = table; //获取存储k-v对象的数组（散列表） int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); //根据TL对象的hashCode（也是特殊计算出来的，保证每个TL对象的hashCode不同）计算出下标 for (ThreadLocal.ThreadLocalMap.Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) { //线性探查法解决哈希冲突问题，发现下标i已经有Entry了，则就查看i+1位置处是否有值，以此类推 ThreadLocal&lt;?&gt; k = e.get(); //获取k if (k == key) { //若k就是当前TL对象，则直接为其value赋值 e.value = value; return; } if (k == null) { //若k为空，则认为是可回收的Entry，则利用当前k和value组成新的Entry替换掉该可回收Entry replaceStaleEntry(key, value, i); return; } } //for循环执行完没有终止程序，说明遇到了空槽，这个时候直接new对象赋值即可 tab[i] = new ThreadLocal.ThreadLocalMap.Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) //这里用来清理掉k为null的废弃Entry rehash(); //如果没有发生清除Entry并且size超过阈值（阈值 = 最大长度 * 2/3），则进行扩容 } //直接为当前Thread初始化它的ThreadLocalMap对象 void createMap(Thread t, T firstValue) { t.threadLocals = new ThreadLocal.ThreadLocalMap(this, firstValue); } ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) { table = new ThreadLocal.ThreadLocalMap.Entry[INITIAL_CAPACITY]; //初始化数组 int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); //计算初始位置 table[i] = new ThreadLocal.ThreadLocalMap.Entry(firstKey, firstValue); //因为初始化不存在hash冲突，直接new size = 1; setThreshold(INITIAL_CAPACITY); //给阈值赋值，上面已经提及，阈值 = 最大长度 * 2/3 } 代码块3 通过上述代码，我们大致了解了TL在set值的时候发生的一些操作，结合之前说的，我们可以确定的是，TL其实对于线程来说，只是一个标识，而真正线程的本地变量被保存在每个线程对象的ThreadLocalMap里，这个map里维护着一个Entry[]的数组（散列表），Entry是个k-v结构的对象（如图1-1），k为TL对象，v为对应TL保存在该线程内的本地变量值，值得注意的是，这里的k针对TL对象的引用是个弱引用，来看下源码： 123456789static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; { /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) { super(k); value = v; } } 代码块4 为什么这里需要弱引用呢？我们先来看一张图，结合上面的介绍和这张图，来了解TL和Thread间的关系： 图中虚线表示弱引用，那么为什么要这么做呢？ 简单来说，一个TL对象被创建出来，并且被一个线程放到自己的ThreadLocalMap里，假如TL对象失去原有的强引用，但是该线程还没有死亡，如果k不是弱引用，那么就意味着TL并不能被回收，现在k为弱引用，那么在TL失去强引用的时候，gc可以直接回收掉它，弱引用失效，这就是上面代码里会进行检查，k=null的清除释放内存的原因（这个可以参考下面expungeStaleEntry方法，而且set、get、remove都会调用该方法，这也是TL防止内存泄漏所做的处理）。 综上，简单来说这个弱引用就是用来解决由于使用TL不当导致的内存泄漏问题的，假如没有弱引用，那么你又用到了线程池（池化后线程不会被销毁），然后TL对象又是局部的，那么就会导致线程池内线程里的ThreadLocalMap存在大量的无意义的TL对象引用，造成过多无意义的Entry对象，因为即便调用了set、get等方法检查k=null，也没有作用，这就导致了内存泄漏，长时间这样最终可能导致OOM，所以TL的开发者为了解决这种问题，就将ThreadLocalMap里对TL对象的引用改为弱引用，一旦TL对象失去强引用，TL对象就会被回收，那么这里的弱引用指向的值就为null，结合上面说的，调用操作方法时会检查k=null的Entry进行回收，从而避免了内存泄漏的可能性。 因为TL解决了内存泄漏的问题，因此即便是局部变量的TL对象且启用线程池技术，也比较难造成内存泄漏的问题，而且我们经常使用的场景就像一开始的示例代码一样，会初始化一个全局的static的TL对象，这就意味着该对象在程序运行期间都不会存在强引用消失的情况，我们可以利用不同的TL对象给不同的Thread里的ThreadLocalMap赋值，通常会set值（覆盖原有值），因此在使用线程池的时候也不会造成问题，异步开始之前set值，用完以后remove，TL对象可以多次得到使用，启用线程池的情况下如果不这样做，很可能业务逻辑也会出问题（一个线程存在之前执行程序时遗留下来的本地变量，一旦这个线程被再次利用，get时就会拿到之前的脏值）； 说完了set，我们再来看下get： 123456789101112131415161718192021222324252627282930313233343536373839404142434445public T get() { Thread t = Thread.currentThread(); ThreadLocal.ThreadLocalMap map = getMap(t); //获取线程内的ThreadLocalMap对象 if (map != null) { ThreadLocal.ThreadLocalMap.Entry e = map.getEntry(this); //根据当前TL对象（key）获取对应的Entry if (e != null) { @SuppressWarnings(\"unchecked\") T result = (T)e.value; return result; //直接返回value即可 } } return setInitialValue(); //如果发现当前线程还没有ThreadLocalMap对象，则进行初始化 } private ThreadLocal.ThreadLocalMap.Entry getEntry(ThreadLocal&lt;?&gt; key) { int i = key.threadLocalHashCode &amp; (table.length - 1); //计算下标 ThreadLocal.ThreadLocalMap.Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) //根据下标获取的Entry对象如果key也等于当前TL对象，则直接返回结果即可 return e; else return getEntryAfterMiss(key, i, e); //上面说过，有些情况下存在下标冲突的问题，TL是通过线性探查法来解决的，所以这里也一样，如果上面没找到，则继续通过下标累加的方式继续寻找 } private ThreadLocal.ThreadLocalMap.Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, ThreadLocal.ThreadLocalMap.Entry e) { ThreadLocal.ThreadLocalMap.Entry[] tab = table; int len = tab.length; while (e != null) { ThreadLocal&lt;?&gt; k = e.get(); //继续累加下标的方式一点点的往下找 if (k == key) //找到了就返回出去结果 return e; if (k == null) //这里也会检查k==null的Entry，满足就执行删除操作 expungeStaleEntry(i); else //否则继续累加下标查找 i = nextIndex(i, len); e = tab[i]; } return null; //找不到返回null } //这里也放一下nextIndex方法 private static int nextIndex(int i, int len) { return ((i + 1 &lt; len) ? i + 1 : 0); } 代码块5 最后再来看看remove方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public void remove() { ThreadLocal.ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this); //清除掉当前线程ThreadLocalMap里以当前TL对象为key的Entry } private void remove(ThreadLocal&lt;?&gt; key) { ThreadLocal.ThreadLocalMap.Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); //计算下标 for (ThreadLocal.ThreadLocalMap.Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) { if (e.get() == key) { //找到目标Entry e.clear(); //清除弱引用 expungeStaleEntry(i); //通过该方法将自己清除 return; } } } private int expungeStaleEntry(int staleSlot) { //参数为目标下标 ThreadLocal.ThreadLocalMap.Entry[] tab = table; int len = tab.length; tab[staleSlot].value = null; //首先将目标value清除 tab[staleSlot] = null; size--; // Rehash until we encounter null ThreadLocal.ThreadLocalMap.Entry e; int i; // 由目标下标开始往后逐个检查，k==null的清除掉，不等于null的要进行rehash for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) { ThreadLocal&lt;?&gt; k = e.get(); if (k == null) { e.value = null; tab[i] = null; size--; } else { int h = k.threadLocalHashCode &amp; (len - 1); if (h != i) { tab[i] = null; // Unlike Knuth 6.4 Algorithm R, we must scan until // null because multiple entries could have been stale. while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; } } } return i; } 代码块6 目前主要方法set、get、remove已经介绍完了，包含其内部存在的弱引用的作用，以及实际项目中建议的用法，以及为什么要这样用，也进行了简要的说明，下面一篇会进行介绍InheritableThreadLocal的用法以及其原理性分析。","link":"/2019/02/15/ThreadLocal%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89-ThreadLocal%E7%9A%84%E4%BD%BF%E7%94%A8%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/"},{"title":"Resilience4j熔断器-使用与源码解析","text":"🌏 环境：&nbsp;&nbsp; 🌾 依赖版本： 🍃 知识依赖：JUC，位图 一、什么是熔断在分布式系统中，各服务间的相互调用更加频繁，上下游调用中充满了可能性，一个服务可能会被很多其他服务依赖并调用，在这个过程中如果某个服务由于某种原因出错（业务出错、负载过高），可能会导致整个分布式调用链路失败： 上面这个过程最终可能会导致全链路瘫痪（服务雪崩），此时需要一种可以解决上述问题的策略，此策略设计目标为： 在发现有服务调用失败后，及时计算失败率 失败率达到某种阈值时，切断与该服务的所有交互，服务走切断后的自定义逻辑 切断并且不再调用该服务后主动监听被切断的服务是否已经恢复了处理能力，若恢复，则继续让其提供服务 这个策略被放进图1中，就变成了下面这样： 这个过程中，C服务在自己出问题的情况下，并不会像图1里那样仍然有大量流量打进来，也不会影响到上游服务，这个结果让调用链看起来比图1更加的稳定，这个过程就叫熔断。 针对这个过程，可以看到在C不可用时，B走了熔断后的降级逻辑，这个逻辑可以自定义，如果C在整个调用链里属于那种必须要成功的服务，那么这里的逻辑就可以是直接抛错，如果C属于那种失败了也无所谓，不影响整个业务处理，那么降级逻辑里就可以不做处理，例如下面的场景： 类似这种接口，降级策略很适合不做处理，返回空信息即可，这样最坏的情况就是页面少了某个板块的信息，可能会对用户造成不太好的体验，但是不影响其对外服务，被熔断的服务恢复后页面也会重新回归正常。熔断后的降级处理方式是件值得思考的事情，熔断和降级是相互独立的概念，熔断后必然会有降级操作（哪怕直接抛异常也是一种降级策略），这个降级操作是熔断这个动作导致的，所以很多时候会把熔断和降级放在一起说，其实降级还可以由其他动作触发，比如限流后抛出“系统繁忙”，这也是一种降级策略，只不过它是由限流触发的，再比如通过开关埋点在系统负载过高时主动关停一些次要服务来提升核心功能的响应速度，这也是一种降级策略，降级是最终产物，而产生它的方式有很多种。 二、Resilience4j中的熔断器2.1：Resilience4j是什么？它是一个轻量、易用、可组装的高可用框架，支持熔断、高频控制、隔离、限流、限时、重试等多种高可用机制。本篇文章只关注其熔断部分。 2.2：如何使用？通过第一部分的介绍，可以认为一个熔断器必须要具备统计单位请求内的错误率、全熔断、半熔断放量、恢复这几个流程，带着这个流程，下面来介绍下Resilience4j里熔断器的用法。 通过图2里服务B调用服务C的例子，现在利用java类来进行简单模拟下这个流程。 首先定义ServerC类，用于模拟服务C： 代码块1123456789public class ServerC { //使用该方法模拟服务C获取C信息的方法，假设现在服务C的getCInfo方法里有个bug，当输入的id为0时报错，其他情况正常 public String getCInfo(int id) { if (id == 0) { throw new RuntimeException(\"输入0异常\"); } return \"id=\" + id + \"的C信息\"; }} 再定义ServerB类，用于模拟服务B，这里给服务B调用服务C方法那里加上熔断器处理，注意这个类里的注释，会详细说明熔断器的主要配置项以及其使用方法： 代码块2123456789101112131415161718192021222324252627282930313233343536public class ServerB { private CircuitBreakerRegistry breakerRegistry; private ServerC serverC = new ServerC(); //让服务B持有一个服务C的引用，用来表示正常服务间调用里的一个连接引用 ServerB() { //初始化breaker注册器，可以利用该对象生产各种breaker对象（注：凡是用同一个注册器生产出来的breaker，都会继承注册器的配置属性） breakerRegistry = CircuitBreakerRegistry.of(CircuitBreakerConfig.custom() //of方法里面放的就是breaker的配置属性对象 .enableAutomaticTransitionFromOpenToHalfOpen() //开启从全开状态经过下面的waitDurationInOpenState时间后自动切换到半开状态 .failureRateThreshold(50) //熔断器闭合状态下的错误率阈值，50表示50%，如果错误率达到这个阈值，那么熔断器将进入全熔断状态 .ringBufferSizeInClosedState(100) //熔断器闭合状态下，以该值为单位请求数，计算错误率，跟上面错误率阈值综合理解，这个值表示至少有100个请求，且错误50个以上才会触发全熔断 .ringBufferSizeInHalfOpenState(10) //熔断器半熔断状态下，以该值为单位请求数，计算错误率，跟上面错误率阈值综合理解，这个值表示至少有10个请求，且错误5个以上会再次触发全熔断，相比闭合状态，半熔断状态下更容易再次进入全熔断状态 .waitDurationInOpenState(Duration.ofMillis(1000L)) //熔断器全熔断状态持续的时间，全熔断后经过该时间后进入半熔断状态 .build()); } //服务B通过服务C来获取到C的info信息，该方法就是用来干这个的，它会发起对服务C的调用 public String getCInfo(int id) { //breaker对象是按照name划分全局单例的 CircuitBreaker breaker = breakerRegistry.circuitBreaker(\"getCInfo\"); //这里给熔断器取个名，一般情况就是一个服务的path或方法名 try { return breaker.executeCallable(() -&gt; serverC.getCInfo(id)); } catch (CircuitBreakerOpenException e) { //一旦抛出该异常说明已经进入全熔断状态 //被熔断后的降级逻辑 return \"服务C出错，触发服务B的降级逻辑\"; } catch (Exception e) { //熔断关闭或者半熔断状态下，C抛出的错误会被catch到这里 return \"调用服务C出错\"; } } public CircuitBreaker getBreaker() { return breakerRegistry.circuitBreaker(\"getCInfo\"); //为了方便做测试，这里返回对应的breaker对象 }} 上述配置的熔断器解释如下： 在熔断器闭合的情况下（也即是正常情况下），以100个请求为单位窗口计算错误率，一旦错误率达到50%，立刻进入全熔断状态，该状态下服务B不会再发生对服务C的调用，直接走自己的降级逻辑，经过1000ms后恢复为半熔断状态，此时流量开始打进服务C，此时仍然会计算错误率，只是半熔断状态下，是以10个请求为单位窗口计算的错误率，这个可以保证在服务C没有恢复正常的情况下可以更快速的进入全熔断状态。 2.3：测试-熔断器状态切换然后开始编写测试方法，下面会通过测试方法来详细解析该熔断器的状态变迁： 代码块3123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public void testBreak() throws Exception { //按照B服务里熔断器的配置，如果进行100次请求，有50次失败了，则对ServerC的调用进入全熔断状态 //1000ms后恢复为半熔断状态，半熔断状态下进行10次请求，如果有5次依然失败，则再次进入全熔断状态 for (int i = 0; i &lt; 100; i++) { if (i &lt; 50) { serverB.getCInfo(0); //前50次全部报错 } else { serverB.getCInfo(1); //后50次全部成功 } } //断言：此时熔断器为全熔断状态 System.out.println(serverB.getBreaker().getState().equals(CircuitBreaker.State.OPEN)); //全熔断状态下并不会实际调用C，而是会走服务B的降级逻辑，即便我们输入的参数是对的，也一样会被降级 System.out.println(serverB.getCInfo(1)); Thread.sleep(500L); //断言：由于全熔断状态配置的持续时间时1000ms，所以500ms过去后，仍然是全熔断状态 System.out.println(serverB.getBreaker().getState().equals(CircuitBreaker.State.OPEN)); Thread.sleep(500L); //断言：1000ms过后，熔断器处于半熔断状态 System.out.println(serverB.getBreaker().getState().equals(CircuitBreaker.State.HALF_OPEN)); //半熔断状态下会尝试恢复，所以会实际调用C，分别输入正确和错误的参数进行测试 System.out.println(serverB.getCInfo(1)); System.out.println(serverB.getCInfo(0)); //半熔断状态下，只需要请求10次，有5次出错即可再次进入全熔断状态 for (int i = 0; i &lt; 10; i++) { if (i &lt; 4) { //因为上面传过一次0了，所以这里只需要4次便可以重新回到全开状态 serverB.getCInfo(0); //前5次全部报错 } else { serverB.getCInfo(1); //后5次全部成功 } } //断言：此时熔断器为全熔断状态 System.out.println(serverB.getBreaker().getState().equals(CircuitBreaker.State.OPEN)); //同样的，全熔断状态下并不会实际调用C，而是会走服务B的降级逻辑 System.out.println(serverB.getCInfo(1)); //这时静待1000ms，再次进入半熔断状态，我们尝试恢复服务C的调用 Thread.sleep(1000L); //这时我们让其10次请求里有6次成功 for (int i = 0; i &lt; 10; i++) { if (i &lt; 6) { //前6次成功 serverB.getCInfo(1); } else { //后4次失败 serverB.getCInfo(0); } } //由于10次请求里只失败了4次，达不到50%的全开阈值，所以此时会恢复 //断言：此时熔断器为闭合状态 System.out.println(serverB.getBreaker().getState().equals(CircuitBreaker.State.CLOSED)); System.out.println(serverB.getCInfo(1)); //正常输出 System.out.println(serverB.getCInfo(0)); //走普通异常逻辑 } 最终输出如下： 1234567891011true服务C出错，触发服务B的降级逻辑truetrueid=1的C信息调用服务C出错true服务C出错，触发服务B的降级逻辑trueid=1的C信息调用服务C出错 可以看到，单位请求内达到错误率阈值后熔断器会进入全开状态（全熔断），全开状态下走降级逻辑，此时不再会实际请求服务C，一段时间后（全开持续时间），进入半开状态（半熔断），半开时仍然正常打入服务C，只是由于单位请求量相比闭合时更小，若服务还没恢复，计算错误率会更快达到错误率阈值而迅速进入全开状态，以此类推。如果服务已经恢复，那么将会从半开状态进入闭合状态。 2.4：测试-错误率统计方式通过上面的测试用例可以知道触发熔断器状态切换的时机，而且闭合状态下和半熔断状态下统计错误率的单位请求数不相同，那么这个请求数量又是怎么统计的呢？如果一个请求先错误了49次，然后在第101次请求的时候再错误1次是否可以成功触发熔断器全开？如果把这49次失败往后挪一位呢？现在再来按照设想测试下其错误率的统计方式： 代码块412345678910111213141516public void testRate() { //首先闭合状态下单位请求仍然是100，现在让前49次全部失败 for (int i = 0; i &lt; 100; i++) { if (i &lt; 49) { serverB.getCInfo(0); } else { serverB.getCInfo(1); } } //断言：虽然请求了100次，但是错误率并没有达到阈值（50%），所以这里仍然是闭合状态的 System.out.println(serverB.getBreaker().getState().equals(CircuitBreaker.State.CLOSED)); //这里再让其失败一次 serverB.getCInfo(0); //断言：这里应该还是闭合状态的，按照100次单位请求来看，第一次失败的那个请求会被这次失败这个请求顶替掉（这里不理解没关系，下面有图） System.out.println(serverB.getBreaker().getState().equals(CircuitBreaker.State.CLOSED)); } 输出结果为： 12truetrue 然后我们让第一次失败的那次请求和其后面出错的请求后移一位： 代码块512345678910111213141516public void testRate() { //首先闭合状态下单位请求仍然是100，仍然让其错误49次，但现在让第2~50次失败 for (int i = 0; i &lt; 100; i++) { if (i != 0 &amp;&amp; i &lt; 50) { //第2~50次请求失败，总计失败49次 serverB.getCInfo(0); } else { serverB.getCInfo(1); } } //断言：跟上面例子一样，错误率并没有达到阈值，仍然是闭合状态 System.out.println(serverB.getBreaker().getState().equals(CircuitBreaker.State.CLOSED)); //这里再让其失败一次 serverB.getCInfo(0); //断言：这里应该是全开状态，按照100次单位请求来看，第一次成功的那个请求会被这次失败这个请求顶替掉，然后凑够50次失败请求（参考图4） System.out.println(serverB.getBreaker().getState().equals(CircuitBreaker.State.OPEN)); } 输出结果为： 12truetrue 用图来描述下导致这两种情况发生的流程： 所以Resilience4j在计算失败率的时候，是会发生滑动的，错误率是根据当前滑动窗口内的请求进行计算得出的，每次请求都会导致窗口移动，都会重新计算当前失败率，这个在源码解析里会说明这是怎样的一种结构，这里简单了解即可。 三、源码解析3.1：注册器入口通过上面ServerB类里的使用，首先会通过CircuitBreakerRegistry.of生成一个注册器对象，然后利用注册器对象的circuitBreaker方法来生成一个实际的breaker对象，代码如下： 代码块6123456public interface CircuitBreakerRegistry { //静态方法返回了InMemoryCircuitBreakerRegistry的实例 static CircuitBreakerRegistry of(CircuitBreakerConfig circuitBreakerConfig) { return new InMemoryCircuitBreakerRegistry(circuitBreakerConfig); }} InMemoryCircuitBreakerRegistry类代码如下（已简化处理，只展示流程相关代码）： 代码块71234567891011121314151617public final class InMemoryCircuitBreakerRegistry implements CircuitBreakerRegistry { //所有的breaker被存方在这个map里，breaker按照name不同而不同，每个breaker里都有自己的一份错误率统计数据 private final ConcurrentMap&lt;String, CircuitBreaker&gt; circuitBreakers; private final CircuitBreakerConfig defaultCircuitBreakerConfig; //开始的配置对象，闭合状态单位请求量、半开状态单位请求量、错误率阈值等都会放在这里面 public InMemoryCircuitBreakerRegistry(CircuitBreakerConfig defaultCircuitBreakerConfig) { this.defaultCircuitBreakerConfig = Objects.requireNonNull(defaultCircuitBreakerConfig, \"CircuitBreakerConfig must not be null\"); this.circuitBreakers = new ConcurrentHashMap&lt;&gt;(); } @Override public CircuitBreaker circuitBreaker(String name) { //添加一个breaker，若存在，直接返回 return circuitBreakers.computeIfAbsent(Objects.requireNonNull(name, \"Name must not be null\"), (k) -&gt; CircuitBreaker.of(name, defaultCircuitBreakerConfig)); }} 这个流程很简单，就是用一个map来维护所有breaker的，所以需要注意的是，命名breaker的时候，不要携带一些id之类的字段，很容易把map撑爆。 3.2：Breaker实体-CircuitBreaker拿到breaker实体后首先会通过其executeCallable方法执行需要被熔断的逻辑块，之前提到的所有的错误率统计、状态切换都发生在这个实体内。 代码块8123456789101112131415161718192021222324252627public interface CircuitBreaker { default T executeCallable(Callable callable) throws Exception{ return decorateCallable(this, callable).call(); //包装原始的callable } //方法包装，返回一个Callable对象，真正的业务逻辑callable在这里被执行 static Callable decorateCallable(CircuitBreaker circuitBreaker, Callable callable){ return () -&gt; { //全熔断状态下，这里返回false，会抛出CircuitBreakerOpenException类型的异常，ServerB里判定是否走降级逻辑就是通过catch该异常来决定的 if(!circuitBreaker.isCallPermitted()) { throw new CircuitBreakerOpenException(String.format(\"CircuitBreaker '%s' is open\", circuitBreaker.getName())); } //非全熔断状态触发下面的逻辑 long start = System.nanoTime(); try { T returnValue = callable.call(); //执行实际的业务逻辑 long durationInNanos = System.nanoTime() - start; circuitBreaker.onSuccess(durationInNanos); //非常关键的方法，用来累计执行成功的数量，计算错误率 return returnValue; } catch (Throwable throwable) { //执行异常，调用onError累计出错数 long durationInNanos = System.nanoTime() - start; circuitBreaker.onError(durationInNanos, throwable); //非常关键的方法，用来累计执行失败的数量，计算错误率 throw throwable; } }; }} CircuitBreaker是一个接口，CircuitBreakerStateMachine是它的实现类，上述代码里比较关键的isCallPermitted、onSuccess、onError都是在这个CircuitBreakerStateMachine类里实现的。 CircuitBreakerStateMachine类比较复杂，牵扯到整个熔断器的状态切换、错误统计触发等，精简一下该类，只关注核心部分： 代码块912345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394public final class CircuitBreakerStateMachine implements CircuitBreaker { //熔断器的名称 private final String name; /** * 非常非常关键的一个属性，它是一个引用对象，CircuitBreakerState一共有以下子类：ClosedState、HalfOpenState、OpenState、DisabledState、ForcedOpenState * 熔断器每次发生状态切换，都会new出一个新的XXState对象，让下面的引用指向新的状态对象 */ private final AtomicReference stateReference; //开始设置的熔断器配置，通过该对象可以拿到错误率阈值、全熔断持续状态等信息 private final CircuitBreakerConfig circuitBreakerConfig; //&amp;&amp;&amp; 事件处理器，这里不是重点，放到第四部分说，可以先忽略 private final CircuitBreakerEventProcessor eventProcessor; //构造器 public CircuitBreakerStateMachine(String name, CircuitBreakerConfig circuitBreakerConfig) { this.name = name; this.circuitBreakerConfig = circuitBreakerConfig; this.stateReference = new AtomicReference&lt;&gt;(new ClosedState(this)); //初始化的时候，熔断器状态都是闭合状态，所以首先new一个ClosedState并让stateReference指向它 this.eventProcessor = new CircuitBreakerEventProcessor(); } //切换到闭合状态，new ClosedState，可以看到每个XXState对象都持有当前CircuitBreakerStateMachine对象 @Override public void transitionToClosedState() { stateTransition(CLOSED, currentState -&gt; new ClosedState(this, currentState.getMetrics())); } //切换到全熔断状态，new OpenState， @Override public void transitionToOpenState() { stateTransition(OPEN, currentState -&gt; new OpenState(this, currentState.getMetrics())); } //切换到半熔断状态，new HalfOpenState， @Override public void transitionToHalfOpenState() { stateTransition(HALF_OPEN, currentState -&gt; new HalfOpenState(this)); } //状态切换方法（也即是XXState对象切换的地方） private void stateTransition(State newState, Function&lt;CircuitBreakerState, CircuitBreakerState&gt; newStateGenerator) { //引用指向新的XXState对象 CircuitBreakerState previousState = stateReference.getAndUpdate(currentState -&gt; { if (currentState.getState() == newState) { return currentState; } return newStateGenerator.apply(currentState); }); if (previousState.getState() != newState) { //&amp;&amp;&amp; 状态切换事件发布，本部分忽略，参考第四部分 publishStateTransitionEvent(StateTransition.transitionBetween(previousState.getState(), newState)); } } //代码块8里的isCallPermitted方法，这个方法决定了是否抛出\"已熔断\"异常 @Override public boolean isCallPermitted() { //可以看到，这个解决取决于对应XXState里isCallPermitted方法的返回结果 boolean callPermitted = stateReference.get().isCallPermitted(); if (!callPermitted) { //&amp;&amp;&amp; 已熔断异常事件发布，本部分忽略，参考第四部分 publishCallNotPermittedEvent(); } return callPermitted; } //代码块8里的onError方法，业务处理错误后会触发这个方法的调用 @Override public void onError(long durationInNanos, Throwable throwable) { //这个判断是过滤需要忽略的异常处理，一般情况下没配置的话所有异常都会走下面实际的onError逻辑 if (circuitBreakerConfig.getRecordFailurePredicate().test(throwable)) { //&amp;&amp;&amp; 处理错误事件发布，参考第四部分 publishCircuitErrorEvent(name, durationInNanos, throwable); //可以看到，实际上onError也是调用的XXState里的onError方法 stateReference.get().onError(throwable); } else { //&amp;&amp;&amp; 命中了可忽略的异常，忽略错误事件发布，本部分忽略，参考第四部分 publishCircuitIgnoredErrorEvent(name, durationInNanos, throwable); } } //代码块8里的onSuccess方法，业务处理正常会触发这个方法的调用 @Override public void onSuccess(long durationInNanos) { //&amp;&amp;&amp; 处理正常事件发布，本部分忽略，参考第四部分 publishSuccessEvent(durationInNanos); //同样的，onSuccess也是调用的XXState里的onError方法 stateReference.get().onSuccess(); }} 3.3：状态类通过上面的代码可以知道isCallPermitted、onSuccess、onError这三个方法实际上都是调用对应XXState对象里的方法，下面来看下ClosedState、OpenState、HalfOpenState这三个状态对象里有关这三个方法的实现（因为上面的测试用例只涉及这三种状态的互转，实际上这三种状态也是最常用的，所以为了避免混乱，只展示这三种，所有状态类均继承自CircuitBreakerState抽象类） 3.3.1：ClosedState闭合状态时初始状态，中途只会由半熔断状态切换而来，正常情况下都是闭合状态，代码如下： 代码块101234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556final class ClosedState extends CircuitBreakerState { //用来度量错误率的对象 private final CircuitBreakerMetrics circuitBreakerMetrics; //就是配置里的failureRateThreshold属性，闭合状态时的错误率阈值（第二部分的测试用例中是50） private final float failureRateThreshold; //参考代码块9的CircuitBreakerStateMachine构造器中初始化stateReference时，初始态都是闭合状态，最初都是通过该方法完成初始化的 ClosedState(CircuitBreakerStateMachine stateMachine) { this(stateMachine, null); } //这个构造器是状态转换时触发的，参考代码块9里的transitionToClosedState方法 ClosedState(CircuitBreakerStateMachine stateMachine, CircuitBreakerMetrics circuitBreakerMetrics) { super(stateMachine); //拿到熔断器的配置 CircuitBreakerConfig circuitBreakerConfig = stateMachine.getCircuitBreakerConfig(); if(circuitBreakerMetrics == null){ //初始化metrics对象，传进去的是闭合状态时计算错误率的单位请求数（第二部分的测试用例中是100） this.circuitBreakerMetrics = new CircuitBreakerMetrics( circuitBreakerConfig.getRingBufferSizeInClosedState()); }else{ //中途进行状态转换，调用的都是这里的逻辑，利用circuitBreakerMetrics的copy方法，重新赋值给circuitBreakerMetrics属性，暂时忽略，参考第3.4部分 this.circuitBreakerMetrics = circuitBreakerMetrics.copy(circuitBreakerConfig.getRingBufferSizeInClosedState()); } //赋值错误率阈值 this.failureRateThreshold = stateMachine.getCircuitBreakerConfig().getFailureRateThreshold(); } @Override boolean isCallPermitted() { //闭合状态下返回true，不会触发降级逻辑（ps：只有在全熔断状态下才会返回true） return true; } @Override void onError(Throwable throwable) { // 闭合状态下，onerror需要记录错误率，注：circuitBreakerMetrics的onError方法会记录一笔错误的记录，并把当前的错误率返回 checkFailureRate(circuitBreakerMetrics.onError()); } @Override void onSuccess() { // 闭合状态下，onerror需要记录成功数，注：circuitBreakerMetrics的onSuccess方法会记录一笔正确的记录，并把当前的错误率返回 checkFailureRate(circuitBreakerMetrics.onSuccess()); } //根据当前的错误率，决定是否切到半熔断状态 private void checkFailureRate(float currentFailureRate) { if (currentFailureRate &gt;= failureRateThreshold) { //这里判断当前错误率是否超过阈值 // 利用CircuitBreakerStateMachine的transitionToOpenState方法，将状态对象转换成OpenState stateMachine.transitionToOpenState(); } }} 3.3.2：OpenState一般全熔断状态会从闭合或者半熔断状态里切换而来，它的代码如下： 代码块111234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253final class OpenState extends CircuitBreakerState { //根据全熔断持续时间推出的进入半熔断状态的时间 private final Instant retryAfterWaitDuration; //同样是用来度量错误率的对象，该对象就是上一个State对象里的Metrics对象 private final CircuitBreakerMetrics circuitBreakerMetrics; OpenState(CircuitBreakerStateMachine stateMachine, CircuitBreakerMetrics circuitBreakerMetrics) { super(stateMachine); //就是配置里的waitDurationInOpenState属性，全熔断持续时间（第二部分的测试用例中是100ms） final Duration waitDurationInOpenState = stateMachine.getCircuitBreakerConfig().getWaitDurationInOpenState(); //当前时间加上持续时间，就是切换至半熔断状态的时机 this.retryAfterWaitDuration = Instant.now().plus(waitDurationInOpenState); //直接用之前的circuitBreakerMetrics对象 this.circuitBreakerMetrics = circuitBreakerMetrics; //如果配置了自动切换半熔断状态的开关为true，则会发起一个延时任务，用来主动切换状态 if (stateMachine.getCircuitBreakerConfig().isAutomaticTransitionFromOpenToHalfOpenEnabled()) { AutoTransitioner.scheduleAutoTransition(stateMachine::transitionToHalfOpenState, waitDurationInOpenState); } } @Override boolean isCallPermitted() { // 如果全熔断状态持续时间超出目标范围，则认为现在可以切换为半熔断状态，然后返回true if (Instant.now().isAfter(retryAfterWaitDuration)) { stateMachine.transitionToHalfOpenState(); return true; } circuitBreakerMetrics.onCallNotPermitted(); //记录一次NotPermitted（简单的累加） return false; //全熔断状态，直接返回false，表示已被熔断，让调用方抛出CircuitBreakerOpenException异常 } @Override void onError(Throwable throwable) { //理论上处于全熔断状态，isCallPermitted返回false，onError不会被触发（参考代码块8里的decorateCallable方法） //但是存在一种特殊的情况，假设有俩线程，线程1执行的时候还是闭合状态，isCallPermitted返回true，这时线程2里触发了熔断阈值 //线程2把stateReference的指向置为OpenState，这时线程1继续往下执行，触发的onError其实是OpenState里的onError（也即是本例中的这个方法） //全熔断状态下即便是上面这种临界情况发生，这次失败也会被统计上去 circuitBreakerMetrics.onError(); } /** * Should never be called when isCallPermitted returns false. */ @Override void onSuccess() { //跟onError一样，有概率会访问到 circuitBreakerMetrics.onSuccess(); }} 3.3.3：HalfOpenState半熔断状态一定是由全熔断切换出来的，来看下它的代码： 代码块1212345678910111213141516171819202122232425262728293031323334353637383940414243444546474849final class HalfOpenState extends CircuitBreakerState { //同样是用来度量错误率的对象 private CircuitBreakerMetrics circuitBreakerMetrics; //同样是配置里的failureRateThreshold属性 private final float failureRateThreshold; HalfOpenState(CircuitBreakerStateMachine stateMachine) { super(stateMachine); CircuitBreakerConfig circuitBreakerConfig = stateMachine.getCircuitBreakerConfig(); //初始化度量对象，相比闭合状态，这里传入的是ringBufferSizeInHalfOpenState（第二部分的测试用例中是10） this.circuitBreakerMetrics = new CircuitBreakerMetrics( circuitBreakerConfig.getRingBufferSizeInHalfOpenState()); //闭合状态和半开状态共用同一个错误率阈值（第二部分的测试用例中是50） this.failureRateThreshold = stateMachine.getCircuitBreakerConfig().getFailureRateThreshold(); } @Override boolean isCallPermitted() { //跟闭合状态一样，返回true return true; } @Override void onError(Throwable throwable) { // 跟闭合状态一样，要记录和判断当前的错误率（来决定是恢复闭合状态还是进入全熔断状态） checkFailureRate(circuitBreakerMetrics.onError()); } @Override void onSuccess() { // 同上 checkFailureRate(circuitBreakerMetrics.onSuccess()); } //通过该方法，判断错误率，决定是否恢复为闭合状态或者再次进入全熔断状态 private void checkFailureRate(float currentFailureRate) { //Metrics返回-1表示请求量表示还没有达到单位请求量（ringBufferSizeInHalfOpenState） //下面的逻辑可以看出，在半熔断状态下，经过ringBufferSizeInHalfOpenState次请求后根据错误率判断，就可以决定出下一步切换到哪个状态了 if (currentFailureRate != -1) { //当前错误率如果再次超出阈值，则再次进入全熔断状态 if (currentFailureRate &gt;= failureRateThreshold) { stateMachine.transitionToOpenState(); } else { //否则恢复为闭合状态 stateMachine.transitionToClosedState(); } } }} 3.3.4：状态间的切换关系上面三种状态的切换关系如下： 在这些状态中，最初为熔断闭合状态，ServerB的所有请求正常访问ServerC，ServerC报错，错误率累计达到50%后触发熔断全开状态，此时Server对ServerC发出的请求将走ServerB的降级逻辑，不再实际访问ServerC的方法，这个状态会持续waitDurationInOpenState这么久（测试用例中是1000ms），然后进入熔断半开状态，此时跟闭合状态一样，ServerB的所有请求仍会正常访问ServerC，不同的是半开状态下只需要满足ringBufferSizeInHalfOpenState次调用（测试用例中是10次），就可以直接判断错误率是否达到阈值，这点可以在代码块12里的checkFailureRate方法体现，图5中可以看到，如果未达到错误阈值表示ServerC已恢复，则可以关闭熔断，否则再次进入全熔断状态。 3.3.5：度量对象（CircuitBreakerMetrics）的传递这个对象在3.4中会详细说明，目前只需要知道该类用于做错误统计用，错误率计算的核心，核心方法为onError和onSuccess，这俩方法用于错误/正确请求的触发点，用于触发CircuitBreakerMetrics对象对错误率的统计。 通过代码块10、11、12可以看到CircuitBreakerMetrics对象的流向，首先初始化的时候是调用ClosedState第一个构造器触发第二个构造器，第二个构造器会new一个CircuitBreakerMetrics，传过去的size为ringBufferSizeInClosedState，然后由ClosedState切换至OpenState状态时，其CircuitBreakerMetrics会被传递给OpenState对象，根据代码块11可以知道，OpenState利用该对象统计熔断期间被熔断的次数，然后OpenState切换至HalfOpenState时，HalfOpenState没有接受CircuitBreakerMetrics对象的构造器，不管由谁切换到半开状态，CircuitBreakerMetrics对象都是全新的，由代码块12可知，初始化CircuitBreakerMetrics对象时传过去的size就是ringBufferSizeInHalfOpenState。 CircuitBreakerMetrics对象的传递以及传递后在State对象里所做的操作： 图6根据代码块10、11、12画出，简单体现了Metrics对象的生成以及流向，以及这个对象在各State对象里所做的主要操作。通过图6可以看出实际产生新的Metrics对象的地方为闭合态和半开态，因为这俩地方是需要做错误统计的，需要全新的Metric对象，全开态下仅接收前一状态的Metrics对象，在命中熔断后对其内部numberOfNotPermittedCalls（不是很懂这个属性，简单的累加，连用到的地方都没，可能仅仅是做个熔断数统计让业务方获取的吧，做监控可以用），在半开态再次进入闭合态时，其Metrics仍然被传递给了闭合态，由代码块10可知，如果传了Metrics对象，闭合态在产生新的Metrics对象时，会通过copy方法来产生，这个方法在3.4会详细说明，简单来说就是把前一个状态（只可能是半开态）的Metrics里的请求计数同步到它自己的Metrics里，这样做有一个好处，就是新的闭合态不用重新累计错误率了，以单元测试所配的参数试想一下，如果在半开态下，进行了10次请求，发生了4次错误，此时会切回闭合态，闭合态copy了这10次请求的数据，那么只需要再经过90次请求和46次错误便可以再次进入全熔断状态（其实就是保证了状态的平滑切换，不丢失之前已经统计了的数据）。 3.4：错误统计3.4.1：CircuitBreakerMetrics通过3.3的了解，闭合和半开时的请求状态计数都是通过CircuitBreakerMetrics对象来完成的，现在来看下这个类里都干了些什么： 代码块1312345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485class CircuitBreakerMetrics implements CircuitBreaker.Metrics { //通过3.3的代码块可知，该值就是闭合或者半开状态下设置的ringBufferSizeInClosedState和ringBufferSizeInHalfOpenState //表示一次请求窗口的大小，测试用例中就是闭合时的100以及半开时的10，通过图4和下方的getFailureRate方法可以知道， //至少要累计完成一个请求窗口的请求量后才会实际计算错误率 private final int ringBufferSize; //实际用来记录一个请求窗口的请求统计数据的结构，本节不深究，详细参考3.4.2 private final RingBitSet ringBitSet; //全开状态下累计被熔断的请求个数，触发点参考图6以及代码块11 private final LongAdder numberOfNotPermittedCalls; //构造器1，参考图6，在最开始的闭合状态以及后续的半开状态下初始化Metrics对象用的就是该构造器 CircuitBreakerMetrics(int ringBufferSize) { this(ringBufferSize, null); } //参考图6，由半开转到闭合态的时候，是通过该方法进行初始化的 public CircuitBreakerMetrics copy(int targetRingBufferSize) { return new CircuitBreakerMetrics(targetRingBufferSize, this.ringBitSet); //这里会把当前Metrics对象里的ringBitSet传递下去 } //构造器2 CircuitBreakerMetrics(int ringBufferSize, RingBitSet sourceSet) { this.ringBufferSize = ringBufferSize; if(sourceSet != null) { //通过copy初始化会走这里（每次的半开态转闭合态），将原来Metrics对象里的ringBitSet传递下去（用来初始化新的请求窗口） this.ringBitSet = new RingBitSet(this.ringBufferSize, sourceSet); }else{ //非copy新建Metrics对象（每次的半开态和最初的闭合态） this.ringBitSet = new RingBitSet(this.ringBufferSize); } this.numberOfNotPermittedCalls = new LongAdder(); } //onError和onSuccess的触发点参考3.3里的State类 //当请求发生错误时触发该方法，该方法用于记一次失败，然后把当前错误率返回 float onError() { int currentNumberOfFailedCalls = ringBitSet.setNextBit(true); //通过ringBitSet的setNextBit置为true，算作一笔失败的记录 return getFailureRate(currentNumberOfFailedCalls); } //当请求正常时触发该方法，该方法用于记一次成功，然后把当前错误率返回 float onSuccess() { int currentNumberOfFailedCalls = ringBitSet.setNextBit(false); //通过ringBitSet的setNextBit置为false，算作一笔成功的记录 return getFailureRate(currentNumberOfFailedCalls); } //全开状态下累计被熔断的请求个数 void onCallNotPermitted() { numberOfNotPermittedCalls.increment(); } //通过getFailureRate计算错误率并返回 @Override public float getFailureRate() { return getFailureRate(getNumberOfFailedCalls()); } //下方注释中的窗口大小就是ringBufferSize属性 //该方法通过ringBitSet对象返回当前请求窗口内发生请求的总次数，如果达到了ringBufferSize次，则这个值就恒等于ringBufferSize @Override public int getNumberOfBufferedCalls() { return this.ringBitSet.length(); } //该方法通过ringBitSet对象返回当前请求窗口内发生错误的次数 @Override public int getNumberOfFailedCalls() { return this.ringBitSet.cardinality(); } //错误率计算方法 private float getFailureRate(int numberOfFailedCalls) { //若请求还没有完成一个请求窗口，则返回-1 if (getNumberOfBufferedCalls() &lt; ringBufferSize) { return -1.0f; } //完成了一次请求窗口，才会真正计算错误率 return numberOfFailedCalls * 100.0f / ringBufferSize; }} 通过上面的代码可以知道最终统计错误数的是在RingBitSet结构中，下面来仔细了解下这个类~ 3.4.2：位图&amp;BitSetMod了解RingBitSet之前，先来了解一种数据结构-位图，如果已经了解过位图，那么可以直接去看RingBitSet。 RingBitSet持有一个BitSetMod对象，BitSetMod基于位图实现，位图是怎样的一种结构呢？先看下图7，然后再去解析它的源码实现。 通过上图可知，位图就是利用数组内每个元素的bit位存入一个标记，标记只有存在或者不存在（对应二进制的0和1），这样就可以做到用一个long型的数字就可以产生出64个标记信息，非常适合数据量庞大而判断状态少的应用场景，比如判断一个词语是否是屏蔽词，首先屏蔽词状态只有两种：命中or不命中，但是屏蔽词可能是个非常庞大的集合，如果一个个拿来比较，效率完全保证不了，那么就可以利用这个数据结构来解决这类问题，可以首先把所有的屏蔽词放到一个位图结构里，如果有相同的词语，只需要简单的两部运算就可以拿到是否命中结果，构建这个位图结构的过程如下： 通过上图，屏蔽词位图结构就构建好了，如果有个词语需要判定是否命中屏蔽词，只需要让这个词语通过上面的哈希算法计算出哈希值，然后找到对应的数组下标，通过位运算算出其所在位置，将该位置的值取出，如果是0，则认为没有命中，1则认为命中。 以上就是位图结构，通过上面的例子，可以认为同一个值一定命中位图里的同一个位置，那么抽象成熔断器的错误率，错误状态只有0和1，1表示错误，0表示正确，给每次请求编号，当成是图8中的哈希值，相同编号的请求一定会落到同一个位置，现在不理解没关系，这个要结合RingBitSet一起看，目前只需要理解位图特性即可。 Resilience4j里通过BitSetMod简单实现了一个位图结构，来看下代码（注：代码里有大量位运算，过程说明都写在了注释里）： 代码块14123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125/** * 下方为源码注释↓↓ * {@link io.github.resilience4j.circuitbreaker.internal.BitSetMod} is simplified version of {@link java.util.BitSet}. * It has no dynamic allocation, expanding logic, boundary checks * and it's set method returns previous bit state. */public class BitSetMod { /** * 1.此类是一种怎样的数据结构？ * 根据原有注释，可知这是一个简易版的BitSet，即位图结构，可以通过图7更为直观的了解下该结构 * 由图7可知，位图分为x，y轴，y轴就是本类的long型的数组（words），其中内部每一个元素都包括64个bit，因此bit位横向扩展就是x轴（x轴大小恒等于64） * 如果要标记一个数字是否存在于图中，只需要先找到所属的y轴位置（即对应的words下标），然后再计算出它应该出现的x轴long型数字中哪个bit位， * 然后判断该bit位是否已被标记为true，若是，则返回已存在，否则返回不存在。 * &lt;p&gt; * &lt;p&gt; * 2.位运算 * 简单了解下本类中出现的位运算，任意两个数的乘法或除法都可以用&lt;&lt;（左移）或&gt;&gt;（右移）来表示 * 例： * a * b == a &lt;&lt; log2(b) * a / b == a &gt;&gt; log2(b) * 本例中的ADDRESS_BITS_PER_WORD属性，其实就是long型位数以2为底的对数，即log2(64) = 6 * 那么接下来代码中针对ADDRESS_BITS_PER_WORD的位运算就可以简单理解为乘以/除以64了 */ //long类型bit位的对数，即log2(64)＝6，利用该值可以进行简单的乘除法的位运算 private final static int ADDRESS_BITS_PER_WORD = 6; //最终可以存放的总位数，计算方式：words.length * 64（每个long型有64位，利用数组长度乘以位数，就计算出了位图的总位数） //用位运算表示为：words.length &lt;&lt; 6（右移表示乘法，右移6位表示乘以2^6，即words.length * 64） private final int size; //位图数组，long型，64个bit位 private final long[] words; //构造器，传入位图的容量大小 public BitSetMod(final int capacity) { //计算数组大小（即y轴大小），根据上面对位图的基本解释，可以知道，y轴是一个long型数组， //而每次一个数字进来，会首先找到y轴所属的位置，那么这个数组得多大才合适呢？我们知道x轴固定为64个， //也就是说正常情况下，任意数字进来后都会被分到某个y轴对应的long型数字里的某一位，那么y轴大小就很好推算了， //利用给出的容量大小（这个表示任意数最大时为多大），除以64进行平均分组，这样不管传的任意数为多大，始终都可以找到对应的[x,y]，且不会越界 int countOfWordsRequired = wordIndex(capacity - 1) + 1; //上面说过，size就是位图里所有位数，即x * y，也就是words.length * 64，用位运算表示为：words.length &lt;&lt; 6 size = countOfWordsRequired &lt;&lt; ADDRESS_BITS_PER_WORD; //最终((capacity - 1)/64)+1就是y轴数组大小，初始化数组即可 words = new long[countOfWordsRequired]; //到这里，一个位图对象就被我们创建好了，数组（y轴）是它实际的实体，x轴是数组里long型数字的二进制位（64） } private static int wordIndex(int bitIndex) { //下面这个位运算等同于：bitIndex/64 return bitIndex &gt;&gt; ADDRESS_BITS_PER_WORD; } //开始设置数字信息，bitIndex为目标放置位置，value为值（0或1） public int set(int bitIndex, boolean value) { // 利用位置数字除以64，推算出它对应的y轴下标 int wordIndex = wordIndex(bitIndex); // 注：下面的代码都是位运算，开始前先来了解一下如何定位某个数字的二进制第n位上的数字是0还是1 // 将1右移bitIndex位，可以得到一个类似1000000的二进制数字，利用这个数字跟原来的数字本身做位与运算，可以推算出原数第bitIndex位上的数字是1还是0 // 举个例子，我想知道下面这个二进制数字中第5位的数字是0还是1（跟十进制一样，位数是从右往左数，位数最高的在最左边，下标从0开始算起） // 假设该二进制数为λ，设：λ=101010101 // 现在将1右移5位得到bitMask，它用二进制表示为：100000，1的位置正好位于第5位（从右往左，下标从0算起） // 利用λ跟bitMask进行位与运算： // 101010101（λ） // &amp; // 000100000（bitMask） // ------------------ // 000000000（位与结果） // 由这个过程可以发现，λ的第5位如果是0，位与后的结果也是0，如果是1，那么位与运算后的结果肯定是不等于0的，通过这种方式，我们就可以利用1右移的方式， // 知道λ的第n位是0还是1 // // 通过上面的例子，可以知道，任意数与1右移后的数字（bitMask）进行位与运算的结果要么不等于0，要么等于0，因为1右移n位后生成的二进制数在其n位上一定为1， // 其余位置一定为0，0&amp;0、0&amp;1均为0，所以最后的结果要么是000000000，要么还等于1右移后的那个数：000010000，这取决于原始数字里第n位上是否是1， // 如果是1，则相与后的结果值一定不等于0，反之则等于0 // 结合上面所有的描述，这里可以再思考一个问题，为什么位不会相互覆盖？比如我传了一个bitIndex为100，long型1&lt;&lt;100等价于1&lt;&lt;36（以64为模轮回），那么当我传100的时候岂不是会覆盖掉传36时那次做标记？ // 这个问题答案是否定的，因为在最初的时候就已经把bitIndex按照64为单位进行相除计算出下标了，也就是说bitIndex等于100那次，跟bitIndex等于36那次，不在一个下标里（不在一个次元） // 根据这些规则，下面的代码就好理解了。 long bitMask = 1L &lt;&lt; bitIndex; int previous = (words[wordIndex] &amp; bitMask) != 0 ? 1 : 0; //把该位置上当前的值（0或1）赋值给previous（也就是最后返回出去的结果） if (value) { // 重新赋值，注意，这里是原值跟bitMask进行或运算，意味着目标位的值会直接变成1，其余位置的值均不变 words[wordIndex] = words[wordIndex] | bitMask; // 结合例子，参考下面这个过程更容易理解 // 101010101 // | // 000100000 // --------- // 101110101 } else { // value等于false的时候，bitMask取反后跟原值进行与运算，跟上面相反，这是把目标位变成0 words[wordIndex] = words[wordIndex] &amp; ~bitMask; // 结合例子，参考下面这个过程更容易理解 // 101010101 // &amp; // 111011111（bitMask的反码） // --------- // 101010101 } return previous; } int size() { //返回位图里的总位数 return size; } boolean get(int bitIndex) { // 注：如果对下方的右移等操作还不是很了解，请先看set方法里的注释 // 首先还是利用位置数字除以64，推算出它对应的y轴下标 int wordIndex = wordIndex(bitIndex); //如果set里的位运算理解了，下面这个很容易理解，这个流程跟set方法里获取previous一样 long bitMask = 1L &lt;&lt; bitIndex; return (words[wordIndex] &amp; bitMask) != 0; //大于0时返回true，表示目标位是1，否则返回false，目标位是0 }} 上面是Resilience4j针对位图的简单实现，它负责存储单位请求内的错误/成功标志。 3.4.3：RingBitSet之前说过，最终请求被放到了一个环形结构里才对，沿着环执行一周就是一次单位请求，回看下图4，其实第101次请求就是顶替掉第一次请求的结果罢了，现在把图4中以100为请求窗口弯曲成一个环，假如第一次请求是失败的，第101次请求是成功的（绿色背景表示成功的请求，红色背景表示失败的请求）： 如何利用位图结构记录每次请求的错误/成功标记然后再实现图9里的环形结构呢？Resilience4j通过RingBitSet来实现，来看下它的代码： 代码块1512345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697public class RingBitSet { //单位请求数，根据State类初始化RingSet时给的size值，可以确定该值就是各种ringBufferSize private final int size; //真正存放错误率的位图结构 private final BitSetMod bitSet; //在完成一个请求窗口后，该值为false，表示请求已满一次请求窗口 private boolean notFull; //给请求编号，方便位图计算位置 private int index = -1; //请求数量，最终等于size private volatile int length; //当前请求窗口内的错误数，就是利用这个数实时计算错误率的（参考CircuitBreakerMetrics.getNumberOfFailedCalls） private volatile int cardinality = 0; RingBitSet(int bitSetSize) { notFull = true; size = bitSetSize; bitSet = new BitSetMod(bitSetSize); } //携带RingBitSet参数的构造器会把sourceSet里的统计数据赋值给新的RingBitSet（继承其请求数、错误率等） //调用该构造器的触发点在CircuitBreakerMetrics.copy中触发，通过图6可知，每次由半开状态转到闭合状态时，都会调用copy方法， //让新的闭合态继承上次半开态的请求量和错误率，这是合理的，比较平滑无损的过度到闭合态。 RingBitSet(int bitSetSize, RingBitSet sourceSet) { this(bitSetSize); int targetLength = Integer.min(bitSetSize, sourceSet.length); int sourceIndex = sourceSet.index; int forwardIndex = sourceSet.size - sourceIndex; for (int i = 0; i &lt; targetLength; i++) { this.setNextBit(sourceSet.bitSet.get(sourceIndex)); // looping sourceIndex backwards without conditional statements forwardIndex = (forwardIndex + 1) % sourceSet.size; sourceIndex = (sourceSet.size - forwardIndex) % sourceSet.size; } } //非常非常重要的方法，它的触发点在CircuitBreakerMetrics的onError和onSuccess，主要用于记录错误率 public synchronized int setNextBit(boolean value) { increaseLength(); //环形结构依靠这里来实现，index永远在0~size间循环累加，类似：[0,1,2,3...99,0,1,2,3...99] index = (index + 1) % size; //利用位图，将本次的错误/成功标记设置到对应index的位置上， //并且拿到当前index对应上次请求窗口中同样为index位置的请求结果previous，至于为啥要拿到这个值，参考下方的逻辑 int previous = bitSet.set(index, value); //本次请求结果 int current = value ? 1 : 0; //下面这一步就是刷新错误数的，计算方式为：减去同位置上个请求窗口的请求结果，然后加上这次的请求结果 //举个例子，假设单位请求窗口是100，第一个请求窗口的第一次请求错误，index=0的位置被标为1，第101次请求，也就是第二个请求窗口的第一次请求， //意味着index仍然为0，那么第101次请求的结果就会覆盖掉第1次请求的那个结果，以此来完成窗口滚动（参考图9） cardinality = cardinality - previous + current; return cardinality; } //返回当前请求窗口内的错误总量 public int cardinality() { return cardinality; } public int size() { return bitSet.size(); } public int length() { return length; } @Override public String toString() { StringBuilder result = new StringBuilder(); for (int i = 0; i &lt; size; i++) { result.append(bitSet.get(i) ? '1' : '0'); } return result.toString(); } synchronized int getIndex() { return index; } //累加当前请求窗口内的请求量，当完成一次单位请求窗口时，length恒等于单位请求窗口大小（size） private void increaseLength() { if (notFull) { int nextLength = length + 1; if (nextLength &lt; size) { length = nextLength; } else { length = size; notFull = false; } } }} 四、总结Resilience4j通过CircuitBreakerStateMachine来独立出一个熔断器，其内部持有一个CircuitBreakerState对象的引用，在错误率达到某个阈值时，会发生状态切换，CircuitBreakerState的引用会指向新的状态对象。每个状态对象持有一个CircuitBreakerMetrics对象，用于做实时统计和错误率监听使用，CircuitBreakerMetrics对象通过RingBitSet来完成单位请求窗口的错误率统计，这个统计是实时的，每次请求都会触发一次错误率的判断。RingBitSet通过Resilience4j自己实现的一个轻量级的位图结构BitSetMod来标记请求错误/成功，顺便说下，这里通过RingBitSet来保证环形结构，而位图只负责存储请求结果，那么既然这样，我用普通的数组或者其他的可以通过下标获取数值的集合结构也可以实现啊，为什么一定要用位图呢？猜测是位图既可以保证跟数组一样高效，都是O(1)的复杂度，又可以节省存储空间，比如我的单位请求是1w次，如果是数组结构，虽然效率跟位图一样高，但是数组却需要存1w个0或1这样的数组，即便用byte类型的数组，每个数组元素都浪费了7个bit位。其他集合就更不用说了，效率无法保证，其次他们浪费的内存比单纯数组要高，所以，类似这种只有true或false的数据的存储，位图再适合不过了。 感觉有些地方说的不太清晰，待后续改进描述方式。","link":"/2019/12/10/Resilience4j%E7%86%94%E6%96%AD%E5%99%A8-%E4%BD%BF%E7%94%A8%E4%B8%8E%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"},{"title":"ThreadLocal系列（三）-TransmittableThreadLocal的使用及原理解析","text":"一、基本使用首先，TTL是用来解决ITL解决不了的问题而诞生的，所以TTL一定是支持父线程的本地变量传递给子线程这种基本操作的，ITL也可以做到，但是前面有讲过，ITL在线程池的模式下，就没办法再正确传递了，所以TTL做出的改进就是即便是在线程池模式下，也可以很好的将父线程本地变量传递下去，先来看个例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103// 需要注意的是，使用TTL的时候，要想传递的值不出问题，线程池必须得用TTL加一层代理（下面会讲这样做的目的） private static ExecutorService executorService = TtlExecutors.getTtlExecutorService(Executors.newFixedThreadPool(2)); private static ThreadLocal tl = new TransmittableThreadLocal&lt;&gt;(); //这里采用TTL的实现 public static void main(String[] args) { new Thread(() -&gt; { String mainThreadName = \"main_01\"; tl.set(1); executorService.execute(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之前(1), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }); executorService.execute(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之前(1), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }); executorService.execute(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之前(1), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }); sleep(1L); //确保上面的会在tl.set执行之前执行 tl.set(2); // 等上面的线程池第一次启用完了，父线程再给自己赋值 executorService.execute(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之后(2), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }); executorService.execute(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之后(2), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }); executorService.execute(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之后(2), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }); System.out.println(String.format(\"线程名称-%s, 变量值=%s\", Thread.currentThread().getName(), tl.get())); }).start(); new Thread(() -&gt; { String mainThreadName = \"main_02\"; tl.set(3); executorService.execute(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之前(3), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }); executorService.execute(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之前(3), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }); executorService.execute(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之前(3), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }); sleep(1L); //确保上面的会在tl.set执行之前执行 tl.set(4); // 等上面的线程池第一次启用完了，父线程再给自己赋值 executorService.execute(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之后(4), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }); executorService.execute(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之后(4), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }); executorService.execute(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之后(4), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }); System.out.println(String.format(\"线程名称-%s, 变量值=%s\", Thread.currentThread().getName(), tl.get())); }).start(); } private static void sleep(long time) { try { Thread.sleep(time); } catch (InterruptedException e) { e.printStackTrace(); } } 代码块1 运行结果： 1234567891011121314线程名称-Thread-2, 变量值=4本地变量改变之前(3), 父线程名称-main_02, 子线程名称-pool-1-thread-1, 变量值=3线程名称-Thread-1, 变量值=2本地变量改变之前(1), 父线程名称-main_01, 子线程名称-pool-1-thread-2, 变量值=1本地变量改变之前(1), 父线程名称-main_01, 子线程名称-pool-1-thread-1, 变量值=1本地变量改变之前(3), 父线程名称-main_02, 子线程名称-pool-1-thread-2, 变量值=3本地变量改变之前(3), 父线程名称-main_02, 子线程名称-pool-1-thread-2, 变量值=3本地变量改变之前(1), 父线程名称-main_01, 子线程名称-pool-1-thread-1, 变量值=1本地变量改变之后(2), 父线程名称-main_01, 子线程名称-pool-1-thread-2, 变量值=2本地变量改变之后(4), 父线程名称-main_02, 子线程名称-pool-1-thread-1, 变量值=4本地变量改变之后(4), 父线程名称-main_02, 子线程名称-pool-1-thread-1, 变量值=4本地变量改变之后(4), 父线程名称-main_02, 子线程名称-pool-1-thread-2, 变量值=4本地变量改变之后(2), 父线程名称-main_01, 子线程名称-pool-1-thread-1, 变量值=2本地变量改变之后(2), 父线程名称-main_01, 子线程名称-pool-1-thread-2, 变量值=2 程序有些啰嗦，为了说明问题，加了很多说明，但至少通过上面的例子，不难发现，两个主线程里都使用线程池异步，而且值在主线程里还发生过改变，测试结果展示一切正常，由此可以知道TTL在使用线程池的情况下，也可以很好的完成传递，而且不会发生错乱。 那么是不是对普通线程异步也有这么好的支撑呢？ 改造下上面的测试代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192private static ThreadLocal tl = new TransmittableThreadLocal&lt;&gt;(); public static void main(String[] args) { new Thread(() -&gt; { String mainThreadName = \"main_01\"; tl.set(1); new Thread(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之前(1), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }).start(); new Thread(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之前(1), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }).start(); new Thread(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之前(1), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }).start(); sleep(1L); //确保上面的会在tl.set执行之前执行 tl.set(2); // 等上面的线程池第一次启用完了，父线程再给自己赋值 new Thread(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之后(2), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }).start(); new Thread(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之后(2), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }).start(); new Thread(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之后(2), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }).start(); System.out.println(String.format(\"线程名称-%s, 变量值=%s\", Thread.currentThread().getName(), tl.get())); }).start(); new Thread(() -&gt; { String mainThreadName = \"main_02\"; tl.set(3); new Thread(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之前(3), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }).start(); new Thread(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之前(3), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }).start(); new Thread(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之前(3), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }).start(); sleep(1L); //确保上面的会在tl.set执行之前执行 tl.set(4); // 等上面的线程池第一次启用完了，父线程再给自己赋值 new Thread(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之后(4), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }).start(); new Thread(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之后(4), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }).start(); new Thread(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之后(4), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }).start(); System.out.println(String.format(\"线程名称-%s, 变量值=%s\", Thread.currentThread().getName(), tl.get())); }).start(); } 代码块2 相比代码块1，这一段的异步全都是普通异步，未采用线程池的方式进行异步，看下运行结果： 1234567891011121314本地变量改变之后(4), 父线程名称-main_02, 子线程名称-Thread-14, 变量值=4本地变量改变之前(1), 父线程名称-main_01, 子线程名称-Thread-5, 变量值=1线程名称-Thread-1, 变量值=2本地变量改变之前(1), 父线程名称-main_01, 子线程名称-Thread-3, 变量值=1本地变量改变之后(2), 父线程名称-main_01, 子线程名称-Thread-11, 变量值=2本地变量改变之前(3), 父线程名称-main_02, 子线程名称-Thread-6, 变量值=3本地变量改变之后(4), 父线程名称-main_02, 子线程名称-Thread-12, 变量值=4本地变量改变之后(4), 父线程名称-main_02, 子线程名称-Thread-10, 变量值=4本地变量改变之前(3), 父线程名称-main_02, 子线程名称-Thread-8, 变量值=3本地变量改变之前(3), 父线程名称-main_02, 子线程名称-Thread-4, 变量值=3本地变量改变之前(1), 父线程名称-main_01, 子线程名称-Thread-7, 变量值=1线程名称-Thread-2, 变量值=4本地变量改变之后(2), 父线程名称-main_01, 子线程名称-Thread-9, 变量值=2本地变量改变之后(2), 父线程名称-main_01, 子线程名称-Thread-13, 变量值=2 ok，可以看到，达到了跟第一个测试一致的结果。 到这里，通过上述两个例子，TTL的基本使用，以及其解决的问题，我们已经有了初步的了解，下面我们来解析一下其内部原理，看看TTL是怎么完成对ITL的优化的。 二、原理分析先来看TTL里面的几个重要属性及方法 TTL定义： 1public class TransmittableThreadLocal extends InheritableThreadLocal 代码块3 可以看到，TTL继承了ITL，意味着TTL首先具备ITL的功能。 再来看看一个重要属性holder： 12345678910111213141516/** * 这是一个ITL类型的对象，持有一个全局的WeakMap（weakMap的key是弱引用，同TL一样，也是为了解决内存泄漏的问题），里面存放了TTL对象 * 并且重写了initialValue和childValue方法，尤其是childValue，可以看到在即将异步时父线程的属性是直接作为初始化值赋值给子线程的本地变量对象（TTL）的 */ private static InheritableThreadLocal&lt;Map&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt;&gt; holder = new InheritableThreadLocal&lt;Map&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt;&gt;() { @Override protected Map&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt; initialValue() { return new WeakHashMap&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt;(); } @Override protected Map&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt; childValue(Map&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt; parentValue) { return new WeakHashMap&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt;(parentValue); } }; 代码块4 再来看下set和get： 123456789101112131415161718192021222324//下面的方法均属于TTL类@Override public final void set(T value) { super.set(value); if (null == value) removeValue(); else addValue(); } @Override public final T get() { T value = super.get(); if (null != value) addValue(); return value; } private void removeValue() { holder.get().remove(this); //从holder持有的map对象中移除 } private void addValue() { if (!holder.get().containsKey(this)) { holder.get().put(this, null); //从holder持有的map对象中添加 } } 代码块5 TTL里先了解上述的几个方法及对象，可以看出，单纯的使用TTL是达不到支持线程池本地变量的传递的，通过第一部分的例子，可以发现，除了要启用TTL，还需要通过TtlExecutors.getTtlExecutorService包装一下线程池才可以，那么，下面就来看看在程序即将通过线程池异步的时候，TTL帮我们做了哪些操作（这一部分是TTL支持线程池传递的核心部分）： 首先打开包装类，看下execute方法在执行时做了些什么。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// 此方法属于线程池包装类ExecutorTtlWrapper@Override public void execute(@Nonnull Runnable command) { executor.execute(TtlRunnable.get(command)); //这里会把Rannable包装一层，这是关键，有些逻辑处理，需要在run之前执行 } // 对应上面的get方法，返回一个TtlRunnable对象，属于TtLRannable包装类 @Nullable public static TtlRunnable get(@Nullable Runnable runnable) { return get(runnable, false, false); } // 对应上面的get方法 @Nullable public static TtlRunnable get(@Nullable Runnable runnable, boolean releaseTtlValueReferenceAfterRun, boolean idempotent) { if (null == runnable) return null; if (runnable instanceof TtlEnhanced) { // 若发现已经是目标类型了（说明已经被包装过了）直接返回 // avoid redundant decoration, and ensure idempotency if (idempotent) return (TtlRunnable) runnable; else throw new IllegalStateException(\"Already TtlRunnable!\"); } return new TtlRunnable(runnable, releaseTtlValueReferenceAfterRun); //最终初始化 } // 对应上面的TtlRunnable方法 private TtlRunnable(@Nonnull Runnable runnable, boolean releaseTtlValueReferenceAfterRun) { this.capturedRef = new AtomicReference&lt;Object&gt;(capture()); //这里将捕获后的父线程本地变量存储在当前对象的capturedRef里 this.runnable = runnable; this.releaseTtlValueReferenceAfterRun = releaseTtlValueReferenceAfterRun; } // 对应上面的capture方法，用于捕获当前线程（父线程）里的本地变量，此方法属于TTL的静态内部类Transmitter @Nonnull public static Object capture() { Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt; captured = new HashMap&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt;(); for (TransmittableThreadLocal&lt;?&gt; threadLocal : holder.get().keySet()) { // holder里目前存放的k-v里的key，就是需要传给子线程的TTL对象 captured.put(threadLocal, threadLocal.copyValue()); } return captured; // 这里返回的这个对象，就是当前将要使用线程池异步出来的子线程，所继承的本地变量合集 } // 对应上面的copyValue，简单的将TTL对象里的值返回（结合之前的源码可以知道get方法其实就是获取当前线程（父线程）里的值，调用super.get方法） private T copyValue() { return copy(get()); } protected T copy(T parentValue) { return parentValue; } 代码块6 结合上述代码，大致知道了在线程池异步之前需要做的事情，其实就是把当前父线程里的本地变量取出来，然后赋值给Rannable包装类里的capturedRef属性，到此为止，下面会发生什么，我们大致上可以猜出来了，接下来大概率会在run方法里，将这些捕获到的值赋给子线程的holder赋对应的TTL值，那么我们继续往下看Rannable包装类里的run方法是怎么实现的： 1234567891011121314151617181920//run方法属于Rannable的包装类TtlRunnable@Override public void run() { Object captured = capturedRef.get(); // 获取由之前捕获到的父线程变量集 if (captured == null || releaseTtlValueReferenceAfterRun &amp;&amp; !capturedRef.compareAndSet(captured, null)) { throw new IllegalStateException(\"TTL value reference is released after run!\"); } /** * 重点方法replay，此方法用来给当前子线程赋本地变量，返回的backup是此子线程原来就有的本地变量值（原生本地变量，下面会详细讲）， * backup用于恢复数据（如果任务执行完毕，意味着该子线程会归还线程池，那么需要将其原生本地变量属性恢复） */ Object backup = replay(captured); try { runnable.run(); // 执行异步逻辑 } finally { restore(backup); // 结合上面对于replay的解释，不难理解，这个方法就是用来恢复原有值的 } } 代码块7 根据上述代码，我们看到了TTL在异步任务执行前，会先进行赋值操作（就是拿着异步发生时捕获到的父线程的本地变量，赋给自己），当任务执行完，就恢复原生的自己本身的线程变量值。 下面来具体看这俩方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677//下面的方法均属于TTL的静态内部类Transmittable@Nonnull public static Object replay(@Nonnull Object captured) { @SuppressWarnings(\"unchecked\") Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt; capturedMap = (Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt;) captured; //使用此线程异步时捕获到的父线程里的本地变量值 Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt; backup = new HashMap&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt;(); //当前线程原生的本地变量，用于使用完线程后恢复用 //注意：这里循环的是当前子线程原生的本地变量集合，与本方法相反，restore方法里循环这个holder是指：该线程运行期间产生的变量+父线程继承来的变量 for (Iterator&lt;? extends Map.Entry&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt;&gt; iterator = holder.get().entrySet().iterator(); iterator.hasNext(); ) { Map.Entry&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt; next = iterator.next(); TransmittableThreadLocal&lt;?&gt; threadLocal = next.getKey(); backup.put(threadLocal, threadLocal.get()); // 所有原生的本地变量都暂时存储在backup里，用于之后恢复用 /** * 检查，如果捕获到的线程变量里，不包含当前原生变量值，则从当前原生变量里清除掉，对应的线程本地变量也清掉 * 这就是为什么会将原生变量保存在backup里的原因，为了恢复原生值使用 * 那么，为什么这里要清除掉呢？因为从使用这个子线程做异步那里，捕获到的本地变量并不包含原生的变量，当前线程 * 在做任务时的首要目标，是将父线程里的变量完全传递给任务，如果不清除这个子线程原生的本地变量， * 意味着很可能会影响到任务里取值的准确性。 * * 打个比方，有ttl对象tl，这个tl在线程池的某个子线程里存在对应的值2，当某个主线程使用该子线程做异步任务时 * tl这个对象在当前主线程里没有值，那么如果不进行下面这一步的操作，那么在使用该子线程做的任务里就可以通过 * 该tl对象取到值2，不符合预期 */ if (!capturedMap.containsKey(threadLocal)) { iterator.remove(); threadLocal.superRemove(); } } // 这一步就是直接把父线程本地变量赋值给当前线程了（这一步起就刷新了holder里的值了，具体往下看该方法，在异步线程运行期间，还可能产生别的本地变量，比如在真正的run方法内的业务代码，再用一个tl对象设置一个值） setTtlValuesTo(capturedMap); // 这个方法属于扩展方法，ttl本身支持重写异步任务执行前后的操作，这里不再具体赘述 doExecuteCallback(true); return backup; } // 结合之前Rannable包装类的run方法来看，这个方法就是使用上面replay记录下的原生线程变量做恢复用的 public static void restore(@Nonnull Object backup) { @SuppressWarnings(\"unchecked\") Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt; backupMap = (Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt;) backup; // call afterExecute callback doExecuteCallback(false); // 注意，这里的holder取出来的，实际上是replay方法设置进去的关于父线程里的所有变量（结合上面来看，就是：该线程运行期间产生的变量+父线程继承来的变量） for (Iterator&lt;? extends Map.Entry&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt;&gt; iterator = holder.get().entrySet().iterator(); iterator.hasNext(); ) { Map.Entry&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt; next = iterator.next(); TransmittableThreadLocal&lt;?&gt; threadLocal = next.getKey(); /** * 同样的，如果子线程原生变量不包含某个父线程传来的对象，那么就删除，可以思考下，这里的清除跟上面replay里的有什么不同？ * 这里会把不属于原生变量的对象给删除掉（这里被删除掉的可能是父线程继承下来的，也可能是异步任务在执行时产生的新值） */ if (!backupMap.containsKey(threadLocal)) { iterator.remove(); threadLocal.superRemove(); } } // 同样调用这个方法，进行值的恢复 setTtlValuesTo(backupMap); } // 真正给当前子线程赋值的方法，对应上面的setTtlValuesTo方法 private static void setTtlValuesTo(@Nonnull Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt; ttlValues) { for (Map.Entry&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt; entry : ttlValues.entrySet()) { @SuppressWarnings(\"unchecked\") TransmittableThreadLocal&lt;Object&gt; threadLocal = (TransmittableThreadLocal&lt;Object&gt;) entry.getKey(); threadLocal.set(entry.getValue()); //赋值，注意，从这里开始，子线程的holder里的值会被重新赋值刷新，可以参照上面ttl的set方法的实现 } } 代码块8 ok，到这里基本上把TTL比较核心的代码看完了，下面整理下整个流程，这是官方给出的时序图： 上图第一行指的是类名称，下面的流程指的是类所做的事情，根据上面罗列出来的源码，结合这个时序图，可以比较直观一些的理解整个流程。 三、TTL中线程池子线程原生变量的产生这一节是为了验证上面replay和restore，现在通过一个例子来验证下，先把源码down下来，在源码的restore和replay上分别加上输出语句，遍历holder： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657//replay前后打印holder里面的值public static Object replay(@Nonnull Object captured) { @SuppressWarnings(\"unchecked\") Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt; capturedMap = (Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt;) captured; Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt; backup = new HashMap&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt;(); System.out.println(\"--------------------replay前置，当前拿到的holder里的TTL列表\"); for (Iterator&lt;? extends Map.Entry&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt;&gt; iterator = holder.get().entrySet().iterator(); iterator.hasNext(); ) { Map.Entry&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt; next = iterator.next(); TransmittableThreadLocal&lt;?&gt; threadLocal = next.getKey(); System.out.println(String.format(\"replay前置里拿到原生的ttl_k=%s, ttl_value=%s\", threadLocal.hashCode(), threadLocal.get())); } for...//代码省略，具体看上面 setTtlValuesTo(capturedMap); doExecuteCallback(true); System.out.println(\"--------------------reply后置，当前拿到的holder里的TTL列表\"); for (Iterator&lt;? extends Map.Entry&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt;&gt; iterator = holder.get().entrySet().iterator(); iterator.hasNext(); ) { Map.Entry&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt; next = iterator.next(); TransmittableThreadLocal&lt;?&gt; threadLocal = next.getKey(); System.out.println(String.format(\"replay后置里拿到原生的ttl_k=%s, ttl_value=%s\", threadLocal.hashCode(), threadLocal.get())); } return backup; }//restore前后打印holder里面的值public static void restore(@Nonnull Object backup) { @SuppressWarnings(\"unchecked\") Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt; backupMap = (Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt;) backup; // call afterExecute callback doExecuteCallback(false); System.out.println(\"--------------------restore前置，当前拿到的holder里的TTL列表\"); for (Iterator&lt;? extends Map.Entry&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt;&gt; iterator = holder.get().entrySet().iterator(); iterator.hasNext(); ) { Map.Entry&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt; next = iterator.next(); TransmittableThreadLocal&lt;?&gt; threadLocal = next.getKey(); System.out.println(String.format(\"restore前置里拿到当前线程内变量，ttl_k=%s, ttl_value=%s\", threadLocal.hashCode(), threadLocal.get())); } for...//省略代码，具体具体看上面 setTtlValuesTo(backupMap); System.out.println(\"--------------------restore后置，当前拿到的holder里的TTL列表\"); for (Iterator&lt;? extends Map.Entry&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt;&gt; iterator = holder.get().entrySet().iterator(); iterator.hasNext(); ) { Map.Entry&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt; next = iterator.next(); TransmittableThreadLocal&lt;?&gt; threadLocal = next.getKey(); System.out.println(String.format(\"restore后置里拿到当前线程内变量，ttl_k=%s, ttl_value=%s\", threadLocal.hashCode(), threadLocal.get())); } } 代码块9 代码这样做的目的，就是要说明线程池所谓的原生本地变量是怎么产生的，以及replay和restore是怎么设置和恢复的，下面来看个简单的例子： 123456789101112131415161718192021private static ExecutorService executorService = TtlExecutors.getTtlExecutorService(Executors.newFixedThreadPool(1)); private static ThreadLocal tl = new TransmittableThreadLocal(); private static ThreadLocal tl2 = new TransmittableThreadLocal(); public static void main(String[] args) throws InterruptedException { tl.set(1); tl2.set(2); executorService.execute(new Runnable() { @Override public void run() { try { Thread.sleep(1000L); } catch (InterruptedException e) { e.printStackTrace(); } } }); } 代码块10 运行结果如下： 123456789101112--------------------replay前置，当前拿到的holder里的TTL列表replay前置里拿到原生的ttl_k=1259475182, ttl_value=2replay前置里拿到原生的ttl_k=929338653, ttl_value=1--------------------reply后置，当前拿到的holder里的TTL列表replay后置里拿到原生的ttl_k=1259475182, ttl_value=2replay后置里拿到原生的ttl_k=929338653, ttl_value=1--------------------restore前置，当前拿到的holder里的TTL列表restore前置里拿到当前线程内变量，ttl_k=1259475182, ttl_value=2restore前置里拿到当前线程内变量，ttl_k=929338653, ttl_value=1--------------------restore后置，当前拿到的holder里的TTL列表restore后置里拿到当前线程内变量，ttl_k=1259475182, ttl_value=2restore后置里拿到当前线程内变量，ttl_k=929338653, ttl_value=1 我们会发现，原生值产生了，从异步开始，就确定了线程池里的线程具备了1和2的值，那么，再来改动下上面的测试代码： 12345678910111213141516171819202122232425262728293031public static void main(String[] args) throws InterruptedException { tl.set(1); executorService.execute(new Runnable() { @Override public void run() { try { Thread.sleep(100L); } catch (InterruptedException e) { e.printStackTrace(); } } }); Thread.sleep(1000L); tl2.set(2);//较第一次换下位置，换到第一次使用线程池后执行（这意味着下面这次异步不会再触发Thread的init方法了） System.out.println(\"---------------------------------------------------------------------------------\"); executorService.execute(new Runnable() { @Override public void run() { try { Thread.sleep(1000L); } catch (InterruptedException e) { e.printStackTrace(); } } }); } 代码块11 运行结果为： 12345678910111213141516171819--------------------replay前置，当前拿到的holder里的TTL列表replay前置里拿到原生的ttl_k=929338653, ttl_value=1--------------------reply后置，当前拿到的holder里的TTL列表replay后置里拿到原生的ttl_k=929338653, ttl_value=1--------------------restore前置，当前拿到的holder里的TTL列表restore前置里拿到当前线程内变量，ttl_k=929338653, ttl_value=1--------------------restore后置，当前拿到的holder里的TTL列表restore后置里拿到当前线程内变量，ttl_k=929338653, ttl_value=1-----------------------------------------------------------------------------------------------------replay前置，当前拿到的holder里的TTL列表replay前置里拿到原生的ttl_k=929338653, ttl_value=1--------------------reply后置，当前拿到的holder里的TTL列表replay后置里拿到原生的ttl_k=1020371697, ttl_value=2replay后置里拿到原生的ttl_k=929338653, ttl_value=1--------------------restore前置，当前拿到的holder里的TTL列表restore前置里拿到当前线程内变量，ttl_k=1020371697, ttl_value=2restore前置里拿到当前线程内变量，ttl_k=929338653, ttl_value=1--------------------restore后置，当前拿到的holder里的TTL列表restore后置里拿到当前线程内变量，ttl_k=929338653, ttl_value=1 可以发现，第一次异步时，只有一个值被传递了下去，然后第二次异步，新加了一个tl2的值，但是看第二次异步的打印，会发现，restore恢复后，仍然是第一次异步发生时放进去的那个tl的值。 通过上面的例子，基本可以确认，所谓线程池内线程的本地原生变量，其实是第一次使用线程时被传递进去的值，我们之前有说过TTL是继承至ITL的，之前的文章也说过，线程池第一次启用时是会触发Thread的init方法的，也就是说，在第一次异步时拿到的主线程的变量会被传递给子线程，作为子线程的原生本地变量保存起来，后续是replay操作和restore操作也是围绕着这个原生变量（即原生holder里的值）来进行设置、恢复的，设置的是当前父线程捕获到的本地变量，恢复的是子线程原生本地变量。 holder里持有的可以理解就是当前线程内的所有本地变量，当子线程将异步任务执行完毕后，会执行restore进行恢复原生本地变量，具体参照上面的代码和测试代码。 四、总结到这里基本上确认了TTL是如何进行线程池传值的，以及被包装的run方法执行异步任务之前，会使用replay进行设置父线程里的本地变量给当前子线程，任务执行完毕，会调用restore恢复该子线程原生的本地变量（目前原生本地变量的产生，就只碰到上述测试代码中的这一种情况，即线程第一次使用时通过ITL属性以及Thread的init方法传给子线程，还不太清楚有没有其他方式设置）。 其实，正常程序里想要完成线程池上下文传递，使用TL就足够了，我们可以效仿TTL包装线程池对象的原理，进行值传递，异步任务结束后，再remove，以此类推来完成线程池值传递，不过这种方式过于单纯，且要求上下文为只读对象，否则子线程存在写操作，就会发生上下文污染。 TTL项目地址（可以详细了解下它的其他特性和用法）：https://github.com/alibaba/transmittable-thread-local","link":"/2019/02/20/ThreadLocal%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%89%EF%BC%89-TransmittableThreadLocal%E7%9A%84%E4%BD%BF%E7%94%A8%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/"},{"title":"ThreadLocal系列（二）-InheritableThreadLocal的使用及原理解析","text":"一、基本使用我们继续来看之前写的例子： 123456789101112131415161718private static ThreadLocal tl = new ThreadLocal&lt;&gt;();public static void main(String[] args) throws Exception { tl.set(1); System.out.println(String.format(\"当前线程名称: %s, main方法内获取线程内数据为: %s\", Thread.currentThread().getName(), tl.get())); fc(); new Thread(() -&gt; { fc(); }).start(); Thread.sleep(1000L); //保证下面fc执行一定在上面异步代码之后执行 fc(); //继续在主线程内执行，验证上面那一步是否对主线程上下文内容造成影响 } private static void fc() { System.out.println(String.format(\"当前线程名称: %s, fc方法内获取线程内数据为: %s\", Thread.currentThread().getName(), tl.get())); } 代码块1 输出为： 1234当前线程名称: main, main方法内获取线程内数据为: 1当前线程名称: main, fc方法内获取线程内数据为: 1当前线程名称: Thread-0, fc方法内获取线程内数据为: null当前线程名称: main, fc方法内获取线程内数据为: 1 我们会发现，父线程的本地变量是无法传递给子线程的，这当然是正常的，因为线程本地变量来就不应该相互有交集，但是有些时候，我们的确是需要子线程里仍然可以获取到父线程里的本地变量，现在就需要借助TL的一个子类：InheritableThreadLocal（下面简称ITL），来完成上述要求 现在我们将例子里的 1private static ThreadLocal tl = new ThreadLocal&lt;&gt;(); 代码块2 改为： 1private static ThreadLocal tl = new InheritableThreadLocal&lt;&gt;(); 代码块3 然后我们再来运行下结果： 1234当前线程名称: main, main方法内获取线程内数据为: 1当前线程名称: main, fc方法内获取线程内数据为: 1当前线程名称: Thread-0, fc方法内获取线程内数据为: 1当前线程名称: main, fc方法内获取线程内数据为: 1 可以发现，子线程里已经可以获得父线程里的本地变量了。 结合之前讲的TL的实现，简单理解起来并不难，基本可以认定，是在创建子线程的时候，父线程的ThreadLocalMap（下面简称TLMap）里的值递给了子线程，子线程针对上述tl对象持有的k-v进行了copy，其实这里不是真正意义上对象copy，只是给v的值多了一条子线程TLMap的引用而已，v的值在父子线程里指向的均是同一个对象，因此任意线程改了这个值，对其他线程是可见的，为了验证这一点，我们可以改造以上测试代码： 12345678910111213141516171819202122232425private static ThreadLocal tl = new InheritableThreadLocal&lt;&gt;(); private static ThreadLocal tl2 = new InheritableThreadLocal&lt;&gt;(); public static void main(String[] args) throws Exception { tl.set(1); Hello hello = new Hello(); hello.setName(\"init\"); tl2.set(hello); System.out.println(String.format(\"当前线程名称: %s, main方法内获取线程内数据为: tl = %s，tl2.name = %s\", Thread.currentThread().getName(), tl.get(), tl2.get().getName())); fc(); new Thread(() -&gt; { Hello hello1 = tl2.get(); hello1.setName(\"init2\"); fc(); }).start(); Thread.sleep(1000L); //保证下面fc执行一定在上面异步代码之后执行 fc(); //继续在主线程内执行，验证上面那一步是否对主线程上下文内容造成影响 } private static void fc() { System.out.println(String.format(\"当前线程名称: %s, fc方法内获取线程内数据为: tl = %s，tl2.name = %s\", Thread.currentThread().getName(), tl.get(), tl2.get().getName())); } 代码块4 输出结果为： 1234当前线程名称: main, main方法内获取线程内数据为: tl = 1，tl2.name = init当前线程名称: main, fc方法内获取线程内数据为: tl = 1，tl2.name = init当前线程名称: Thread-0, fc方法内获取线程内数据为: tl = 1，tl2.name = init2当前线程名称: main, fc方法内获取线程内数据为: tl = 1，tl2.name = init2 可以确认，子线程里持有的本地变量跟父线程里那个是同一个对象。 二、原理分析通过上述的测试代码，基本可以确定父线程的TLMap被传递到了下一级，那么我们基本可以确认ITL是TL派生出来专门解决线程本地变量父传子问题的，那么下面通过源码来分析一下ITL到底是怎么完成这个操作的。 先来了解下Thread类，上节说到，其实最终线程本地变量是通过TLMap存储在Thread对象内的，那么来看下Thread对象内关于TLMap的两个属性： 12ThreadLocal.ThreadLocalMap threadLocals = null;ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; 代码块5 Thread类里其实有两个TLMap属性，第一个就是普通TL对象为其赋值，第二个则由ITL对象为其赋值，来看下TL的set方法的实现，这次针对该方法介绍下TL子类的相关方法实现： 123456789101112131415161718192021// TL的set方法，如果是子类的实现，那么获取（getMap）和初始化赋值（createMap）都是ITL对象里的方法 // 其余操作不变（因为hash计算、查找、扩容都是TLMap里需要做的，这里子类ITL只起到一个为Thread对象里哪个TLMap属性赋值的作用） public void set(T value) { Thread t = Thread.currentThread(); ThreadLocal.ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); } // ITL里getMap方法的实现 ThreadLocal.ThreadLocalMap getMap(Thread t) { return t.inheritableThreadLocals; //返回的其实是Thread对象的inheritableThreadLocals属性 } // ITL里createMap方法的实现 void createMap(Thread t, T firstValue) { // 也是给Thread的inheritableThreadLocals属性赋值 t.inheritableThreadLocals = new ThreadLocal.ThreadLocalMap(this, firstValue); } 代码块6 而inheritableThreadLocals里的信息通过Thread的init方法是可以被传递下去的： 123456789101112131415161718192021222324252627282930313233343536373839404142// 初始化一个Thread对象时的代码段（Thread类的init方法） Thread parent = currentThread(); if (parent.inheritableThreadLocals != null){ //可以看到，如果父线程存在inheritableThreadLocals的时候，会赋值给子线程（当前正在被初始化的线程） // 利用父线程的TLMap对象，初始化一个TLMap，赋值给自己的inheritableThreadLocals（这就意味着这个TLMap里的值会一直被传递下去） this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); } // 看下TL里对应的方法 static ThreadLocal.ThreadLocalMap createInheritedMap(ThreadLocal.ThreadLocalMap parentMap) { return new ThreadLocal.ThreadLocalMap(parentMap); //这里就开始初始化TLMap对象了 } // 根据parentMap来进行初始化子线程的TLMap对象 private ThreadLocalMap(ThreadLocal.ThreadLocalMap parentMap) { ThreadLocal.ThreadLocalMap.Entry[] parentTable = parentMap.table; //拿到父线程里的哈希表 int len = parentTable.length; setThreshold(len); // 设置阈值（具体方法参考上一篇） table = new ThreadLocal.ThreadLocalMap.Entry[len]; for (int j = 0; j &lt; len; j++) { ThreadLocal.ThreadLocalMap.Entry e = parentTable[j]; //将父线程里的Entry取出 if (e != null) { @SuppressWarnings(\"unchecked\") ThreadLocal&lt;Object&gt; key = (ThreadLocal&lt;Object&gt;) e.get(); //获取key if (key != null) { Object value = key.childValue(e.value); //获取value ThreadLocal.ThreadLocalMap.Entry c = new ThreadLocal.ThreadLocalMap.Entry(key, value); //根据k-v重新生成一个Entry int h = key.threadLocalHashCode &amp; (len - 1); //计算哈希值 while (table[h] != null) h = nextIndex(h, len); //线性探查解决哈希冲突问题（具体方法参考上一篇） table[h] = c; //找到合适的位置后进行赋值 size++; } } } } // ITL里的childValue的实现 protected T childValue(T parentValue) { return parentValue; //直接将父线程里的值返回 } 代码块7 三、ITL所带来的的问题看过上述代码后，现在关于ITL的实现我们基本上有了清晰的认识了，根据其实现性质，可以总结出在使用ITL时可能存在的问题： 3.1：线程不安全 写在前面：这里讨论的线程不安全对象不包含Integer等类型，因为这种对象被重新赋值，变掉的是整个引用，这里说的是那种不改变对象引用，直接可以修改其内容的对象（典型的就是自定义对象的set方法） 如果说线程本地变量是只读变量不会受到影响，但是如果是可写的，那么任意子线程针对本地变量的修改都会影响到主线程的本地变量（本质上是同一个对象），参考上面的第三个例子，子线程写入后会覆盖掉主线程的变量，也是通过这个结果，我们确认了子线程TLMap里变量指向的对象和父线程是同一个。 3.2：线程池中可能失效按照上述实现，在使用线程池的时候，ITL会完全失效，因为父线程的TLMap是通过init一个Thread的时候进行赋值给子线程的，而线程池在执行异步任务时可能不再需要创建新的线程了，因此也就不会再传递父线程的TLMap给子线程了。 针对上述2，我们来做个实验，来证明下猜想： 123456789101112131415161718192021// 为了方便观察，我们假定线程池里只有一个线程 private static ExecutorService executorService = Executors.newFixedThreadPool(1); private static ThreadLocal tl = new InheritableThreadLocal&lt;&gt;(); public static void main(String[] args) { tl.set(1); System.out.println(String.format(\"线程名称-%s, 变量值=%s\", Thread.currentThread().getName(), tl.get())); executorService.execute(()-&gt;{ System.out.println(String.format(\"线程名称-%s, 变量值=%s\", Thread.currentThread().getName(), tl.get())); }); executorService.execute(()-&gt;{ System.out.println(String.format(\"线程名称-%s, 变量值=%s\", Thread.currentThread().getName(), tl.get())); }); System.out.println(String.format(\"线程名称-%s, 变量值=%s\", Thread.currentThread().getName(), tl.get())); } 代码块8 输出结果为： 1234线程名称-main, 变量值=1线程名称-pool-1-thread-1, 变量值=1线程名称-main, 变量值=1线程名称-pool-1-thread-1, 变量值=1 会发现，并没有什么问题，和我们预想的并不一样，原因是什么呢？因为线程池本身存在一个初始化的过程，第一次使用的时候发现里面的线程数（worker数）少于核心线程数时，会进行创建线程，既然是创建线程，一定会执行Thread的init方法，参考上面提到的源码，在第一次启用线程池的时候，类似做了一次new Thread的操作，因此是没有什么问题的，父线程的TLMap依然可以传递下去。 现在我们改造下代码，把tl.set(1)改到第一次启用线程池的下面一行，然后再看看： 12345678910111213141516public static void main(String[] args) throws Exception{ System.out.println(String.format(\"线程名称-%s, 变量值=%s\", Thread.currentThread().getName(), tl.get())); executorService.execute(()-&gt;{ System.out.println(String.format(\"线程名称-%s, 变量值=%s\", Thread.currentThread().getName(), tl.get())); }); tl.set(1); // 等上面的线程池第一次启用完了，父线程再给自己赋值 executorService.execute(()-&gt;{ System.out.println(String.format(\"线程名称-%s, 变量值=%s\", Thread.currentThread().getName(), tl.get())); }); System.out.println(String.format(\"线程名称-%s, 变量值=%s\", Thread.currentThread().getName(), tl.get())); } 代码块9 输出结果为： 1234线程名称-main, 变量值=null线程名称-main, 变量值=1线程名称-pool-1-thread-1, 变量值=null线程名称-pool-1-thread-1, 变量值=null 很明显，第一次启用时没有递进去的值，在后续的子线程启动时就再也传递不进去了。 尾声但是，在实际项目中我们大多数采用线程池进行做异步任务，假如真的需要传递主线程的本地变量，使用ITL的问题显然是很大的，因为是有极大可能性拿不到任何值的，显然在实际项目中，ITL的位置实在是尴尬，所以在启用线程池的情况下，不建议使用ITL做值传递。为了解决这种问题，阿里做了transmittable-thread-local（TTL）来解决线程池异步值传递问题，下一篇，我们将会分析TTL的用法及原理。","link":"/2019/02/19/ThreadLocal%E7%B3%BB%E5%88%97%EF%BC%88%E4%BA%8C%EF%BC%89-InheritableThreadLocal%E7%9A%84%E4%BD%BF%E7%94%A8%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/"},{"title":"java实现二叉树","text":"定义一个节点下面最多拥有两个子节点，并且两个子节点分为左值和右值，左值比父节点要小，右值比父节点要大 java实现下面，我们来利用java实现一棵如下图中的二叉树： 大家可以根据我的描述分析一下这棵二叉树 下面就来写代码实现这棵二叉树： 首先是要建立一个节点类Node： 123456789101112131415161718192021222324252627282930313233343536package Tree;/** * 节点类 * @author javadaodechengxuyuan * */public class Node { private long value; private Node leftNode;//节点下面的左节点 private Node RightNode;//节点下面的右节点 //构造器 public Node(long value){ this.value=value; } public long getValue() { return value; } public void setValue(long value) { this.value = value; } public Node getLeftNode() { return leftNode; } public void setLeftNode(Node leftNode) { this.leftNode = leftNode; } public Node getRightNode() { return RightNode; } public void setRightNode(Node rightNode) { RightNode = rightNode; }} 代码块1 这是二叉树类，就是这个类用来操作节点类的： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package Tree;/** * @author javadaodechengxuyuan * 二叉树：每个节点有最多两个分叉， * 分别作为父节点的左值和右值，遵循左小右大的规则进行分叉 */public class Tree { private Node root; private Node current; private Node parent; /** * @author javadaodechengxuyuan * 为一颗二叉树添加节点 */ public void insert(long value){//为二叉树插入新的节点 //创建新的节点 Node newNode=new Node(value); //创建完后就该考虑把这个节点放在哪里了，下面这些代码就是用来判断将这个节点放在哪里的 if(root==null){ this.root=newNode;//如果root为空，那么第一次调用添加时应给root初始化 }else{ this.current=root;//初始化current while(true){//进入死循环，一直等到给newNode找到合适的位置时进行终止死循环 if(this.current.getValue()&gt;value){//比root小，放在左侧 this.parent=this.current;//让parent一直保留本次的current this.current=this.current.getLeftNode(); if(this.current==null){//如果当前的左值为空，那么就终止循环并赋值给这个左值 this.parent.setLeftNode(newNode);//将这个新节点放在这个位置 return;//最终找到合适位置，死循环终止 } }else{//比root大，放在右侧 this.parent=this.current;//让parent一直保留本次的current this.current=this.current.getRightNode();//将当前的节点重新赋值给下一次需要比较的节点 if(this.current==null){//如果当前的右值为空，那么就终止循环并赋值给这个左值 this.parent.setRightNode(newNode);//将这个新节点放在这个位置 return;//最终找到合适位置，死循环终止 } } } } } public Node getRoot() { return root; } public void setRoot(Node root) { this.root = root; }} 代码块2 这是测试类： 12345678910111213141516171819202122package Tree;/** * 测试类 * @author javadaodechengxuyuan * */public class Test { public static void main(String args[]){ Tree t=new Tree(); t.insert(10);//根节点 t.insert(20); t.insert(15); t.insert(9); t.insert(35); System.out.print(t.getRoot().getValue()+\"、\");//第0层：根节点 System.out.print(t.getRoot().getLeftNode().getValue()+\"、\");//第一层左值 System.out.print(t.getRoot().getRightNode().getValue()+\"、\");//第一层右值 System.out.print(t.getRoot().getRightNode().getLeftNode().getValue()+\"、\");//第二层左值 System.out.print(t.getRoot().getRightNode().getRightNode().getValue());//第二层右值 //输出结果应为：10、9、20、15、35 }} 代码块3 输出结果应该为： 110、9、20、15、35 这只是简单的插入功能，下一节我会写如何查找二叉树的节点以及删除节点、还有如何遍历一棵二叉树","link":"/2014/07/04/java%E5%AE%9E%E7%8E%B0%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"title":"java性能火焰图的生成","text":"一、前言开始之前，你需要准备的环境： Linux系统机器或者虚拟机一台，里面需要安装的软件：git、jdk、perl。 二、简单介绍java性能分析火焰图的所做的事情就是能够分析出java程序运行期间存在的性能问题，因为某段代码拖慢整个程序执行是不允许的，因此靠火焰图的绘制和分析就可以找出类似的“问题代码段”。 那么这个图是怎么来的呢？首先跟大多数监控系统一样，数据采集+前端绘图，这个图也是根据某些数据绘制而成的，绘图工具本篇文章采用FlameGraph，而负责收集这些数据的工具，本篇采用async-profiler，这个工具会在程序运行期间向jvm发送信号采集其运行期数据（简单来说就是通过该工具可以找出程序中占用CPU资源时间最长的代码块，这里async-profiler的实现使用了jvmti，戳这里简单了解一下），然后生成相应的数据格式文件，而FlameGraph则负责读取和解析数据文件生成对应的火焰图（svg文件）。 三、使用&amp;安装🔥3.1：环境搭建确认你的机器已经安装了git、jdk、perl、c++编译器，部分可参考：安装杂记 🔥3.2：clone相关项目下载下来所需要的两个项目（这里建议放到data目录下）： 12git clone https://github.com/jvm-profiling-tools/async-profilergit clone https://github.com/brendangregg/FlameGraph 🔥3.3：编译下载好以后，需要打开async-profiler文件，输入make指令进行编译： 12cd async-profilermake 🔥3.4：编写测试程序编译完成后，我们来写一个简单的java程序： 123456789101112131415161718192021222324public class Test { public static void main(String[] args) throws Exception { Test test = new Test(); while (true) { test.func1(); test.func2(); test.func3(); } } public void func1() throws Exception { //调用第一个方法，需要100ms Thread.sleep(100L); } public void func2() throws Exception { //调用第二个方法，需要500ms Thread.sleep(500L); } public void func3() throws Exception { //调用第三个方法，需要1500ms Thread.sleep(1500L); }} 代码块1 非常简单的一个java类，main方法里所做的事情也很简单，现在把这个文件搞到data目录下，javac命令编译，java命令启动。 然后找到这个java程序的进程id： 123ps -ef | grep javaroot 30937 17605 0 19:12 pts/0 00:00:00 java Testroot 30961 23135 0 19:12 pts/1 00:00:00 /bin/grep --color=auto java 可以确认此时Test类运行时的java进程pid = 30937，当然也可以使用jps命令直接查看java进程，效果是一样的。 🔥3.5：生成火焰图数据ok，上述步骤完成后，现在进入async-profiler那个项目的目录下，然后输入如下指令： 1./profiler.sh -d 60 -o collapsed -f /tmp/test_01.txt ${pid} 上面的-d表示的是持续时长，后面60代表持续采集时间60s，-o表示的是采集规范，这里用的是collapsed，-f后面的路径，表示的是数据采集后生成的数据存放的文件路径（这里放在了/tmp/test_01.txt），${pid}表示的是采集目标进程的pid，也就是上面提到的30937 回车运行，运行期间阻塞，知道约定时间完成。运行完成后，现在去tmp下看看有没有对应文件： 🔥3.6：生成svg文件上一步产生的文件里的内容，肉眼是很难看懂的，所以现在FlameGraph的作用就体现出来了，它可以读取该文件并生成直观的火焰图，现在进入该项目目录下面，执行如下语句： 1perl flamegraph.pl --colors=java /tmp/test_01.txt &gt; test_01.svg 因为是perl文件，这里使用perl指令运行该文件，后面--colors表示着色风格，这里是java，后面的是数据文件的路径，这里是刚刚上面生成的那个文件/tmp/test_01.txt，最后的test_01.svg就是最终生成的火焰图文件存放的路径和文件命名，这里是命名为test_01.svg并保存在当前路径，运行后看到该文件已经存在于当前目录下： 🔥3.7：展示现在下载下来该文件，使用浏览器打开，效果如下： 果然还是看不懂啊-_-|| 后续会更新这东西怎么看和分析，或者说我这篇文章里的java例子可能并不能很好的体现出什么。 续更续更，公司内部火焰图已经上线，通过更为复杂的业务场景生成的图反而看起来更容易理解一些，因为业务代码的调用也会打印出来，下面贴一下内部某业务系统火焰图： 这张图是在某个业务系统运行时，采样60s生成的火焰图，通过这样一张图可以看出，x轴为调用顺序，y轴为栈深，线条颜色无实际意义（并不是越红性能越差之类的），线条长度代表CPU执行该方法时所花费的时间占比，一般来说需要关注的就是栈顶，且宽度比较大的那个。因为一般处于栈顶的，而且宽度比较大的调用栈，说明其存在性能问题，这样分析的原因如下： 栈深度与y轴高度成正比，一般造成性能问题的都在调用栈的栈顶位置，因为栈顶位置的性能问题会间接拖慢整个调用栈，比如上图中每个栈底的线条都很长，这是因为越往上栈越深，对下层的影响就越大，可以简单抽象成方法调用：A调用B，B调用C，C慢会间接导致B慢，从而导致A慢，当然符合这种情况就适合之前说的看栈顶分析瓶颈的方法，如果A本身就慢呢？通过火焰图也是可以看出来的，比如栈底的线条宽度很宽，但是建立在该栈底的调用链上，线条都很窄，火焰图呈现┻型，那么就可以认定，栈底方法存在性能问题，一般情况下都是从栈顶看起，视情况而定~","link":"/2019/03/22/java%E6%80%A7%E8%83%BD%E7%81%AB%E7%84%B0%E5%9B%BE%E7%9A%84%E7%94%9F%E6%88%90/"},{"title":"【杂记】linux下各种软件安装方法（持续记录）","text":"1.安装jdk网上一堆说先从windows下压缩包，然后通过共享文件夹copy到linux系统里，然后解压安装，emmmmm 首先进入usr文件夹，新建java文件夹： 1mkdir java 直接通过wget命令下载压缩包（如果找不到wget工具，可以通过apt-get install wget安装此工具）： 1wget --no-cookies --no-check-certificate --header \"Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie\" \"http://download.oracle.com/otn-pub/java/jdk/8u141-b15/336fa29ff2bb4ef291e347e091f7f4a7/jdk-8u141-linux-x64.tar.gz\" 后面url需要按照自己需要调整。 进入所在文件夹（这里指java文件夹）解压： 1tar -zxvf jdk-8u141-linux-x64.tar.gz 解压好了如下： 12root@xxx-xxx-xxx-01:/usr/java # ls -a. .. jdk1.8.0_141 jdk-8u141-linux-x64.tar.gz 接着配置环境变量，输入指令： 1vim /etc/profile 然后编辑： 1234export JAVA_HOME=/usr/java/jdk1.8.0_141 export PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarexport JRE_HOME=$JAVA_HOME/jre 然后让其生效： 1source /etc/profile 最后进行测试看看是否生效了： 1234root@xxx-xxx1-xxx-01:~# java -versionjava version \"1.8.0_141\"Java(TM) SE Runtime Environment (build 1.8.0_141-b15)Java HotSpot(TM) 64-Bit Server VM (build 25.141-b15, mixed mode) 出现版本号，视为安装配置成功。 2.安装Perl1234567wget http://www.cpan.org/src/5.0/perl-5.26.1.tar.gztar zxvf perl-5.26.1.tar.gzcd perl-5.26.1./Configure -demakemake testmake install wget后面的路径可以按需更改。安装过程比较耗时间，安装完成后可通过perl -version查看是否安装成功。 3.tcpdump抓包工具12apt-get updateapt-get install tcpdump 抓包工具tcpdump可以抓到容器内的网络请求，具体用法如下： 1tcpdump -i any -A -n port 80 | grep -C 50 'path' 上面是抓取端口为80的网络交互，且过滤出包含path关键词的交互，展示50行。 比如你想抓取http请求，知道http请求端口是80，还知道http请求具体的path，那么就可以抓取一个接口的请求信息（包含请求报文、响应报文），redis等同理，知道端口，知道关键词，就可以抓到交互。 4.C++编译器1apt-get install g++ 一般用于编译c++程序，缺少这个编译器进行make编译c++代码时，会报g++: not found的错误。 5.zookeeper的安装&amp;启动先下载zookeeper的安装包，然后解压： 1tar -zxvf zookeeper-3.4.6.tar.gz 解压后进入该包路径，然后进入conf目录修改zoo_sample.cfg的名字为zoo.cfg： 1mv zoo_sample.cfg zoo.cfg 然后打开该文件： 12345678910111213141516171819202122232425262728# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial # synchronization phase can takeinitLimit=10# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just # example sakes.dataDir=/tmp/zookeeper# the port at which the clients will connectclientPort=2181# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the # administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to \"0\" to disable auto purge feature#autopurge.purgeInterval=1 重要解释： tickTime：这个时间是作为 Zookeeper服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime时间就会发送一个心跳。dataDir：顾名思义就是Zookeeper保存数据的目录，默认情况下，Zookeeper的日志文件是在bin目录下，有一个zookeeper.out文件。clientPort：这个端口就是客户端连接 Zookeeper服务器的端口，Zookeeper会监听这个端口，接受客户端的访问请求。伪集群模式下，这个端口需要配置成不同的。如果是多台虚拟机或者服务器下，则无需更改。 接下来，我们来标记下该zk节点的id（节点号），在dataDir显示的路径下新建myid文件，写上一个数字（1~255间），这里写的是1： 123vim myid1:wq 然后继续回到conf目录下，编辑zoo.cfg，在下面添加如下配置： 1server.1=xx.xx.xxx.xx:8881:7771 前面的server.1里的1就是之前在myid里写的id号，zk节点唯一标识，后面的xx.xx.xxx.xx标识本机ip； 再往后的8881表示的是这个服务器与集群中的 Leader 服务器交换信息的端口（自定义）； 再后面的7771表示的是万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，选出一个新的 Leader，而这个端口就是用来执行选举时服务器相互通信的端口。 接下来返回到zk的bin目录，进行启动这个zk服务： 1./zkServer.sh start 看到下面的打印说明启动成功： 123JMX enabled by defaultUsing config: /usr/zk/zookeeper-3.4.6/bin/../conf/zoo.cfgStarting zookeeper ... STARTED 集群搭建比较简单，直接改下配置，把zoo.cfg下面的ip+port往下面加节点就行了，例子： 123server.x=yyy.yy.yyy.yy:8881:7771server.x=yyy.yy.yyy.yy:8881:7771server.x=yyy.yy.yyy.yy:8881:7771 注意，集群里的每一个节点都要加上上面的配置，上面配置里的x就是指之前单机的myid文件放的id号，需要注意的是集群模式下，这些id是不允许有重复的，后面的yy.yy指的是节点ip地址，再往后的8881和7771之前有解释过，上翻查看。 这样配置后，将所有节点重启一遍即可，期间会进行Leader的选举，完成后可以运行bin目录下的zkServer.sh status查看其身份。","link":"/2019/03/22/%E3%80%90%E6%9D%82%E8%AE%B0%E3%80%91linux%E4%B8%8B%E5%90%84%E7%A7%8D%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95%EF%BC%88%E6%8C%81%E7%BB%AD%E8%AE%B0%E5%BD%95%EF%BC%89/"},{"title":"一Van♂年以后","text":"一VAN♂年以后（视频插入测试）","link":"/2019/03/10/%E4%B8%80Van%E2%99%82%E5%B9%B4%E4%BB%A5%E5%90%8E/"},{"title":"利用CompletableFuture优化程序的执行效率","text":"一、线程池的Future模式在了解java8的CompletableFuture之前，先通过Future来解决一个问题，看个例子： 假设现在有一个网站，首页有顶部Banner位、左边栏、右边栏、用户信息几大模块需要加载，现在出一个接口，要求包装并吐出这几大模块的内容 先来抽象一个首页接口对象： 1234567891011121314151617public class WebModule { private String top; //顶部Banner位 private String left; //左边栏 private String right; //右边栏 private String user; //用户信息 //...get...set... @Override public String toString() { return String.format(\"top: %s; left: %s; right: %s; user: %s\", top, left, right, user); }} 代码块1 现在提供下面几个业务方法来获取这些信息： 1234567891011121314151617181920212223242526272829303132333435private String getTop() { // 这里假设getTop需要执行200ms try { Thread.sleep(200L); } catch (InterruptedException e) { e.printStackTrace(); } return \"顶部banner位\"; } private String getLeft() { // 这里假设getLeft需要执行50ms try { Thread.sleep(50L); } catch (InterruptedException e) { e.printStackTrace(); } return \"左边栏\"; } private String getRight() { // 这里假设getRight需要执行80ms try { Thread.sleep(80L); } catch (InterruptedException e) { e.printStackTrace(); } return \"右边栏\"; } private String getUser() { // 这里假设getUser需要执行100ms try { Thread.sleep(100L); } catch (InterruptedException e) { e.printStackTrace(); } return \"用户信息\"; } 代码块2 ok，现在来实现下这个接口： 123456789// 同步获取public WebModule getWebModuleMsgSync() { WebModule webModule = new WebModule(); webModule.setTop(getTop()); webModule.setLeft(getLeft()); webModule.setRight(getRight()); webModule.setUser(getUser()); return webModule;} 代码块3 上面的代码会一次调用一个方法来赋值，最终返回接口对象，这个方法的最终耗时为几个业务方法耗时的总和： 12通过同步方法获取首页全部信息消耗时间：435ms结果为：top: 顶部banner位; left: 左边栏; right: 右边栏; user: 用户信息 430ms左右的执行时间，其实这几个模块是相互独立没有影响的，因此可以使用线程池的Future模式来进行多线程处理优化： 12345678910111213// 异步获取public WebModule getWebModuleMsgAsync() throws ExecutionException, InterruptedException { Future top = executorService.submit(this::getTop); Future left = executorService.submit(this::getLeft); Future right = executorService.submit(this::getRight); Future user = executorService.submit(this::getUser); WebModule webModule = new WebModule(); webModule.setTop(top.get()); webModule.setLeft(left.get()); webModule.setRight(right.get()); webModule.setUser(user.get()); return webModule;} 代码块4 这几个方法会被异步执行，get方法会被阻塞，直到执行结束，运行结果如下： 12通过异步方法获取首页全部信息消耗时间：276ms结果为：top: 顶部banner位; left: 左边栏; right: 右边栏; user: 用户信息 可以看到，执行速度几乎降了近200ms，这取决于最慢的那个任务的耗时。 通过上述的例子可以发现，很多程序都是可以通过异步充分利用CPU资源的方式来进行优化处理的，单看上面的程序没什么问题，但是仔细想想会发现太过局限，因为几个模块相互独立，但在实际开发中，我们可能存在B方法需要拿到A方法的结果才可以往下进行的问题，所以上面的程序就不太适用了，java8出现了今天要说的一个内容：CompletableFuture，该类可以帮助你实现上面所说的任务顺序调度，不相干的程序依然在异步，相干的存在先后顺序的将会通过一定的设置来满足自己的顺序期望。 二、CompletableFuture现在再来假设一个例子，现在存在以下几个方法的调用： zero方法、a方法、b方法、ab方法、c方法、d方法、e方法 定义如下： 123456789101112131415161718192021222324252627282930313233343536//各个方法，sleep当成是执行时间private void zero() { sleep(100L); System.out.println(\"zero方法触发！\\n-----------------------------\");}private String a() { sleep(500L); return \"a\";}private String b(String a) { sleep(1000L); return a + \"b\";}private String c() { sleep(500L); return \"c\";}private String ab(String a, String b) { sleep(100L); return a + \"|\" + b;}private void d(String a) { sleep(1000L); System.out.println(\"d方法触发，拿到的a = \" + a);}private String e(String a) { sleep(100L); return a + \"e\";} 代码块5 根据上面的方法定义，可以整理出来其执行关系： zero、a、c都是独立调用的方法，而b、d、e方法都需要拿到a的执行结果值才能触发，ab方法则要求更加苛刻，需要同时拿到a和b的执行结果才可以触发，现在假设需要把所有的方法都触发一遍，我们又期望通过异步的方式来尽可能的优化代码，这个时候如果还用上面例子里的方式，恐怕就很难进行下去了，因为很多方法存在相互依赖的现象，不过现在有了CompletableFuture，这个问题就可以解决了，来看下代码（方法及作用都写在注释上了，下面的文章就不多做说明了）： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public static void main(String[] args) throws ExecutionException, InterruptedException { long s = System.currentTimeMillis(); Test t = new Test(); //runAsync用于执行没有返回值的异步任务 CompletableFuture future0 = CompletableFuture.runAsync(t::zero) .exceptionally(e -&gt; { System.out.println(\"Zero出错！\"); return null; }); //这里是异常处理，指的是该异步任务执行中出错，应该做的处理 //supplyAsync方法用于执行带有返回值的异步任务 CompletableFuture futureA = CompletableFuture.supplyAsync(t::a) .exceptionally(e -&gt; { System.out.println(\"方法A出错！\"); return null; }); //thenCompose方法用于连接两个CompletableFuture任务，如下代表futureA结束后将执行结果交由另外一个CompletableFuture处理，然后将执行链路最终赋值给futureB CompletableFuture futureB = futureA.thenCompose(a -&gt; CompletableFuture.supplyAsync(() -&gt; t.b(a))) .exceptionally(e -&gt; { System.out.println(\"方法B出错！\"); return null; }); //thenAccept方法用于将一个任务的结果，传给需要该结果的任务，如下表示futureD的执行需要futureA的结果，与thenApply不同的是，这个方法没有有返回值 CompletableFuture futureD = futureA.thenAccept(t::d); //thenApply方法用于将一个任务的结果，传给需要该结果的任务，如下表示futureE的执行需要futureA的结果，与thenAccept不同的是，这个方法有返回值 CompletableFuture futureE = futureA.thenApply(t::e) .exceptionally(e -&gt; { System.out.println(\"方法E出错！\"); return null; }); /** * thenApply方法概念容易与thenCompose混淆，毕竟最终目的很相似 */ //thenCombine方法用于连接多个异步任务的结果，如下ab方法需要futureA和futureB的执行结果，那么就可以使用thenCombine进行连接 //注意，执行到ab这里，说明futureA和futureB一定已经执行完了 CompletableFuture futureAB = futureA.thenCombine(futureB, t::ab) .exceptionally(e -&gt; { System.out.println(\"方法AB出错！\"); return null; }); //单纯的一个异步任务，不依赖任何其他任务 CompletableFuture futureC = CompletableFuture.supplyAsync(t::c) .exceptionally(e -&gt; { System.out.println(\"方法C出错！\"); return null; }); //allOf如果阻塞结束则表示所有任务都执行结束了 CompletableFuture.allOf(future0, futureA, futureB, futureAB, futureC, futureD, futureE).get(); System.out.println(\"方法Zero输出：\" + future0.get()); System.out.println(\"方法A输出：\" + futureA.get()); System.out.println(\"方法B输出：\" + futureB.get()); System.out.println(\"方法AB输出：\" + futureAB.get()); System.out.println(\"方法C输出：\" + futureC.get()); System.out.println(\"方法D输出：\" + futureD.get()); System.out.println(\"方法E输出：\" + futureE.get()); System.out.println(\"耗时：\" + (System.currentTimeMillis() - s) + \"ms\"); } 代码块6 输出结果如下： 1234567891011zero方法触发！-----------------------------d方法触发，拿到的a = a方法Zero输出：null方法A输出：a方法B输出：ab方法AB输出：a|ab方法C输出：c方法D输出：null方法E输出：ae耗时：1668ms 可以看到，逻辑方面是没有任何问题的，也按照预期的顺序和方式进行了，注意看这里的运行时间，约等于1600ms，与第一个例子时长取决于执行时间最长的那个方法不同，上面的例子时长取决于有序的执行链的耗时最长的执行时间，分析下上面的程序，顺序链最长的，就是ab这条，ab需要a和b全部执行完，而b又依赖a的结果，因此ab执行完的时间就是500+1000的时间（a需要500ms，b又需要等待a，500ms后b触发，b自身又需要1000ms，等都结束了，再触发ab方法，而ab方法又需要100ms的执行时间，因此ab是最长的耗时方法，ab耗时=500+1000+100） 需要说明的是上述例子里用到的方法，几乎每个都有个重载方法，用来传递一个线程池对象，例子里用的都是不传的，用的是其内部的ForkJoinPool.commonPool()。 CompletableFuture的用法还有很多很多，较常用的应该就是例子里的几种，更多的用法以后会继续记录到这里。","link":"/2019/03/14/%E5%88%A9%E7%94%A8CompletableFuture%E4%BC%98%E5%8C%96%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%89%A7%E8%A1%8C%E6%95%88%E7%8E%87/"},{"title":"利用ReentrantLock简单实现一个阻塞队列","text":"借助JUC里的ReentrantLock实现一个阻塞队列结构： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677package demo.concurrent.lock.queue;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.ReentrantLock;/** * @author sunqinwen * @version \\: SimpleQueue.java,v 0.1 2019-01-16 14:47 * 利用重入锁和重入锁的线程调度实现的简单阻塞队列 */public class SimpleQueue { private static ReentrantLock lock = new ReentrantLock(); private T[] nodes; private int tail = 0; // 入元素下标 private int count = 0; // 元素个数 private int head = 0; // 出元素下标 public SimpleQueue(int size) { nodes = (T[]) new Object[size]; } private static Condition notFull = lock.newCondition(); private static Condition notEmpty = lock.newCondition(); public void put(T t) { try { lock.lock(); if (count == nodes.length) { // 队列已满，阻塞 System.out.println(\"目前队列已满，等待取值中\"); notFull.await(); } if (tail &gt; (nodes.length - 1)) { // 当前游标值已经大于数组游标最大值了，则从0开始计算 tail = 0; } nodes[tail] = t; // 给当前游标位赋值 count++; // 入元素元素个数+1 tail++; // 游标值+1 notEmpty.signalAll(); // 走到这里说明队列内至少有一个元素，则唤醒取值 } catch (Exception e) { e.printStackTrace(); } finally { lock.unlock(); } } public T take() { T t = null; try { lock.lock(); if (count == 0) { // 队列已空，等待加值 System.out.println(\"目前队列已空，等待入值中\"); notEmpty.await(); } if (head &gt; (nodes.length - 1)) { // 若取值游标大于游标最大值，则从0开始计算 head = 0; } t = nodes[head]; // 拿到元素值 nodes[head] = null; // 清空原有位置上的值 head++; // 取值游标+1 count--; // 元素个数-1 notFull.signalAll(); // 走到这里说明队列至少有一个空位，则唤醒入值 } catch (Exception e) { e.printStackTrace(); } finally { lock.unlock(); } return t; }} 代码块1 以上为主要代码，下面进行简单的测试： 12345678910111213141516171819202122232425262728293031@Testpublic void simpleQueueTest() throws Exception { executorService.execute(() -&gt; { simpleQueue.put(1); simpleQueue.put(2); simpleQueue.put(3); simpleQueue.put(4); simpleQueue.put(5); simpleQueue.put(6); simpleQueue.put(7); simpleQueue.put(8); simpleQueue.put(9); simpleQueue.put(10); simpleQueue.put(11); simpleQueue.put(12); }); Thread.sleep(5000L); executorService.execute(() -&gt; { Integer r; while ((r = simpleQueue.take()) != null) { System.out.println(r); } }); Thread.sleep(5000L);} 代码块2 运行结果： 123456789101112131415161718目前队列已满，等待取值中目前队列已满，等待取值中12目前队列已满，等待取值中3目前队列已满，等待取值中456789目前队列已空，等待入值中101112目前队列已空，等待入值中","link":"/2019/02/12/%E5%88%A9%E7%94%A8ReentrantLock%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97/"},{"title":"利用Spring的BeanPostProcessor来修改bean属性","text":"一、关于BeanPostProcessor1.1：它是什么？首先它是一个接口，定义了两个方法： 1234567891011public interface BeanPostProcessor { @Nullable //所有bean初始化之前触发该方法 default Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { return bean; } @Nullable //所有bean初始化之后触发该方法 default Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { return bean; }} 代码块1 它定义了两个方法，分别是： postProcessBeforeInitialization：bean初始化前置处理 postProcessAfterInitialization：bean初始化后置处理 ⚙️ 注：这里的初始化是指一个被实例化后的bean的完成其一些初始化方法的调用（最基本的就是通过@PostConstruct预设的初始化方法），上面两个方法的before和after就是针对这个状态来区分触发时机的。 我们可以定义一个实现了该接口的bean，来达到对其他bean做一些初始化前后要做的事情。 1.2：什么时候触发？首先看下spring beans的生命周期（图片来源于网络）： 上图中标红的位置就是BeanPostProcessor两个方法的触发点，可以看到这些方法的触发是在初始化阶段。 那么，如何定义一个类似的bean的初始化阶段的后置处理器呢？很简单，让一个bean实现BeanPostProcessor接口并重写其before、after方法即可，可以搞很多个这样的bean，触发过程就是，容器里的任何bean在实例化后初始化前，都会触发一次所有实现了BeanPostProcessor接口的bean的before方法，初始化以后都会触发一次所有实现了BeanPostProcessor接口的bean的after方法，也就是说，spring在启动时，会预先加载实现了该接口的对象（通过registerBeanPostProcessors方法注册这类bean），这样，其他任何bean在初始化时，都可以通过之前已经加载好的逻辑，逐个触发一遍（当然如果想要保证实现顺序，还可以通过实现Order接口，来定义触发顺序）。 1.3：可以用来做什么？了解了它的触发时机，那么它通常可以用来做哪些事情呢？一般来说，可以利用其做一些通用性的bean属性注入，下面通过一个实例来说下其应用方式和场景。 二、使用方式实战一下，给目前项目内所有的SqlSessionFactory对象都加一个拦截器。 2.1：定义一个Mybatis拦截器现在来定义一个Mybatis里的拦截器，它的作用就是简单拿到sql，然后打印出该sql执行耗时： 12345678910111213141516171819202122232425262728293031323334@Slf4j@Intercepts({@Signature(type = StatementHandler.class, method = \"query\", args = {Statement.class, ResultHandler.class}), @Signature(type = StatementHandler.class, method = \"update\", args = {Statement.class}), @Signature(type = StatementHandler.class, method = \"batch\", args = {Statement.class})})public class SqlInterceptor implements Interceptor { @Override public Object intercept(Invocation invocation) throws Throwable { //拦截每次的sql执行 Object target = invocation.getTarget(); StatementHandler statementHandler = (StatementHandler) target; BoundSql boundSql = statementHandler.getBoundSql(); String sql = boundSql.getSql(); //获取sql long start = System.currentTimeMillis(); try { return invocation.proceed(); //sql运行 } catch (Throwable t) { System.out.println(String.format(\"错误SQL=%s\", sql)); throw t; } finally { System.out.println(String.format(\"耗时%s ms, SQL=%s\", (System.currentTimeMillis() - start), sql)); } } @Override public Object plugin(Object target) { return Plugin.wrap(target, this); } @Override public void setProperties(Properties properties) { }} 代码块2 Mybatis的拦截器需要预先往SqlSessionFactory设置： 12345678@Bean(name = \"sqlSession\") public SqlSessionFactory sqlSession(@Qualifier(\"dataSource\") DataSource dataSource) throws Exception { SqlSessionFactoryBean bean = new SqlSessionFactoryBean(); bean.setDataSource(dataSource); bean.setVfs(SpringBootVFS.class); bean.getObject().getConfiguration().addInterceptor(new SqlInterceptor()); //手动加入 return bean.getObject(); } 代码块3 2.2：借助BeanPostProcessor操作相关Bean这时项目模块如果很多，但是这个拦截器又要求对所有项目所有的SqlSessionFactory都生效，一个个去改每个项目里的SqlSessionFactory类型的bean太过繁琐，这个时候就可以在公共模块里定义一个BeanPostProcessor去干这件事，比如可以定义成下面这样： 123456789101112131415@Slf4jpublic class SqlSessionFactoryBeanPostProcessor implements BeanPostProcessor { @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { if (bean instanceof SqlSessionFactory) { //所有bean初始化之后都会进入这个方法，这个时候需要滤出需要的类型，比如这次就只需要拿到SqlSessionFactory类型的对象对其设置拦截器就行了 SqlSessionFactory nowBean = (SqlSessionFactory) bean; nowBean.getConfiguration().addInterceptor(new SqlInterceptor(nowBean //设置拦截器 .getConfiguration() .getEnvironment() .getDataSource())); } return bean; //完成后返回出去，可能直接进入容器，也可能会去执行其他的BeanPostProcessor }} 代码块4 然后再把它也定义成一个bean，其本身也是一个bean，才能被spring扫到去装载，否则只是实现BeanPostProcessor接口spring是没办法察觉做管理的： 1234567@ConditionalOnClass({SqlSessionFactory.class}) //存在SqlSessionFactory类型时，才会触发下面bean的装载public class MysqlAutoConfiguration { @Bean public SqlSessionFactoryBeanPostProcessor sqlSessionFactoryBeanPostProcessor() { return new SqlSessionFactoryBeanPostProcessor(); }} 代码块5 这样写完，就不用去一个个的改SqlSessionFactory对象了，只要引入该公共模块，那么在bean初始化完成后，就会走这段逻辑，然后滤出自己需要的类型，对其进行修改就好，这样，所有SqlSessionFactory就在不修改别的地方初始化SqlSessionFactory代码的情况下，全局生效了。","link":"/2019/07/16/%E5%88%A9%E7%94%A8Spring%E7%9A%84BeanPostProcessor%E6%9D%A5%E4%BF%AE%E6%94%B9bean%E5%B1%9E%E6%80%A7/"},{"title":"利用java实现一个简单的链表结构","text":"定义所谓链表就是指在某节点存储数据的过程中还要有一个属性用来指向下一个链表节点，这样的数据存储方式叫做链表 链表的优缺点优点：易于存储和删除 缺点：查询起来较麻烦 java实现下面我们用java来实现如下链表结构： 首先定义节点类： 123456789101112131415161718192021222324252627282930package LinkTest;/** * 链表节点类 * @author admin * */public class Node { private int value;//存储数据 private Node next;//下一个节点 /** * 定义构造器 * @param vlaue * @param value */ public Node(int value){ this.value=value; } public int getValue() { return value; } public void setValue(int value) { this.value = value; } public Node getNext() { return next; } public void setNext(Node next) { this.next = next; }} 代码块1 然后定义一个链表类： 注意：遍历链表定义了两个方法，一个是普通方法，一个是递归方法，都可以遍历出来 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package LinkTest;/** * 链表 * @author admin * */public class Link { private Node current; private Node root; public void insert(int vlaue){ Node newNode=new Node(vlaue); if(this.current==null){ this.current=newNode; this.root=this.current; }else{ this.current.setNext(newNode); this.current=this.current.getNext(); } } //普通遍历 public void getList(){ this.current=this.root; while(this.current!=null){ System.out.print(this.current.getValue()); this.current=this.current.getNext(); if(this.current!=null){ System.out.print(\"-------&gt;\"); } } } //递归遍历 public void getList2(){ DG(this.root); } //递归方法 public void DG(Node node){ System.out.print(node.getValue()+\"-----&gt;\"); if(node.getNext()!=null){ DG(node.getNext()); }else{ return; } }} 代码块2 测试类： 123456789101112131415161718package LinkTest;/** * 测试类 * @author admin * */public class Test { public static void main(String[] args){ Link l=new Link(); l.insert(1); l.insert(4); l.insert(5); l.insert(6); l.insert(9); l.insert(8); l.getList(); }} 代码块3 测试类运行结果： 11-------&gt;4-------&gt;5-------&gt;6-------&gt;9-------&gt;8 这样我们就用java实现了一个简单的链表结构。","link":"/2014/07/04/%E5%88%A9%E7%94%A8java%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E9%93%BE%E8%A1%A8%E7%BB%93%E6%9E%84/"},{"title":"图解java多线程设计模式（一）","text":"去年看完的《图解java多线程设计模式》，可惜当时没做笔记，导致后来忘了许多东西，打算再温习下这本书，顺便在这里记录一下~ 一、顺序执行、并行、并发 顺序执行：多个操作按照顺序依次执行。 并行：多个任务同时进行，同一时间内可以执行多个任务，这种方式，叫做并行执行，比如多核处理器，多个核可以同时处理多个任务。 并发：多个任务通过切分时间段，来达到“同时进行”的效果，比如单核处理器，在“同时”处理多个任务时，就会不停的切换来执行不同的任务，不可能有同一时间执行不同任务的情况。 下面引用别人的一句话来说明下并行和并发： 并发是两个任务可以在重叠的时间段内启动，运行和完成。并行是任务在同一时间运行，例如，在多核处理器上，并发是独立执行过程的组合，而并行是同时执行（可能相关的）计算。 并发是一次处理很多事情，并行是同时做很多事情。 应用程序可以是并发的，但不是并行的，这意味着它可以同时处理多个任务，但是没有两个任务在同一时刻执行。应用程序可以是并行的，但不是并发的，这意味着它同时处理多核CPU中的任务的多个子任务。一个应用程序可以即不是并行的，也不是并发的，这意味着它一次一个地处理所有任务。应用程序可以即是并行的也是并发的，这意味着它同时在多核CPU中同时处理多个任务。 二、synchronized修饰符当我们说一个线程获得锁以后，则意味着这个线程可以执行当前对象（或类）里的synchronized方法，而且他线程则需要排队等待该线程释放锁以后才可能获得锁，进而执行锁里面的程序。 synchronized修饰后，存在对象锁和类锁两种类型。 2.1：对象锁123synchronized (this){ ...略} 代码块1 2.2：类锁123synchronized (XXX.class){ ...略} 代码块2 2.3：区别和作用域对象锁指的是当前线程获得了某个实例的锁，假如有个Word类，有A、B两个同步方法，C属于普通方法，如图所示： 可以发现，对象锁的作用域只针对当前对象生效，就像w1和w2里的A方法可以被不同的线程同时执行，但是同一个对象内的同步块，却只允许持有当前对象锁的线程执行，如t2、t3均被挡在了外面，当t1释放锁以后，t2、t3才会重新竞争锁，竞争到锁以后就会执行自己想要执行的同步逻辑。 类锁指的是当前线程获得了某个类的锁，还是Word类，有A、B两个static方法（静态方法属于类方法，加synchronized修饰符后等效于上面提到的synchronized(Word.class))，C属于普通static方法，如图所示： 跟上面相比较，这里的t5受到了t1的影响，因为t1获得了Word类的锁，w1和w2共属一个类，因此t1获得类锁以后，其他线程想要访问这个类里的同步块，就得等到t1释放锁以后才可以继续竞争锁然后执行自己想要执行的同步逻辑。 三、线程间的通信3.1：Wait这几个方法是属于每个实例对象的，所有实例都拥有一个“等待队列”（虚拟概念，实例里并不存在该字段），它是在实例的wait方法调用后存放停止操作线程的队列。执行wait方法后，线程进入当前实例的“等待队列”，以下几种情况可以让线程退出“等待队列”： 其他线程调用notify、notifyAll方法来将其唤醒 其他线程调用interrupt来将其唤醒 wait方法本身超时 当执行了下面的代码： 1obj.wait(); 代码块3 我们可以说当前线程在obj上发生了等待，当前线程进入了obj的“等待队列”，此时当前线程会让出锁，让其他线程继续竞争获得该实例的锁（因此这里有个规则，调用wait的线程必须持有当前实例对象的锁） 过程如下图： 3.2：notify现在先来介绍下notify，该方法会将等待队列里的线程取出，让其退出等待并参与锁竞争然后继续执行上次wait后没有执行完的语句。整体过程如下图所示： 可以看到，t1在被挂起后，会因为t2调用了同实例的notify方法，而让t1被从等待队列里释放，重新加入到所得竞争力，t2执行完毕后释放锁，锁又再次被t1竞争到，t1将继续执行上次被挂起时后面未执行完的语句。 需要指出的是，如果等待队列里的线程是多个，那么被唤醒的那一个，将会是等待队列里所有线程随机的一个，不会特定哪一个线程会被唤起。 3.3：notifyAll接下来介绍notifyAll方法，顾名思义，就是将等待队列里的线程全部唤起，然后这些线程将全部加入到锁竞争，竞争到，继续完成上次被挂起时未执行完毕的操作，流程图如下： 说明，当线程调用实例的wait、notify、notifyAll方法有个大前提，就是必须要求该线程拥有该实例的锁，否则会抛IllegalMonitorStateException异常。 在编写程序时，是该选择notify还是选择notifyAll？这个可以指出的是，notifyAll往往更加健壮，而notify由于唤起的线程少，因此效率会更高，但是存在程序停止的风险。 附上使用wait、notify进行线程通信的例子： 利用ReentrantLock简单实现一个阻塞队列 java设计模式：简单实现生产者和消费者模式","link":"/2019/02/26/%E5%9B%BE%E8%A7%A3java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%88%E4%B8%80%EF%BC%89/"},{"title":"图解java多线程设计模式（二）","text":"一、join &amp; interrupt这俩方法属于线程对象里的方法，属于线程本身的操作。 1.1：join方法用于等待一个线程的终止，等待期间将会阻塞，直到被等待的线程终止结束。 所以join可以用来做多任务异步处理，比如还是拿利用CompletableFuture优化程序的执行效率这篇里的第一个例子做优化，这篇文章里使用线程池的future模式进行多任务异步处理，现在使用join改写下： 再来简单贴下这几个方法： 1234567891011121314151617181920212223242526272829303132333435private String getTop() { // 这里假设getTop需要执行200ms try { Thread.sleep(200L); } catch (InterruptedException e) { e.printStackTrace(); } return \"顶部banner位\"; } private String getLeft() { // 这里假设getLeft需要执行50ms try { Thread.sleep(50L); } catch (InterruptedException e) { e.printStackTrace(); } return \"左边栏\"; } private String getRight() { // 这里假设getRight需要执行80ms try { Thread.sleep(80L); } catch (InterruptedException e) { e.printStackTrace(); } return \"右边栏\"; } private String getUser() { // 这里假设getUser需要执行100ms try { Thread.sleep(100L); } catch (InterruptedException e) { e.printStackTrace(); } return \"用户信息\"; } 代码块1 然后现在使用简单的线程做异步处理： 123456789101112131415161718192021222324// 简单异步获取 public WebModule getWebModuleMsgSimpleAsync() throws ExecutionException, InterruptedException { WebModule webModule = new WebModule(); Thread topTask = new Thread(() -&gt; webModule.setTop(this.getTop())); Thread leftTask = new Thread(() -&gt; webModule.setLeft(this.getLeft())); Thread rightTask = new Thread(() -&gt; webModule.setRight(this.getRight())); Thread userTask = new Thread(() -&gt; webModule.setUser(this.getUser())); //触发各个异步任务 topTask.start(); leftTask.start(); rightTask.start(); userTask.start(); //等待所有的任务均执行完毕 topTask.join(); leftTask.join(); rightTask.join(); userTask.join(); return webModule; } 代码块2 测试代码： 12345678@Test public void testSimpleASync() throws Exception { // 同步方法测试，预估耗时200ms long start = System.currentTimeMillis(); WebModule module = webHome.getWebModuleMsgSimpleAsync(); System.out.println(\"通过异步方法获取首页全部信息消耗时间：\" + (System.currentTimeMillis() - start) + \"ms\"); System.out.println(\"结果为：\" + module.toString()); } 代码块3 测试结果： 12通过异步方法获取首页全部信息消耗时间：272ms结果为：top: 顶部banner位; left: 左边栏; right: 右边栏; user: 用户信息 比预估的要多72ms，经过后来的测试，发现这72ms耗时发生在线程创建的时候，以及后续线程状态转换带来的消耗，下面等待异步结束的时间约等于200ms，符合预期。 1.2：interrupt方法用于主动终止一个线程，线程本身调用该方法后，视为已终止状态，join解除阻塞，下面来用interrupt和join来做个实验： 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class JoinTest { private boolean isStop = false; public static void main(String[] args) throws Exception { JoinTest test = new JoinTest(); Thread loopT = new Thread(test::loopTask); loopT.start(); sleep(2000L); //2s后终止线程 test.setStop(true); long s = System.currentTimeMillis(); loopT.join(); System.out.println(\"线程终止后，join阻塞时间为：\" + (System.currentTimeMillis() - s)); System.out.println(\"end~\"); } public void setStop(boolean stop) { isStop = stop; } public void loopTask() { while (!isStop) { //若状态为false，则继续执行下面的逻辑，每隔1s打印一次 sleep(1000L); System.out.println(\"loop trigger ~\"); } Thread.currentThread().interrupt(); //在这里终止掉当前线程 //事实上，在终止掉线程后，还有接下来的逻辑要执行 long s = System.currentTimeMillis(); for (int i = 0; i &lt; 1000000; i++) { int[] a = new int[100]; //模拟耗时操作，这里不能用sleep了，因为当前线程已经被终止了 } System.out.println(\"线程终止后，逻辑块运行时间：\" + (System.currentTimeMillis() - s)); } public static void sleep(long time) { try { Thread.sleep(time); } catch (InterruptedException e) { e.printStackTrace(); } }} 代码块4 执行结果： 12345loop trigger ~loop trigger ~线程终止后，逻辑块运行时间：129线程终止后，join阻塞时间为：129end~ 即便线程被终止了，后面的逻辑也会触发，join依旧会选择阻塞，直到后续逻辑执行完毕，事实上，大部分任务都可以及时的终止，比如第一个例子，异步出去的任务，最终都会执行完成，线程变为终止状态，join都可以顺利结束，但是反观上例，如果没人及时的设置isStop的值，程序会一直执行下去，没有终止态，join会无止境的终止下去，这里提一下stop，线程的stop方法已被官方标记为不建议使用的方法，如果把上例的interrupt的调用换成stop，来看看其运行结果： 1234loop trigger ~loop trigger ~线程终止后，join阻塞时间为：0end~ 可以看到，线程终止后的后续逻辑均没有触发，等于说stop是一种很粗暴的终止线程的方式，一旦被stop，那么里面的业务逻辑将直接断掉，因此官方并不推荐使用该方法来终止线程。 而interrupt，仅仅是对目标线程发送了了一个中断信号（改变了线程的中断状态而已），当目标线程再次通过obj.wait、thread.sleep、thread.join方法进入阻塞状态时，接收到该信号，就会抛出InterruptedException异常，这时候需要业务方自行处理或者直接抛出，以结束线程阻塞状态（这里需要注意的是被obj.wait方法阻塞时，抛出该异常需要目标线程再次获得实例对象obj的锁才行）。 上述三个需要花费时间的方法均抛出了InterruptedException异常，针对这些特性，想要完成以下操作就非常方便了： 取消wait方法等待notify/notifyAll的处理 取消在sleep方法指定时间内停止的处理 取消join方法等待其他线程终止的处理 取消之后所做的处理，取决于需求，可能会终止线程，或者通知用户已取消，或者终止当前处理进入下一个处理阶段。 二、线程状态迁移图 上面的图太多太杂，我们通过对一些可以影响线程状态的操作的分类，来简化一下上面的图：","link":"/2019/03/13/%E5%9B%BE%E8%A7%A3java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%88%E4%BA%8C%EF%BC%89/"},{"title":"工作中有关分布式缓存的使用和需要注意的问题梳理","text":"目前工作中用到的分布式缓存技术有redis和memcached两种，缓存的目的是为了在高并发系统中有效降低DB的压力，但是在使用的时候可能会因为缓存结构设计不当造成一些问题，这里会把可能遇到的坑整理出来，方便日后查找。 一、常用的两种缓存技术的服务端特点1.1：Memcache服务端Memcache（下面简称mc）服务端是没有集群概念的，所有的存储分发全部交由mc client去做，我这里使用的是xmemcached，这个客户端支持多种哈希策略，默认使用key与实例数取模来进行简单的数据分片，这种分片方式会导致一个问题，那就是新增或者减少节点后会在一瞬间导致大量key失效，最终导致缓存雪崩的发生，给DB带来巨大压力，所以我们的mc client启用了xmemcached的一致性哈希算法来进行数据分片： 代码块11234567XMemcachedClientBuilder builder = new XMemcachedClientBuilder(AddrUtil.getAddresses(servers));builder.setOpTimeout(opTimeout);builder.setConnectTimeout(connectTimeout);builder.setTranscoder(transcoder);builder.setConnectionPoolSize(connectPoolSize);builder.setKeyProvider(keyProvider);builder.setSessionLocator(new KetamaMemcachedSessionLocator()); //启用ketama一致性哈希算法进行数据分片 根据一致性哈希算法的特性，在新增或减少mc的节点只会影响较少一部分的数据。但这种模式下也意味着分配不均匀，新增的节点可能并不能及时达到均摊数据的效果，不过mc采用了虚拟节点的方式来优化原始一致性哈希算法（由ketama算法控制实现），实现了新增物理节点后也可以均摊数据的能力。 最后，mc服务端是多线程处理模式，mc一个value最大只能存储1M的数据，所有的k-v过期后不会自动移除，而是下次访问时与当前时间做对比，过期时间小于当前时间则删除，如果一个k-v产生后就没有再次访问了，那么数据将会一直存在在内存中，直到触发LRU。 1.2：Redis服务端redis服务端有集群模式，key的路由交由redis服务端做处理，除此之外redis有主从配置以达到服务高可用。 redis服务端是单线程处理模式，这意味着如果有一个指令导致redis处理过慢，会阻塞其他指令的响应，所以redis禁止在生产环境使用重量级操作（例如keys，再例如缓存较大的值导致传输过慢） redis服务端并没有采用一致性哈希来做数据分片，而是采用了哈希槽的概念来做数据分片，一个redis cluster整体拥有16384个哈希槽（slot），这些哈希槽按照编号区间的不同，分布在不同节点上，然后一个key进来，通过内部哈希算法（CRC16(key)）计算出槽位置，然后将数据存放进对应的哈希槽对应的空间，redis在新增或者减少节点时，其实就是对这些哈希槽进行重新分配，以新增节点为例，新增节点意味着原先节点上的哈希槽区间会相对缩小，被减去的那些哈希槽里的数据将会顺延至下一个对应节点，这个过程由redis服务端协调完成，过程如下： 迁移过程是以槽为单位，将槽内的key按批次进行迁移的（migrate）。 有关哈希槽和一致性哈希算法的对比参考：一致性哈希和哈希槽对比 二、选型问题2.1：缓存结构化选型mc提供简单的k-v存储，value最大可以存储1M的数据，多线程处理模式，不会出现因为某次处理慢而导致其他请求排队等待的情况，适合存储数据的文本信息。 redis提供丰富的数据结构，服务端是单线程处理模式，虽然处理速度很快，但是如果有一次查询出现瓶颈，那么后续的操作将被阻塞，所以相比k-v这种可能因为数据过大而导致网络交互产生瓶颈的结构来说，它更适合处理一些数据结构的查询、排序、分页等操作，这些操作往往复杂度不高，且耗时极短，因此不太可能会阻塞redis的处理。 使用这两种缓存服务来构建我们的缓存数据，目前提倡所有数据按照标志性字段（例如id）组成自己的信息缓存存储，这个一般由mc的k-v结构来完成存储。而redis提供了很多好用的数据结构，一般构建结构化的缓存数据都使用redis的数据结构来保存数据的基本结构，然后组装数据时根据redis里缓存的标志性字段去mc里查询具体数据，例如一个排行榜接口的获取： 上图redis提供排行榜的结构存储，排行榜里存储的是id和score，通过redis可以获取到结构内所有信息的id，然后利用获得的id可以从mc中查出详细信息，redis在这个过程负责分页、排序，mc则负责存储详细信息。 上面是比较合适的缓存做法，建议每条数据都有一个自己的基本缓存数据，这样便于管理，而不是把一个接口的巨大结构完全缓存到mc或者redis里，这样划分太粗，日积月累下来每个接口或者巨大方法都有一个缓存，key会越来越多，越来越杂。 2.2：Redis的数据结构常用操作和时间复杂度：Redis基础、常用类型介绍、时间复杂度 特殊结构BitMap：Redis中BitMap使用 BitMap适用于实现用户签到、在线状态等功能，空间占有量极低，除此之外还可以用它来实现一个BloomFilter。 在使用redis时，对于时间复杂度非O(1)的操作都需要推算现有的数据量是否可能导致redis阻塞（分页操作一般不会命中这个问题，因为单页个数有限，出问题较多的一般都是全量输出大列表导致的，生产环境应避免全量操作）。 2.3：Redis构造大索引回源问题Redis如果做缓存使用，始终会有过期时间存在，如果到了过期时间，使用redis构建的索引将会消失，这个时候回源，如果存在大批量的数据需要构建redis索引，就会存在回源方法过慢的问题，这里以某个评论系统为例： 评论系统采用有序集合作为评论列表的索引，存储的是评论id，用于排序的score值则按照排序维度拆分，比如发布时间、点赞数等，这也意味着一个资源下的评论列表根据排序维度不同存在着多个redis索引列表，而具体评论内容存mc，正常情况下结构如下： 上面是正常触发一个资源的评论区，每次触发读缓存，都会顺带延长一次缓存的过期时间，这样可以保证较热的内容不会轻易过期，但是如果一个评论区时间过长没人访问过，redis索引就会过期，如果一个评论区有数万条评论数据，长时间没人访问，突然有人过去考古，那么在回源构建redis索引时会很缓慢，如果没有控制措施，还会造成下面缓存穿透的问题，从而导致这种重量级操作反复被多个线程执行，对DB造成巨大压力。 对于上面这种回源构建索引缓慢的问题，处理方式可以是下面这样： 相比直接执行回源方法，这种通过消息队列构造redis索引的方法更加适合，首先仅构建单页或者前面几页的索引数据，然后通过队列通知job（这里可以理解为消费者）进行完整索引构造，当然，这只适合对一致性要求不高的场景。 三、一致性问题一般情况下缓存内的数据要和数据库源数据保持一致性，这就涉及到更新DB后主动失效缓存策略（通俗叫法：清缓存），大部分会经过如下过程： 假如现在有两个服务，服务A和服务B，现在假设服务A会触发某个数据的写操作，而服务B则是只读程序，数据被缓存在一个Cache服务内，现在假如服务A更新了一次数据库，那么结合上图得出以下流程： 服务A触发更新数据库的操作 更新完成后删除数据对应的缓存key 只读服务（服务B）读取缓存时发现缓存miss 服务B读取数据库源信息 写入缓存并返回对应信息 这个过程乍一看是没什么问题的，但是往往多线程运转的程序会导致意想不到的结果，现在来想象下服务A和服务B被多个线程运行着，这个时候重复上述过程，就会存在一致性问题： 3.1：并发读写导致的一致性问题 运行着服务A的线程1首先修改数据，然后删除缓存 运行着服务B的线程3读缓存时发现缓存miss，开始读取DB中的源数据，需要注意的是这次读出来的数据是线程1修改后的那份 这个时候运行着服务A的线程2上线，开始修改数据库，同样的，删除缓存，需要注意的是，这次删除的其实是一个空缓存，没有意义，因为本来线程3那边还没有回源完成 运行着服务B的线程3将读到的由线程1写的那份数据回写进Cache 上述过程完成后，最终结果就是DB里保存的最终数据是线程2写进去的那份，而Cache经过线程3的回源后保存的却是线程1写的那份数据，不一致问题出现。 3.2：主从同步延时导致的一致性问题这种情况要稍微修改下程序的流程图，多出一个从库： 现在读操作走从库，这个时候如果在主库写操作删除缓存后，由于主从同步有可能稍微慢于回源流程触发，回源时读取从库仍然会读到老数据。 3.3：缓存污染导致的一致性问题每次做新需求时更新了原有的缓存结构，或去除几个属性，或新增几个属性，假如新需求是给某个缓存对象O新增一个属性B，如果新逻辑已经在预发或者处于灰度中，就会出现生产环境回源后的缓存数据没有B属性的情况，而预发和灰度时，新逻辑需要使用B属性，就会导致生产&amp;预发缓存污染。过程大致如下： 四、应对缓存一致性问题4.1：binlog+消息队列+消费者del cache 上图是现在常用的清缓存策略，每次表发生变动，通过mysql产生的binlog去给消息队列发送变动消息，这里监听DB变动的服务由canal提供，canal可以简单理解成一个实现了mysql通信协议的从库，通过mysql主从配置完成binlog同步，且它只接收binlog，通过这种机制，就可以很自然的监听数据库表数据变动了，可以保证每次数据库发生的变动，都会被顺序发往消费者去清除对应的缓存key。 4.2：从库binlog+消息队列+消费者del cache上面的过程能保证写库时清缓存的顺序问题，看似并没有什么问题，但是生产环境往往存在主从分离的情况，也就是说上面的图中如果回源时读的是从库（参考问题3.2），那上面的过程仍然是存在一致性问题的： 从库延迟导致的脏读问题，如何解决这类问题呢？只需要将canal监听的数据库设置成从库即可，保证在canal推送过来消息时，所有的从库和主库完全一致，不过这只针对一主一从的情况，如果一主多从，且回源读取的从库有多个，那么上述也是存在一定的风险的（一主多从需要订阅每个从节点的binlog，找出最后发过来的那个节点，然后清缓存，确保所有的从节点全部和主节点一致）。 不过，正常情况下，从库binlog的同步速度都要比canal发消息快，因为canal要接收binlog，然后组装数据变动实体（这一步是有额外开销的），然后通过消息队列推送给各消费者（这一步也是有开销的），所以即便是订阅的master库的表变更，出问题的概率也极小。 ps：目前笔者公司内数据库都是一主一从，canal监听的都是从库的变动。 4.3：更新后key升级针对上面的一致性问题3.3（缓存污染），修改某个缓存结构可能导致在预发或者灰度中状态时和实际生产环境的缓存相互污染，这个时候建议每次更新结构时都进行一次key升级（比如在原有的key名称基础上加上_v2的后缀）。 ⚡⚡⚡binlog是否真的是准确无误的呢？⚡⚡⚡ 并不是，比如上面的情况： 首先线程1走到服务A，写DB，发binlog删除缓存 然后线程3运行的服务B这时cache miss，然后读取DB回源（这时读到的数据是线程1写入的那份数据） 此时线程2再次触发服务A写DB，同样发送binlog删除缓存 最后线程3把读到的数据写入cache，最终导致DB里存储的是线程2写入的数据，但是cache里存储的却是线程1写入的数据，不一致达成 这种情况比较难以触发，因为极少会出现线程3那里写cache的动作会晚于第二次binlog发送的，除非在回源时做了别的带有阻塞性质的操作，所以根据现有的策略，针对问题3.1，没有特别完美的解决方案，只能尽可能保证一致性，但由于实际生产环境就像问题3.1里那样，处于多线程并发读写的环境，即便有binlog做最终的保证，也不能保证最后回源方法写缓存那里的顺序性。除非回源全部交由binlog消费者来做，不过这本就不太现实，这样等于说服务B没有回源方法了。 针对这个问题，出现概率最大的就是那种写并发概率很大的情况，这个时候伴随而来的还有命中率（参考五）问题。 4.4：一致性问题解决总结没有很好的避免问题3.1的方法，从库binlog订阅+清缓存可以保证在清缓存后服务回源读到的一定是最新数据，但是这并不妨碍图11中的问题发生，只是概率极小，在高并发写+读回源时没有什么办法是可以保证完全没有问题的，可以加分布式锁控制回源方法（这样出问题的概率就更加低了）。当然，只有在这种大量写操作的情况下，才会使问题3.1出现的概率提升，一般这种大量写的还会有命中率低的问题，所以这类缓存的更新一般交给binlog消费者直接去做，在单线程处理模式下，一致性问题几乎不会出现。相比问题3.1里的直接delete缓存，binlog模式可以保证清缓存后缓存回源时读到的内容一定是最新的，极大的降低了因为主从配置导致的问题3.1、3.2出现的概率。 五、命中率问题通过前面的流程，抛开特殊因素，已经解决了一致性的问题，但随着清缓存而来的另一个问题就是命中率问题，比如一个数据变更过于频繁，以至于产生过多的binlog消息，这个时候每次都会触发消费者的清缓存操作，这样的话缓存的命中率会瞬间下降，导致大部分用户访问直接访问DB，而且这种频繁变更的数据还会加大问题①出现的概率，所以针对这种频繁变更的数据，不再删除缓存key，而是直接在binlog消费者那里直接回源更新缓存，这样即便表频繁变更，用户访问时每次都是消费者更新好的那份缓存数据，只是这时候消费者要严格按照消息顺序来处理，否则也会有写脏的危险，比如开两个线程同时消费binlog消息，线程1接收到了第一次数据变更的binlog，而线程2接收到了第二次数据变更的binlog，这时线程1读出数据（旧数据），线程2读出数据（新数据）更新缓存，然后线程1再执行更新，这时缓存又会被写脏，所以为了保证消费顺序，必须是单线程处理，如果想要启用多线程均摊压力，可以利用key、id等标识性字段做任务分组，这样同一个id的binlog消息始终会被同一个线程执行。 六、缓存穿透6.1：什么是缓存穿透？正常情况下用户请求一个数据时会携带标记性的参数（比如id），而我们的缓存key则会以这些标记性的参数来划分不同的cache value，然后我们根据这些参数去查缓存，查到就返回，否则回源，然后写入cache服务后返回，详细过程参考上述第三部分。 这个过程看起来也没什么问题，但是某些情况下，根据带进来的参数，在数据库里并不能找到对应的信息，这个时候每次带有这种参数的请求，都会走到数据库回源，这种现象叫做缓存穿透，比较典型的出现这种问题的情况有： ①恶意攻击或者爬虫，携带数据库里本就不存在的数据做参数回源 ②公司内部别的业务方调用我方的接口时，由于沟通不当或其他原因导致的参数大量误传 ③客户端bug导致的参数大量误传 6.2：如何解决缓存穿透问题？目前我们提倡的做法是回源查不到信息时直接缓存空数据（注意：空数据缓存的过期时间要尽可能小，防止无意义内容过多占用Cache内存），这样即便是有参数误传、恶意攻击等情况，也不会每次都打进DB。 但是目前这种做法仍然存在被攻击的风险，如果恶意攻击时携带少量参数还好，这样不存在的空数据缓存仅仅会占用少量内存，但是如果攻击者使用大量穿透攻击，携带的参数千奇百怪，这样就会产生大量无意义的空对象缓存，使得我们的缓存服务器内存暴增，这个时候就需要服务端来进行简单的控制：按照业务内自己的估算，合理的id大致在什么范围内，比如按照用户id做标记的缓存，就直接在获取缓存前判断所传用户id参数是否超过了某个阈值，超过直接返回空。（比如用户总量才几十万或者上百万，结果用户id传过来个几千万甚至几亿明显不合理的情况） 七、缓存击穿7.1：什么是缓存击穿？缓存击穿是指在一个key失效后，大量请求打进回源方法，多线程并发回源的问题。 这种情况在少量访问时不能算作一个问题，但是当一个热点key失效后，就会发生回源时涌进过多流量，全部打在DB上，这样会导致DB在这一时刻压力剧增。 7.2：如何解决缓存击穿？7.2.1：回源方法内追加互斥锁这个可以避免多次回源，但是n台实例群模式下，仍然会存在实例并发回源的情况，这个量级相比之前大量打进，已经大量降低了。 7.2.2：回源方法内追加分布式锁这个可以完全避免上面多实例下并发回源的情况，但是缺点也很明显，那就是又引入了一个新的服务，这意味着发生异常的风险会加大。 八、缓存雪崩8.1：什么是缓存雪崩？缓存雪崩是指缓存数据某一时刻出现大量失效的情况，所有请求全部打进DB，导致短期内DB负载暴增的问题，一般来说造成缓存雪崩有以下几种情况： 8.1.1：缓存服务扩缩容这个是由缓存的数据分片策略的而导致的，如果采用简单的取模运算进行数据分片，那么服务端扩缩容就会导致雪崩的发生。 8.1.2：缓存服务宕机某一时刻缓存服务器出现大量宕机的情况，导致缓存服务不可用，根据现有的实现，是直接打到DB上的。 8.2：如何避免雪崩的发生？8.2.1：缓存服务端的高可用配置*上面mc和redis的分片策略已经说过，所以扩缩容带来的雪崩几率很小，其次redis服务实现了高可用配置：启用cluster模式，一主一从配置。由于对一致性哈希算法的优化，mc宕机、扩缩容对整体影响不大，所以缓存服务器服务端本身目前是可以保证良好的可用性的，尽可能的避免了雪崩的发生（除非大规模宕机，概率很小）。 8.2.2：数据分片策略调整调整缓存服务器的分片策略，比如上面第一部分所讲的，给mc开启一致性哈希算法的分片策略，防止缓存服务端扩缩容后缓存数据大量不可用。 8.2.3：回源限流如果缓存服务真的挂掉了，请求全打在DB上，以至于超出了DB所能承受之重，这个时候建议回源时进行整体限流，被限到的请求紫自动走降级逻辑，或者直接报错。 九、热key问题9.1：什么是热key问题？了解了缓存服务端的实现，可以知道某一个确定的key始终会落到某一台服务器上，如果某个key在生产环境被大量访问，就导致了某个缓存服务节点流量暴增，等访问超出单节点负载，就可能会出现单点故障，单点故障后转移该key的数据到其他节点，单点问题依旧存在，则可能继续会让被转移到的节点也出现故障，最终影响整个缓存服务集群。 9.2：如何解决热key问题？9.2.1：多缓存副本预先感知到发生热点访问的key，生成多个副本key，这样可以保证热点key会被多个缓存服务器持有，然后回源方法公用一个，请求时按照一定的算法随机访问某个副本key： 9.2.2：本地缓存针对热点key外面包一层短存活期的本地缓存，用于缓冲热点服务器的压力。","link":"/2019/10/24/%E5%B7%A5%E4%BD%9C%E4%B8%AD%E6%9C%89%E5%85%B3%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98%E7%9A%84%E4%BD%BF%E7%94%A8%E5%92%8C%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E9%97%AE%E9%A2%98%E6%A2%B3%E7%90%86/"},{"title":"数据库事务的隔离级别","text":"一、数据库事务的几个特性1.1：原子性最基本的特性，意思是在一个事务内里所有关于数据库的操作，要么全部成功，要么全部失败；成功时意味着本次操作所有数据库相关的写操作全部持久化，无法更改，失败意味着本次操作相对于操作前对数据库没有任何影响和改变。 1.2：一致性指的是一次完整的事务必须将数据库的一个一致状态转变到另外一个一致状态。 一致性写 例如：事务A要做的操作是将A、B、C三个记录修改为D、E、F，那么A、B、C—–&gt;D、E、F的过程就满足了事务一致性，但是如果出现类似：A、B、C—-&gt;D、E、C（A、B修改成功，但是C未修改）则认定违背了事务的一致性，简单理解一致性就是指事务的“初始状态”到“修改完成状态”与“目标状态一致”。 一致性读 事务A在某一刻发起查询请求，那么查询结果是以那一刻为准，保证了数据在查询一刻的一致性。 1.3：持久性指一次事务的成功提交对数据库造成的修改是永久性的。 1.4：隔离性当多个用户并发访问数据库时，数据库为每一个用户开启的事务不可以被其他事务所影响，也就是说并发事务间要相互独立不受到干扰。关于隔离性分了集中隔离等级，本篇文章将详细介绍这几种隔离等级。 二、事务并发时的隔离级别2.1：Read Uncommitted（读未提交）这个隔离级别下未被提交的事务下所做的任何操作都可以被其他事务所读取到，这时候会造成数据的脏读、幻读、不可重复读问题。 2.2：Read Committed（读已提交）这个隔离级别下未被提交的操作不可以被其他事务所读取到，简单来讲就是单个事务里的内容在事务成功提交之前，是不会被其他事务所读取（发现）到的，但是这样同样会出现幻读、不可重复读现象。 举个栗子：事务T1要对C表做添加操作，同时事务T2里要读取C表，T2第一次读取C表时返回1条数据，这时T1执行完毕，那么T2如果再次取一次C表数据就会发现多出一条数据。 2.3：Repeatable Read（可重读）Mysql默认的隔离级别，这个隔离级别下同一事务读取到的数据一致（简单点说就是T1一旦开始，读取到数据如果中间被T2修改，那么T1再次读取该数据是和第一次读取时一样的），因此，在该隔离级别下，不会造成脏读、不可重复读，但依旧会造成幻读现象。 2.4：Serializable（串行）最高隔离级别，会为每个事务排序（为每条数据都加上锁），使之执行串行化，不可能产生冲突，因此解决了脏读、幻读、不可重复读问题，但是会造成锁竞争甚至超时，一般不会采用这种极端的隔离机制。 三、事务并发过程中产生的问题3.1：脏读一个事务读取到了另外一个事务中未提交的数据。 3.2：不可重复读一个事务读取到了另外一个事务中提交的修改掉的数据。 3.3：幻读一个事务读取到了另外一个事务中添加的数据。 Tip：不可重复读和幻读的区别在于着重点一个是update，一个是insert 四、各种隔离级别下对应的问题通过设置不同的事务隔离级别，可以避免事务并发时所造成的部分问题。 总结四种隔离级别所造成和避免的问题（请先看以上内容后再看此表）： 隔离级别 脏读 不可重复读 幻读 Read Uncommitted 是 是 是 Read Committed 否 是 是 Repeatable Read 否 否 是 Serializable 否 否 否 表1","link":"/2017/04/10/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1%E7%9A%84%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/"},{"title":"池化技术（二）HikariCP是如何管理数据库连接的？","text":"基于依赖程序的版本信息：&nbsp;&nbsp; 上一篇：Druid是如何管理数据库连接的 零、类图和流程图开始前先来了解下HikariCP获取一个连接时类间的交互流程，方便下面详细流程的阅读。 获取连接时的类间交互： 一、主流程1：获取连接流程HikariCP获取连接时的入口是HikariDataSource里的getConnection方法，现在来看下该方法的具体流程： 上述为HikariCP获取连接时的流程图，由图1可知，每个datasource对象里都会持有一个HikariPool对象，记为pool，初始化后的datasource对象pool是空的，所以第一次getConnection的时候会进行实例化pool属性（参考主流程1），初始化的时候需要将当前datasource里的config属性传过去，用于pool的初始化，最终标记sealed，然后根据pool对象调用getConnection方法（参考流程1.1），获取成功后返回连接对象。 二、主流程2：初始化池对象 该流程用于初始化整个连接池，这个流程会给连接池内所有的属性做初始化的工作，其中比较主要的几个流程上图已经指出，简单概括一下： 利用config初始化各种连接池属性，并且产生一个用于生产物理连接的数据源DriverDataSource 初始化存放连接对象的核心类connectionBag 初始化一个延时任务线程池类型的对象houseKeepingExecutorService，用于后续执行一些延时/定时类任务（比如连接泄漏检查延时任务，参考流程2.2以及主流程4，除此之外maxLifeTime后主动回收关闭连接也是交由该对象来执行的，这个过程可以参考主流程3） 预热连接池，HikariCP会在该流程的checkFailFast里初始化好一个连接对象放进池子内，当然触发该流程得保证initializationTimeout &gt; 0时（默认值1），这个配置属性表示留给预热操作的时间（默认值1在预热失败时不会发生重试）。与Druid通过initialSize控制预热连接对象数不一样的是，HikariCP仅预热进池一个连接对象。 初始化一个线程池对象addConnectionExecutor，用于后续扩充连接对象 初始化一个线程池对象closeConnectionExecutor，用于关闭一些连接对象，怎么触发关闭任务呢？可以参考流程1.1.2 三、流程1.1：通过HikariPool获取连接对象 从最开始的结构图可知，每个HikariPool里都维护一个ConcurrentBag对象，用于存放连接对象，由上图可以看到，实际上HikariPool的getConnection就是从ConcurrentBag里获取连接的（调用其borrow方法获得，对应ConnectionBag主流程），在长连接检查这块，与之前说的Druid不同，这里的长连接判活检查在连接对象没有被标记为“已丢弃”时，只要距离上次使用超过500ms每次取出都会进行检查（500ms是默认值，可通过配置com.zaxxer.hikari.aliveBypassWindowMs的系统参数来控制），emmmm，也就是说HikariCP对长连接的活性检查很频繁，但是其并发性能依旧优于Druid，说明频繁的长连接检查并不是导致连接池性能高低的关键所在。 这个其实是由于HikariCP的无锁实现，在高并发时对CPU的负载没有其他连接池那么高而产生的并发性能差异，后面会说HikariCP的具体做法，即使是Druid，在获取连接、生成连接、归还连接时都进行了锁控制，因为通过上篇解析Druid的文章可以知道，Druid里的连接池资源是多线程共享的，不可避免的会有锁竞争，有锁竞争意味着线程状态的变化会很频繁，线程状态变化频繁意味着CPU上下文切换也将会很频繁。 回到流程1.1，如果拿到的连接为空，直接报错，不为空则进行相应的检查，如果检查通过，则包装成ConnectionProxy对象返回给业务方，不通过则调用closeConnection方法关闭连接（对应流程1.1.2，该流程会触发ConcurrentBag的remove方法丢弃该连接，然后把实际的驱动连接交给closeConnectionExecutor线程池，异步关闭驱动连接）。 四、流程1.1.1：连接判活 承接上面的流程1.1里的判活流程，来看下判活是如何做的，首先说验证方法（注意这里该方法接受的这个connection对象不是poolEntry，而是poolEntry持有的实际驱动的连接对象），在之前介绍Druid的时候就知道，Druid是根据驱动程序里是否存在ping方法来判断是否启用ping的方式判断连接是否存活，但是到了HikariCP则更加简单粗暴，仅根据是否配置了connectionTestQuery觉定是否启用ping： 1this.isUseJdbc4Validation = config.getConnectionTestQuery() == null; 代码块1 所以一般驱动如果不是特别低的版本，不建议配置该项，否则便会走createStatement+excute的方式，相比ping简单发送心跳数据，这种方式显然更低效。 此外，这里在刚进来还会通过驱动的连接对象重新给它设置一遍networkTimeout的值，使之变成validationTimeout，表示一次验证的超时时间，为啥这里要重新设置这个属性呢？因为在使用ping方法校验时，是没办法通过类似statement那样可以setQueryTimeout的，所以只能由网络通信的超时时间来控制，这个时间可以通过jdbc的连接参数socketTimeout来控制： 1jdbc:mysql://127.0.0.1:3306/xxx?socketTimeout=250 这个值最终会被赋值给HikariCP的networkTimeout字段，这就是为什么最后那一步使用这个字段来还原驱动连接超时属性的原因；说到这里，最后那里为啥要再次还原呢？这就很容易理解了，因为验证结束了，连接对象还存活的情况下，它的networkTimeout的值这时仍然等于validationTimeout（不合预期），显然在拿出去用之前，需要恢复成本来的值，也就是HikariCP里的networkTimeout属性。 五、流程1.1.2：关闭连接对象 这个流程简单来说就是把流程1.1.1中验证不通过的死连接，主动关闭的一个流程，首先会把这个连接对象从ConnectionBag里移除，然后把实际的物理连接交给一个线程池去异步执行，这个线程池就是在主流程2里初始化池的时候初始化的线程池closeConnectionExecutor，然后异步任务内开始实际的关连接操作，因为主动关闭了一个连接相当于少了一个连接，所以还会触发一次扩充连接池（参考主流程5）操作。 六、流程2.1：HikariCP监控设置不同于Druid那样监控指标那么多，HikariCP会把我们非常关心的几项指标暴露给我们，比如当前连接池内闲置连接数、总连接数、一个连接被用了多久归还、创建一个物理连接花费多久等，HikariCP的连接池的监控我们这一节专门详细的分解一下，首先找到HikariCP下面的metrics文件夹，这下面放置了一些规范实现的监控接口等，还有一些现成的实现（比如HikariCP自带对prometheus、micrometer、dropwizard的支持，不太了解后面两个，prometheus下文直接称为普罗米修斯）： 下面，来着重看下接口的定义： 123456789101112131415161718//这个接口的实现主要负责收集一些动作的耗时public interface IMetricsTracker extends AutoCloseable{ //这个方法触发点在创建实际的物理连接时（主流程3），用于记录一个实际的物理连接创建所耗费的时间 default void recordConnectionCreatedMillis(long connectionCreatedMillis) {} //这个方法触发点在getConnection时（主流程1），用于记录获取一个连接时实际的耗时 default void recordConnectionAcquiredNanos(final long elapsedAcquiredNanos) {} //这个方法触发点在回收连接时（主流程6），用于记录一个连接从被获取到被回收时所消耗的时间 default void recordConnectionUsageMillis(final long elapsedBorrowedMillis) {} //这个方法触发点也在getConnection时（主流程1），用于记录获取连接超时的次数，每发生一次获取连接超时，就会触发一次该方法的调用 default void recordConnectionTimeout() {} @Override default void close() {}} 代码块2 触发点都了解清楚后，再来看看MetricsTrackerFactory的接口定义： 123456//用于创建IMetricsTracker实例，并且按需记录PoolStats对象里的属性（这个对象里的属性就是类似连接池当前闲置连接数之类的线程池状态类指标）public interface MetricsTrackerFactory{ //返回一个IMetricsTracker对象，并且把PoolStats传了过去 IMetricsTracker create(String poolName, PoolStats poolStats);} 代码块3 上面的接口用法见注释，针对新出现的PoolStats类，我们来看看它做了什么： 123456789101112131415161718192021222324252627282930313233343536373839404142434445public abstract class PoolStats { private final AtomicLong reloadAt; //触发下次刷新的时间（时间戳） private final long timeoutMs; //刷新下面的各项属性值的频率，默认1s，无法改变 // 总连接数 protected volatile int totalConnections; // 闲置连接数 protected volatile int idleConnections; // 活动连接数 protected volatile int activeConnections; // 由于无法获取到可用连接而阻塞的业务线程数 protected volatile int pendingThreads; // 最大连接数 protected volatile int maxConnections; // 最小连接数 protected volatile int minConnections; public PoolStats(final long timeoutMs) { this.timeoutMs = timeoutMs; this.reloadAt = new AtomicLong(); } //这里以获取最大连接数为例，其他的跟这个差不多 public int getMaxConnections() { if (shouldLoad()) { //是否应该刷新 update(); //刷新属性值，注意这个update的实现在HikariPool里，因为这些属性值的直接或间接来源都是HikariPool } return maxConnections; } protected abstract void update(); //实现在↑上面已经说了 private boolean shouldLoad() { //按照更新频率来决定是否刷新属性值 for (; ; ) { final long now = currentTime(); final long reloadTime = reloadAt.get(); if (reloadTime &gt; now) { return false; } else if (reloadAt.compareAndSet(reloadTime, plusMillis(now, timeoutMs))) { return true; } } }} 代码块4 实际上这里就是这些属性获取和触发刷新的地方，那么这个对象是在哪里被生成并且丢给MetricsTrackerFactory的create方法的呢？这就是本节所需要讲述的要点：主流程2里的设置监控器的流程，来看看那里发生了什么事吧： 123456789101112131415161718192021222324252627//监控器设置方法（此方法在HikariPool中，metricsTracker属性就是HikariPool用来触发IMetricsTracker里方法调用的）public void setMetricsTrackerFactory(MetricsTrackerFactory metricsTrackerFactory) { if (metricsTrackerFactory != null) { //MetricsTrackerDelegate是包装类，是HikariPool的一个静态内部类，是实际持有IMetricsTracker对象的类，也是实际触发IMetricsTracker里方法调用的类 //这里首先会触发MetricsTrackerFactory类的create方法拿到IMetricsTracker对象，然后利用getPoolStats初始化PoolStat对象，然后也一并传给MetricsTrackerFactory this.metricsTracker = new MetricsTrackerDelegate(metricsTrackerFactory.create(config.getPoolName(), getPoolStats())); } else { //不启用监控，直接等于一个没有实现方法的空类 this.metricsTracker = new NopMetricsTrackerDelegate(); }}private PoolStats getPoolStats() { //初始化PoolStats对象，并且规定1s触发一次属性值刷新的update方法 return new PoolStats(SECONDS.toMillis(1)) { @Override protected void update() { //实现了PoolStat的update方法，刷新各个属性的值 this.pendingThreads = HikariPool.this.getThreadsAwaitingConnection(); this.idleConnections = HikariPool.this.getIdleConnections(); this.totalConnections = HikariPool.this.getTotalConnections(); this.activeConnections = HikariPool.this.getActiveConnections(); this.maxConnections = config.getMaximumPoolSize(); this.minConnections = config.getMinimumIdle(); } };} 代码块5 到这里HikariCP的监控器就算是注册进去了，所以要想实现自己的监控器拿到上面的指标，要经过如下步骤： 新建一个类实现IMetricsTracker接口，我们这里将该类记为IMetricsTrackerImpl 新建一个类实现MetricsTrackerFactory接口，我们这里将该类记为MetricsTrackerFactoryImpl，并且将上面的IMetricsTrackerImpl在其create方法内实例化 将MetricsTrackerFactoryImpl实例化后调用HikariPool的setMetricsTrackerFactory方法注册到Hikari连接池。 上面没有提到PoolStats里的属性怎么监控，这里来说下，由于create方法是调用一次就没了，create方法只是接收了PoolStats对象的实例，如果不处理，那么随着create调用的结束，这个实例针对监控模块来说就失去持有了，所以这里如果想要拿到PoolStats里的属性，就需要开启一个守护线程，让其持有PoolStats对象实例，并且定时获取其内部属性值，然后push给监控系统，如果是普罗米修斯等使用pull方式获取监控数据的监控系统，可以效仿HikariCP原生普罗米修斯监控的实现，自定义一个Collector对象来接收PoolStats实例，这样普罗米修斯就可以定期拉取了，比如HikariCP根据普罗米修斯监控系统自己定义的MetricsTrackerFactory实现（对应图2里的PrometheusMetricsTrackerFactory类）： 12345678910111213@Overridepublic IMetricsTracker create(String poolName, PoolStats poolStats) { getCollector().add(poolName, poolStats); //将接收到的PoolStats对象直接交给Collector，这样普罗米修斯服务端每触发一次采集接口的调用，PoolStats都会跟着执行一遍内部属性获取流程 return new PrometheusMetricsTracker(poolName, this.collectorRegistry); //返回IMetricsTracker接口的实现类}//自定义的Collectorprivate HikariCPCollector getCollector() { if (collector == null) { //注册到普罗米修斯收集中心 collector = new HikariCPCollector().register(this.collectorRegistry); } return collector; 代码块6 通过上面的解释可以知道在HikariCP中如何自定义一个自己的监控器，以及相比Druid的监控，有什么区别。工作中很多时候都是需要自定义的，我司虽然也是用的普罗米修斯监控，但是因为HikariCP原生的普罗米修斯收集器里面对监控指标的命名并不符合我司的规范，所以就自定义了一个，有类似问题的不妨也试一试。 🍁 这一节没有画图，纯代码，因为画图不太好解释这部分的东西，这部分内容与连接池整体流程关系也不大，充其量获取了连接池本身的一些属性，在连接池里的触发点也在上面代码段的注释里说清楚了，看代码定义可能更好理解一些。 七、流程2.2：连接泄漏的检测与告警本节对应主流程2里的子流程2.2，在初始化池对象时，初始化了一个叫做leakTaskFactory的属性，本节来看下它具体是用来做什么的。 7.1：它是做什么的？一个连接被拿出去使用时间超过leakDetectionThreshold（可配置，默认0）未归还的，会触发一个连接泄漏警告，通知业务方目前存在连接泄漏的问题。 7.2：过程详解该属性是ProxyLeakTaskFactory类型对象，且它还会持有houseKeepingExecutorService这个线程池对象，用于生产ProxyLeakTask对象，然后利用上面的houseKeepingExecutorService延时运行该对象里的run方法。该流程的触发点在上面的流程1.1最后包装成ProxyConnection对象的那一步，来看看具体的流程图： 每次在流程1.1那里生成ProxyConnection对象时，都会触发上面的流程，由流程图可以知道，ProxyConnection对象持有PoolEntry和ProxyLeakTask的对象，其中初始化ProxyLeakTask对象时就用到了leakTaskFactory对象，通过其schedule方法可以进行ProxyLeakTask的初始化，并将其实例传递给ProxyConnection进行初始化赋值（ps：由图知ProxyConnection在触发回收事件时，会主动取消这个泄漏检查任务，这也是ProxyConnection需要持有ProxyLeakTask对象的原因）。 在上面的流程图中可以知道，只有在leakDetectionThreshold不等于0的时候才会生成一个带有实际延时任务的ProxyLeakTask对象，否则返回无实际意义的空对象。所以要想启用连接泄漏检查，首先要把leakDetectionThreshold配置设置上，这个属性表示经过该时间后借出去的连接仍未归还，则触发连接泄漏告警。 ProxyConnection之所以要持有ProxyLeakTask对象，是因为它可以监听到连接是否触发归还操作，如果触发，则调用cancel方法取消延时任务，防止误告。 由此流程可以知道，跟Druid一样，HikariCP也有连接对象泄漏检查，与Druid主动回收连接相比，HikariCP实现更加简单，仅仅是在触发时打印警告日志，不会采取具体的强制回收的措施。 与Druid一样，默认也是关闭这个流程的，因为实际开发中一般使用第三方框架，框架本身会保证及时的close连接，防止连接对象泄漏，开启与否还是取决于业务是否需要，如果一定要开启，如何设置leakDetectionThreshold的大小也是需要考虑的一件事。 八、主流程3：生成连接对象本节来讲下主流程2里的createEntry方法，这个方法利用PoolBase里的DriverDataSource对象生成一个实际的连接对象（如果忘记DriverDatasource是哪里初始化的了，可以看下主流程2里PoolBase的initializeDataSource方法的作用），然后用PoolEntry类包装成PoolEntry对象，现在来看下这个包装类有哪些主要属性： 123456789101112131415161718192021final class PoolEntry implements IConcurrentBagEntry { private static final Logger LOGGER = LoggerFactory.getLogger(PoolEntry.class); //通过cas来修改state属性 private static final AtomicIntegerFieldUpdater stateUpdater; Connection connection; //实际的物理连接对象 long lastAccessed; //触发回收时刷新该时间，表示“最近一次使用时间” long lastBorrowed; //getConnection里borrow成功后刷新该时间，表示“最近一次借出的时间” @SuppressWarnings(\"FieldCanBeLocal\") private volatile int state = 0; //连接状态，枚举值：IN_USE（使用中）、NOT_IN_USE（闲置中）、REMOVED（已移除）、RESERVED（标记为保留中） private volatile boolean evict; //是否被标记为废弃，很多地方用到（比如流程1.1靠这个判断连接是否已被废弃，再比如主流程4里时钟回拨时触发的直接废弃逻辑） private volatile ScheduledFuture&lt;?&gt; endOfLife; //用于在超过连接生命周期（maxLifeTime）时废弃连接的延时任务，这里poolEntry要持有该对象，主要是因为在对象主动被关闭时（意味着不需要在超过maxLifeTime时主动失效了），需要cancel掉该任务 private final FastList openStatements; //当前该连接对象上生成的所有的statement对象，用于在回收连接时主动关闭这些对象，防止存在漏关的statement private final HikariPool hikariPool; //持有pool对象 private final boolean isReadOnly; //是否为只读 private final boolean isAutoCommit; //是否存在事务} 代码块7 上面就是整个PoolEntry对象里所有的属性，这里再说下endOfLife对象，它是一个利用houseKeepingExecutorService这个线程池对象做的延时任务，这个延时任务一般在创建好连接对象后maxLifeTime左右的时间触发，具体来看下createEntry代码： 123456789101112131415161718192021222324252627282930313233private PoolEntry createPoolEntry() { final PoolEntry poolEntry = newPoolEntry(); //生成实际的连接对象 final long maxLifetime = config.getMaxLifetime(); //拿到配置好的maxLifetime if (maxLifetime &gt; 0) { //&lt;=0的时候不启用主动过期策略 // 计算需要减去的随机数 // 源注释：variance up to 2.5% of the maxlifetime final long variance = maxLifetime &gt; 10_000 ? ThreadLocalRandom.current().nextLong(maxLifetime / 40) : 0; final long lifetime = maxLifetime - variance; //生成实际的延时时间 poolEntry.setFutureEol(houseKeepingExecutorService.schedule( () -&gt; { //实际的延时任务，这里直接触发softEvictConnection，而softEvictConnection内则会标记该连接对象为废弃状态，然后尝试修改其状态为STATE_RESERVED，若成功，则触发closeConnection（对应流程1.1.2） if (softEvictConnection(poolEntry, \"(connection has passed maxLifetime)\", false /* not owner */)) { addBagItem(connectionBag.getWaitingThreadCount()); //回收完毕后，连接池内少了一个连接，就会尝试新增一个连接对象 } }, lifetime, MILLISECONDS)); //给endOfLife赋值，并且提交延时任务，lifetime后触发 } return poolEntry; } //触发新增连接任务 public void addBagItem(final int waiting) { //前排提示：addConnectionQueue和addConnectionExecutor的关系和初始化参考主流程2 //当添加连接的队列里已提交的任务超过那些因为获取不到连接而发生阻塞的线程个数时，就进行提交连接新增连接的任务 final boolean shouldAdd = waiting - addConnectionQueue.size() &gt;= 0; // Yes, &gt;= is intentional. if (shouldAdd) { //提交任务给addConnectionExecutor这个线程池，PoolEntryCreator是一个实现了Callable接口的类，下面将通过流程图的方式介绍该类的call方法 addConnectionExecutor.submit(poolEntryCreator); } } 代码块8 通过上面的流程，可以知道，HikariCP一般通过createEntry方法来新增一个连接入池，每个连接被包装成PoolEntry对象，在创建好对象时，同时会提交一个延时任务来关闭废弃该连接，这个时间就是我们配置的maxLifeTime，为了保证不在同一时间失效，HikariCP还会利用maxLifeTime减去一个随机数作为最终的延时任务延迟时间，然后在触发废弃任务时，还会触发addBagItem，进行连接添加任务（因为废弃了一个连接，需要往池子里补充一个），该任务则交给由主流程2里定义好的addConnectionExecutor线程池执行，那么，现在来看下这个异步添加连接对象的任务流程： 这个流程就是往连接池里加连接用的，跟createEntry结合起来说是因为这俩流程是紧密相关的，除此之外，主流程5（fillPool，扩充连接池）也会触发该任务。 九、主流程4：连接池缩容HikariCP会按照minIdle定时清理闲置过久的连接，这个定时任务在主流程2初始化连接池对象时被启用，跟上面的流程一样，也是利用houseKeepingExecutorService这个线程池对象做该定时任务的执行器。 来看下主流程2里是怎么启用该任务的： 12//housekeepingPeriodMs的默认值是30s，所以定时任务的间隔为30sthis.houseKeeperTask = houseKeepingExecutorService.scheduleWithFixedDelay(new HouseKeeper(), 100L, housekeepingPeriodMs, MILLISECONDS); 代码块9 那么本节主要来说下HouseKeeper这个类，该类实现了Runnable接口，回收逻辑主要在其run方法内，来看看run方法的逻辑流程图： 上面的流程就是HouseKeeper的run方法里具体做的事情，由于系统时间回拨会导致该定时任务回收一些连接时产生误差，因此存在如下判断： 12345//now就是当前系统时间，previous就是上次触发该任务时的时间，housekeepingPeriodMs就是隔多久触发该任务一次//也就是说plusMillis(previous, housekeepingPeriodMs)表示当前时间//如果系统时间没被回拨，那么plusMillis(now, 128)一定是大于当前时间的，如果被系统时间被回拨//回拨的时间超过128ms，那么下面的判断就成立，否则永远不会成立if (plusMillis(now, 128) &lt; plusMillis(previous, housekeepingPeriodMs)) 代码块10 这是hikariCP在解决系统时钟被回拨时做出的一种措施，通过流程图可以看到，它是直接把池子里所有的连接对象取出来挨个儿的标记成废弃，并且尝试把状态值修改为STATE_RESERVED（后面会说明这些状态，这里先不深究）。如果系统时钟没有发生改变（绝大多数情况会命中这一块的逻辑），由图知，会把当前池内所有处于闲置状态（STATE_NOT_IN_USE）的连接拿出来，然后计算需要检查的范围，然后循环着修改连接的状态： 123456789101112//拿到所有处于闲置状态的连接final List notInUse = connectionBag.values(STATE_NOT_IN_USE);//计算出需要被检查闲置时间的数量，简单来说，池内需要保证最小minIdle个连接活着，所以需要计算出超出这个范围的闲置对象进行检查int toRemove = notInUse.size() - config.getMinIdle();for (PoolEntry entry : notInUse) { //在检查范围内，且闲置时间超出idleTimeout，然后尝试将连接对象状态由STATE_NOT_IN_USE变为STATE_RESERVED成功 if (toRemove &gt; 0 &amp;&amp; elapsedMillis(entry.lastAccessed, now) &gt; idleTimeout &amp;&amp; connectionBag.reserve(entry)) { closeConnection(entry, \"(connection has passed idleTimeout)\"); //满足上述条件，进行连接关闭 toRemove--; }}fillPool(); //因为可能回收了一些连接，所以要再次触发连接池扩充流程检查下是否需要新增连接。 代码块11 上面的代码就是流程图里对应的没有回拨系统时间时的流程逻辑。该流程在idleTimeout大于0（默认等于0）并且minIdle小于maxPoolSize的时候才会启用，默认是不启用的，若需要启用，可以按照条件来配置。 十、主流程5：扩充连接池这个流程主要依附HikariPool里的fillPool方法，这个方法已经在上面很多流程里出现过了，它的作用就是在触发连接废弃、连接池连接不够用时，发起扩充连接数的操作，这是个很简单的过程，下面看下源码（为了使代码结构更加清晰，对源码做了细微改动）： 123456789101112131415161718// PoolEntryCreator关于call方法的实现流程在主流程3里已经看过了，但是这里却有俩PoolEntryCreator对象，// 这是个较细节的地方，用于打日志用，不再说这部分，为了便于理解，只需要知道这俩对象执行的是同一块call方法即可private final PoolEntryCreator poolEntryCreator = new PoolEntryCreator(null);private final PoolEntryCreator postFillPoolEntryCreator = new PoolEntryCreator(\"After adding \");private synchronized void fillPool() { // 这个判断就是根据当前池子里相关数据，推算出需要扩充的连接数， // 判断方式就是利用最大连接数跟当前连接总数的差值，与最小连接数与当前池内闲置的连接数的差值，取其最小的那一个得到 int needAdd = Math.min(maxPoolSize - connectionBag.size(), minIdle - connectionBag.getCount(STATE_NOT_IN_USE)); //减去当前排队的任务，就是最终需要新增的连接数 final int connectionsToAdd = needAdd - addConnectionQueue.size(); for (int i = 0; i &lt; connectionsToAdd; i++) { //一般循环的最后一次会命中postFillPoolEntryCreator任务，其实就是在最后一次会打印一次日志而已（可以忽略该干扰逻辑） addConnectionExecutor.submit((i &lt; connectionsToAdd - 1) ? poolEntryCreator : postFillPoolEntryCreator); }} 代码块12 由该过程可以知道，最终这个新增连接的任务也是交由addConnectionExecutor线程池来处理的，而任务的主题也是PoolEntryCreator，这个流程可以参考主流程3. 然后needAdd的推算： 1Math.min(最大连接数 - 池内当前连接总数, 最小连接数 - 池内闲置的连接数) 根据这个方式判断，可以保证池内的连接数永远不会超过maxPoolSize，也永远不会低于minIdle。在连接吃紧的时候，可以保证每次触发都以minIdle的数量扩容。因此如果在maxPoolSize跟minIdle配置的值一样的话，在池内连接吃紧的时候，就不会发生任何扩容了。 十一、主流程6：连接回收最开始说过，最终真实的物理连接对象会被包装成PoolEntry对象，存放进ConcurrentBag，然后获取时，PoolEntry对象又会被再次包装成ProxyConnection对象暴露给使用方的，那么触发连接回收，实际上就是触发ProxyConnection里的close方法： 12345678910111213141516public final void close() throws SQLException { // 原注释：Closing statements can cause connection eviction, so this must run before the conditional below closeStatements(); //此连接对象在业务方使用过程中产生的所有statement对象，进行统一close，防止漏close的情况 if (delegate != ClosedConnection.CLOSED_CONNECTION) { leakTask.cancel(); //取消连接泄漏检查任务，参考流程2.2 try { if (isCommitStateDirty &amp;&amp; !isAutoCommit) { //在存在执行语句后并且还打开了事务，调用close时需要主动回滚事务 delegate.rollback(); //回滚 lastAccess = currentTime(); //刷新\"最后一次使用时间\" } } finally { delegate = ClosedConnection.CLOSED_CONNECTION; poolEntry.recycle(lastAccess); //触发回收 } }} 代码块13 这个就是ProxyConnection里的close方法，可以看到它最终会调用PoolEntry的recycle方法进行回收，除此之外，连接对象的最后一次使用时间也是在这个时候刷新的，该时间是个很重要的属性，可以用来判断一个连接对象的闲置时间，来看下PoolEntry的recycle方法： 123456void recycle(final long lastAccessed) { if (connection != null) { this.lastAccessed = lastAccessed; //刷新最后使用时间 hikariPool.recycle(this); //触发HikariPool的回收方法，把自己传过去 }} 代码块14 之前有说过，每个PoolEntry对象都持有HikariPool的对象，方便触发连接池的一些操作，由上述代码可以看到，最终还是会触发HikariPool里的recycle方法，再来看下HikariPool的recycle方法： 1234void recycle(final PoolEntry poolEntry) { metricsTracker.recordConnectionUsage(poolEntry); //监控指标相关，忽略 connectionBag.requite(poolEntry); //最终触发connectionBag的requite方法归还连接，该流程参考ConnectionBag主流程里的requite方法部分} 代码块15 以上就是连接回收部分的逻辑，相比其他流程，还是比较简洁的。 十二、ConcurrentBag主流程这个类用来存放最终的PoolEntry类型的连接对象，提供了基本的增删查的功能，被HikariPool持有，上面那么多的操作，几乎都是在HikariPool中完成的，HikariPool用来管理实际的连接生产动作和回收动作，实际操作的却是ConcurrentBag类，梳理下上面所有流程的触发点： 主流程2：初始化HikariPool时初始化ConcurrentBag（构造方法），预热时通过createEntry拿到连接对象，调用ConcurrentBag.add添加连接到ConcurrentBag。 流程1.1：通过HikariPool获取连接时，通过调用ConcurrentBag.borrow拿到一个连接对象。 主流程6：通过ConcurrentBag.requite归还一个连接。 流程1.1.2：触发关闭连接时，会通过ConcurrentBag.remove移除连接对象，由前面的流程可知关闭连接触发点为：连接超过最大生命周期maxLifeTime主动废弃、健康检查不通过主动废弃、连接池缩容。 主流程3：通过异步添加连接时，通过调用ConcurrentBag.add添加连接到ConcurrentBag，由前面的流程可知添加连接触发点为：连接超过最大生命周期maxLifeTime主动废弃连接后、连接池扩容。 主流程4：连接池缩容任务，通过调用ConcurrentBag.values筛选出需要的做操作的连接对象，然后再通过ConcurrentBag.reserve完成对连接对象状态的修改，然后会通过流程1.1.2触发关闭和移除连接操作。 通过触发点整理，可以知道该结构里的主要方法，就是上面触发点里标记为标签色的部分，然后来具体看下该类的基本定义和主要方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public class ConcurrentBag&lt;T extends IConcurrentBagEntry&gt; implements AutoCloseable { private final CopyOnWriteArrayList&lt;T&gt; sharedList; //最终存放PoolEntry对象的地方，它是一个CopyOnWriteArrayList private final boolean weakThreadLocals; //默认false，为true时可以让一个连接对象在下方threadList里的list内处于弱引用状态，防止内存泄漏（参见备注1） private final ThreadLocal&lt;List&lt;Object&gt;&gt; threadList; //线程级的缓存，从sharedList拿到的连接对象，会被缓存进当前线程内，borrow时会先从缓存中拿，从而达到池内无锁实现 private final IBagStateListener listener; //内部接口，HikariPool实现了该接口，主要用于ConcurrentBag主动通知HikariPool触发添加连接对象的异步操作（也就是主流程3里的addConnectionExecutor所触发的流程） private final AtomicInteger waiters; //当前因为获取不到连接而发生阻塞的业务线程数，这个在之前的流程里也出现过，比如主流程3里addBagItem就会根据该指标进行判断是否需要新增连接 private volatile boolean closed; //标记当前ConcurrentBag是否已被关闭 private final SynchronousQueue&lt;T&gt; handoffQueue; //这是个即产即销的队列，用于在连接不够用时，及时获取到add方法里新创建的连接对象，详情可以参考下面borrow和add的代码 //内部接口，PoolEntry类实现了该接口 public interface IConcurrentBagEntry { //连接对象的状态，前面的流程很多地方都已经涉及到了，比如主流程4的缩容 int STATE_NOT_IN_USE = 0; //闲置 int STATE_IN_USE = 1; //使用中 int STATE_REMOVED = -1; //已废弃 int STATE_RESERVED = -2; //标记保留，介于闲置和废弃之间的中间状态，主要由缩容那里触发修改 boolean compareAndSet(int expectState, int newState); //尝试利用cas修改连接对象的状态值 void setState(int newState); //设置状态值 int getState(); //获取状态值 } //参考上面listener属性的解释 public interface IBagStateListener { void addBagItem(int waiting); } //获取连接方法 public T borrow(long timeout, final TimeUnit timeUnit) { // 省略... } //回收连接方法 public void requite(final T bagEntry) { //省略... } //添加连接方法 public void add(final T bagEntry) { //省略... } //移除连接方法 public boolean remove(final T bagEntry) { //省略... } //根据连接状态值获取当前池子内所有符合条件的连接集合 public List values(final int state) { //省略... } //获取当前池子内所有的连接 public List values() { //省略... } //利用cas把传入的连接对象的state从 STATE_NOT_IN_USE 变为 STATE_RESERVED public boolean reserve(final T bagEntry) { //省略... } //获取当前池子内符合传入状态值的连接数量 public int getCount(final int state) { //省略... }} 代码块16 从这个基本结构就可以稍微看出HikariCP是如何优化传统连接池实现的了，相比Druid来说，HikariCP更加偏向无锁实现，尽量避免锁竞争的发生。 12.1：borrow这个方法用来获取一个可用的连接对象，触发点为流程1.1，HikariPool就是利用该方法获取连接的，下面来看下该方法做了什么： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public T borrow(long timeout, final TimeUnit timeUnit) throws InterruptedException { // 源注释：Try the thread-local list first final List&lt;Object&gt; list = threadList.get(); //首先从当前线程的缓存里拿到之前被缓存进来的连接对象集合 for (int i = list.size() - 1; i &gt;= 0; i--) { final Object entry = list.remove(i); //先移除，回收方法那里会再次add进来 final T bagEntry = weakThreadLocals ? ((WeakReference&lt;T&gt;) entry).get() : (T) entry; //默认不启用弱引用 // 获取到对象后，通过cas尝试把其状态从STATE_NOT_IN_USE 变为 STATE_IN_USE，注意，这里如果其他线程也在使用这个连接对象， // 并且成功修改属性，那么当前线程的cas会失败，那么就会继续循环尝试获取下一个连接对象 if (bagEntry != null &amp;&amp; bagEntry.compareAndSet(STATE_NOT_IN_USE, STATE_IN_USE)) { return bagEntry; //cas设置成功后，表示当前线程绕过其他线程干扰，成功获取到该连接对象，直接返回 } } // 源注释：Otherwise, scan the shared list ... then poll the handoff queue final int waiting = waiters.incrementAndGet(); //如果缓存内找不到一个可用的连接对象，则认为需要“回源”，waiters+1 try { for (T bagEntry : sharedList) { //循环sharedList，尝试把连接状态值从STATE_NOT_IN_USE 变为 STATE_IN_USE if (bagEntry.compareAndSet(STATE_NOT_IN_USE, STATE_IN_USE)) { // 源注释：If we may have stolen another waiter's connection, request another bag add. if (waiting &gt; 1) { //阻塞线程数大于1时，需要触发HikariPool的addBagItem方法来进行添加连接入池，这个方法的实现参考主流程3 listener.addBagItem(waiting - 1); } return bagEntry; //cas设置成功，跟上面的逻辑一样，表示当前线程绕过其他线程干扰，成功获取到该连接对象，直接返回 } } //走到这里说明不光线程缓存里的列表竞争不到连接对象，连sharedList里也找不到可用的连接，这时则认为需要通知HikariPool，该触发添加连接操作了 listener.addBagItem(waiting); timeout = timeUnit.toNanos(timeout); //这时候开始利用timeout控制获取时间 do { final long start = currentTime(); //尝试从handoffQueue队列里获取最新被加进来的连接对象（一般新入的连接对象除了加进sharedList之外，还会被offer进该队列） final T bagEntry = handoffQueue.poll(timeout, NANOSECONDS); //如果超出指定时间后仍然没有获取到可用的连接对象，或者获取到对象后通过cas设置成功，这两种情况都不需要重试，直接返回对象 if (bagEntry == null || bagEntry.compareAndSet(STATE_NOT_IN_USE, STATE_IN_USE)) { return bagEntry; } //走到这里说明从队列内获取到了连接对象，但是cas设置失败，说明又该对象又被其他线程率先拿去用了，若时间还够，则再次尝试获取 timeout -= elapsedNanos(start); //timeout减去消耗的时间，表示下次循环可用时间 } while (timeout &gt; 10_000); //剩余时间大于10s时才继续进行，一般情况下，这个循环只会走一次，因为timeout很少会配的比10s还大 return null; //超时，仍然返回null } finally { waiters.decrementAndGet(); //这一步出去后，HikariPool收到borrow的结果，算是走出阻塞，所以waiters-1 }} 代码块17 仔细看下注释，该过程大致分成三个主要步骤： 从线程缓存获取连接 获取不到再从sharedList里获取 都获取不到则触发添加连接逻辑，并尝试从队列里获取新生成的连接对象 12.2：add这个流程会添加一个连接对象进入bag，通常由主流程3里的addBagItem方法通过addConnectionExecutor异步任务触发添加操作，该方法主流程如下： 12345678910public void add(final T bagEntry) { sharedList.add(bagEntry); //直接加到sharedList里去 // 源注释：spin until a thread takes it or none are waiting // 参考borrow流程，当存在线程等待获取可用连接，并且当前新入的这个连接状态仍然是闲置状态，且队列里无消费者等待获取时，发起一次线程调度 while (waiters.get() &gt; 0 &amp;&amp; bagEntry.getState() == STATE_NOT_IN_USE &amp;&amp; !handoffQueue.offer(bagEntry)) { //注意这里会offer一个连接对象入队列 yield(); }} 代码块18 结合borrow来理解的话，这里在存在等待线程时会添加一个连接对象入队列，可以让borrow里发生等待的地方更容易poll到这个连接对象。 12.3：requite这个流程会回收一个连接，该方法的触发点在主流程6，具体代码如下： 1234567891011121314151617181920public void requite(final T bagEntry) { bagEntry.setState(STATE_NOT_IN_USE); //回收意味着使用完毕，更改state为STATE_NOT_IN_USE状态 for (int i = 0; waiters.get() &gt; 0; i++) { //如果存在等待线程的话，尝试传给队列，让borrow获取 if (bagEntry.getState() != STATE_NOT_IN_USE || handoffQueue.offer(bagEntry)) { return; } else if ((i &amp; 0xff) == 0xff) { parkNanos(MICROSECONDS.toNanos(10)); } else { yield(); } } final List&lt;Object&gt; threadLocalList = threadList.get(); if (threadLocalList.size() &lt; 50) { //线程内连接集合的缓存最多50个，这里回收连接时会再次加进当前线程的缓存里，方便下次borrow获取 threadLocalList.add(weakThreadLocals ? new WeakReference&lt;&gt;(bagEntry) : bagEntry); //默认不启用弱引用，若启用的话，则缓存集合里的连接对象没有内存泄露的风险 }} 代码块19 12.4：remove这个负责从池子里移除一个连接对象，触发点在流程1.1.2，代码如下： 123456789101112131415public boolean remove(final T bagEntry) { // 下面两个cas操作，都是从其他状态变为移除状态，任意一个成功，都不会走到下面的warn log if (!bagEntry.compareAndSet(STATE_IN_USE, STATE_REMOVED) &amp;&amp; !bagEntry.compareAndSet(STATE_RESERVED, STATE_REMOVED) &amp;&amp; !closed) { LOGGER.warn(\"Attempt to remove an object from the bag that was not borrowed or reserved: {}\", bagEntry); return false; } // 直接从sharedList移除掉 final boolean removed = sharedList.remove(bagEntry); if (!removed &amp;&amp; !closed) { LOGGER.warn(\"Attempt to remove an object from the bag that does not exist: {}\", bagEntry); } return removed;} 代码块20 这里需要注意的是，移除时仅仅移除了sharedList里的对象，各个线程内缓存的那一份集合里对应的对象并没有被移除，这个时候会不会存在该连接再次从缓存里拿到呢？会的，但是不会返回出去，而是直接remove掉了，仔细看borrow的代码发现状态不是闲置状态的时候，取出来时就会remove掉，然后也拿不出去，自然也不会触发回收方法。 12.5：values该方法存在重载方法，用于返回当前池子内连接对象的集合，触发点在主流程4，代码如下： 1234567891011public List values(final int state) { //过滤出来符合状态值的对象集合逆序后返回出去 final List list = sharedList.stream().filter(e -&gt; e.getState() == state).collect(Collectors.toList()); Collections.reverse(list); return list;}public List values() { //返回全部连接对象（注意下方clone为浅拷贝） return (List) sharedList.clone();} 代码块21 12.6：reserve该方法单纯将连接对象的状态值由STATE_NOT_IN_USE修改为STATE_RESERVED，触发点仍然是主流程4，缩容时使用，代码如下： 123public boolean reserve(final T bagEntry){ return bagEntry.compareAndSet(STATE_NOT_IN_USE, STATE_RESERVED);} 代码块22 12.7：getCount该方法用于返回池内符合某个状态值的连接的总数量，触发点为主流程5，扩充连接池时用于获取闲置连接总数，代码如下： 123456789public int getCount(final int state){ int count = 0; for (IConcurrentBagEntry e : sharedList) { if (e.getState() == state) { count++; } } return count;} 代码块23 以上就是ConcurrentBag的主要方法和处理连接对象的主要流程。 十三、总结到这里基本上一个连接的生产到获取到回收到废弃一整个生命周期在HikariCP内是如何管理的就说完了，相比之前的Druid的实现，有很大的不同，主要是HikariCP的无锁获取连接，本篇没有涉及FastList的说明，因为从连接管理这个角度确实很少用到该结构，用到FastList的地方主要在存储连接对象生成的statement对象以及用于存储线程内缓存起来的连接对象； 除此之外HikariCP还利用javassist技术编译期生成了ProxyConnection的初始化，这里也没有相关说明，网上有关HikariCP的优化有很多文章，大多数都提到了字节码优化、fastList、concurrentBag的实现，本篇主要通过深入解析HikariPool和ConcurrentBag的实现，来说明HikariCP相比Druid具体做了哪些不一样的操作。","link":"/2019/08/28/%E6%B1%A0%E5%8C%96%E6%8A%80%E6%9C%AF%EF%BC%88%E4%BA%8C%EF%BC%89HikariCP%E6%98%AF%E5%A6%82%E4%BD%95%E7%AE%A1%E7%90%86%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E7%9A%84%EF%BC%9F/"},{"title":"深入理解map系列-HashMap（一）","text":"Map系列之HashMap（源码基于java8） HashMap是我们最常用的map实现之一，这篇文章将会介绍HashMap内部是如何工作的，以及内部的数据结构是怎样的 一、数据结构简图 二、源码解析首先看下Map接口里常用的几个方法： 1234V put(K key, V value);V get(Object key);V remove(Object key);boolean containsKey(Object key); 代码块1 上面是常用的主要操作方法，下面来看下map的基本存储单位Entry： 12345678910111213interface Entry&lt;K,V&gt; { K getKey(); //返回当前存储数据里的key V getValue(); //返回当前存储数据里的value V setValue(V value); //给value赋值 boolean equals(Object o); //重写equals方法 int hashCode(); //重写hashCode方法 } 代码块2 然后我们来看下HashMap里对该接口的实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243// 基本存储结构，可以看出来这是一个简单的链表结构，这里的实现类叫Nodestatic class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final int hash; //根据key计算出来的哈希值 final K key; //数据键 V value; //数据值 Node&lt;K,V&gt; next; //下一个数据节点 Node(int hash, K key, V value, Node&lt;K,V&gt; next) { this.hash = hash; this.key = key; this.value = value; this.next = next; } public final K getKey() { return key; } public final V getValue() { return value; } public final String toString() { return key + \"=\" + value; } public final int hashCode() { return Objects.hashCode(key) ^ Objects.hashCode(value); } public final V setValue(V newValue) { V oldValue = value; value = newValue; return oldValue; } // 判等，要求k，v必须满足相等才行 public final boolean equals(Object o) { if (o == this) return true; if (o instanceof Map.Entry) { Map.Entry e = (Map.Entry)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; } return false; } } 代码块3 我们再来看看hash值的计算，在哈希表中，哈希值取决了散列度，最终插入的数据会分布到哪个数组下标下，hash值起着至关重要的作用： 1234static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); } 代码块4 下面我们来看看具体插入数据时做的操作，具体解释已经加上注释： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { HashMap.Node&lt;K,V&gt;[] tab; //存储链表的数组结构 HashMap.Node&lt;K,V&gt; p; //被插入的元素链表头部元素 int n, i; //n表示当前哈希表数组长度，i表示本次插入元素被分配的下标 if ((tab = table) == null || (n = tab.length) == 0) { //表示哈希表数组还未被初始化 n = (tab = resize()).length; //初始化，resize用来扩容 } //表示当前（下标由最大下标值和当前元素哈希值位运算得出）位置还没有任何链表结构，这时直接初始化即可 if ((p = tab[i = (n - 1) &amp; hash]) == null) { tab[i] = newNode(hash, key, value, null); } else { // 否则，需要进行链表数据插入的操作，注意现在p已经是计算出来的链表头元素了 HashMap.Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) { e = p; // 若发现插入的数据跟p哈希值、key完全一致，则直接让新插入的数据等于p即可 } else if (p instanceof HashMap.TreeNode){ // 结合下面的代码，链表深度大于8后，就是个红黑树结构了，这时启用下面的代码加入新数据 e = ((HashMap.TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); } else { // 说明插入的是新元素 for (int binCount = 0; ; ++binCount) { // 遍历链表 if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); //插入链表尾部 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // java8新引入的概念，当链表深度大于8时，就转换为红黑树结构了 treeifyBin(tab, hash); break; } if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) { break; // 若发现遍历过程中存在与插入值一致的，直接break } p = e; } } if (e != null) { // 说明未成功插入 V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; // 返回已存在的旧值 } } ++modCount; if (++size &gt; threshold) { //新插入值后，满足扩容条件则进行扩容 resize(); //扩容 } afterNodeInsertion(evict); return null; } 代码块5 由于java8做了根据元素数量，转换成红黑树结构的优化处理，所以上述代码中会掺杂一些相关的代码，这里先不用关心，我们按照最基本的哈希表结构来看就行，下一讲将会分析红黑树结构。 我们接下来来看下get方法： 1234public V get(Object key) { Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;} 代码块6 然后getNode方法： 1234567891011121314151617181920212223242526final HashMap.Node&lt;K,V&gt; getNode(int hash, Object key) { HashMap.Node&lt;K,V&gt;[] tab; //哈希表数组 HashMap.Node&lt;K,V&gt; first, e; //根据hash查找数组内的第一个元素 int n; K k; // n表示数组长度 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) { // 根据下标（下标由最大下标值和当前元素哈希值位运算得出）获取当前对应第一个元素（链表或者红黑树的根元素） if (first.hash == hash &amp;&amp; // 检查第一个节点的key是否等于当前查找的key，若等，直接返回 ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))){ return first; } // 否则继续遍历查找 if ((e = first.next) != null) { if (first instanceof HashMap.TreeNode) { //红黑树结构的查询 return ((HashMap.TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); } // 普通链表结构遍历查询，查到直接返回 do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))){ return e; } } while ((e = e.next) != null); } } return null; } 代码块7 ok,上面说完了put和get，现在我们来看下remove，也是先抛开红黑树不谈，只看链表部分，会很容易： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public V remove(Object key) { HashMap.Node&lt;K, V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value; }final HashMap.Node&lt;K, V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) { HashMap.Node&lt;K, V&gt;[] tab; //哈希表数组 HashMap.Node&lt;K, V&gt; p; //需要被移除的元素所属的根元素 int n, index; //n表示数组长度，index表示需要被移除元素根元素位于数组的下标值 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) { HashMap.Node&lt;K, V&gt; node = null, e; // node表示最终需要被移除的元素 K k; V v; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) { node = p; // 若根元素就等于需要被移除的元素，则直接将node赋值为p } else if ((e = p.next) != null) { // 否则继续往下查找，结构依然分为两种，红黑树暂不看 if (p instanceof HashMap.TreeNode) { node = ((HashMap.TreeNode&lt;K, V&gt;) p).getTreeNode(hash, key); } else { do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) { node = e; break; // 找到对应的元素，break } p = e; // 找不到对应元素时，让p一直下移（e.next） } while ((e = e.next) != null); } } if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) { if (node instanceof HashMap.TreeNode) { //红黑树移除 ((HashMap.TreeNode&lt;K, V&gt;) node).removeTreeNode(this, tab, movable); } else if (node == p) { // 待移除元素等于根元素时，直接让对应下标下的数组元素赋值为根元素的下一个值 tab[index] = node.next; } else { //否则，就进行链表正常删除逻辑，让被移除元素的前一个元素（为什么现在的p是前一个元素呢？因为在上述do while操作时已经重新赋值了）的下一个值指向被移除元素的下一个值 p.next = node.next; } ++modCount; --size; afterNodeRemoval(node); return node; } } return null; } 代码块8 好了，目前基本上把重要的一些操作给介绍完了，现在再看下containsKay这个方法，这个方法极度简单，直接调用getNode方法判空即可： 123public boolean containsKey(Object key) { return getNode(hash(key), key) != null;} 代码块9 本篇的侧重点在于HashMap在使用纯链表时的插入、移除、查找方式，下一篇将会介绍HashMap如何扩容数组、以及在启用红黑树结构下，会如何做插入、移除、查找这几种操作方式。","link":"/2019/02/12/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map%E7%B3%BB%E5%88%97-HashMap%EF%BC%88%E4%B8%80%EF%BC%89/"},{"title":"简单实现生产者和消费者模式","text":"本实例中单独为生产者和消费者各开辟一个线程作为生产者和消费者的执行线程，在生产者消费者设计模式中存在一个数据缓冲区，使生产者和消费者的“生产”和“消费”动作都在该缓冲区进行，这样做的目的就是保证了生产者和消费者的完美解耦，试想一下如果没了这个缓冲区，生产者和消费者中的方法互调，那么两个类的关联度（耦合度）就会很高，一旦一个发生变化，势必会影响另外一个； 下面开始我们的实例： 首先是生产者的代码： 12345678910111213141516171819202122/** * 生产者 */public class Product implements Runnable{ private Queue queue; public Product(Queue queue){ this.queue = queue; } @Override public void run() { try{ for(int i = 0; i &lt; 10; i++){ queue.product(\"Product------\" + \"No.\" + i);//开始生产 } }catch (Exception e){ e.printStackTrace(); } }} 代码块1 这是消费者： 12345678910111213141516171819202122/** * 消费者 */public class Consumer implements Runnable{ private Queue queue; public Consumer(Queue queue){ this.queue = queue; } @Override public void run() { try{ for(int i = 0; i &lt; 10; i++){ System.out.println(\"already gone : \" + queue.consumer());//开始消费 } }catch (Exception e){ e.printStackTrace(); } }} 代码块2 这是缓冲区，几乎所有的逻辑都是在这里实现的： 123456789101112131415161718192021222324252627282930313233343536373839/** * 队列缓冲区 */public class Queue { private Object signal = new Object();//当前线程的挂起和执行标记 private boolean isFull = false;//队列是否已满 private List list = new ArrayList&lt;&gt;();//队列 public void product(String msg) throws Exception{ synchronized (signal){ if(!isFull){//如果没有满，执行如下代码 list.add(msg);//加进队列 isFull = true; System.out.println(\"Product One !\"); signal.notify();//唤醒当前消费者里面被挂起的线程 } signal.wait();//否则，如果当前满了，说明消费者正在消费，挂起当前生产线程 } } public String consumer() throws Exception{ synchronized (signal){ if(!isFull){ //不满，说明生产者正在生产，应当挂起consumer线程 System.out.println(\"Empty Product !\"); signal.wait(); } isFull = false;//已消费，队列被标记为不满状态 signal.notify();//通知生产者 } //消费（读取） String result = \"\"; if(list.size() &gt; 0){ result = this.list.get(list.size() - 1); this.list.remove(list.size() - 1); } return result; }} 代码块3 上面这个模式利用java现有的阻塞队列很容易实现，可以避免上述代码中很大一部分代码（线程的挂起、唤醒、队列弹出数据等）","link":"/2016/04/15/%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0%E7%94%9F%E4%BA%A7%E8%80%85%E5%92%8C%E6%B6%88%E8%B4%B9%E8%80%85%E6%A8%A1%E5%BC%8F/"},{"title":"简单工厂模式&策略模式-简介与区别","text":"前言：两种模式的相似点与不同点不得不说，这两种模式真的很像。 相似点：都用到了面向对象的继承、多态、抽象，都拥有相似的结构。 不同点：工厂模式仅提供具体的实例对象，怎么使用这个对象是client的自由，策略模式client可以通过策略类来决定使用哪个实例的哪个方法。 一、两种模式的公共相同部分下面，我们假设有一台红白机，里面有一些游戏，每个游戏拥有play（玩）和uninstall（卸载）两个方法。 按照工厂和策略模式，我们抽象出来一个Game接口： 1234567public interface Game { void play(); void uninstall();} 代码块1 然后，我们假设游戏机里有魂斗罗、马戏团、默认的俄罗斯方块三款游戏，每个游戏有不同的玩法和卸载算法： 123456789101112131415161718192021222324252627282930313233343536373839404142// 魂斗罗，实现Gamepublic class Hundouluo implements Game { @Override public void play() { System.out.println(\"游戏：魂斗罗...playing\"); } @Override public void uninstall() { System.out.println(\"游戏：魂斗罗...卸载\"); }}// 马戏团，实现Gamepublic class Maxituan implements Game { @Override public void play() { System.out.println(\"游戏：马戏团...playing\"); } @Override public void uninstall() { System.out.println(\"游戏：马戏团...卸载\"); }}// 默认的俄罗斯方块，实现Gamepublic class Default implements Game { @Override public void play() { System.out.println(\"游戏：俄罗斯方块...playing\"); } @Override public void uninstall() { System.out.println(\"游戏：俄罗斯方块...卸载\"); }} 代码块2 ok，工厂模式和策略模式的相同部分就已经写好了，通过上面的代码，我们可以发现这两种模式都是需要把相同的部分抽象出来，通过多态来实例化不同的对象，调用其对应的实现。 二、两种模式的不同部分的实现2.1：工厂模式工厂需要一个工厂类，用来返回具体的实例对象用，代码如下： 1234567891011121314public class GameFactory { public static Game getGame(String name) { switch (name) { //根据传来的游戏名（这里偷懒用了首字母），来实例化具体的对象 case \"hdl\": return new Hundouluo(); case \"mxt\": return new Maxituan(); default: return new Default(); } }} 代码块3 2.2：策略模式策略模式需要策略类来封装具体的行为（方法），并且还可以指定使用哪个实例的哪个行为，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839// 为了和工厂做充分的区分，这里定义了两个类型的context，分别维护一个行为算法（也就是方法函数，其次建立两个context是为了说明问题，实际使用时可能不需要这么多）// 用来维护play这个算法的实现public class PlayContext { private Game game; public PlayContext() { this.game = new Default(); } public PlayContext(Game game) { this.game = game; // 这里根据传入的具体实例赋值 } public void trigger() { this.game.play(); // 这里是对行为的封装，只提供play方法的触发 }}// 用来维护uninstall这个算法的实现public class UninstallContext { private Game game; public UninstallContext() { this.game = new Default(); } public UninstallContext(Game game) { this.game = game; // 这里根据传入的具体实例赋值 } public void trigger() { this.game.uninstall(); // 这里是对行为的封装，只提供uninstall方法的触发 }} 代码块4 测试代码： 1234new PlayContext(new Hundouluo()).trigger();new UninstallContext(new Hundouluo()).trigger();new PlayContext(new Maxituan()).trigger();new UninstallContext(new Maxituan()).trigger(); 代码块5 运行结果： 1234游戏：魂斗罗...playing游戏：魂斗罗...卸载游戏：马戏团...playing游戏：马戏团...卸载 通过上面的实验，和对比，会发现，工厂模式是简单的对实例的封装，而策略模式更在意的是对具体实例的具体行为（方法）的封装。 还有一种情况就是利用工厂模式的思想，实现的策略模式，我们现在来改造下上面的PlayContext源码： 1234567891011121314151617181920212223242526public class PlayContext { private Game game; public PlayContext() { this.game = new Default(); } public PlayContext(String name) { switch (name) { //根据传来的游戏名（这里偷懒用了首字母），来实例化具体的对象 case \"hdl\": this.game = new Hundouluo(); break; case \"mxt\": this.game = new Maxituan(); break; default: this.game = new Default(); } } public void trigger() { this.game.play(); // 这里是对行为的封装，只提供play方法的触发 }} 代码块6 测试类： 1234new PlayContext(\"hdl\").trigger();new UninstallContext(new Hundouluo()).trigger();new PlayContext(\"mxt\").trigger();new UninstallContext(new Maxituan()).trigger(); 代码块7 测试结果： 1234游戏：魂斗罗...playing游戏：魂斗罗...卸载游戏：马戏团...playing游戏：马戏团...卸载 三、总结策略模式是一种定义一系列算法的方法，所有这些算法完成的都是相同的工作，只是实现不同，它可以以相同的方式调用所有算法，减少了各种算法类与使用算法类之间的耦合。 工厂模式仅提供对应的实例，不对其方法做封装，减少了具体实现的实例与使用实例的业务方的耦合。 （↑描述待改进）","link":"/2019/02/27/%E7%AE%80%E5%8D%95%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F&%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F-%E7%AE%80%E4%BB%8B%E4%B8%8E%E5%8C%BA%E5%88%AB/"},{"title":"致十年后的我-歌词","text":"这是由doriko制作、初音ミク演唱的一首歌，2015年初遇这首歌，转眼间到了2019年。 歌词 好きな人と歩いた場所も曾和喜欢的人一起走过的地方その時見た景色も那时曾看到的景色振り返らず 今を駆け抜け统统抛掉 不再回头 向前飞奔私は何と出会うの我将会遇见些什么呢 立ち止まるほど驻足不前意味を問うほど探索意义きっとまだ大人ではなくて一定是我还不够成熟今見てるもの现在看到的事物今出会う人现在遇见的人その中でただ前だけを見てる在这片纷繁喧嚣之中 我只会看向前方10年後の私へ致十年以后的我今は幸せでしょうか现在的你感到幸福么？それとも悲しみで还是正沉浸在悲伤中泣いているのでしょうか默默地流着泪？けどあなたの傍に不过在你的身旁変わらないものがあり依然会有不变的存在気付いていないだけで未能察觉的你守られていませんか依然在被守护着吧過ぎし日々に 想いを预け把思念寄托于流逝的日子里時間だけ ただ追いかけてく只有时间在不停的追赶背に寄り添った 誰かの夢に托付在我肩上的 是谁的梦想振り向ける日がいつか来るのかな总有一天必须要面对的吧10年後の私へ致十年以后的我今は誰を好きですか现在的你喜欢着谁呢？それとも変わらずに还是和以前一样あの人が好きですか继续喜欢着那个人呢？けどいつか不过 现在的你知らない誰かを爱する前に在爱上某个人之前自分のことを好きと“喜欢自己”这句话言えるようになりましたか能否先说出来呢大切な人たちは我所珍爱的朋友们今も変わらずいますか依然在反复平凡的生活吗？それとも遠く離れ还是已经远去それぞれ歩んでますか踏上了各自的旅途けど そんな出会いを但是在重复了无数次的相遇别れを 缲り返して和离别之后今の私よりも是否比现在的我すてきになっていますか更有魅力呢？10年後の私へ致十年后的我今がもし幸せなら如果现在的你是幸福的あの日の私のこと从前的我思い出してくれますか能否请你想起来呢そこにはつらいことに回忆中的我泣いた私がいるけど一定在伤心的哭泣吧その涙を優しく请将这温柔的泪水思い出に変えてください融入记忆的海洋","link":"/2019/02/12/%E8%87%B4%E5%8D%81%E5%B9%B4%E5%90%8E%E7%9A%84%E6%88%91-%E6%AD%8C%E8%AF%8D/"},{"title":"简单模拟spring的ioc和aop","text":"spring最核心的部分莫过于ioc和aop了，下面来简单模拟下这两种思想 ps：如果有哪里理解的不对或者代码上有瑕疵的地方欢迎大家指正，大家互相学习，还有就是这只是模仿一下spring思想，只是把事务管理和bean管理简单模仿一下，完全不代表spring，如果想深入理解请看spring源码 下面就开始进行简单的模拟。 这个项目不是web项目，只是一个简单的java项目，测试用junit，废话不多说了，下面上代码： 项目的目录结构： 说明：图中划红线的部分都是核心部分 红线部分说明： BeanFactory：所有bean的核心生成器（spring容器） ConnBean：jdbc连接生成器（没用连接池哦~） Transaction：事务管理的代理类 beans.properties：配置文件 其余的没划线的就是domain、dao、service、controller这些web基本层次结构，待会会说 主要几个类的代码： ① BeanFactory： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package sun.juwin.factory;import java.io.BufferedReader;import java.io.InputStreamReader;import java.util.HashMap;/** * 本类用来读取配置文件中的信息对每个接口对象生成具体的实现 * 主要是将接口作为key，实例作为value存储进去，这是个单例， * spring默认为每个层次生成实现也是单例，但可以通过@Scope * 来指定，我们简单模仿一下，只是单例 */public class BeanFactory { private static HashMap&lt;String, Object&gt; mapResult; public static HashMap&lt;String, Object&gt; getBean() { if (mapResult == null) { synchronized (BeanFactory.class) {//双重检查的单例，防止多线程访问时多次new对象 if (mapResult == null) { BufferedReader bf = null; String line = null; try { /** *下面这句代码通过流来读取资源包下面的配置文件，为了省去不必要的麻烦， * 我们没有用xml，而是用了properties */ InputStreamReader inputStreamReader = new InputStreamReader(BeanFactory.class.getClassLoader().getResourceAsStream(\"beans.properties\")); bf = new BufferedReader(inputStreamReader); mapResult = new HashMap&lt;&gt;(); while ((line = bf.readLine()) != null) {//每次仅读一行 if (\"\".equals(line)){//有可能读到换行时隔了一行（即只有一个换行符） continue; } String[] point = line.trim().split(\"=\");//按照等号拼接 if (point.length &gt; 2) { throw new Exception(\"beans文件格式不对！\"); } Object obj = Class.forName(point[1].trim()).newInstance();//反射实例化出目标对象 mapResult.put(point[0].trim(), obj);//然后以键值对的形式存入 } } catch (Exception e) { e.printStackTrace(); } } } } return mapResult; }} 代码块1 上面的类可以通过配置文件来实例化不同的对象，符合ioc最基本的思想，下面让我们来看看配置文件beans.properties的内容吧： 12userDao = sun.juwin.dao.impl.UserDaoImpluserDetailDao = sun.juwin.dao.impl.UserDetailDaoImpl 这里面只有两句话，指定dao层接口对象的实现类的路径，其实已经很接近spring的xml里对bean的配置了，只不过这里是properties文件，简化了许多 ② TransactionProxy代理类： 123456789101112131415161718192021222324252627282930313233343536package sun.juwin.proxy.transctional;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.sql.Connection;/** * 事务代理类，通过这个类可以为要执行的方法加上事务管理 */public class TransactionProxy implements InvocationHandler { private Object targetObj; public Object getTargetObj(Object targetObj){ this.targetObj = targetObj; return Proxy.newProxyInstance(this.targetObj.getClass().getClassLoader(), this.targetObj.getClass().getInterfaces(), this); } /*下面这个方法会在被代理类执行方法时调用，拿到被代理类的要执行的method对象*/ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { Object result = null; Connection connection = (Connection)args[0];//要求第一个参数必须是conn try{ connection.setAutoCommit(false);//开启事务 result = method.invoke(this.targetObj, args);//执行目标方法 connection.commit();//事务提交 System.out.print(\"commit success!\"); }catch (Exception e){ connection.rollback();//事务回滚 System.err.println(\"rollback!\"); e.printStackTrace(); }finally { connection.close();//关闭连接 System.out.println(\"connection closed!\"); } return result; }} 代码块2 说明：java在1.3版本的时候就为我们提供了一个用作代理类实现的接口InvacationHandler，通过实现这个接口可以很随意的写一个耦合度特别低的动态代理类（即这一个代理类可以代理任何类） ③ ConnBean，用来生成一个数据库连接对象，在不用连接池的情况下，我们用ThreadLocal进行封装，代码如下： 123456789101112131415161718192021222324package sun.juwin.db;import java.sql.Connection;import java.sql.DriverManager;/*原始产生数据库连接的类*/public class ConnBean { private static ThreadLocal conn = new ThreadLocal&lt;&gt;(); private ConnBean(){} public static Connection getConn(){ Connection connection = conn.get(); if(connection == null){ synchronized (ConnBean.class){//由于用到了ThreadLocal，因此该单例仅仅相对于当前线程是单例的 if(connection == null){ try{ Connection realConn = DriverManager.getConnection(\"jdbc:mysql://localhost:3306/db_useradd\", \"root\", \"\"); conn.set(realConn); }catch (Exception e){ e.printStackTrace(); } } } } return conn.get();//返回给当前线程一个Connection对象 }} 代码块3 以上就是核心的一些实现代码，下面让我们来看一下我们的业务吧： 实体类：User，UserDetail，要求添加一个User的同时要添加一个UserDetail User： 1234private Long id;private String userName;private String address;private int money; 代码块4 UserDetail： 123private Long id;private int age;private String realname; 代码块5 dao层的接口和实现： UserDao： 123public interface UserDao { public void save(User user, Connection conn)throws Exception;} 代码块6 UserDaoImpl： 123456789101112public class UserDaoImpl implements UserDao{ @Override public void save(User user, Connection conn) throws Exception { Statement statement = conn.createStatement();//为了省去不必要的麻烦，我们不用预编译语句 String sql = \"insert into tb_user (userName, address, money) values ('\" + user.getUserName() + \"', '\" + user.getAddress() + \"', \" + user.getMoney() + \")\"; statement.executeUpdate(sql); statement.close(); }} 代码块7 UserDetailDao： 123public interface UserDetailDao { public void save(UserDetail userDetail, Connection connection) throws Exception;} 代码块8 UserDetailDaoImpl： 12345678910public class UserDetailDaoImpl implements UserDetailDao { @Override public void save(UserDetail userDetail, Connection connection) throws Exception { Statement statement = connection.createStatement(); String sql = \"insert into user_detail (age, realname) values (\" +userDetail.getAge()+\", '\" +userDetail.getRealname()+\"')\"; statement.executeUpdate(sql); }} 代码块9 UserService： 123public interface UserService { public void saveService(Connection connection, User user) throws Exception;} 代码块10 UserServiceImpl： 123456789101112131415161718192021222324/** * 业务层 * juwin * 2015-12-04 */public class UserServiceImpl implements UserService { //下面的dao层实例由BeanFactory通过properties配置文件帮我们生成对应的实例对象 private UserDao userDao = (UserDao) BeanFactory.getBean().get(\"userDao\"); private UserDetailDao userDetailDao = (UserDetailDao) BeanFactory.getBean().get(\"userDetailDao\"); @Override public void saveService( Connection connection, User user)throws Exception { /** * 这个业务层方法执行了两个dao层方法，可以看做一个事务， * 任意一个dao层调用过程中如果发生异常，整个业务方法进行的所有dao层操作就会回滚 */ userDao.save(user, connection); /*要求在添加user的同时生产一个对应的detail，这里偷个懒，就自己new一个UserDetail对象吧*/ UserDetail userDetail = new UserDetail(); userDetail.setAge(22); userDetail.setRealname(\"juwin\"); userDetailDao.save(userDetail, connection); throw new Exception(\"拦-路-虎\");//这个异常是用来测试事务会不会回滚的，正常情况下不加这个 }} 代码块11 UserController： 12345678910111213141516171819202122/** * 程序入口，类似于controller层 */public class UserController { public void SaveUser(User user)throws Exception{ /** * 这一步很关键，为每一个执行这个操作的线程分配一个connection连接对象 * 说明：在实际web开发中客户端通过发送http请求到业务后台，这时候tomcat会为这次请求分配一个线程 * 因此就出现了并发甚至并行的现象，假象一下，我们如果只是利用单例写一个生成connection对象的方法， * 那么多线程并发访问的时候就有可能出现：线程1利用完connection对象将其状态修改为close，而此时线程2 * 也要用connection，这时候就会报“connection已经关闭”的异常 * 因此我们采用ThreadLocal，为单独一个线程生成一个单例的connection对象 */ Connection connection = ConnBean.getConn(); /** * 下面这个实例要加一层事务代理，就是让TransactionProxy这个代理类搅合一下， * 这样我们再利用service层对象调用任何方法时，都会加上事务管理了 */ UserService userService = (UserService) new TransactionProxy().getTargetObj(new UserServiceImpl()); userService.saveService(connection,user); }} 代码块12 测试类： 123456789101112public class UserAddTest { @Test public void Test1() throws Exception{ User user = new User(); user.setUserName(\"weixiaojie1993\"); user.setAddress(\"beijing\"); user.setMoney(1); UserController userController = new UserController(); userController.SaveUser(user); System.out.print(\"Done !\"); }} 代码块13 ok，大功告成了，现在让我们用junit来测试一下吧： service层不加： 1throw new Exception(\"拦-路-虎\"); 代码块14 执行结果： 可以看出来事务已经提交了，我们来看看数据库里面的变化： tb_user表： user_detail表： 然后在业务层加上： 1throw new Exception(\"拦-路-虎\"); 代码块15 运行结果： 仔细观察划绿色线的部分就能发现，事务已经回滚了，看数据库表也是没有记录的 我们主键id由于是递增的，因此我们还要确定一下事务是不是真的回滚了，我们把异常代码去掉，然后再往里面插入成功一次数据，运行后的数据库表记录如下： tb_user： user_detail： 大家仔细看id，已经是3了，说明原来事务成功回滚了 说明：其实connection对象不必每次都作为参数传递给方法，这里只是为了更清楚的展示connection的流向，其实我们用ThreadLocal封装成一个单例的时候就已经注定了本次访问（即当前线程从controller层调用到dao层）所有get到的connection对象都是同一个； 最后，个人感觉这个程序有个非常要命的地方，就是我要给service层加事务代理，这样就导致了sevice层的对象不能通过配置文件来实例化，正在纠结中。。以后还会优化，这只是简单实现以下，真正的spring要复杂的多得多，第一次在开源中国发表博客，以后也会多发一些，大家互相学习~","link":"/2015/12/04/%E7%AE%80%E5%8D%95%E6%A8%A1%E6%8B%9Fspring%E7%9A%84ioc%E5%92%8Caop/"},{"title":"链路追踪（一）-分布式链路追踪系统的介绍","text":"一、分布式链路追踪可以做什么？1.1：简单集群架构&amp;微服务架构先来看下最简单的网站集群架构图： 在这个图里，存在从1~n个服务器，通过负载均衡器SLB进行请求分发，在每个服务器里，都做同一件事情。 现在来看下这个系统的具体业务逻辑（就是图1中每台服务器执行的逻辑，这里是假设其中一个业务接口的处理，真实系统中可能存在n多业务接口）： 图2是对系统中某一个接口（API）的逻辑做了描述，假设处理流程就是请求一次Redis服务，然后做下处理，然后再请求下Memecached服务，在做下业务处理，后续可能还有其他各种业务逻辑，我们统称为逻辑块。 现在假设这个接口存在性能问题，那么找对应开发负责人排查是比较容易的，因为服务器只执行一套逻辑，瓶颈点一定发生在当前接口对应代码里的某个点，那么就找接口对应的负责人去排查优化即可。 但是当业务发展到一定的程度，比如上述单系统逻辑越来越复杂（业务接口越来越多，逻辑越来越复杂），就会造成很多我们不愿意看到的问题发生： 每一次微小的改动都需要整体走一次打包、发版的流程，对测试也是种负担，因为n多个人如果同时开发不同的功能，这时候就会对测试和发布流程造成很大的困扰。 如果因为做某次活动，某一个接口可能引入大量请求，需要紧急扩容，那么只能对整体扩容（因为该接口与其他接口都处于同一个系统中）。 系统各模块高度耦合，不适合多人开发和维护。 简单集群带来的问题会随着系统复杂度的提升，维护成本变得越来越大，基于此，便有了微服务架构（微服务是一种架构思想，简单来说就是将复杂庞大耦合度高的系统按照功能特性拆分成一个个独立的系统，通过网络互相通信，这种架构可以借助RPC框架（比如grpc、dubbo）实现拆分。当然，熟悉的HTTP框架也可以做到（比如okhttp），但是受限于HTTP协议，性能可能并没有普通RPC框架高，比如grpc采用HTTP2应用层协议进行数据通信，这个协议相比HTTP1来说，支持数据流的标记，可以在一个长连接上做N多请求和接收的并发处理，属于全双工网络通信，这点放到HTTP1就很难做到，此外，它还采用了轻量级且跨语言的protobuf来编解码信息，在性能上尽可能做到极致）。 结合图2，我们来简单按照业务划分一下服务，可以将A代码块里的逻辑抽象成A服务，将B代码块里的逻辑抽象成B服务，当然还有可能有其他n多细化的服务，网关层API（负责聚合信息以及业务处理的模块，对应上面简单集群里的具体接口），服务注册与发现、SLB等。 下面再来看一下被拆分后的架构图： 这张图是一个很简单的微服务化的架构图，图中虚线部分都是在各服务启动时或者运行期发生的调用，负责注册与发现（如zookeeper、Eurake等都可以作服务注册与发现，这里不再细说，只关注实线部分即可）。 这种架构很好的解决了普通集群架构带来的问题（参考上述1、2、3），微服务架构的好处： 降低了系统（逻辑块）间的耦合度，可以独立开发、独立部署和测试，系统间的边界明确，可以细分相关负责人，开发效率大大提升。 如果因为做某次活动，某一个接口可能引入大量请求，需要紧急扩容，那么只需要将该接口涉及到的服务进行扩容即可，而不是像之前那样整体扩容，降低了维护成本（某种意义上的降低，维护人员要足够多，每个人去负责自己的小模块，如果一个公司只有一个维护人员，微服务反而是在加重维护人员的工作:）。 提高了系统（逻辑块）的复用性，比如上面的服务A做自己的事情，万一以后有个API仍然需要A逻辑块，那么该API只需要再次调用A服务即可（实际应用当中的例子：用户服务）。 服务化以后，每个服务甚至可以用不同的语言来实现（存在支持跨语言的RPC框架，比如grpc），一个公司大了以后，可能存在语言差异，有的组使用JAVA，有的组用Go，通过服务化的方式，来将两个不同语言的系统互联。 上面简单介绍了普通集群架构和微服务架构，同样的，微服务化也意味着系统调用的复杂化，有可能一次API的调用对应大批量的服务调用，服务方自己又有一堆服务调用，那么针对这种问题，我们来模拟一次复杂的API调用（注册与发现服务已隐藏），如图4所示: 这是模拟了一次微服务架构中比较复杂的系统调用。 ⚠️注意：图画的有点歪，微服务架构的设计目标是要高度解耦，每个独立的服务最好都有一份自己独立的资源访问，比如服务A只访问A业务相关的数据库和缓存等资源，图中针对这些资源划分做的很糙 那么现在如果这个较复杂的链路调用上的其中一环发生了性能瓶颈，拖慢了整个API的调用，比如图中的慢标识，现在我们再来模拟一下这个性能问题的排查过程（过程相当鬼畜）： 负责API编写的同学发现API的响应时间总是达不到预期，自己debug发现导致性能问题的原因是服务C，于是找到了服务C的服务负责人，假设就叫他C服务负责人，C服务负责人紧接着排查，发现原来是服务D的调用过慢，于是又跑去找D服务负责人，D服务负责人收到C服务负责人的反馈，然后去查自己的服务，发现自己调用的服务E响应缓慢，于是D服务负责人又跑去找E服务负责人，E服务负责人紧接着排查，发现原来是自己这里调用的Redis_02服务有问题，然后自己排查，如果不是自己调用方式有问题，接下来还可能去联系对应的Redis_02相关维护人员帮助检查瓶颈点。 对比简单集群方式中的单系统性能问题排查，微服务针对此类问题的排查简直是一场噩梦，这其中涉及到的人跟瓶颈节点的深度成正比，因为任何一个环节都有可能存在性能问题，而拖慢整个进度的根源未知，那么有没有一种工具可以完成跨服务跨系统的去跟踪这次的调用链路呢？ 1.2：分布式链路追踪结合上面的问题，分布式链路追踪系统就诞生了，来看下Google的这篇文章：Dapper，大规模分布式系统的跟踪系统，可以对分布式链路追踪系统有个系统的认识。 单纯的理解链路追踪，就是指一次任务的开始到结束，期间调用的所有系统及耗时（时间跨度）都可以完整记录下来，比如上面图4的例子，假设总耗时100ms，存在瓶颈链路C--&gt;D--&gt;E--&gt;Redis02，如果链路追踪系统做好了，链路数据有了，借助前端解析和渲染工具，可以达到下图中的效果： 可以看到从API的调用开始到每个涉及到的系统调用以及系统内部的调用链路和时间跨度被直观的展示出来了，通过上图，可以看到时间跨度最长的就是Redis_02，该服务的调用间接拖慢了E服务、D服务、C服务的响应，最后由C服务直接导致API整体响应缓慢，通过这个图，就可以直接找到对应的责任人去排查对应的问题，而不是像之前那样找一群人。 二、分布式链路追踪系统的组成类似很多监控系统，该系统也分为基础数据采集+数据存储+前端展示几个部分，来看下一个分布式链路系统的基本结构： 上图比较粗略的展示了一个完整的链路追踪系统的结构，本篇文章不会介绍具体的链路追踪系统的实现，可以先简单将该系统理解为接收+存储链路数据的作用，前端也一样，可以先简单理解为请求链路系统API，API内部负责读取db，并将数据封装成前端需要的格式，前端负责绘制图5中的页面即可（只要数据结构约定好，对于专业的前端工程师做出图5的效果是很容易的，当然网上也有现成的前端工具）。 本篇文章主要介绍链路追踪究竟是什么，可以解决什么问题，下一篇将会详细介绍“链路数据采集SDK”，因为这一部分是跟业务组件开发人员直接挂钩的，下一篇会说明链路追踪的数据结构、如何做到链路数据的采集和上报、如何做到跨服务的链路追踪。 开始前可以先了解一个标准：OpenTracing语义标准 这里面讲了两个很重要的概念：Tracer和Span，一个Tracer认为是一次完整的链路，内部包含n多个Span，Span表示具体的一次调用，图5中就是一次完整的调用链路，里面每个耗时条都是一个Span，Tracer和Span存在一对多的关系（看到这里，图6中的链路追踪API的实现可以认为是根据Tracer的id聚合一批存在父子关系的Span封装成定义好的数据结构传给前端进行渲染的），根据图5，可以知道Span与Span之间又存在父子关系。 具体的实现方案和实现方法，下一篇会通过一个针对简单实现了OpenTracing协议的例子来介绍，下一篇会围绕着图5进行展开。","link":"/2019/04/11/%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA%EF%BC%88%E4%B8%80%EF%BC%89-%E5%88%86%E5%B8%83%E5%BC%8F%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA%E7%B3%BB%E7%BB%9F%E7%9A%84%E4%BB%8B%E7%BB%8D/"},{"title":"链路追踪（二）-分布式链路追踪系统数据采集","text":"本篇文章基于上一篇，只针对数据采集做介绍，会提供一个SDK的实现和使用，会做实现方案的介绍，具体详细介绍下面边框加粗的部分： 一、数据采集接着拿上一篇里的例子来说，把例子里的图贴过来： 简单回顾下上图，一次API调用，完成上面各个业务服务的调用，然后聚合所有服务的信息，然后Redis_02的调用发生瓶颈，继而影响到E、D、C三个服务，现在需要直观的展示这条链路上的瓶颈点，于是需要一个链路系统，展示成如下图的效果： 要想展示成上图中的效果，则必须要进行数据的采集和上报，那么这就牵扯到两个概念，Span和Tracer，抽象成数据库的设计层面，可以理解成Tracer对Span等于一对多的关系，而一个Span可能包含多个子Span，一个Tracer表示一次调用所经过的整个系统链路，里面包含N多Span，每个Span表示一次事件的触发（也就是调用），那么就用图2来解释下这种关系： 所以上报数据最关键的地方就是要做到如下几点： 在调用之处（比如例子中API调用开始的地方），创建Tracer，生成唯一Trace ID； 在需要追踪的地方（比如例子中发生服务调用的地方），创建Span，指定Trace ID，并生成唯一Span ID，然后按需建立父子关系，追踪结束时（比如例子中调用完成时）释放Span（即置为finished，此时计时已完成）； 跨系统追踪时做好协议约定，每次跨系统调用时可以在协议头传输发起调用系统的TraceID，以便链路可以做到跨系统顺利传输。 最终主链路执行完毕（例子中就是指API调用结束）时，推送此链路产生的所有Span到链路系统，链路系统负责落库、数据分析和展示。 以上便是链路追踪业务SDK需要参与做到的事情。 Tracer是个虚拟概念，负责聚合Span使用，实际上报的数据全是Span，下面来看下Span的结构定义（JSON）： 12345678910111213{ \"spanId\": 123456, \"traceId\": 1234, \"parentId\": 123455, \"title\": \"getSomeThing\", \"project\": \"project.tree.group.project_name\", \"startTime\": 1555731560000, \"endTime\": 1555731570000, \"tags\": { \"component\": \"rpc\", \"span.kind\": \"client\" }} 这是一个span的基本结构定义，startTime和endTime可以推算出本次Span耗时（交给链路系统前端时可以用来展示时间轴的长短），title表示的是Span本身的描述，一般是一个method的名字，project是当前所处项目的全称，项目的全称可以交给链路系统前端用来搜索出该项目的所有链路信息。spanId、traceId、parentId结合上面的图理解即可，tags表示的是一些描述信息，这里有一些标准化的东西：标准的Span tag 和 log field 二、数据采集基于Java语言的实现一般基于io.opentracing标准实现上报SDK，下面来逐步实现一个最简单的数据收集器，首先在项目中引入io.opentracing的jar包，然后追加两个基本类SimpleTracer和SimpleSpan，这里只贴出关键代码。 SimpleTracer定义： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475// 追踪器，实现Tracer接口public class SimpleTracer implements Tracer { private final List finishedSpans = new ArrayList&lt;&gt;(); //存放链路中已执行完成的span（finished span） private String project; //项目名称 private Boolean sampled; //是否上报（由采样率算法生成该值） public SimpleTracer(boolean sampled, String project) { this.project = project; this.sampled = sampled; } public SimpleTracer(String uri, String project) { this.project = project; this.sampled = PushUtils.sampled(uri); //本次追踪是否上报 } @Override public SpanBuilder buildSpan(String operationName) { return new SpanBuilder(operationName); //创建span一般交给Tracer去做，这里由其内部类SpanBuilder触发创建 } //上报span，这个方法一般在一次链路完成时调用，负责将finishedSpans里的数据上报给追踪系统 public synchronized void pushSpans() { if (sampled != null &amp;&amp; sampled) { List finished = this.finishedSpans; if (finished.size() &gt; 0) { finished.stream().filter(SimpleSpan::sampled).forEach(span -&gt; PushHandler.getHandler().pushSpan(span)); //实际负责推送的方法 this.reset(); //每发生一次推送，则清理一次已完成span集合 } } } // Tracer对象内部类SpanBuilder，实现了标准里的Tracer.SpanBuilder接口，用来负责创建span public final class SpanBuilder implements Tracer.SpanBuilder { private final String title; //操作名，也就是span的title private long startMicros; //初始化开始时间 private List references = new ArrayList&lt;&gt;(); //父子关系 private Map&lt;String, Object&gt; initialTags = new HashMap&lt;&gt;(); //tag描述信息初始化 //创建span用的title传入 SpanBuilder(String title) { this.title = title; } @Override public SpanBuilder asChildOf(SpanContext parent) { //传入父子关系 return addReference(References.CHILD_OF, parent); } @Override public SpanBuilder addReference(String referenceType, SpanContext referencedContext) { if (referencedContext != null) { //添加父子关系，其实这里就是初始化了Span里的Reference对象，这个对象会在创建Span对象时作为参数传进去，然后具体关系的确立，是在Span对象内（具体Span类的代码段会展示） this.references.add(new SimpleSpan.Reference((SimpleSpan.SimpleSpanContext) referencedContext, referenceType)); } return this; } @Override public SimpleSpan start() { return startManual(); } @Override public SimpleSpan startManual() { //创建并开始一个span if (this.startMicros == 0) { this.startMicros = SimpleSpan.nowMicros(); //就是在这里初始化startTime的 } //这里触发SimpleSpan的构造方法，之前的references会被传入，此外初始化的tag信息、title、开始时间等也会被传入参与初始化 return new SimpleSpan(SimpleTracer.this, title, startMicros, initialTags, references); } }} 代码块1 上面放了SimpleTracer的代码片段，关键信息已标注，这个类的作用就是帮助创建span，上面还有一个比较重要的方法，也就是sampled方法，该方法用来生成这次链路是否上报（也就是采样率，实际的追踪系统不可能每次的请求都上报，对于一些QPS较高的系统，会带来额外大量的存储数据，因此需要一个上报率），下面来简单看下上报率的实现： 12345678910111213141516171819202122232425262728293031public class PushUtils { public static final Random random = new Random(); private static final Map&lt;String, Long&gt; requestMap = Maps.newConcurrentMap(); public static boolean sampled(String uri) { if (Strings.isNullOrEmpty(uri)) { return false; } Long start = requestMap.get(uri); Long end = System.currentTimeMillis(); if (start == null) { requestMap.put(uri, end); return true; } if ((end - start) &gt;= 60000) { //距离上次上报已经超过1min了 requestMap.put(uri, end); return true; } else { // 没超过1min，则按照1/1000的概率上报 if (random.nextInt(999) == 0) { requestMap.put(uri, end); return true; } } return false; }} 代码块2 这种是比较适中的做法，如果1min内没有上报一次，则必定上报，如果1min内连续上报多次，则按照千分之一的概率上报，这样既保证了低QPS的系统可以有相对较多的链路数据，也可以保证高QPS的系统可以有相对较少的链路数据。 下面来看下SimpleSpan的关键代码段： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788// 链路Span，实现标准里的Span接口public class SimpleSpan implements Span { private final SimpleTracer simpleTracer; //链路追踪对象（一次追踪建议生成一个链路对象，尽量不要用单例，会有同步锁影响并发效率） private final long parentId; // 父span该值为0 private final long startTime; // 计时开始开始时间戳 private final Map&lt;String, Object&gt; tags; //一些扩展信息 private final List references; // 关系，外部传入 private final List errors = new ArrayList&lt;&gt;(); private SimpleSpanContext context; // spanContext,内部包含traceId、span自身id private boolean finished; // 当前span是否结束标识 private long endTime; // 计时结束时间戳 private boolean sampled; // 是否为抽样数据，取决于父节点，依次嫡传下来给其子节点 private String project; // 追踪目标的项目名 private String title; //方法名 SimpleSpan(SimpleTracer tracer, String title, long startTime, Map&lt;String, Object&gt; initialTags, List refs) { this.simpleTracer = tracer; // 这里传入的tracer是针对本次跟踪过程唯一对象，负责收集已完成的span this.title = title; this.startTime = startTime; this.project = tracer.getProject(); this.sampled = tracer.isSampled(); //是否上报，该字段根据具体的采样率方法生成 if (initialTags == null) { this.tags = new HashMap&lt;&gt;(); } else { this.tags = new HashMap&lt;&gt;(initialTags); } if (refs == null) { //span对象由tracer对象创建，创建时会把父子关系传入 this.references = Collections.emptyList(); } else { this.references = new ArrayList&lt;&gt;(refs); } SimpleSpanContext parent = findPreferredParentRef(this.references); //查看是否存在父span if (parent == null) { //通常父span为空的情况，都是链路开始的地方，这里会生成traceId // 当前链路还不存在父span，则本次span就置为父span，下面会生成traceId和当前父span的spanId this.context = new SimpleSpanContext(nextId(), nextId(), new HashMap&lt;&gt;()); this.parentId = 0; //父span的parentId是0 } else { // 当前链路已经存在父span了，那么子span的parentId置为当前父span的id，表示当前span是属于这个父span的子span，同时traceId也延用父span的（表示属于同一链路） this.context = new SimpleSpanContext(parent.traceId, nextId(), mergeBaggages(this.references)); this.parentId = parent.spanId; } } @Nullable private static SimpleSpanContext findPreferredParentRef(List references) { if (references.isEmpty()) { return null; } for (Reference reference : references) { if (References.CHILD_OF.equals(reference.getReferenceType())) { //现有的reference中存在父子关系（简单理解，这个关系就是BuildSpan的时候传入的） return reference.getContext(); //返回父span的context信息（包含traceId和它的spanId） } } return references.get(0).getContext(); } @Override public synchronized void finish(long endTime) { finishedCheck(\"当前span处于完成态\"); this.endTime = endTime; this.simpleTracer.appendFinishedSpan(this); //span完成时放进链路对象的finishedSpans集合里 this.finished = true; } // SimpleSpan的内部类SimpleSpanContext，存放当前Span的id、链路id，实现了标准里的SpanContext接口 public static final class SimpleSpanContext implements SpanContext { private final long traceId; //链路id private final Map&lt;String, String&gt; baggage; private final long spanId; //spanId public SimpleSpanContext(long traceId, long spanId, Map&lt;String, String&gt; baggage) { this.baggage = baggage; this.traceId = traceId; this.spanId = spanId; } } public static final class Reference { //用于建立Span间关系的内部类 private final SimpleSpanContext context; //存放了某一个Span的context（用于跟当前span建立关系时使用） private final String referenceType; //关系类型，目前有两种：child_of和follows_from，第一种代表当前span是上面context里span的子span，第二个则表示同级顺序关系 public Reference(SimpleSpanContext context, String referenceType) { this.context = context; this.referenceType = referenceType; } }} 代码块3 上面就是SimpleSpan的关键实现，关键点已标注，下面来看下数据上报这里的实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class PushHandler { private static final PushHandler handler = new PushHandler(); private BlockingQueue queue; private PushHandler() { this.queue = new LinkedBlockingQueue&lt;&gt;(); //数据管道 new Thread(this::pushTask).start(); } public static PushHandler getHandler() { return handler; } public void pushSpan(SimpleSpan span) { queue.offer(span); } private void pushTask() { if (queue != null) { SimpleSpan span; while (true) { try { span = queue.take(); //为了测试，这里只打印了基本信息，实际环境中这里需要做数据推送（kafka、UnixSocket等） StringBuilder sb = new StringBuilder() .append(\"tracerId=\") .append(span.context().traceId()) .append(\", parentId=\") .append(span.parentId()) .append(\", spanId=\") .append(span.context().spanId()) .append(\", title=\") .append(span.title()) .append(\", 耗时=\") .append((span.endTime() / 1000000) - (span.startTime() / 1000000)) .append(\"ms, tags=\") .append(span.tags().toString()); System.out.println(sb.toString()); } catch (InterruptedException e) { e.printStackTrace(); } } } }} 代码块4 只是做了简单的测试，所以处理逻辑只是简单的做了打印，实际当中这里要上报链路数据（spans）。这里使用了一个阻塞队列做数据接收的缓冲区。 这套实现是非常简单的，只进行简单的计时、推送，并没有涉及active方式的用法，一切创建、建立父子关系均交由开发人员自己把控，清晰度也更高些。 代码完整地址：simple-trace 三、simple-trace的使用看了上面的实现，这里利用simple-trace来进行程序追踪，看一个简单的例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384public class SimpleTest { private SimpleTracer tracer = null; private SimpleSpan parent = null; //假设这里是链路开始的地方 @Test public void test1() { //创建链路 tracer = new SimpleTracer(\"test1\", \"projectName\"); parent = tracer.buildSpan(\"test1\") .withTag(SpanTags.COMPONENT, \"http\") .withTag(SpanTags.SPAN_KIND, \"server\") .start(); //span开始 //-------------------------------------------------- String result1 = getResult1(); //假设getResult1需要链路追踪 System.out.println(\"r1 = \" + result1); String result2 = getResult2(); //假设getResult2需要链路追踪 System.out.println(\"r2 = \" + result2); //-------------------------------------------------- //下面标记着一次链路追踪的结束 parent.finish(); //主span结束 tracer.pushSpans(); //触发span数据推送 } public String getResult1() { //前戏，建立getResult1自己的追踪span SimpleSpan currentSpan = null; if (tracer != null &amp;&amp; parent != null) { //当前链路视为test1方法的子链路，建立父子关系 SimpleSpan.SimpleSpanContext context = new SimpleSpan.SimpleSpanContext(parent.context().traceId(), parent.context().spanId(), new HashMap&lt;&gt;()); //建立父子关系，traceId和父spanId被指定 currentSpan = tracer.buildSpan(\"getResult1\") .addReference(References.CHILD_OF, context) .withTag(SpanTags.COMPONENT, \"redis\") .withTag(SpanTags.SPAN_KIND, \"client\").start(); //启动自己的追踪span } try { Thread.sleep(1000L); return \"result1\"; } catch (InterruptedException e) { e.printStackTrace(); return \"\"; } finally { if (currentSpan != null) { currentSpan.finish(); //最后完成本次链路追踪 } } } public String getResult2() { //前戏，建立getResult2自己的追踪span SimpleSpan currentSpan = null; if (tracer != null &amp;&amp; parent != null) { //当前链路视为test2方法的子链路，建立父子关系 SimpleSpan.SimpleSpanContext context = new SimpleSpan.SimpleSpanContext(parent.context().traceId(), parent.context().spanId(), new HashMap&lt;&gt;()); //建立父子关系，traceId和父spanId被指定 currentSpan = tracer.buildSpan(\"getResult2\") .addReference(References.CHILD_OF, context) .withTag(SpanTags.COMPONENT, \"redis\") .withTag(SpanTags.SPAN_KIND, \"client\").start(); //启动自己的追踪span } try { Thread.sleep(2000L); return \"result2\"; } catch (InterruptedException e) { e.printStackTrace(); return \"\"; } finally { if (currentSpan != null) { currentSpan.finish(); //最后完成本次链路追踪 } } }} 代码块5 运行结果： 12345r1 = result1r2 = result2tracerId=1507767477962777317, parentId=2107142446015091038, spanId=5095502823334701185, title=getResult1, 耗时=1555839336570 - 1555839335569 = 1001ms, tags={span.kind=client, component=redis}tracerId=1507767477962777317, parentId=2107142446015091038, spanId=9071431876337611242, title=getResult2, 耗时=1555839338572 - 1555839336571 = 2001ms, tags={span.kind=client, component=redis}tracerId=1507767477962777317, parentId=0, spanId=2107142446015091038, title=test1, 耗时=1555839338572 - 1555839334687 = 3885ms, tags={span.kind=server, component=http} 通过该实例，关于simple-trace的基本用法已经展示出来了（创建tracer、span、建立关系、tags、finish等），看下打印结果（打印结果就是simple-trace推送数据时直接打印的，耗时是根据startTime和endTime推算出来的），父子关系建立完成，假如说这些数据已经落库完成，那么通过链路系统的API解析和前端渲染，会变成下面这样（绘图和上面测试结果不是同一次，所以图里耗时跟上面打印的耗时不一致😭）： 本篇不讨论图如何生成，可以说下后端可以给前端提供的接口结构以及组装方式：首先可以根据traceId查出来所有相关span，然后根据parentId进行封装层级，比如图4的API结构大致上如下： 123456789101112131415161718192021222324252627282930313233343536373839404142{ \"spanId\": 2107142446015091038, \"traceId\": 1507767477962777317, \"parentId\": 0, \"title\": \"test1\", \"project\": \"projectName\", \"startTime\": 1555839334687, \"endTime\": 1555839338572, \"tags\": { \"span.kind\": \"server\", \"component\": \"http\" }, \"children\": [{ \"spanId\": 5095502823334701185, \"traceId\": 1507767477962777317, \"parentId\": 2107142446015091038, \"title\": \"getResult1\", \"project\": \"projectName\", \"startTime\": 1555839335569, \"endTime\": 1555839336570, \"tags\": { \"span.kind\": \"client\", \"component\": \"redis\" }, \"children\": [] }, { \"spanId\": 9071431876337611242, \"traceId\": 1507767477962777317, \"parentId\": 2107142446015091038, \"title\": \"getResult2\", \"project\": \"projectName\", \"startTime\": 1555839336571, \"endTime\": 1555839338572, \"tags\": { \"span.kind\": \"client\", \"component\": \"redis\" }, \"children\": [] } ]} 包装成上面的结构，前端根据层级关系、startTime、endTime进行调用树和时间轴的渲染即可，在实际生产中，这个层级树可能更加庞大，比如图2。 基本使用很简单，那么基于简单的例子再进行一层抽象，如果在生实际项目中，就不能单单像上面那样使用了，需要封装、解耦，那么实际项目中一般会通过怎样的方式来使用呢？跨系统的时候如何建立层级关系呢？下面针对图2中的例子，进行简单的方案设计（图2过于复杂，这里只说服务A的调用链路，其余按照服务A类推即可），下面将会采用伪代码的方式进行说明问题的解决方案，实际当中需要自己按照实现思路自行封装。 现在引入两个概念，拦截器和Context（上下文），它们属于正常业务中常用的概念，Context是指一次调用产生的上下文信息，上下文信息可以在单次程序调用中的任意位置取到，一般上下文都是利用ThreadLocal（简称TL）实现的，线程本地变量，单纯理解就是只要本次调用的信息都处于同一个线程，那么任意地方都可以通过TL对象拿到上下文对象信息，但是由于系统的复杂度越来越高，一些地方会采用线程池来进行优化业务代码，比如一次调用可能会利用CompletableFuture来进行异步任务调度来优化当前代码执行效率，这个时候单纯使用TL就办不成事儿了，而使用InheritableThreadLocal（简称ITL）又解决不了线程池传递问题，于是就有了阿里推出的TransmittableThreadLocal（简称TTL），这个可以完美解决跨线程传递上下文信息（不管是new Thread还是线程池，都可以准确传递），当然，你也可以仿照TTL的实现，简单代理线程池对象，仍然使用TL实现跨线程传递，也是可以的，TL系列文章传送门：ThreadLocal、InheritableThreadLocal、TransmittableThreadLocal 下面是关于系统上下文的简单定义： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849//自定上下文类public class Context { private SimpleTracer simpleTracer; //当前链路对象 private SimpleSpan parent; //当前链路全局父span //也可以放很多别的上下文内容，这里省略... public SimpleTracer getSimpleTracer() { return simpleTracer; } public void setSimpleTracer(SimpleTracer simpleTracer) { this.simpleTracer = simpleTracer; } public SimpleSpan getParent() { return parent; } public void setParent(SimpleSpan parent) { this.parent = parent; }}public class ContextHolder { //这里仅用TL简单实现，如果项目里使用了线程池，那么这里的实现要变成TTL，并让TTL代理全局的线程池对象，也可以不用TTL，自己代理线程池对象，这里不再详述 private static ThreadLocal contextThreadLocal = new ThreadLocal&lt;&gt;(); private ContextHolder() { } public static void removeContext() { contextThreadLocal.remove(); } public static Context getContext() { return contextThreadLocal.get(); } public static void setContext(Context context) { if (context == null) { removeContext(); } contextThreadLocal.set(context); }} 代码块6 我们把链路对象和链路第一次产生的父span放到上下文，意味着我们可以在这次调用的任意位置通过ContextHolder获取到当前链路对象（伪代码会出现该类），下面来结合图2的A服务链路，结合aop思想，写一次从图2API调用开始到Redis01调用结束的代码。 按照流程，API属于一次Http调用，也是链路入口，那么利用这一点，和Http服务的拦截器功能（大部分系统都会用到一个http调用的拦截器，一般上下文也是这里产生的），伪代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class ApiInterceptor { //开始Http处理请求之前要做的，一般这里产生上下文，并交给TL传递上下文对象，这里也是链路初始化的地方 public void beforeHandle(Request request) { Context context = new Context(); //上下文对象 SimpleTracer tracer = null; SimpleSpan parent = null; //这里是为跨系统调用做的协议头传递，因为我们这个API也可能是公司内别的业务方内部调用，那么这个时候就需要约定协议头，一旦协议头中带有约定好的链路字段，那么就认为我们这个API本次调用相对于别的系统是个子链路 String traceId = request.headers.get(\"x1-trace-id\"); //拿到协议头的父链路id，子链路继承之 String parentId = request.headers.get(\"x1-span-id\"); //拿到协议头的父span信息 String sampled = request.headers.get.get(\"x1-sampled\"); //是否上报 if (traceId != null &amp;&amp; parentId != null &amp;&amp; sampled == true) { tracer = new SimpleTracer(request.getUri, \"所属项目名\"); //这里用url当成是初始化span的title // 符合这种情况的，我们这里的parent其实只是一个相对于别的系统的child SimpleSpan.SimpleSpanContext simpleSpanContext = new SimpleSpan.SimpleSpanContext(traceId, parentId, new HashMap&lt;&gt;()); parent = tracer.buildSpan(request.getUri) .addReference(References.CHILD_OF, simpleSpanContext) //建立父子关系，如果是别的业务方调用我们这个http服务，那么这里这一步，也就建立了跟调用方的父子关系，traceId等是继承的调用方的，意味着本次调用也属于调用方的一环，这也就实现了跨系统的链路追踪 .withTag(SpanTags.COMPONENT, \"http\") .withTag(SpanTags.SPAN_KIND, \"server\").start(); //启动span } else { //执行else，说明该http调用是一次自己完整的调用，不属于任何父链路，那么就无需建立关系，直接初始化tracer即可 tracer = new SimpleTracer(request.getUri, \"所属项目名\"); parent = tracer.buildSpan(request.getUri) .withTag(SpanTags.COMPONENT, \"http\") .withTag(SpanTags.SPAN_KIND, \"server\") .start(); //启动span } //将封装好的tracer和parentSpan设置到上下文对象里去 context.setSimpleTracer(tracer); context.setParent(parent); ContextHolder.setContext(context); //将本次请求生成的上下文对象放进ContextHolder（也就是TL里），方便在任意位置取出使用 } //业务逻辑处理中 public void hadle() { //本次API请求实际走的业务逻辑，也就是A服务调用、B服务调用等这些实际的业务逻辑处理 doing(); } //Http业务处理完成后的触发 public void afterHandler() { //Http调用结束的时候，取出当前链路信息，完成数据的上报 SimpleTracer tracer = ContextHolder.getContext().getTracer(); SimpleSpan parent = ContextHolder.getContext().getParent(); if (tracer != null &amp;&amp; parent != null) { parent.finish(); //结束掉parent Span tracer.pushSpans(); //上报这次产生的链路数据（spans） } }} 代码块7 通过这个外部的API链路包装，可以知道的事情是上下文在这里面充当的角色，API调用是一个系统的入口，这种入口有很多，一次系统调用都会有一个类似的入口，比如RPC调用，跨系统后的rpcServer端也是一个入口，这种入口级的拦截器，before里面做的通常都是建立Tracer，但是代码里不是简单的创建一个Tracer对象就完事儿了，还有协议头的分析，链路系统如何实现跨系统的传输呢？这就牵扯到协议约定，比如Http请求，可以在协议头里约定几个特殊字符串来存放来源系统的tracerId等，结合上面的例子，假如我们这个API是公司内别的系统API01发起的http调用，API01本身也会有链路追踪，API01系统内发起对我们API的http请求，这就属于跨系统调用，我们这次API调用相对于API01是一个子链路，需要建立父子关系，结合上面的例子简单画下这次调用图： 包括API的其他跨系统的调用，比如A服务的调用，也是使用同样的原理进行链路跨系统传输的（很多RPC框架上层协议也是支持扩展协议头（即协议的元数据信息）的，比如grpc的上层协议就是http2，同样有header），那么接下来看下图中（截自图2）标红模块对应的伪代码吧： 这块是指当前系统通过rpc client发起对A服务的调用，从发起调用到A服务响应，这个过程仍然属于API这次调用的子span（没有出系统），但是到了A服务的触发，就牵扯到跨系统，A服务的链路相对于rpc client（图6标红的操作）的span，是一个子span，通过上面对跨系统的处理，这里rpc client里一定会把自身的spanId作为A服务的parentId传过去，包括traceId等，来看下伪代码： 1234567891011121314151617181920212223242526272829public class RpcClient { //等待服务端响应方法 public void requestRpc(RpcRequest request) { //调用前执行 SimpleSpan span = null; SimpleSpan parent = ContextHolder.getContext().getParent(); SimpleTracer tracer = ContextHolder.getContext().getTracer(); if (tracer != null &amp;&amp; parent != null) {//↓这个title就设置成rpc调用的那个方法名即可 span = tracer.buildSpan(request.getRpcMethod).asChildOf(parent) //建立父子关系，因为rpc client调用属于API调用的子链路 .withTag(SpanTags.COMPONENT, \"grpc\") .withTag(SpanTags.PEER_SERVICE, request.getRpcMethod) .withTag(SpanTags.SPAN_KIND, \"client\") .start(); //启动这个span //设置协议头，因为被调用的RPC服务相对于我们来说是个子链路 request.setHeader(\"x1-rpc-span-id\", span.context().spanId()); request.setHeader(\"x1-rpc-trace-id\", span.context().traceId()); request.setHeader(\"x1-rpc-sampled\", span.sampled()); } rpcServerRequest(request); //实际调用rpc服务 //调用后执行 if(span != null){ span.finish(); //完成本次追踪 } }} 代码块8 这样就完成了图6中红线部分的span，然后来看下被调用的服务A内部是怎么处理的（其实很像上面http入口的处理方式）： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class RpcServerInterceptor { //服务的入口，Rpc服务处理请求之前要做的，一般这里产生上下文，并交给TL传递上下文对象，这里也是链路初始化的地方 public void beforeHandle(RpcRequest request) { Context context = new Context(); //上下文对象 SimpleTracer tracer = null; SimpleSpan parent = null; //解析协议头 String traceId = request.headers.get(\"x1-rpc-trace-id\"); //拿到协议头的父链路id，子链路继承之 String parentId = request.headers.get(\"x1-rpc-span-id\"); //拿到协议头的父span信息 String sampled = request.headers.get.get(\"x1-rpc-sampled\"); //是否上报 if (traceId != null &amp;&amp; parentId != null &amp;&amp; sampled == true) { tracer = new SimpleTracer(request.getMethod, \"所属项目名\"); // 符合这种情况的，我们这里的parent其实只是一个相对于别的系统的child SimpleSpan.SimpleSpanContext simpleSpanContext = new SimpleSpan.SimpleSpanContext(traceId, parentId, new HashMap&lt;&gt;()); parent = tracer.buildSpan(request.getMethod) .addReference(References.CHILD_OF, simpleSpanContext) //建立父子关系，如果是别的业务方调用我们这个服务，那么这里这一步，也就建立了跟调用方的父子关系，traceId等是继承的调用方的，意味着本次调用也属于调用方的一环，这也就实现了跨系统的链路追踪 .withTag(SpanTags.COMPONENT, \"rpc\") .withTag(SpanTags.SPAN_KIND, \"server\").start(); //启动span } else { //执行else，说明该rpc调用是一次自己完整的调用，不属于任何父链路，那么就无需建立关系，直接初始化tracer即可 tracer = new SimpleTracer(request.getMethod, \"所属项目名\"); parent = tracer.buildSpan(request.getMethod) .withTag(SpanTags.COMPONENT, \"rpc\") .withTag(SpanTags.SPAN_KIND, \"server\") .start(); //启动span } //将封装好的tracer和parentSpan设置到上下文对象里去 context.setSimpleTracer(tracer); context.setParent(parent); ContextHolder.setContext(context); //将本次请求生成的上下文对象放进ContextHolder（也就是TL里），方便在任意位置取出使用 } //业务逻辑处理中 public void rpcServerHadle() { doing(); } //Rpc业务处理完成后的触发 public void afterHandler() { //Rpc Server调用结束的时候，取出当前链路信息，完成数据的上报 SimpleTracer tracer = ContextHolder.getContext().getTracer(); SimpleSpan parent = ContextHolder.getContext().getParent(); if (tracer != null &amp;&amp; parent != null) { parent.finish(); //结束掉parent Span tracer.pushSpans(); //上报这次产生的链路数据（spans） } }} 代码块9 可以看到，client发起调用时传递的协议字段，在服务端这里被解析了，建立好父子关系后，A服务再去处理自己的逻辑和链路。 没有牵扯到跨系统的链路追踪，如对redis、memcached、mysql等DB的调用，可以简单在调用元方法上搞个aop代理，然后通过通过上下文对象里的Tracer和parent建立父子关系，结束时finish即可，而pushSpans这个动作通常发生在一次系统调用执行完毕的时候发生，比如API的调用结束时、A服务调用结束时，都是pushSpans的触发点。 到这里基本上关于链路追踪的介绍算结束了，因为系统级的实现方式想要完整的展现在一篇文章里不太现实，所以在使用simple-trace sdk的时候使用了伪代码，便于说明问题，文章没有针对整个链路系统作说明，主要是针对数据采集、数据跨系统追踪做了描述，因为数据采集这一环算是比较重要的一环，也是跟业务开发人员息息相关的一环，如果想要完整搞一个链路追踪系统，可以参考之前的架构搭建一套，以完成采集、上报、落库、解析、展示整个流程。","link":"/2019/04/15/%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA%EF%BC%88%E4%BA%8C%EF%BC%89-%E5%88%86%E5%B8%83%E5%BC%8F%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA%E7%B3%BB%E7%BB%9F%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/"},{"title":"顾村的樱花-20190323","text":"记录于2019年3月23日，上海，多云，7~16℃ 下午从杨浦出发去顾村公园，据说撒苦辣开了，兴奋的骑车过去，骑行1.5小时，逛了1.5小时，回来时找不到共享单车，坐了528路公交，因为顾村连个地铁站都没有==，公交到站，又骑了一小时的车回家。 BGM：夜の向日葵","link":"/2019/03/23/%E9%A1%BE%E6%9D%91%E7%9A%84%E6%A8%B1%E8%8A%B1-20190323/"},{"title":"池化技术（一）Druid是如何管理数据库连接的？","text":"基于依赖程序的版本信息：&nbsp;&nbsp; 下一篇：HikariCP是如何管理数据库连接的 零、类图&amp;流程预览下方流程中涉及到的类、属性、方法名均列在这里：Druid-类图-属性表 ←该表格用来辅助理解下面的流程图和代码，不用细看，混乱时可用来理清关系。 本文会通过getConnection作为入口，探索在druid里，一个连接的生命周期。大体流程被划分成了以下几个主流程： 一、主流程1：获取连接流程首先从入口来看看它在获取连接时做了哪些操作： 上述流程对应源代码如下（请展开）： 代码段1-1 &gt;folded123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104public DruidPooledConnection getConnection(long maxWaitMillis) throws SQLException { init(); //初始化，即主流程2 if (filters.size() &gt; 0) { FilterChainImpl filterChain = new FilterChainImpl(this); //责任链，内部也是触发下面的getConnectionDirect方法，只是要走一遍责任链上每个filter的逻辑，这里不做描述，后续放到流程1.1里体现 return filterChain.dataSource_connect(this, maxWaitMillis); } else { return getConnectionDirect(maxWaitMillis); //触发getConnectionDirect } } public DruidPooledConnection getConnectionDirect(long maxWaitMillis) throws SQLException { int notFullTimeoutRetryCnt = 0; for (;;) { //死循环 /** * 真正返回出去的连接对象，注意这里是被druid包装成了DruidPooledConnection类型， * 实际上池子里存放的连接类型是DruidConnectionHolder，DruidPooledConnection类本身持有一个holder属性， * 用于保存真正的连接对象，而DruidConnectionHolder才是真正保存驱动连接对象的类。 */ DruidPooledConnection poolableConnection; try { poolableConnection = getConnectionInternal(maxWaitMillis); //从池子里获取连接，这一个后续放到流程1.2体现 } catch (GetConnectionTimeoutException ex) { if (notFullTimeoutRetryCnt &lt;= this.notFullTimeoutRetryCount &amp;&amp; !isFull()) { //出现了超时异常，在连接池没满且重试次数未超过上限的情况下，重试一次（notFullTimeoutRetryCount默认是0，所以至少可以重试一次）。 notFullTimeoutRetryCnt++; //重试次数+1 if (LOG.isWarnEnabled()) { LOG.warn(\"get connection timeout retry : \" + notFullTimeoutRetryCnt); } continue; } throw ex; //超过重试次数或者池子已满仍然获取失败，则直接抛出异常 } if (testOnBorrow) { //testOnBorrow开启时，每次都进行检测连接可用性 boolean validate = testConnectionInternal(poolableConnection.holder, poolableConnection.conn); if (!validate) { if (LOG.isDebugEnabled()) { LOG.debug(\"skip not validate connection.\"); } Connection realConnection = poolableConnection.conn; //获取真正驱动的连接对象 discardConnection(realConnection); //若连接不可用，则触发discard，这个方法具体放到流程1.4体现 continue; } } else { Connection realConnection = poolableConnection.conn; if (poolableConnection.conn.isClosed()) { discardConnection(null); // 传入null，避免重复关闭 continue; } if (testWhileIdle) { //不启用testOnBorrow的情况下，才会判断是否启用testWhileIdle final DruidConnectionHolder holder = poolableConnection.holder; long currentTimeMillis = System.currentTimeMillis(); long lastActiveTimeMillis = holder.lastActiveTimeMillis; //上次被使用的时间 long lastKeepTimeMillis = holder.lastKeepTimeMillis; if (lastKeepTimeMillis &gt; lastActiveTimeMillis) { lastActiveTimeMillis = lastKeepTimeMillis; } long idleMillis = currentTimeMillis - lastActiveTimeMillis; //计算出闲置时间 long timeBetweenEvictionRunsMillis = this.timeBetweenEvictionRunsMillis; if (timeBetweenEvictionRunsMillis &lt;= 0) { timeBetweenEvictionRunsMillis = DEFAULT_TIME_BETWEEN_EVICTION_RUNS_MILLIS; } if (idleMillis &gt;= timeBetweenEvictionRunsMillis || idleMillis &lt; 0) { //当闲置时间超出timeBetweenEvictionRunsMillis（默认60s）时，则触发检查逻辑 boolean validate = testConnectionInternal(poolableConnection.holder, poolableConnection.conn); if (!validate) { if (LOG.isDebugEnabled()) { LOG.debug(\"skip not validate connection.\"); } discardConnection(realConnection); //连接不可用，同样触发discard continue; } } } } if (removeAbandoned) { //若开启removeAbandoned，则把当前拿到的连接放到activeConnections里，方便后续检查（后面流程4.2体现） StackTraceElement[] stackTrace = Thread.currentThread().getStackTrace(); poolableConnection.connectStackTrace = stackTrace; poolableConnection.setConnectedTimeNano(); //设置连接获取时间为当前时间 poolableConnection.traceEnable = true; //这个设置为true，则在归还该连接时会在activeConnections里清除掉该连接对象 activeConnectionLock.lock(); try { activeConnections.put(poolableConnection, PRESENT); } finally { activeConnectionLock.unlock(); } } if (!this.defaultAutoCommit) { //默认是不开事务的，所以这里是true，不会触发下面的逻辑；这个不建议手动设置默认值，一般开启事务的工作自己做或者交给第三方框架（如spring）做比较好 poolableConnection.setAutoCommit(false); } return poolableConnection; //最终返回可用连接 } } 上述为获取连接时的流程图，首先会调用init进行连接池的初始化，然后运行责任链上的每一个filter，最终执行getConnectionDirect获取真正的连接对象，如果开启了testOnBorrow，则每次都会去测试连接是否可用 这也是官方不建议设置testOnBorrow为true的原因，影响性能，这里的测试是指测试mysql服务端的长连接是否断开，一般mysql服务端长连保活时间是8h，被使用一次则刷新一次使用时间，若一个连接距离上次被使用超过了保活时间，那么再次使用时将无法与mysql服务端通信 如果testOnBorrow没有被置为true，则会进行testWhileIdle的检查（这一项官方建议设置为true，缺省值也是true），检查时会判断当前连接对象距离上次被使用的时间是否超过规定检查的时间，若超过，则进行检查一次，这个检查时间通过timeBetweenEvictionRunsMillis来控制，默认60s，每个连接对象会记录下上次被使用的时间，用当前时间减去上一次的使用时间得出闲置时间，闲置时间再跟timeBetweenEvictionRunsMillis比较，超过这个时间就做一次连接可用性检查，这个相比testOnBorrow每次都检查来说，性能会提升很多，用的时候无需关注该值，因为缺省值是true，经测试如果将该值设置为false，testOnBorrow也设置为false，数据库服务端长连保活时间改为60s，60s内不使用连接，超过60s后使用将会报连接错误。若使用testConnectionInternal方法测试长连接结果为false，则证明该连接已被服务端断开或者有其他的网络原因导致该连接不可用，则会触发discardConnection进行连接回收（对应流程1.4，因为丢弃了一个连接，因此该方法会唤醒主流程3进行检查是否需要新建连接）。整个流程运行在一个死循环内，直到取到可用连接或者超过重试上限报错退出（在连接没有超过连接池上限的话，最多重试一次（重试次数默认重试1次，可以通过notFullTimeoutRetryCount属性来控制），所以取连接这里一旦发生等待，在连接池没有满的情况下，最大等待2 × maxWait的时间 ←这个有待验证）。 特别说明项 为了保证性能，不建议将testOnBorrow设置为true，或者说牵扯到长连接可用检测的那几项配置使用druid默认的配置就可以保证性能是最好的，如上所说，默认长连接检查是60s一次，所以不启用testOnBorrow的情况下要想保证万无一失，自己要确认下所连的那个mysql服务端的长连接保活时间（虽然默认是8h，但是dba可能给测试环境设置的时间远小于这个时间，所以如果这个时间小于60s，就需要手动设置timeBetweenEvictionRunsMillis了，如果mysql服务端长连接时间是8h或者更长，则用默认值即可。 为了防止不必要的扩容，在mysql服务端长连接够用的情况下，对于一些qps较高的服务、网关业务，建议把池子的最小闲置连接数minIdle和最大连接数maxActive设置成一样的，且按照需要调大，且开启keepAlive进行连接活性检查（参考流程4.1），这样就不会后期发生动态新建连接的情况（建连还是个比较重的操作，所以不如一开始就申请好所有需要的连接，个人意见，仅供参考），但是像管理后台这种，长期qps非常低，但是有的时候需要用管理后台做一些巨大的操作（比如导数据什么的）导致需要的连接暴增，且管理后台不会特别要求性能，就适合将minIdle的值设置的比maxActive小，这样不会造成不必要的连接浪费，也不会在需要暴增连接的时候无法动态扩增连接。 二、主流程2：初始化连接池通过上面的流程图可以看到，在获取一个连接的时候首先会检查连接池是否已经初始化完毕（通过inited来控制，bool类型，未初始化为flase，初始化完毕为true，这个判断过程在init方法内完成），若没有初始化，则调用init进行初始化（图主流程1中的紫色部分），下面来看看init方法里又做了哪些操作： 上述流程对应源代码如下（请展开）： 代码段2-1 >folded123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295public void init() throws SQLException { if (inited) { return; //如果已经被初始化过，则终止该方法 } // bug fixed for dead lock, for issue #2980 DruidDriver.getInstance(); final ReentrantLock lock = this.lock; //获取重入锁 try { lock.lockInterruptibly(); } catch (InterruptedException e) { throw new SQLException(\"interrupt\", e); } boolean init = false; try { if (inited) { //双重检查 return; } initStackTrace = Utils.toString(Thread.currentThread().getStackTrace()); this.id = DruidDriver.createDataSourceId(); //生成连接池id if (this.id &gt; 1) { //生成其他对象的id，比如连接对象的id、statement对象的id long delta = (this.id - 1) * 100000; this.connectionIdSeedUpdater.addAndGet(this, delta); this.statementIdSeedUpdater.addAndGet(this, delta); this.resultSetIdSeedUpdater.addAndGet(this, delta); this.transactionIdSeedUpdater.addAndGet(this, delta); } if (this.jdbcUrl != null) { this.jdbcUrl = this.jdbcUrl.trim(); initFromWrapDriverUrl(); //jdbc url的头必须是jdbc:wrap-jdbc才会触发该方法里的逻辑（这个头貌似是oracle的？本篇文章仅针对mysql） } for (Filter filter : filters) { filter.init(this); //通过池对象初始化filters（因为filter里面可能会用到一些池属性） } if (this.dbType == null || this.dbType.length() == 0) { this.dbType = JdbcUtils.getDbType(jdbcUrl, null); //根据jdbc协议头分析出当前数据库的类型（本文默认mysql） } if (JdbcConstants.MYSQL.equals(this.dbType) || JdbcConstants.MARIADB.equals(this.dbType) || JdbcConstants.ALIYUN_ADS.equals(this.dbType)) { boolean cacheServerConfigurationSet = false; if (this.connectProperties.containsKey(\"cacheServerConfiguration\")) { cacheServerConfigurationSet = true; } else if (this.jdbcUrl.indexOf(\"cacheServerConfiguration\") != -1) { cacheServerConfigurationSet = true; } if (cacheServerConfigurationSet) { this.connectProperties.put(\"cacheServerConfiguration\", \"true\"); } } //下面就是对设置的这些属性合理性的判断，不符合要求的将直接抛异常 if (maxActive &lt;= 0) { throw new IllegalArgumentException(\"illegal maxActive \" + maxActive); } if (maxActive &lt; minIdle) { throw new IllegalArgumentException(\"illegal maxActive \" + maxActive); } if (getInitialSize() &gt; maxActive) { throw new IllegalArgumentException(\"illegal initialSize \" + this.initialSize + \", maxActive \" + maxActive); } if (timeBetweenLogStatsMillis &gt; 0 &amp;&amp; useGlobalDataSourceStat) { throw new IllegalArgumentException(\"timeBetweenLogStatsMillis not support useGlobalDataSourceStat=true\"); } if (maxEvictableIdleTimeMillis &lt; minEvictableIdleTimeMillis) { throw new SQLException(\"maxEvictableIdleTimeMillis must be grater than minEvictableIdleTimeMillis\"); } if (this.driverClass != null) { this.driverClass = driverClass.trim(); } //通过SPI机制加载责任链上需要执行的filter，方法详情在下面 initFromSPIServiceLoader(); //如果driver为空，加载驱动，最终将加载到的驱动注册到DriverManager上去 if (this.driver == null) { if (this.driverClass == null || this.driverClass.isEmpty()) { this.driverClass = JdbcUtils.getDriverClassName(this.jdbcUrl); //在driverClass不配置的情况下，druid会通过url来判定属于哪个driverClass } if (MockDriver.class.getName().equals(driverClass)) { //忽略 driver = MockDriver.instance; } else { if (jdbcUrl == null &amp;&amp; (driverClass == null || driverClass.length() == 0)) { throw new SQLException(\"url not set\"); } driver = JdbcUtils.createDriver(driverClassLoader, driverClass); //driverClass不为空的情况下直接触发驱动加载 } } else { //除非手动设置驱动，否则不会走这里的逻辑 if (this.driverClass == null) { this.driverClass = driver.getClass().getName(); } } initCheck(); //根据dbType的不同，来初始化一些标记字段（比如isMySql） initExceptionSorter(); //异常处理器初始化 initValidConnectionChecker(); //初始化长连接检测时所需要用到的checker的适配类型，具体实现在下面 validationQueryCheck(); //简单的检测validationQuery参数是否填写了，若没填写会打印一个错误日志，不影响主流程 if (isUseGlobalDataSourceStat()) { //默认不开启，忽略 dataSourceStat = JdbcDataSourceStat.getGlobal(); if (dataSourceStat == null) { dataSourceStat = new JdbcDataSourceStat(\"Global\", \"Global\", this.dbType); JdbcDataSourceStat.setGlobal(dataSourceStat); } if (dataSourceStat.getDbType() == null) { dataSourceStat.setDbType(this.dbType); } } else { dataSourceStat = new JdbcDataSourceStat(this.name, this.jdbcUrl, this.dbType, this.connectProperties); } dataSourceStat.setResetStatEnable(this.resetStatEnable); //下面三个数组都跟池子本身有关系，所以容量为maxActive connections = new DruidConnectionHolder[maxActive]; //初始化连接池本体 evictConnections = new DruidConnectionHolder[maxActive]; //初始化丢弃连接数组（流程4.1需要用到） keepAliveConnections = new DruidConnectionHolder[maxActive]; //初始化需要检测可用性连接数组（流程4.1要用） SQLException connectError = null; if (createScheduler != null &amp;&amp; asyncInit) { //另外一种通过线程池管理连接池的方式，默认不启用，忽略 for (int i = 0; i &lt; initialSize; ++i) { createTaskCount++; CreateConnectionTask task = new CreateConnectionTask(true); this.createSchedulerFuture = createScheduler.submit(task); } } else if (!asyncInit) { // init connections while (poolingCount &lt; initialSize) { //当池子里的连接数少于需要初始化的个数时，则需要不断新增连接填充连接池，直到等于初始化连接数 try { PhysicalConnectionInfo pyConnectInfo = createPhysicalConnection(); //直接通过驱动程序创建连接对象，参考流程2.1 DruidConnectionHolder holder = new DruidConnectionHolder(this, pyConnectInfo); //拿着驱动连接包装成holder对象 connections[poolingCount++] = holder; //生成好的连接直接往后排 } catch (SQLException ex) { LOG.error(\"init datasource error, url: \" + this.getUrl(), ex); if (initExceptionThrow) { connectError = ex; break; } else { Thread.sleep(3000); //异常报错后会休眠3s来进行下次的添加 } } } if (poolingCount &gt; 0) { poolingPeak = poolingCount; poolingPeakTime = System.currentTimeMillis(); } } createAndLogThread(); //开启打印log日志的守护线程 createAndStartCreatorThread(); //开启负责新增连接的守护线程（主流程3） createAndStartDestroyThread(); //开启负责丢弃连接的守护线程（主流程4） initedLatch.await(); //倒计数器，用来保证上面的主流程3和4两个守护线程全部开启完毕后才进行接下来的操作 init = true; initedTime = new Date(); registerMbean(); if (connectError != null &amp;&amp; poolingCount == 0) { throw connectError; } if (keepAlive) { // async fill to minIdle if (createScheduler != null) { //默认不启用该模式，忽略 for (int i = 0; i &lt; minIdle; ++i) { createTaskCount++; CreateConnectionTask task = new CreateConnectionTask(true); this.createSchedulerFuture = createScheduler.submit(task); } } else { this.emptySignal(); //keepAlive=true，主动唤起主流程3一次 } } } catch (SQLException e) { LOG.error(\"{dataSource-\" + this.getID() + \"} init error\", e); throw e; } catch (InterruptedException e) { throw new SQLException(e.getMessage(), e); } catch (RuntimeException e){ LOG.error(\"{dataSource-\" + this.getID() + \"} init error\", e); throw e; } catch (Error e){ LOG.error(\"{dataSource-\" + this.getID() + \"} init error\", e); throw e; } finally { inited = true; //初始化完成后置为true lock.unlock(); //释放锁 if (init &amp;&amp; LOG.isInfoEnabled()) { String msg = \"{dataSource-\" + this.getID(); if (this.name != null &amp;&amp; !this.name.isEmpty()) { msg += \",\"; msg += this.name; } msg += \"} inited\"; LOG.info(msg); } } } private void initFromSPIServiceLoader() { if (loadSpifilterSkip) { //默认不跳过SPI加载 return; } if (autoFilters == null) { List filters = new ArrayList(); ServiceLoader autoFilterLoader = ServiceLoader.load(Filter.class); //加载Filter的实现 for (Filter filter : autoFilterLoader) { AutoLoad autoLoad = filter.getClass().getAnnotation(AutoLoad.class); if (autoLoad != null &amp;&amp; autoLoad.value()) { filters.add(filter); } } autoFilters = filters; } for (Filter filter : autoFilters) { if (LOG.isInfoEnabled()) { LOG.info(\"load filter from spi :\" + filter.getClass().getName()); } addFilter(filter); //把通过SPI机制加载到的filter放到池子的filters里，用于后续责任链触发 } } private void initValidConnectionChecker() { //初始化checker if (this.validConnectionChecker != null) { return; } String realDriverClassName = driver.getClass().getName(); //根据驱动的class名称，来适配具体的checker实现 if (JdbcUtils.isMySqlDriver(realDriverClassName)) { this.validConnectionChecker = new MySqlValidConnectionChecker(); //假设是mysql类型的驱动，那么适配到mysql的checker，MySqlValidConnectionChecker的构造器参考下面的方法 } else if (realDriverClassName.equals(JdbcConstants.ORACLE_DRIVER) || realDriverClassName.equals(JdbcConstants.ORACLE_DRIVER2)) { this.validConnectionChecker = new OracleValidConnectionChecker(); } else if (realDriverClassName.equals(JdbcConstants.SQL_SERVER_DRIVER) || realDriverClassName.equals(JdbcConstants.SQL_SERVER_DRIVER_SQLJDBC4) || realDriverClassName.equals(JdbcConstants.SQL_SERVER_DRIVER_JTDS)) { this.validConnectionChecker = new MSSQLValidConnectionChecker(); } else if (realDriverClassName.equals(JdbcConstants.POSTGRESQL_DRIVER) || realDriverClassName.equals(JdbcConstants.ENTERPRISEDB_DRIVER)) { this.validConnectionChecker = new PGValidConnectionChecker(); } } //Mysql对应的checker构造器 public MySqlValidConnectionChecker(){ try { clazz = Utils.loadClass(\"com.mysql.jdbc.MySQLConnection\"); if (clazz == null) { clazz = Utils.loadClass(\"com.mysql.cj.jdbc.ConnectionImpl\"); } if (clazz != null) { //如果驱动程序本身有ping方法，则下面的usePingMethod设置为true，后续连接保活测试就会采用ping.invoke的方式触发。 ping = clazz.getMethod(\"pingInternal\", boolean.class, int.class); } if (ping != null) { usePingMethod = true; } } catch (Exception e) { LOG.warn(\"Cannot resolve com.mysql.jdbc.Connection.ping method. Will use 'SELECT 1' instead.\", e); } configFromProperties(System.getProperties()); } 可以看到，实例化的时候会初始化全局的重入锁lock，在初始化过程中包括后续的连接池操作都会利用该锁保证线程安全，初始化连接池的时候首先会进行双重检查是否已经初始化过，若没有，则进行连接池的初始化，这时候还会通过SPI机制额外加载责任链上的filter，但是这类filter需要在类上加上@AutoLoad注解。然后初始化了三个数组，容积都为maxActive，首先connections就是用来存放池子里连接对象的，evictConnections用来存放每次检查需要抛弃的连接（结合流程4.1理解），keepAliveConnections用于存放需要连接检查的存活连接（同样结合流程4.1理解），然后生成初始化数（initialSize）个连接，放进connections，然后生成两个必须的守护线程，用来添加连接进池以及从池子里摘除不需要的连接，这俩过程较复杂，因此拆出来单说（主流程3和主流程4）。 特别说明项 从流程上看如果一开始实例化的时候不对连接池进行初始化（这个初始化是指对池子本身的初始化，并非单纯的指druid对象属性的初始化），那么在第一次调用getConnection时就会走上图那么多逻辑，尤其是耗时较久的建立连接操作，被重复执行了很多次，导致第一次getConnection时耗时过久，如果你的程序并发量很大，那么第一次获取连接时就会因为初始化流程而发生排队，所以建议在实例化连接池后对其进行预热，通过调用init方法或者getConnection方法都可以。 在构建全局重入锁的时候，利用lock对象生成了俩Condition，对这俩Condition解释如下： 当连接池连接够用时，利用empty阻塞添加连接的守护线程（主流程3），当连接池连接不够用时，获取连接的那个线程（这里记为业务线程A）就会阻塞在notEmpty上，且唤起阻塞在empty上的添加连接的守护线程，走完添加连接的流程，走完后会重新唤起阻塞在notEmpty上的业务线程A，业务线程A就会继续尝试获取连接。 三、流程1.1：责任链 ⚠️ 这块东西结合源码看更容易理解 上述流程对应源代码如下（请展开）： 代码段-1-2 >folded1234567891011121314151617181920212223242526272829303132333435363738394041424344454647//DruidDataSource类里的方法：获取连接 public DruidPooledConnection getConnection(long maxWaitMillis) throws SQLException { init(); if (filters.size() &gt; 0) { //责任链上的filter存在 FilterChainImpl filterChain = new FilterChainImpl(this); //该类是执行整个责任链的执行者 return filterChain.dataSource_connect(this, maxWaitMillis); //每个需要执行责任链的方法，在filterChain里都可以找到映射方法，比如本方法getConnection，就对应filterChain.dataSource_connect（参考流程1.1） } else { return getConnectionDirect(maxWaitMillis); } } //FilterChainImpl类里的方法：获取连接映射方法 @Override public DruidPooledConnection dataSource_connect(DruidDataSource dataSource, long maxWaitMillis) throws SQLException { if (this.pos &lt; filterSize) { //除了FilterChainImpl里面包含一些datasource的映射方法，需要执行的filter里面也包括，比如下面的dataSource_getConnection方法 DruidPooledConnection conn = nextFilter().dataSource_getConnection(this, dataSource, maxWaitMillis); //根据下标，获取下一个filter，触发目标方法 return conn; } return dataSource.getConnectionDirect(maxWaitMillis); //执行到最后一个filter时，触发datasource，返回真正的连接 } //FilterChainImpl类里的方法：获取下一个需要执行的filter private Filter nextFilter() { return getFilters() .get(pos++); //根据游标计算 } //随便找了一个filter里的目标方法 //LogFilter类里的方法：dataSource_getConnection @Override public DruidPooledConnection dataSource_getConnection(FilterChain chain, DruidDataSource dataSource, long maxWaitMillis) throws SQLException { DruidPooledConnection conn = chain.dataSource_connect(dataSource, maxWaitMillis); //这里又会利用FilterChainImpl触发映射方法 //下面就是自己内部的一些特有逻辑，忽略 ConnectionProxy connection = (ConnectionProxy) conn.getConnectionHolder().getConnection(); if (connectionConnectAfterLogEnable &amp;&amp; isConnectionLogEnabled()) { connectionLog(\"{conn-\" + connection.getId() + \"} pool-connect\"); } return conn; //返回 } 这里对应流程1里获取连接时需要执行的责任链，每个DruidAbstractDataSource里都包含filters属性，filters是对Druid里Filters接口的实现，里面有很多对应着连接池里的映射方法，比如例子中dataSource的getConnection方法在触发的时候就会利用FilterChain把每个filter里的dataSource_getConnection给执行一遍，这里也要说明下FilterChain，通过流程1.1可以看出来，datasource是利用FilterChain来触发各个filter的执行的，FilterChain里也有一堆datasource里的映射方法，比如上图里的dataSource_connect，这个方法会把datasource里的filters全部执行一遍直到nextFilter取不到值，才会触发dataSource.getConnectionDirect，这个结合代码会比较容易理解。 四、流程1.2：从池中获取连接的流程 上述流程对应源代码如下（请展开）： 代码段1-3 >folded123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215private DruidPooledConnection getConnectionInternal(long maxWait) throws SQLException { //可用性判断 if (closed) { connectErrorCountUpdater.incrementAndGet(this); throw new DataSourceClosedException(\"dataSource already closed at \" + new Date(closeTimeMillis)); } if (!enable) { connectErrorCountUpdater.incrementAndGet(this); throw new DataSourceDisableException(); } final long nanos = TimeUnit.MILLISECONDS.toNanos(maxWait); //纳秒 final int maxWaitThreadCount = this.maxWaitThreadCount; //目前因为拿不到连接而发生阻塞的业务线程数 DruidConnectionHolder holder; for (boolean createDirect = false;;) { if (createDirect) { //模式未启用，恒等false，下面的逻辑不会触发，所以为了方便阅读，隐藏这部分代码 //代码隐藏 } try { lock.lockInterruptibly(); //锁获取 } catch (InterruptedException e) { connectErrorCountUpdater.incrementAndGet(this); throw new SQLException(\"interrupt\", e); } try { if (maxWaitThreadCount &gt; 0 &amp;&amp; notEmptyWaitThreadCount &gt;= maxWaitThreadCount) { //如果因为拿不到连接而阻塞的业务线程数达到阈值，则直接抛异常 connectErrorCountUpdater.incrementAndGet(this); throw new SQLException(\"maxWaitThreadCount \" + maxWaitThreadCount + \", current wait Thread count \" + lock.getQueueLength()); } if (onFatalError &amp;&amp; onFatalErrorMaxActive &gt; 0 &amp;&amp; activeCount &gt;= onFatalErrorMaxActive) { connectErrorCountUpdater.incrementAndGet(this); StringBuilder errorMsg = new StringBuilder(); errorMsg.append(\"onFatalError, activeCount \") .append(activeCount) .append(\", onFatalErrorMaxActive \") .append(onFatalErrorMaxActive); if (lastFatalErrorTimeMillis &gt; 0) { errorMsg.append(\", time '\") .append(StringUtils.formatDateTime19( lastFatalErrorTimeMillis, TimeZone.getDefault())) .append(\"'\"); } if (lastFatalErrorSql != null) { errorMsg.append(\", sql \\n\") .append(lastFatalErrorSql); } throw new SQLException( errorMsg.toString(), lastFatalError); } connectCount++; //连接数累加 if (createScheduler != null &amp;&amp; poolingCount == 0 &amp;&amp; activeCount &lt; maxActive &amp;&amp; creatingCountUpdater.get(this) == 0 &amp;&amp; createScheduler instanceof ScheduledThreadPoolExecutor) { ScheduledThreadPoolExecutor executor = (ScheduledThreadPoolExecutor) createScheduler; if (executor.getQueue().size() &gt; 0) { createDirect = true; //createScheduler这种异步添加模式不开启（默认不开启，本文也不是基于该模式的），createDirect永远不等于true，所以上面createDirect==true的代码不会被触发 continue; } } if (maxWait &gt; 0) { holder = pollLast(nanos); //尝试从池子里获取连接 } else { holder = takeLast(); } if (holder != null) { activeCount++; //拿到连接，activeCount累加 if (activeCount &gt; activePeak) { activePeak = activeCount; activePeakTime = System.currentTimeMillis(); } } } catch (InterruptedException e) { connectErrorCountUpdater.incrementAndGet(this); throw new SQLException(e.getMessage(), e); } catch (SQLException e) { connectErrorCountUpdater.incrementAndGet(this); throw e; } finally { lock.unlock(); } break; } if (holder == null) { //没有获取到连接，整理错误信息，抛出错误 long waitNanos = waitNanosLocal.get(); StringBuilder buf = new StringBuilder(128); buf.append(\"wait millis \")// .append(waitNanos / (1000 * 1000))// .append(\", active \").append(activeCount)// .append(\", maxActive \").append(maxActive)// .append(\", creating \").append(creatingCount)// ; if (creatingCount &gt; 0 &amp;&amp; createStartNanos &gt; 0) { long createElapseMillis = (System.nanoTime() - createStartNanos) / (1000 * 1000); if (createElapseMillis &gt; 0) { buf.append(\", createElapseMillis \").append(createElapseMillis); } } if (createErrorCount &gt; 0) { buf.append(\", createErrorCount \").append(createErrorCount); } List sqlList = this.getDataSourceStat().getRuningSqlList(); for (int i = 0; i &lt; sqlList.size(); ++i) { if (i != 0) { buf.append('\\n'); } else { buf.append(\", \"); } JdbcSqlStatValue sql = sqlList.get(i); buf.append(\"runningSqlCount \").append(sql.getRunningCount()); buf.append(\" : \"); buf.append(sql.getSql()); } String errorMessage = buf.toString(); if (this.createError != null) { throw new GetConnectionTimeoutException(errorMessage, createError); } else { throw new GetConnectionTimeoutException(errorMessage); } } holder.incrementUseCount(); DruidPooledConnection poolalbeConnection = new DruidPooledConnection(holder); //包装成目标对象 return poolalbeConnection; //返回 } //尝试从池子里获取连接 private DruidConnectionHolder pollLast(long nanos) throws InterruptedException, SQLException { long estimate = nanos; for (;;) { if (poolingCount == 0) { //池子里的空闲连接为0，说明需要通知主流程3新增连接了 emptySignal(); // empty.signal，唤起主流程3新增连接 if (failFast &amp;&amp; isFailContinuous()) { //如果置为快速结束，则不阻塞业务线程，直接抛出异常 throw new DataSourceNotAvailableException(createError); } if (estimate &lt;= 0) { waitNanosLocal.set(nanos - estimate); return null; } notEmptyWaitThreadCount++; //因为获取不到连接而陷入阻塞状态的业务线程数+1 if (notEmptyWaitThreadCount &gt; notEmptyWaitThreadPeak) { notEmptyWaitThreadPeak = notEmptyWaitThreadCount; } try { long startEstimate = estimate; estimate = notEmpty.awaitNanos(estimate); // 阻塞（挂起）estimate这么长的世界，期间如果被唤醒，则estimate就会被刷新成剩余等待时间 // recycle or // creator notEmptyWaitCount++; notEmptyWaitNanos += (startEstimate - estimate); if (!enable) { connectErrorCountUpdater.incrementAndGet(this); throw new DataSourceDisableException(); } } catch (InterruptedException ie) { notEmpty.signal(); // 期间线程被中断，则唤起一次其他处于阻塞状态的业务线程 notEmptySignalCount++; throw ie; } finally { notEmptyWaitThreadCount--; } if (poolingCount == 0) { //依然没有竞争到 if (estimate &gt; 0) { //如果目标阻塞时间（maxWait）还没有用完，则继续尝试获取 continue; } waitNanosLocal.set(nanos - estimate); return null; } } decrementPoolingCount(); //poolingCount-- DruidConnectionHolder last = connections[poolingCount]; //直接获取 connections[poolingCount] = null; //获取后意味着连接已被借出，原有位置置空 long waitNanos = nanos - estimate; //标记这次获取连接花了多长时间，连接够用时便为0 last.setLastNotEmptyWaitNanos(waitNanos); return last; //返回 } } 通过getConnectionInternal方法从池子里获取真正的连接对象，druid支持两种方式新增连接，一种是通过开启不同的守护线程通过await、signal通信实现（本文启用的方式，也是默认的方式），另一种是直接通过线程池异步新增，这个方式通过在初始化druid时传入asyncInit=true，再把一个线程池对象赋值给createScheduler，就成功启用了这种模式，没仔细研究这种方式，所以本文的流程图和代码块都会规避这个模式。 上面的流程很简单，连接足够时就直接poolingCount-1，数组取值，返回，activeCount+1，整体复杂度为O(1)，关键还是看取不到连接时的做法，取不到连接时，druid会先唤起新增连接的守护线程新增连接，然后陷入等待状态，然后唤醒该等待的点有两处，一个是用完了连接recycle（主流程5）进池子后触发，另外一个就是新增连接的守护线程成功新增了一个连接后触发，await被唤起后继续加入锁竞争，然后往下走如果发现池子里的连接数仍然是0（说明在唤醒后参与锁竞争里刚被放进来的连接又被别的线程拿去了），则继续下一次的await，这里采用的是awaitNanos方法，初始值是maxWait，然后下次被刷新后就是maxWait减去上次阻塞花费的实际时间，每次await的时间会逐步减少，直到归零，整体时间是约等于maxWait的，但实际比maxActive要大，因为程序本身存在耗时以及被唤醒后又要参与锁竞争导致也存在一定的耗时。 如果最终都没办法拿到连接则返回null出去，紧接着触发主流程1中的重试逻辑。 druid如何防止在获取不到连接时阻塞过多的业务线程？ 通过上面的流程图和流程描述，如果非常极端的情况，池子里的连接完全不够用时，会阻塞过多的业务线程，甚至会阻塞超过maxWait这么久，有没有一种措施是可以在连接不够用的时候控制阻塞线程的个数，超过这个限制后直接报错，而不是陷入等待呢？ druid其实支持这种策略的，在maxWaitThreadCount属性为默认值（-1）的情况下不启用，如果maxWaitThreadCount配置大于0，表示启用，这是druid做的一种丢弃措施，如果你不希望在池子里的连接完全不够用导阻塞的业务线程过多，就可以考虑配置该项，这个属性的意思是说在连接不够用时最多让多少个业务线程发生阻塞，流程1.2的图里没有体现这个开关的用途，可以在代码里查看，每次在pollLast方法里陷入等待前会把属性notEmptyWaitThreadCount进行累加，阻塞结束后会递减，由此可见notEmptyWaitThreadCount就是表示当前等待可用连接时阻塞的业务线程的总个数，而getConnectionInternal在每次调用pollLast前都会判断这样一段代码： 代码块112345if (maxWaitThreadCount &gt; 0 &amp;&amp; notEmptyWaitThreadCount &gt;= maxWaitThreadCount) { connectErrorCountUpdater.incrementAndGet(this); throw new SQLException(\"maxWaitThreadCount \" + maxWaitThreadCount + \", current wait Thread count \" + lock.getQueueLength()); //直接抛异常，而不是陷入等待状态阻塞业务线程 } 可以看到，如果配置了maxWaitThreadCount所限制的等待线程个数，那么会直接判断当前陷入等待的业务线程是否超过了maxWaitThreadCount，一旦超过甚至不触发pollLast的调用（防止新增等待线程），直接抛错。 一般情况下不需要启用该项，一定要启用建议考虑好maxWaitThreadCount的取值，一般来说发生大量等待说明代码里存在不合理的地方：比如典型的连接池基本配置不合理，高qps的系统里maxActive配置过小；比如借出去的连接没有及时close归还；比如存在慢查询或者慢事务导致连接借出时间过久。这些要比配置maxWaitThreadCount更值得优先考虑，当然配置这个做一个极限保护也是没问题的，只是要结合实际情况考虑好取值。 五、流程1.3：连接可用性测试①init-checker讲这块的东西之前，先来了解下如何初始化检测连接用的checker，整个流程参考下图： ps：上述流程对应源代码位置：代码段2-1中的initValidConnectionChecker方法与MySqlValidConnectionChecker构造器 初始化checker发生在init阶段（限于篇幅，没有在主流程2（init阶段）里体现出来，只需要记住初始化checker也是发生在init阶段就好），druid支持多种数据库的连接源，所以checker针对不同的驱动程序都做了适配，所以才看到图中checker有不同的实现，我们根据加载到的驱动类名匹配不同的数据库checker，上图匹配至mysql的checker，checker的初始化里做了一件事情，就是判断驱动内是否有ping方法（jdbc4开始支持，mysql-connector-java早在3.x的版本就有ping方法的实现了），如果有，则把usePingMethod置为true，用于后续启用checker时做判断用（下面会讲，这里置为true，则通过反射的方式调用驱动程序的ping方法，如果为false，则触发普通的SELECT 1查询检测，SELECT 1就是我们非常熟悉的那个东西啦，新建statement，然后执行SELECT 1，然后再判断连接是否可用）。 ②testConnectionInternal然后回到本节探讨的方法：流程1.3对应的testConnectionInternal 上述流程对应源代码如下（请展开）： 代码段1-4 >folded123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137//数据库连接可用性测试 protected boolean testConnectionInternal(DruidConnectionHolder holder, Connection conn) { String sqlFile = JdbcSqlStat.getContextSqlFile(); String sqlName = JdbcSqlStat.getContextSqlName(); if (sqlFile != null) { JdbcSqlStat.setContextSqlFile(null); } if (sqlName != null) { JdbcSqlStat.setContextSqlName(null); } try { if (validConnectionChecker != null) { //checker不为空 //checker是init（主流程2）里通过驱动进行适配的检测者，因为本篇文章基于mysql，所以假设这里适配到的checker是MySqlValidConnectionChecker类型的 boolean valid = validConnectionChecker.isValidConnection(conn, validationQuery, validationQueryTimeout); long currentTimeMillis = System.currentTimeMillis(); if (holder != null) { holder.lastValidTimeMillis = currentTimeMillis; } if (valid &amp;&amp; isMySql) { //这里在现有驱动版本的情况下拿到的lastPacketReceivedTimeMs始终小于0，因为找不到com.mysql.jdbc.MySQLConnection long lastPacketReceivedTimeMs = MySqlUtils.getLastPacketReceivedTimeMs(conn); if (lastPacketReceivedTimeMs &gt; 0) { long mysqlIdleMillis = currentTimeMillis - lastPacketReceivedTimeMs; if (lastPacketReceivedTimeMs &gt; 0 // &amp;&amp; mysqlIdleMillis &gt;= timeBetweenEvictionRunsMillis) { discardConnection(conn); String errorMsg = \"discard long time none received connection. \" + \", jdbcUrl : \" + jdbcUrl + \", jdbcUrl : \" + jdbcUrl + \", lastPacketReceivedIdleMillis : \" + mysqlIdleMillis; LOG.error(errorMsg); return false; } } } return valid; //返回验证结果 } if (conn.isClosed()) { return false; } //checker为空时，就直接利用validationQuery进行常规测试 if (null == validationQuery) { return true; //validationQuery为空就单纯返回true } Statement stmt = null; ResultSet rset = null; try { stmt = conn.createStatement(); if (getValidationQueryTimeout() &gt; 0) { stmt.setQueryTimeout(validationQueryTimeout); } rset = stmt.executeQuery(validationQuery); if (!rset.next()) { return false; //执行检测语句失败，返回false } } finally { //关闭资源 JdbcUtils.close(rset); JdbcUtils.close(stmt); } return true; //验证通过返回true } catch (Throwable ex) { // skip return false; } finally { if (sqlFile != null) { JdbcSqlStat.setContextSqlFile(sqlFile); } if (sqlName != null) { JdbcSqlStat.setContextSqlName(sqlName); } } } //MySqlValidConnectionChecker类里的验证方法 public boolean isValidConnection(Connection conn, String validateQuery, int validationQueryTimeout) throws Exception { if (conn.isClosed()) { return false; } if (usePingMethod) { //是否启用ping方法（如果驱动程序有该方法，则这里为true，一般情况下都是true） if (conn instanceof DruidPooledConnection) { conn = ((DruidPooledConnection) conn).getConnection(); } if (conn instanceof ConnectionProxy) { conn = ((ConnectionProxy) conn).getRawObject(); } if (clazz.isAssignableFrom(conn.getClass())) { if (validationQueryTimeout &lt; 0) { validationQueryTimeout = DEFAULT_VALIDATION_QUERY_TIMEOUT; } try { //ping对象是初始化时拿到驱动程序的一个Method对象，这里通过invoke触发调用 ping.invoke(conn, true, validationQueryTimeout * 1000); } catch (InvocationTargetException e) { Throwable cause = e.getCause(); if (cause instanceof SQLException) { throw (SQLException) cause; } throw e; //ping出错抛异常 } return true; //通过则返回true } } //如果不支持ping方式检测，则触发SELECT 1的方式进行检测（一般情况下不会触发，都是上面ping方式） String query = validateQuery; if (validateQuery == null || validateQuery.isEmpty()) { query = DEFAULT_VALIDATION_QUERY; } Statement stmt = null; ResultSet rs = null; try { stmt = conn.createStatement(); if (validationQueryTimeout &gt; 0) { stmt.setQueryTimeout(validationQueryTimeout); } rs = stmt.executeQuery(query); return true; } finally { JdbcUtils.close(rs); JdbcUtils.close(stmt); } } 这个方法会利用主流程2（init阶段）里初始化好的checker对象（流程参考init-checker）里的isValidConnection方法，如果启用ping，则该方法会利用invoke触发驱动程序里的ping方法，如果不启用ping，就采用SELECT 1方式（从init-checker里可以看出启不启用取决于加载到的驱动程序里是否存在相应的方法）。 六、流程1.4：抛弃连接 上述流程对应源代码如下（请展开）： 代码段1-5 >folded12345678910111213141516//丢弃连接 public void discardConnection(Connection realConnection) { JdbcUtils.close(realConnection); //close掉真正的连接对象，一般调用该方法传入的connection对象都是最原始的驱动连接对象，所以这里并不会触发recycle lock.lock(); try { activeCount--; //活跃连接数-1 discardCount++; //丢弃连接数+1 if (activeCount &lt;= minIdle) { emptySignal(); //唤起一次主流程3新增连接 } } finally { lock.unlock(); } } 经过流程1.3返回的测试结果，如果发现连接不可用，则直接触发抛弃连接逻辑，这个过程非常简单，如上图所示，由流程1.2获取到该连接时累加上去的activeCount，在本流程里会再次减一，表示被取出来的连接不可用，并不能active状态。其次这里的close是拿着驱动那个连接对象进行close，正常情况下一个连接对象会被druid封装成DruidPooledConnection对象，内部持有的conn就是真正的驱动Connection对象，上图中的关闭连接就是获取的该对象进行close，如果使用包装类DruidPooledConnection进行close，则代表回收连接对象（recycle，参考主流程5）。 七、主流程3：添加连接的守护线程 上述流程对应源代码如下（请展开）： 代码段3-1 >folded123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182//DruidDataSource的内部类，对应主流程3，用来补充连接 public class CreateConnectionThread extends Thread { public CreateConnectionThread(String name){ super(name); //重置线程名称 this.setDaemon(true); //标记为守护线程 } //run方法 public void run() { initedLatch.countDown(); //通知init（主流程2）自己已经启动成功 long lastDiscardCount = 0; int errorCount = 0; for (;;) { //死循环 // addLast try { lock.lockInterruptibly(); //锁获取 } catch (InterruptedException e2) { break; } long discardCount = DruidDataSource.this.discardCount; //当前丢弃连接数与最后一次丢弃连接数的差值大于0，说明又发生了丢弃连接的现象，该条件会促进连接的创建 boolean discardChanged = discardCount - lastDiscardCount &gt; 0; lastDiscardCount = discardCount; try { boolean emptyWait = true; if (createError != null &amp;&amp; poolingCount == 0 &amp;&amp; !discardChanged) { emptyWait = false; } if (emptyWait &amp;&amp; asyncInit &amp;&amp; createCount &lt; initialSize) { emptyWait = false; } if (emptyWait) { // 必须存在线程等待，才创建连接，否则不创建 if (poolingCount &gt;= notEmptyWaitThreadCount &amp;&amp; (!(keepAlive &amp;&amp; activeCount + poolingCount &lt; minIdle)) &amp;&amp; !isFailContinuous() ) { empty.await(); //不需要创建连接时，阻塞（挂起） } // 防止创建超过maxActive数量的连接 if (activeCount + poolingCount &gt;= maxActive) { empty.await(); //超出限制依然挂起，不再新增连接 continue; } } } catch (InterruptedException e) { lastCreateError = e; lastErrorTimeMillis = System.currentTimeMillis(); if (!closing) { LOG.error(\"create connection Thread Interrupted, url: \" + jdbcUrl, e); } break; } finally { lock.unlock(); //锁释放 } //从上面的程序走到这里，说明该线程被成功唤起，则进行新建连接 PhysicalConnectionInfo connection = null; try { connection = createPhysicalConnection(); //利用驱动程序新建物理连接 } catch (SQLException e) { LOG.error(\"create connection SQLException, url: \" + jdbcUrl + \", errorCode \" + e.getErrorCode() + \", state \" + e.getSQLState(), e); errorCount++; if (errorCount &gt; connectionErrorRetryAttempts &amp;&amp; timeBetweenConnectErrorMillis &gt; 0) { // fail over retry attempts setFailContinuous(true); if (failFast) { lock.lock(); try { notEmpty.signalAll(); } finally { lock.unlock(); } } if (breakAfterAcquireFailure) { break; } try { Thread.sleep(timeBetweenConnectErrorMillis); } catch (InterruptedException interruptEx) { break; } } } catch (RuntimeException e) { LOG.error(\"create connection RuntimeException\", e); setFailContinuous(true); continue; } catch (Error e) { LOG.error(\"create connection Error\", e); setFailContinuous(true); break; } if (connection == null) { continue; //新建失败后再次尝试 } boolean result = put(connection); //尝试放入池子 if (!result) { JdbcUtils.close(connection.getPhysicalConnection()); LOG.info(\"put physical connection to pool failed.\"); } errorCount = 0; // reset errorCount } } } //这一个put方法是上面触发接收PhysicalConnectionInfo类型连接用的，之前说过，最终保存在池子里的连接对象都是DruidConnectionHolder类型，所以这里时进行一次包装，然后真正put进去的是更下面的put方法 protected boolean put(PhysicalConnectionInfo physicalConnectionInfo) { DruidConnectionHolder holder = null; try { //包装成holder类型 holder = new DruidConnectionHolder(DruidDataSource.this, physicalConnectionInfo); } catch (SQLException ex) { lock.lock(); try { if (createScheduler != null) { createTaskCount--; } } finally { lock.unlock(); } LOG.error(\"create connection holder error\", ex); return false; } return put(holder); //真正放入池子 } //真正将连接对象放入池子 private boolean put(DruidConnectionHolder holder) { lock.lock(); try { if (poolingCount &gt;= maxActive) { return false; //如果此时发现当前池子里的闲置连接数已经超过了maxActive，那么就不再往里面加了 } connections[poolingCount] = holder; //加在数组尾部 incrementPoolingCount(); //poolingCount++ if (poolingCount &gt; poolingPeak) { poolingPeak = poolingCount; poolingPeakTime = System.currentTimeMillis(); } notEmpty.signal(); //唤起一个因为拿不到连接对象而发生阻塞的业务线程，让其再次进入运行状态，进行获取连接竞争 notEmptySignalCount++; if (createScheduler != null) { //模式未启用 createTaskCount--; if (poolingCount + createTaskCount &lt; notEmptyWaitThreadCount // &amp;&amp; activeCount + poolingCount + createTaskCount &lt; maxActive) { emptySignal(); } } } finally { lock.unlock(); } return true; } 在主流程2（init初始化阶段）时就开启了该流程，该流程独立运行，大部分时间处于等待状态，不会抢占cpu，但是当连接不够用时，就会被唤起追加连接，成功创建连接后将会唤醒其他正在等待获取可用连接的线程，比如： 结合流程1.2来看，当连接不够用时，会通过empty.signal唤醒该线程进行补充连接（阻塞在empty上的线程只有主流程3的单线程），然后通过notEmpty阻塞自己，当该线程补充连接成功后，又会对阻塞在notEmpty上的线程进行唤醒，让其进入锁竞争状态，简单理解就是一个生产-消费模型。这里有一些细节，比如池子里的连接使用中（activeCount）加上池子里剩余连接数（poolingCount）就是指当前一共生成了多少个连接，这个数不能比maxActive还大，如果比maxActive还大，则再次陷入等待。而在往池子里put连接时，则判断poolingCount是否大于maxActive来决定最终是否入池。 八、主流程4：抛弃连接的守护线程 上述流程对应源代码如下（请展开）： 代码段4-1 >folded123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354//连接池瘦身，参考主流程4 public class DestroyConnectionThread extends Thread { public DestroyConnectionThread(String name){ super(name); //给线程重命名 this.setDaemon(true); //标记为守护线程 } //run方法 public void run() { initedLatch.countDown(); //通知init（主流程2）自己已经启动成功 for (;;) { //死循环 // 从前面开始删除 try { if (closed) { break; } if (timeBetweenEvictionRunsMillis &gt; 0) { //检查时间间隔，不启用（小于等于0时）则默认1s，事实上，druid对于该参数的缺省值是60s Thread.sleep(timeBetweenEvictionRunsMillis); } else { Thread.sleep(1000); //默认1s } if (Thread.interrupted()) { break; } destroyTask.run(); //启动destroy的run方法（在下方） } catch (InterruptedException e) { break; } } } } //DruidDataSource内部类 public class DestroyTask implements Runnable { public DestroyTask() { } @Override public void run() { shrink(true, keepAlive); //连接池的检查&amp;瘦身 if (isRemoveAbandoned()) { //如果开启该属性，则进行强制回收检查 removeAbandoned(); } } } 流程4.1：连接池瘦身，检查连接是否可用以及丢弃多余连接整个过程如下： 上述流程对应源代码如下（请展开）： 代码段-4-2 >folded123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164//连接池瘦身 public void shrink(boolean checkTime, boolean keepAlive) { try { lock.lockInterruptibly(); } catch (InterruptedException e) { return; } int evictCount = 0; int keepAliveCount = 0; try { if (!inited) { return; } final int checkCount = poolingCount - minIdle; //根据poolingCount和minIdle计算出evictCheck的范围 final long currentTimeMillis = System.currentTimeMillis(); for (int i = 0; i &lt; poolingCount; ++i) { //开始遍历连接池里闲置的连接 DruidConnectionHolder connection = connections[i]; if (checkTime) { //除非手动调用，不然经过主流程4触发，一般为true if (phyTimeoutMillis &gt; 0) { //默认不启用，忽略 long phyConnectTimeMillis = currentTimeMillis - connection.connectTimeMillis; if (phyConnectTimeMillis &gt; phyTimeoutMillis) { evictConnections[evictCount++] = connection; continue; } } //计算闲置时间 long idleMillis = currentTimeMillis - connection.lastActiveTimeMillis; if (idleMillis &lt; minEvictableIdleTimeMillis &amp;&amp; idleMillis &lt; keepAliveBetweenTimeMillis ) { //如果闲置时间达不到检测&amp;瘦身的阈值，则不处理 break; } if (idleMillis &gt;= minEvictableIdleTimeMillis) { if (checkTime &amp;&amp; i &lt; checkCount) { //达到需要丢弃的阈值时，则判断连接下标是否在evictCheck范围，若在，则视为“可以丢弃的对象”放入evictConnections数组 evictConnections[evictCount++] = connection; continue; } else if (idleMillis &gt; maxEvictableIdleTimeMillis) { //达到必须要丢弃的阈值时，则不管是不是在evictCheck范围内，都直接放入“可以丢弃的对象”的evictConnections数组 evictConnections[evictCount++] = connection; continue; } } //如果上面的条件均没有命中，如果keepAlive为true，则判断是不是超过了闲置连接检查其活性的频次阈值（即由keepAliveBetweenTimeMillis控制） if (keepAlive &amp;&amp; idleMillis &gt;= keepAliveBetweenTimeMillis) { keepAliveConnections[keepAliveCount++] = connection; //满足条件则视为“需要检测活性的对象”，放入keepAliveConnections数组 } } else { if (i &lt; checkCount) { evictConnections[evictCount++] = connection; } else { break; } } } int removeCount = evictCount + keepAliveCount; //这一批需要移除特殊处理的连接总数 if (removeCount &gt; 0) { System.arraycopy(connections, removeCount, connections, 0, poolingCount - removeCount); //根据当前移除的元素，把剩余的元素移动至数组首部（参考流程4.1） Arrays.fill(connections, poolingCount - removeCount, poolingCount, null); //剩余位置清空 poolingCount -= removeCount; } keepAliveCheckCount += keepAliveCount; } finally { lock.unlock(); } if (evictCount &gt; 0) { //如果需要丢弃的连接数量大于0 for (int i = 0; i &lt; evictCount; ++i) { DruidConnectionHolder item = evictConnections[i]; Connection connection = item.getConnection(); JdbcUtils.close(connection); //直接关闭连接（这里是直接关闭驱动连接，不再放回池子） destroyCountUpdater.incrementAndGet(this); } Arrays.fill(evictConnections, null); //将evictConnections数组重新置空（方便下次使用） } if (keepAliveCount &gt; 0) { //检测那些需要判活的连接数 // keep order for (int i = keepAliveCount - 1; i &gt;= 0; --i) { DruidConnectionHolder holer = keepAliveConnections[i]; Connection connection = holer.getConnection(); holer.incrementKeepAliveCheckCount(); boolean validate = false; try { this.validateConnection(connection); //检测其活性 validate = true; } catch (Throwable error) { if (LOG.isDebugEnabled()) { LOG.debug(\"keepAliveErr\", error); } // skip } boolean discard = !validate; if (validate) { //检测通过 holer.lastKeepTimeMillis = System.currentTimeMillis(); boolean putOk = put(holer); //检测通过后，再次放入池子 if (!putOk) { //放不进去池子（说明已经达到连接池最大连接数阈值maxActive），则视为可以“直接抛弃”的连接 discard = true; } } if (discard) { try { connection.close(); //如果可以抛弃，则直接关闭连接（直接调用驱动的close） } catch (Exception e) { // skip } lock.lock(); try { discardCount++; //抛弃连接数累加 if (activeCount &lt;= minIdle) { emptySignal(); //唤起主流程3追加连接对象 } } finally { lock.unlock(); } } } this.getDataSourceStat().addKeepAliveCheckCount(keepAliveCount); Arrays.fill(keepAliveConnections, null); //将keepAliveConnections数组重新置空（方便下次使用） } } //上面检测通过，再次通过该方法重新把连接放入池子 private boolean put(DruidConnectionHolder holder) { lock.lock(); try { if (poolingCount &gt;= maxActive) { return false; //若池子内闲置连接数超过maxActive，则无法继续添加新的连接进来，返回false } connections[poolingCount] = holder; //否则直接把此连接对象放入连接池队尾 incrementPoolingCount(); //poolingCount++ if (poolingCount &gt; poolingPeak) { poolingPeak = poolingCount; poolingPeakTime = System.currentTimeMillis(); } notEmpty.signal(); //唤起那些因获取不到可用连接而陷入阻塞状态的业务线程一次 notEmptySignalCount++; if (createScheduler != null) { //不启用该模式，忽略 createTaskCount--; if (poolingCount + createTaskCount &lt; notEmptyWaitThreadCount // &amp;&amp; activeCount + poolingCount + createTaskCount &lt; maxActive) { emptySignal(); } } } finally { lock.unlock(); } return true; } 整个流程分成图中主要的几步，首先利用poolingCount减去minIdle计算出需要做丢弃检查的连接对象区间，意味着这个区间的对象有被丢弃的可能，具体要不要放进丢弃队列evictConnections，要判断两个属性： minEvictableIdleTimeMillis：最小检查间隙，缺省值30min，官方解释：一个连接在池中最小生存的时间（结合检查区间来看，闲置时间超过这个时间，才会被丢弃）。 maxEvictableIdleTimeMillis：最大检查间隙，缺省值7h，官方解释：一个连接在池中最大生存的时间（无视检查区间，只要闲置时间超过这个时间，就一定会被丢弃）。 如果当前连接对象闲置时间超过minEvictableIdleTimeMillis且下标在evictCheck区间内，则加入丢弃队列evictConnections，如果闲置时间超过maxEvictableIdleTimeMillis，则直接放入evictConnections（一般情况下会命中第一个判断条件，除非一个连接不在检查区间，且闲置时间超过maxEvictableIdleTimeMillis）。 如果连接对象不在evictCheck区间内，且keepAlive属性为true，则判断该对象闲置时间是否超出keepAliveBetweenTimeMillis（缺省值60s），若超出，则意味着该连接需要进行连接可用性检查，则将该对象放入keepAliveConnections队列。 两个队列赋值完成后，则池子会进行一次压缩，没有涉及到的连接对象会被压缩到队首。 然后就是处理evictConnections和keepAliveConnections两个队列了，evictConnections里的对象会被close最后释放掉，keepAliveConnections里面的对象将会其进行检测（流程参考流程1.3的isValidConnection），碰到不可用的连接会调用discard（流程1.4）抛弃掉，可用的连接会再次被放进连接池。 整个流程可以看出，连接闲置后，也并非一下子就减少到minIdle的，如果之前产生一堆的连接（不超过maxActive），突然闲置了下来，则至少需要花minEvictableIdleTimeMillis的时间才可以被移出连接池，如果一个连接闲置时间超过maxEvictableIdleTimeMillis则必定被回收，所以极端情况下（比如一个连接池从初始化后就没有再被使用过），连接池里并不会一直保持minIdle个连接，而是一个都没有，生产环境下这是非常不常见的，默认的maxEvictableIdleTimeMillis都有7h除非是极度冷门的系统才会出现这种情况，而开启keepAlive也不会推翻这个规则，keepAlive的优先级是低于maxEvictableIdleTimeMillis的，keepAlive只是保证了那些检查中不需要被移出连接池的连接在指定检测时间内去检测其连接活性，从而决定是否放入池子或者直接discard。 流程4.2：主动回收连接，防止内存泄漏过程如下： 上述流程对应源代码如下（请展开）： 代码段4-3 >folded1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283//回收长期未归还的连接（再次说明：该方法仅在removeAbandoned设置为true的情况下触发） public int removeAbandoned() { int removeCount = 0; long currrentNanos = System.nanoTime(); //这个列表用于存放满足条件的真正需要强制回收的连接 List abandonedList = new ArrayList(); activeConnectionLock.lock(); try { //在removeAbandoned设置为true的情况下，所有被借出去的连接，都会被保存进activeConnections（参考主流程1），所以要进行“长期未归还”的检查，就是从activeConnections开始的 Iterator iter = activeConnections.keySet().iterator(); for (; iter.hasNext();) { DruidPooledConnection pooledConnection = iter.next(); if (pooledConnection.isRunning()) { continue; //如果当前连接正在使用中（指的是正在execute），则不处理 } //利用当前时间和连接被借出去时的时间，计算出连接被借出去的时间有多久 long timeMillis = (currrentNanos - pooledConnection.getConnectedTimeNano()) / (1000 * 1000); if (timeMillis &gt;= removeAbandonedTimeoutMillis) { //如果连接被借出去的时间超过removeAbandonedTimeoutMillis这个阈值，将会命中“主动归还”的逻辑检查 iter.remove(); //先从activeConnections移除 pooledConnection.setTraceEnable(false); //标记为false，防止回收时重复removeactiveConnections，可以参考主流程5 abandonedList.add(pooledConnection); //放入“强制回收”队列 } } } finally { activeConnectionLock.unlock(); } if (abandonedList.size() &gt; 0) { //如果“强制回收”队列大于0，说明有需要回收的连接 for (DruidPooledConnection pooledConnection : abandonedList) { //循环这些连接 final ReentrantLock lock = pooledConnection.lock; lock.lock(); //拿到连接的锁 try { if (pooledConnection.isDisable()) { continue; //已经被回收的，则不管 } } finally { lock.unlock(); } //触发回收连接对象（pooledConnection）里的holcder（注意这里其实是把pooledConnection对象里的holder给回收至连接池了，pooledConnection对象本身会被销毁） JdbcUtils.close(pooledConnection); //这里触发的close，是DruidPooledConnection的close，也就是会触发recycle方法的close pooledConnection.abandond(); //标记为 removeAbandonedCount++; removeCount++; if (isLogAbandoned()) { //日志打印，忽略 StringBuilder buf = new StringBuilder(); buf.append(\"abandon connection, owner thread: \"); buf.append(pooledConnection.getOwnerThread().getName()); buf.append(\", connected at : \"); buf.append(pooledConnection.getConnectedTimeMillis()); buf.append(\", open stackTrace\\n\"); StackTraceElement[] trace = pooledConnection.getConnectStackTrace(); for (int i = 0; i &lt; trace.length; i++) { buf.append(\"\\tat \"); buf.append(trace[i].toString()); buf.append(\"\\n\"); } buf.append(\"ownerThread current state is \" + pooledConnection.getOwnerThread().getState() + \", current stackTrace\\n\"); trace = pooledConnection.getOwnerThread().getStackTrace(); for (int i = 0; i &lt; trace.length; i++) { buf.append(\"\\tat \"); buf.append(trace[i].toString()); buf.append(\"\\n\"); } LOG.error(buf.toString()); } } } return removeCount; //返回本次被强制回收的连接个数 } 这个流程在removeAbandoned设置为true的情况下才会触发，用于回收那些拿出去的使用长期未归还（归还：调用close方法触发主流程5）的连接。 先来看看activeConnections是什么，activeConnections用来保存当前从池子里被借出去的连接，这个可以通过主流程1看出来，每次调用getConnection时，如果开启removeAbandoned，则会把连接对象放到activeConnections，然后如果长期不调用close，那么这个被借出去的连接将永远无法被重新放回池子，这是一件很麻烦的事情，这将存在内存泄漏的风险，因为不close，意味着池子会不断产生新的连接放进connections，不符合连接池预期（连接池出发点是尽可能少的创建连接），然后之前被借出去的连接对象还有一直无法被回收的风险，存在内存泄漏的风险，因此为了解决这个问题，就有了这个流程，流程整体很简单，就是将现在借出去还没有归还的连接，做一次判断，符合条件的将会被放进abandonedList进行连接回收（这个list里的连接对象里的abandoned将会被置为true，标记已被该流程处理过，防止主流程5再次处理，具体可以参考代码段5-1）。 这个如果在实践中能保证每次都可以正常close，完全不用设置removeAbandoned=true，目前如果使用了类似mybatis、spring等开源框架，框架内部是一定会close的，所以此项是不建议设置的，视情况而定。 九、主流程5：回收连接这个流程通常是靠连接包装类DruidPooledConnection的close方法触发的，目标方法为recycle，流程图如下： 上述流程对应源代码如下（请展开）： 代码段5-1 >folded123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280//DruidPooledConnection类的close方法 @Override public void close() throws SQLException { if (this.disable) { //检查，因为该连接对象是抛出去给别的业务线程使用，也就是说并不受连接池本身管控，所以很可能存在多线程同时close的操作，因此这里需要做一层检查，包括下方的syncClose里的检查也是一个意思 return; } DruidConnectionHolder holder = this.holder; //拿到对应的holder对象（之前说过，这个对象才是最后放进连接池的对象） if (holder == null) { if (dupCloseLogEnable) { LOG.error(\"dup close\"); } return; } DruidAbstractDataSource dataSource = holder.getDataSource(); //拿到对应的连接池对象 boolean isSameThread = this.getOwnerThread() == Thread.currentThread(); if (!isSameThread) { //关闭该连接与获取该连接的线程并非同一个的时候，则触发下面的syncClose dataSource.setAsyncCloseConnectionEnable(true); } if (dataSource.isAsyncCloseConnectionEnable()) { syncClose(); //参考上面的解释，该方法详情在下方 return; } //一些事件监听器的触发，忽略 for (ConnectionEventListener listener : holder.getConnectionEventListeners()) { listener.connectionClosed(new ConnectionEvent(this)); } //责任链的执行，参考流程1.1与代码段1-2，运行方式是一样的，找到映射方法，整个触发一遍责任链上的filters List filters = dataSource.getProxyFilters(); if (filters.size() &gt; 0) { FilterChainImpl filterChain = new FilterChainImpl(dataSource); filterChain.dataSource_recycle(this); } else { recycle(); //触发目标方法recycle } this.disable = true; //标记该连接已失效，无法再次提供服务 } //上面逻辑走syncClose的情况，该方法与上面大体相同，但由于不是同一个线程做的操作，所以这里需要锁控制 public void syncClose() throws SQLException { lock.lock(); //获取锁，这个锁是当前连接对象上的锁，为了解决同一个连接对象在不同的线程里被同时close多次而造成的线程安全问题 try { if (this.disable) { return; } DruidConnectionHolder holder = this.holder; //同样的，拿到需要归还的holder对象 if (holder == null) { if (dupCloseLogEnable) { LOG.error(\"dup close\"); } return; } //同样是一些事件监听器的触发，忽略 for (ConnectionEventListener listener : holder.getConnectionEventListeners()) { listener.connectionClosed(new ConnectionEvent(this)); } //同样的责任链的执行，参考上面的解释 DruidAbstractDataSource dataSource = holder.getDataSource(); List filters = dataSource.getProxyFilters(); if (filters.size() &gt; 0) { FilterChainImpl filterChain = new FilterChainImpl(dataSource); filterChain.dataSource_recycle(this); } else { recycle(); //触发目标方法recycle，方法详情在下方 } this.disable = true; //标记该连接已失效，无法再次提供服务 } finally { lock.unlock(); //解锁 } } //DruidPooledConnection类的recycle方法，由上面俩方法直接触发 public void recycle() throws SQLException { if (this.disable) { return; } DruidConnectionHolder holder = this.holder; //拿到真正需要归还的连接对象 if (holder == null) { if (dupCloseLogEnable) { LOG.error(\"dup close\"); } return; } if (!this.abandoned) { //如果期间已经被流程4.2处理过了（abandoned==true），则不触发下方逻辑 DruidAbstractDataSource dataSource = holder.getDataSource(); dataSource.recycle(this); //真正触发连接池的回收方法，方法详情在下方 } //连接对象一旦被回收处理，则会把所有与连接相关的属性置空（不持有），closed标记为true this.holder = null; conn = null; transactionInfo = null; closed = true; } //DruidDataSource类里的recycle方法，真正回收连接的方法，由上面DruidPooledConnection类的recycle触发 protected void recycle(DruidPooledConnection pooledConnection) throws SQLException { final DruidConnectionHolder holder = pooledConnection.holder; if (holder == null) { LOG.warn(\"connectionHolder is null\"); return; } if (logDifferentThread // &amp;&amp; (!isAsyncCloseConnectionEnable()) // &amp;&amp; pooledConnection.ownerThread != Thread.currentThread()// ) { LOG.warn(\"get/close not same thread\"); } final Connection physicalConnection = holder.conn; //拿到真正的驱动连接对象 if (pooledConnection.traceEnable) { //如果traceEnable为true（满足该属性为true，必须要removeAbandoned设置为true，这样在主流程1那里才会被放进activeConnections，才会置为true），流程4.2处理过后，会把该属性重新置为false，其他情况均为true Object oldInfo = null; activeConnectionLock.lock(); try { if (pooledConnection.traceEnable) { //双重检查 oldInfo = activeConnections.remove(pooledConnection); //从activeConnections移除，防止流程4.2的重复检查 pooledConnection.traceEnable = false; //置为false } } finally { activeConnectionLock.unlock(); } if (oldInfo == null) { if (LOG.isWarnEnabled()) { LOG.warn(\"remove abandonded failed. activeConnections.size \" + activeConnections.size()); } } } final boolean isAutoCommit = holder.underlyingAutoCommit; final boolean isReadOnly = holder.underlyingReadOnly; final boolean testOnReturn = this.testOnReturn; try { // 如果在归还至连接池时发现此连接对象还有未处理完的事务，则直接回滚 if ((!isAutoCommit) &amp;&amp; (!isReadOnly)) { pooledConnection.rollback(); } // reset holder, restore default settings, clear warnings boolean isSameThread = pooledConnection.ownerThread == Thread.currentThread(); if (!isSameThread) { //同样判断线程，为了保证安全性 final ReentrantLock lock = pooledConnection.lock; lock.lock(); try { holder.reset(); //连接被借出去后，可能被业务方改动了一些属性（典型的比如autoCommit），现在利用reset方法还原为默认值 } finally { lock.unlock(); } } else { holder.reset(); //同上，这里认为获取和关闭连接的是同一个线程，不存在线程安全问题，因此不用去竞争锁 } //连接已被抛弃，则不作任何处理（不再归还） if (holder.discard) { return; } //忽略 if (phyMaxUseCount &gt; 0 &amp;&amp; holder.useCount &gt;= phyMaxUseCount) { discardConnection(holder.conn); return; } //如果驱动连接本身被人为关闭了，除一些监控值之外，也不做处理 if (physicalConnection.isClosed()) { lock.lock(); try { activeCount--; closeCount++; } finally { lock.unlock(); } return; } //参考testOnBorrow，这里testOnReturn就是指每次回收连接都要做连接可用性检查，同样官方不建议开启，影响性能，缺省值也是不开启的 if (testOnReturn) { //流程忽略 boolean validate = testConnectionInternal(holder, physicalConnection); if (!validate) { JdbcUtils.close(physicalConnection); destroyCountUpdater.incrementAndGet(this); lock.lock(); try { activeCount--; closeCount++; } finally { lock.unlock(); } return; } } if (!enable) { //中途发现连接又被置为不可用，则直接触发抛弃方法，参考流程1.4和代码段1-5 discardConnection(holder.conn); return; } boolean result; final long currentTimeMillis = System.currentTimeMillis(); if (phyTimeoutMillis &gt; 0) { long phyConnectTimeMillis = currentTimeMillis - holder.connectTimeMillis; if (phyConnectTimeMillis &gt; phyTimeoutMillis) { discardConnection(holder.conn); return; } } lock.lock(); try { activeCount--; closeCount++; //最终放入池子，方法详情在下方 result = putLast(holder, currentTimeMillis); recycleCount++; } finally { lock.unlock(); } if (!result) { //如果加不进去，则直接关闭驱动连接，然后不处理（此时holder已经失去强引用，不久便会被回收） JdbcUtils.close(holder.conn); LOG.info(\"connection recyle failed.\"); } } catch (Throwable e) { holder.clearStatementCache(); if (!holder.discard) { this.discardConnection(physicalConnection); holder.discard = true; } LOG.error(\"recyle error\", e); recycleErrorCountUpdater.incrementAndGet(this); } } //DruidDataSource类里的putLast方法，由上方的recycle方法触发 boolean putLast(DruidConnectionHolder e, long lastActiveTimeMillis) { if (poolingCount &gt;= maxActive) { //池子已满，不加 return false; } e.lastActiveTimeMillis = lastActiveTimeMillis; //刷新上次活跃时间，该时间很重要，直接影响连接检查的触发 connections[poolingCount] = e; //放进连接池数组尾部 incrementPoolingCount(); //poolingCount++ if (poolingCount &gt; poolingPeak) { poolingPeak = poolingCount; poolingPeakTime = lastActiveTimeMillis; } notEmpty.signal(); //因为成功回收了一个连接，那就唤起一次所有因为获取不到连接而被阻塞的业务线程吧~（参考流程1.2） notEmptySignalCount++; return true; } 这也是非常重要的一个流程，连接用完要归还，就是利用该流程完成归还的动作，利用druid对外包装的Connecion包装类DruidPooledConnection的close方法触发，该方法会通过自己内部的close或者syncClose方法来间接触发dataSource对象的recycle方法，从而达到回收的目的。 最终的recycle方法： 如果removeAbandoned被设置为true，则通过traceEnable判断是否需要从activeConnections移除该连接对象，防止流程4.2再次检测到该连接对象，当然如果是流程4.2主动触发的该流程，那么意味着流程4.2里已经remove过该对象了，traceEnable会被置为false，本流程就不再触发remove了（这个流程都是在removeAbandoned=true的情况下进行的，在主流程1里连接被放进activeConnections时traceEnable被置为true，而在removeAbandoned=false的情况下traceEnable恒等于false）。 如果回收过程中发现存在有未处理完的事务，则触发回滚（比较有可能触发这一条的是流程4.2里强制归还连接，也有可能是单纯使用连接，开启事务却没有提交事务就直接close的情况），然后利用holder.reset进行恢复连接对象里一些属性的默认值，除此之外，holder对象还会把由它产生的statement对象放到自己的一个arraylist里面，reset方法会循环着关闭内部未关闭的statement对象，最后清空list，当然，statement对象自己也会记录下其产生的所有的resultSet对象，然后关闭statement时同样也会循环关闭内部未关闭的resultSet对象，这是连接池做的一种保护措施，防止用户拿着连接对象做完一些操作没有对打开的资源关闭。 判断是否开启testOnReturn，这个跟testOnBorrow一样，官方默认不开启，也不建议开启，影响性能，理由参考主流程1里针对testOnBorrow的解释。 直接放回池子（当前connections的尾部），然后需要注意的是putLast方法和put方法的不同之处，putLast会把lastActiveTimeMillis置为当前时间，也就是说不管一个连接被借出去过久，只要归还了，最后活跃时间就是当前时间，这就会有造成某种特殊异常情况的发生（非常极端，几乎不会触发，可以选择不看）： 如果不开启testOnBorrow和testOnReturn，并且keepAlive设置为false，那么长连接可用测试的间隔依据就是利用当前时间减去上次活跃时间（lastActiveTimeMillis）得出闲置时间，然后再利用闲置时间跟timeBetweenEvictionRunsMillis（默认60s）进行对比，超过才进行长连接可用测试。 那么如果一个mysql服务端的长连接保活时间被人为调整为60s，然后timeBetweenEvictionRunsMillis被设置为59s，这个设置是非常合理的，保证了测试间隔小于长连接实际保活时间，然后如果这时一个连接被拿出去后一直过了61s才被close回收，该连接对象的lastActiveTimeMillis被刷为当前时间，如果在59s内再次拿到该连接对象，就会绕过连接检查直接报连接不可用的错误。 十、尾声到这里针对druid连接池的初始化以及其内部一个连接从生产到消亡的整个流程就已经整理完了，主要是列出其运行流程以及一些主要的监控数据都是如何产生的，没有涉及到的是一个sql的执行，因为这个基本上就跟使用原生驱动程序差不多，只是druid又包装了一层Statement等，用于完成一些自己的操作。 对于druid，处理连接只是很小的一块内容，却是很核心的一块内容。 Druid地址：https://github.com/alibaba/druid","link":"/2019/08/28/%E6%B1%A0%E5%8C%96%E6%8A%80%E6%9C%AF%EF%BC%88%E4%B8%80%EF%BC%89Druid%E6%98%AF%E5%A6%82%E4%BD%95%E7%AE%A1%E7%90%86%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E7%9A%84%EF%BC%9F/"}],"tags":[{"name":"池化技术","slug":"池化技术","link":"/tags/%E6%B1%A0%E5%8C%96%E6%8A%80%E6%9C%AF/"},{"name":"连接池","slug":"连接池","link":"/tags/%E8%BF%9E%E6%8E%A5%E6%B1%A0/"},{"name":"Druid","slug":"Druid","link":"/tags/Druid/"},{"name":"IDEA","slug":"IDEA","link":"/tags/IDEA/"},{"name":"IDEA插件开发","slug":"IDEA插件开发","link":"/tags/IDEA%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91/"},{"name":"数据库","slug":"数据库","link":"/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"TSDB","slug":"TSDB","link":"/tags/TSDB/"},{"name":"InfluxDB","slug":"InfluxDB","link":"/tags/InfluxDB/"},{"name":"位运算","slug":"位运算","link":"/tags/%E4%BD%8D%E8%BF%90%E7%AE%97/"},{"name":"教程","slug":"教程","link":"/tags/%E6%95%99%E7%A8%8B/"},{"name":"基础知识","slug":"基础知识","link":"/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"GC","slug":"GC","link":"/tags/GC/"},{"name":"NIO","slug":"NIO","link":"/tags/NIO/"},{"name":"网络编程","slug":"网络编程","link":"/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"},{"name":"游戏","slug":"游戏","link":"/tags/%E6%B8%B8%E6%88%8F/"},{"name":"皇城突袭","slug":"皇城突袭","link":"/tags/%E7%9A%87%E5%9F%8E%E7%AA%81%E8%A2%AD/"},{"name":"Kingdom Rush","slug":"Kingdom-Rush","link":"/tags/Kingdom-Rush/"},{"name":"分布式缓存","slug":"分布式缓存","link":"/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/"},{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"nosql","slug":"nosql","link":"/tags/nosql/"},{"name":"ThreadLocal","slug":"ThreadLocal","link":"/tags/ThreadLocal/"},{"name":"并发编程","slug":"并发编程","link":"/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"熔断","slug":"熔断","link":"/tags/%E7%86%94%E6%96%AD/"},{"name":"位图","slug":"位图","link":"/tags/%E4%BD%8D%E5%9B%BE/"},{"name":"Resilience4j","slug":"Resilience4j","link":"/tags/Resilience4j/"},{"name":"树","slug":"树","link":"/tags/%E6%A0%91/"},{"name":"数据结构","slug":"数据结构","link":"/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"火焰图","slug":"火焰图","link":"/tags/%E7%81%AB%E7%84%B0%E5%9B%BE/"},{"name":"鬼畜","slug":"鬼畜","link":"/tags/%E9%AC%BC%E7%95%9C/"},{"name":"juc","slug":"juc","link":"/tags/juc/"},{"name":"CompletableFuture","slug":"CompletableFuture","link":"/tags/CompletableFuture/"},{"name":"阻塞队列","slug":"阻塞队列","link":"/tags/%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97/"},{"name":"ReentrantLock","slug":"ReentrantLock","link":"/tags/ReentrantLock/"},{"name":"spring","slug":"spring","link":"/tags/spring/"},{"name":"ioc","slug":"ioc","link":"/tags/ioc/"},{"name":"aop","slug":"aop","link":"/tags/aop/"},{"name":"链表","slug":"链表","link":"/tags/%E9%93%BE%E8%A1%A8/"},{"name":"多线程","slug":"多线程","link":"/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"memcache","slug":"memcache","link":"/tags/memcache/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"事务","slug":"事务","link":"/tags/%E4%BA%8B%E5%8A%A1/"},{"name":"HikariCP","slug":"HikariCP","link":"/tags/HikariCP/"},{"name":"map","slug":"map","link":"/tags/map/"},{"name":"散列表","slug":"散列表","link":"/tags/%E6%95%A3%E5%88%97%E8%A1%A8/"},{"name":"集合类","slug":"集合类","link":"/tags/%E9%9B%86%E5%90%88%E7%B1%BB/"},{"name":"设计模式","slug":"设计模式","link":"/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"生产者消费者模式","slug":"生产者消费者模式","link":"/tags/%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%85%E6%A8%A1%E5%BC%8F/"},{"name":"工厂模式","slug":"工厂模式","link":"/tags/%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/"},{"name":"策略模式","slug":"策略模式","link":"/tags/%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F/"},{"name":"miku","slug":"miku","link":"/tags/miku/"},{"name":"letter song","slug":"letter-song","link":"/tags/letter-song/"},{"name":"链路追踪","slug":"链路追踪","link":"/tags/%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA/"},{"name":"OpenTracing","slug":"OpenTracing","link":"/tags/OpenTracing/"},{"name":"顾村公园","slug":"顾村公园","link":"/tags/%E9%A1%BE%E6%9D%91%E5%85%AC%E5%9B%AD/"},{"name":"樱花","slug":"樱花","link":"/tags/%E6%A8%B1%E8%8A%B1/"},{"name":"旅行","slug":"旅行","link":"/tags/%E6%97%85%E8%A1%8C/"}],"categories":[{"name":"池化技术","slug":"池化技术","link":"/categories/%E6%B1%A0%E5%8C%96%E6%8A%80%E6%9C%AF/"},{"name":"IDEA插件开发","slug":"IDEA插件开发","link":"/categories/IDEA%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91/"},{"name":"DB","slug":"DB","link":"/categories/DB/"},{"name":"JAVA基础","slug":"JAVA基础","link":"/categories/JAVA%E5%9F%BA%E7%A1%80/"},{"name":"连接池","slug":"池化技术/连接池","link":"/categories/%E6%B1%A0%E5%8C%96%E6%8A%80%E6%9C%AF/%E8%BF%9E%E6%8E%A5%E6%B1%A0/"},{"name":"网络编程","slug":"网络编程","link":"/categories/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"},{"name":"InfluxDB","slug":"DB/InfluxDB","link":"/categories/DB/InfluxDB/"},{"name":"JAVA进化论","slug":"JAVA基础/JAVA进化论","link":"/categories/JAVA%E5%9F%BA%E7%A1%80/JAVA%E8%BF%9B%E5%8C%96%E8%AE%BA/"},{"name":"游戏","slug":"游戏","link":"/categories/%E6%B8%B8%E6%88%8F/"},{"name":"JVM","slug":"JAVA基础/JVM","link":"/categories/JAVA%E5%9F%BA%E7%A1%80/JVM/"},{"name":"NIO基础","slug":"网络编程/NIO基础","link":"/categories/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/NIO%E5%9F%BA%E7%A1%80/"},{"name":"分布式缓存","slug":"DB/分布式缓存","link":"/categories/DB/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/"},{"name":"并发编程","slug":"并发编程","link":"/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"服务治理","slug":"服务治理","link":"/categories/%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86/"},{"name":"数据结构","slug":"数据结构","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"杂记","slug":"杂记","link":"/categories/%E6%9D%82%E8%AE%B0/"},{"name":"日常","slug":"日常","link":"/categories/%E6%97%A5%E5%B8%B8/"},{"name":"框架","slug":"框架","link":"/categories/%E6%A1%86%E6%9E%B6/"},{"name":"MySQL","slug":"DB/MySQL","link":"/categories/DB/MySQL/"},{"name":"设计模式","slug":"设计模式","link":"/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"ThreadLocal","slug":"并发编程/ThreadLocal","link":"/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/ThreadLocal/"},{"name":"熔断","slug":"服务治理/熔断","link":"/categories/%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86/%E7%86%94%E6%96%AD/"},{"name":"树","slug":"数据结构/树","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/"},{"name":"火焰图","slug":"服务治理/火焰图","link":"/categories/%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86/%E7%81%AB%E7%84%B0%E5%9B%BE/"},{"name":"划水","slug":"日常/划水","link":"/categories/%E6%97%A5%E5%B8%B8/%E5%88%92%E6%B0%B4/"},{"name":"JUC","slug":"并发编程/JUC","link":"/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JUC/"},{"name":"Spring","slug":"框架/Spring","link":"/categories/%E6%A1%86%E6%9E%B6/Spring/"},{"name":"链表","slug":"数据结构/链表","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/"},{"name":"图解多线程设计模式","slug":"并发编程/图解多线程设计模式","link":"/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%9B%BE%E8%A7%A3%E5%A4%9A%E7%BA%BF%E7%A8%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"散列表","slug":"数据结构/散列表","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%A3%E5%88%97%E8%A1%A8/"},{"name":"生产&消费模式","slug":"设计模式/生产-消费模式","link":"/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E7%94%9F%E4%BA%A7-%E6%B6%88%E8%B4%B9%E6%A8%A1%E5%BC%8F/"},{"name":"模式对比","slug":"设计模式/模式对比","link":"/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E6%A8%A1%E5%BC%8F%E5%AF%B9%E6%AF%94/"},{"name":"链路追踪","slug":"服务治理/链路追踪","link":"/categories/%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86/%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA/"},{"name":"旅行","slug":"日常/旅行","link":"/categories/%E6%97%A5%E5%B8%B8/%E6%97%85%E8%A1%8C/"},{"name":"Framework","slug":"框架/Spring/Framework","link":"/categories/%E6%A1%86%E6%9E%B6/Spring/Framework/"}]}