{"pages":[{"title":"","text":"个人简介 93年生人，从事java服务端开发工作4年，现居上海 Icarus 主题以白色的简洁为主，但有时候我们希望在文章中用特别的样式注明一些内容，markdown 语法就不够用了，所以在此分享一下我的高级玩法。","link":"/about/index.html"}],"posts":[{"title":"Java NIO学习与记录（一）：初识NIO","text":"工作中有些地方间接用到了netty，netty是一个NIO框架，对于NIO却不是那么熟悉，这个系列的文章是我在学习NIO时的一个记录，也期待自己可以更好的掌握NIO。 一、NIO是什么？一组由操作系统提供的底层API，java支持对它们的封装，我们需要做的是利用java来使用它们。非阻塞式IO，与传统的BIO（阻塞式IO）不同，NIO可以通过通道（Channels）来监听各通道的动作，一个线程就可以完成对多个通道的动作监听，这些动作包括连接就绪、写就绪、读就绪等，举个例子，建立连接这个动作在BIO中会发生阻塞，直到连接建立完成，而在NIO中，建连只是单线程里Selector监听的一个动作，也就是说在建立连接之前（即建连就绪之前），这个线程是可以继续处理其他动作的（比如读、写等等）。没有传统IO在IO交互时的阻塞现象，仅通过一个线程来处理n多IO通道（Channels），大大提升了程序的处理能力。 二、NIO核心组成部分2.1：Channels &amp; Buffer这两个放在一起讲，Channel是指各种IO通道（包括File、Socket等），也可以理解为双向IO流，即：Channel既可以将自己的内容读到Buffer中，也可以从Buffer中读取数据写入到自己里面。其次，Channel并不一定是双向的，一个Channel如果实现定义read( )方法的 ReadableByteChannel 接口,而另一个 Channel 类也许实现 WritableByteChannel 接口以提供write( )方法。实现这两种接口其中之一的类都是单向的，只能在单个方向上传输数据。如果一个类同时实现这两个接口,那么它是双向的,可以双向传输数据（读&amp;写）。 结合上面描述，Buffer是一个容器，负责存储从Channel里读到的数据或者存储准备写入Channel的数据，属于一个缓冲区。 常见的Channel： FileChannel：文件通道 DatagramChannel：一个能收发UDP包的通道。因为UDP是无连接的网络协议，所以不能像其它通道那样读取和写入。它发送和接收的是数据包 SocketChannel：一个连接到TCP网络套接字的通道 ServerSocketChannel：一个可以监听新进来的TCP连接的通道 常见的Buffer： ByteBuffer、CharBuffer、DoubleBuffer、FloatBuffer、IntBuffer、LongBuffer、ShortBuffer 可以发现，涵盖了基本传输的数据类型。 2.2：Selector可以理解为“Channel事件选择处理器”，第一部分有提到说NIO属于非阻塞式IO，关键点在于Selector可以运行于一个单线程里，然后通过一个死循环（阻塞方法）来监听注册到选择器内的Channel的事件（注意这里，一个Channel的事件想要被选择器监听到，则要求该Channel必须注册到选择器里），这些事件上面也提到过包含：连接就绪、写就绪、读就绪等。这些动作全部由Channel自己完成，什么时候完成了通知选择器去进行相应的逻辑处理即可，而不必阻塞在IO交互上（也是与传统BIO不同的点），选择器工作如下图： 本篇简单介绍了下NIO，接下来将会介绍具体如何去使用","link":"/2019/03/05/Java%20NIO%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%B0%E5%BD%95%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E5%88%9D%E8%AF%86NIO/"},{"title":"Java NIO学习与记录（三）： Scatter&Gather介绍及使用","text":"上一篇知道了Buffer的工作机制，以及FileChannel的简单用法，这一篇介绍下Scatter&amp;Gather 1.Scatter（分散）用于描述在Channel中读取的数据分散在不同的Buffer里。 接着上一篇的例子（rua文件内容为123456789），改造下代码： 1234567891011121314151617181920212223readFile = new RandomAccessFile(\"D:\\\\rua.txt\", \"r\");FileChannel readChannel = readFile.getChannel();ByteBuffer first = ByteBuffer.allocate(2); //第一块bufferByteBuffer second = ByteBuffer.allocate(2); //第二块bufferByteBuffer[] byteBuffers = {first, second};long bytesRead = readChannel.read(byteBuffers); //从通道里读取数据到Buffer内（最大不超过Buffer容积）while (bytesRead != -1) { //当读不到任何东西时返回-1 System.out.println(\"\\nheader里的数据------此时byteRead=\" + bytesRead); first.flip(); //切换到Buffer读模式，读模式下可以读取到之前写入Buffer的数据 while (first.hasRemaining()) { System.out.print(\"-\" + (char) first.get()); //第一块Buffer读出的数据用减号分割，用于跟第二块区分 } first.clear(); System.out.println(\"\\nbody里的数据------此时byteRead=\" + bytesRead); second.flip(); while (second.hasRemaining()) { System.out.print(\"+\" + (char) second.get()); //第二块Buffer读出的数据用加号分割，用于跟第一块区分 } second.clear(); // 切换回Buffer的写模式 System.out.println(\"\\n----------------------------------------------\"); bytesRead = readChannel.read(byteBuffers); //跟上面一样，再次从通道读取数据到Buffer中}System.out.print(\"\\n-----------程序结束\"); 代码块1 上面的代码开了两个Buffer，然后传给了Channel.read一个Buffer数组，运行结果如下： 12345678910111213141516171819header里的数据------此时byteRead=4-1-2body里的数据------此时byteRead=4+3+4----------------------------------------------header里的数据------此时byteRead=4-5-6body里的数据------此时byteRead=4+7+8----------------------------------------------header里的数据------此时byteRead=1-9body里的数据------此时byteRead=1---------------------------------------------------------程序结束 可以看到，文件里的内容被分段加载出来了，first buffer里首选读取一段，然后接着second buffer再接着读取接下来的一段。上面例子符合Scatter的描述。 看过网上一些文章，说的最多的例子就是协议头数据体分开处理的例子： 假设通过Channel获取到的数据存在固定长度的协议头，以及已知最大长度限制的数据体，就可以通过两个Buffer来接收，一个是header buffer，一个是body buffer， 但这个对数据要求很严苛，结合上面的例子，不难发现，想要做到准确无误的处理这个例子，就得要求事先必须知道header的长度，以及数据体的最大长度上限，为什么要这样呢？因为如果不知道header的长度，那么header buffer就可能会读到body buffer里的东西或者body buffer里读到header buffer里的东西，如果不知道body的上限长度，那么如果body数据长度超过了body buffer的长度，body里的数据就会再次读到header buffer中去（这个可以结合上面的例子理解）。 2.Gather（聚集）用于描述在将不同Buffer里的数据写到同一个Channel中去。 来看个例子： 1234567891011readFile = new RandomAccessFile(\"D:\\\\haha.txt\", \"rw\");FileChannel channel = readFile.getChannel();ByteBuffer first = ByteBuffer.allocate(5); //第一块bufferByteBuffer second = ByteBuffer.allocate(5); //第二块bufferfirst.put(\"aa\".getBytes());second.put(\"bb\".getBytes());first.flip();second.flip();ByteBuffer[] byteBuffers = {first, second};channel.write(byteBuffers);System.out.print(\"\\n-----------程序结束\"); 代码块2 运行结束后，haha.txt里的内容为： 1aabb 可以看到，最终写入的数据就是按照顺序把两个buffer里的内容传输进去了。 同样的，还是以网上的协议头数据体的例子说事儿，这个跟Scatter下的传输方式比较起来就不会那么严格了，看到上面，初始容积为5个字节，但实际写到文件里的每个buffer仍然是两个字节，因为Gather模式下，Channel读取Buffer数据的时候，只会读取position到limit间的数据（可读区域），因此这里不用像多Buffer读一样要求那么严格，我们可以随意定义header buffer的长度，只要大于协议头本身长度即可，body buffer的要求其实是同上，也是大于数据体的长度上限即可。 这就是Scatter和Gather的全部内容了~其实简单理解，就是多Buffer操作，以及对网上那个例子，进行了更详细一点的说明。","link":"/2019/03/07/Java%20NIO%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%B0%E5%BD%95%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9A%20Scatter&Gather%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BD%BF%E7%94%A8/"},{"title":"Java NIO学习与记录（七）： Reactor单线程模型的实现","text":"一、Selector&amp;Channel1.1：各种channel写这个模型需要提前了解Selector以及Channel，之前记录过FileChannel，除此之外还有以下几种Channel： ServerSocketChannel：用于监听新的TCP连接的通道，负责读取&amp;响应，通常用于服务端的实现。 SocketChannel：用于发起TCP连接，读写网络中的数据，通常用于客户端的实现。 DatagramChannel：上述两个通道基于TCP传输协议，而这个通道则基于UDP，用于读写网络中的数据。 FileChannel：从文件读取数据。 本篇重点放在ServerSocketChannel和SocketChannel上，大部分客户端/服务端为了保证数据准确性，都是基于TCP传输协议实现的，由于使用Selector注册必须要求被注册的Channel是非阻塞模式的，因此FileChannel由于没有非阻塞模式（无法设置configureBlocking(false)），没办法和注册到selector。 1.2：selectorSelector是个通道注册器（用法会在程序里标注），是实现Reactor模型的关键，多个通道均可以注册到Selector，Selector负责监听每个Channel的几个事件：连接就绪、写就绪、读就绪，当某个channel注册感兴趣就绪事件到selector时，若发生兴趣事件就绪，则Selector.select()方法不再阻塞，返回兴趣事件集合（可能包含多个channel的），然后按照事件不同进行分发处理。 Selector返回对应的就绪事件，封装为SelectionKey，每个Channel对应一个SelectionKey，这个对象还可以通过attach方法附着处理类（Handler、Acceptor等）。 1.3：一个简单的例子先来看个简单使用Selector做处理的服务端实现，可以简单对Selector和SelectionKey的用法做个了解： 123456789101112131415161718192021222324252627282930313233343536373839public static void main(String[] args) throws IOException { Selector selector = Selector.open(); //打开选择器 ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); //打开通道 serverSocketChannel.configureBlocking(false); //设置通道为非阻塞模式 serverSocketChannel.bind(new InetSocketAddress(2333)); //绑定端口 serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); //注册channel到选择器，指定监听该Channel的哪些事件，初始化都是对连接事件监听（因为是入口） while (selector.select() &gt; 0) { // 若收到就绪事件select返回“感兴趣”事件集合，否则阻塞当前线程 Set keys = selector.selectedKeys(); //获取本次拿到的事件集合 Iterator iterator = keys.iterator(); while (iterator.hasNext()) { SelectionKey key = iterator.next(); iterator.remove(); if (key.isAcceptable()) { //当前就绪事件为连接事件 ServerSocketChannel skc = (ServerSocketChannel) key.channel(); //连接就绪触发，说明已经有客户端通道连了过来，这里需要拿服务端通道去获取客户端通道 SocketChannel socketChannel = skc.accept(); //获取客户端通道（连接就绪，说明客户端接下来可能还有别的动作，比如读和写） socketChannel.configureBlocking(false); //同样的需要设置非阻塞模式 System.out.println(String.format(\"收到来自 %s 的连接\", socketChannel.getRemoteAddress())); socketChannel.register(selector, SelectionKey.OP_READ); //将该客户端注册到选择器，感兴趣事件设置为读（客户端连接完毕，很肯能会往服务端写数据，因此这里要注册读事件用以接收这些数据） } else if (key.isReadable()) { //当前事件为读就绪 SocketChannel socketChannel = (SocketChannel) key.channel(); //能触发读就绪，说明客户端已经开始往服务端写数据，通过SelectionKey拿到当前客户端通道 ByteBuffer buffer = ByteBuffer.allocate(1024); int count = socketChannel.read(buffer); //从通道读入数据 if (count &lt; 0) { //若本次读就绪拿到-1，则认为客户端主动断开了连接 socketChannel.close(); //服务端关闭客户端通道 key.cancel(); //断连后就将该事件从选择器的SelectionKey集合中移除（这里说一下，这里不是真正意义上的移除，这里是取消，会将该key放入取消队列里，在下次select函数调用时才负责清空） System.out.println(\"连接关闭\"); continue; } System.out.println(String.format(\"收到来自 %s 的消息: %s\", socketChannel.getRemoteAddress(), new String(buffer.array()))); } keys.remove(key); } } } 代码块1 上面是一个简单的例子，接下来，就利用选择器、通道来实现Reactor单线程模型。 二、单Reactor单线程模型的服务端实现实现服务端，服务端负责接收客户端的连接，接收客户端的请求数据以及响应客户端。 把上一篇的结构图再拿过来展示下，看看需要做的有哪些模块： 通过上图，我们需要实现的模块有Reactor、Acceptor、Handler，下面来逐个编写： 2.1：Reactor核心模块该模块内部包含两个核心方法，select和dispatch，该模块负责监听就绪事件和对事件的分发处理： 123456789101112131415161718192021222324252627282930313233343536373839404142public class Reactor implements Runnable { private final Selector selector; private final ServerSocketChannel serverSocketChannel; public Reactor(int port) throws IOException { //Reactor初始化 selector = Selector.open(); //打开一个Selector serverSocketChannel = ServerSocketChannel.open(); //建立一个Server端通道 serverSocketChannel.socket().bind(new InetSocketAddress(port)); //绑定服务端口 serverSocketChannel.configureBlocking(false); //selector模式下，所有通道必须是非阻塞的 //Reactor是入口，最初给一个channel注册上去的事件都是accept SelectionKey sk = serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); //attach callback object, Acceptor sk.attach(new Acceptor(serverSocketChannel, selector)); } @Override public void run() { try { while (!Thread.interrupted()) { selector.select(); //就绪事件到达之前，阻塞 Set selected = selector.selectedKeys(); //拿到本次select获取的就绪事件 Iterator it = selected.iterator(); while (it.hasNext()) { //这里进行任务分发 dispatch((SelectionKey) (it.next())); } selected.clear(); } } catch (IOException e) { e.printStackTrace(); } } void dispatch(SelectionKey k) { Runnable r = (Runnable) (k.attachment()); //这里很关键，拿到每次selectKey里面附带的处理对象，然后调用其run，这个对象在具体的Handler里会进行创建，初始化的附带对象为Acceptor（看上面构造器） //调用之前注册的callback对象 if (r != null) { r.run(); } }} 代码块2 细节已标注。 2.2：实现Acceptor模块这个模块只负责处理连接就绪事件，有了这个事件就可以拿到客户单的SocketChannel，就可以继续完成接下来的读写任务了： 1234567891011121314151617181920212223242526public class Acceptor implements Runnable { private final Selector selector; private final ServerSocketChannel serverSocketChannel; Acceptor(ServerSocketChannel serverSocketChannel, Selector selector) { this.serverSocketChannel = serverSocketChannel; this.selector = selector; } @Override public void run() { SocketChannel socketChannel; try { socketChannel = serverSocketChannel.accept(); if (socketChannel != null) { System.out.println(String.format(\"收到来自 %s 的连接\", socketChannel.getRemoteAddress())); new Handler(socketChannel, selector); //这里把客户端通道传给Handler，Handler负责接下来的事件处理（除了连接事件以外的事件均可） } } catch (IOException e) { e.printStackTrace(); } }} 代码块3 细节已标注。 2.3：Handler模块的实现这个模块负责接下来的读写操作： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788public class Handler implements Runnable { private final SelectionKey selectionKey; private final SocketChannel socketChannel; private ByteBuffer readBuffer = ByteBuffer.allocate(1024); private ByteBuffer sendBuffer = ByteBuffer.allocate(2048); private final static int READ = 0; private final static int SEND = 1; private int status = READ; Handler(SocketChannel socketChannel, Selector selector) throws IOException { this.socketChannel = socketChannel; //接收客户端连接 this.socketChannel.configureBlocking(false); //置为非阻塞模式（selector仅允非阻塞模式） selectionKey = socketChannel.register(selector, 0); //将该客户端注册到selector，得到一个SelectionKey，以后的select到的就绪动作全都是由该对象进行封装 selectionKey.attach(this); //附加处理对象，当前是Handler对象，run是对象处理业务的方法 selectionKey.interestOps(SelectionKey.OP_READ); //走到这里，说明之前Acceptor里的建连已完成，那么接下来就是读取动作，因此这里首先将读事件标记为“感兴趣”事件 selector.wakeup(); //唤起select阻塞 } @Override public void run() { try { switch (status) { case READ: read(); break; case SEND: send(); break; default: } } catch (IOException e) { //这里的异常处理是做了汇总，常出的异常就是server端还有未读/写完的客户端消息，客户端就主动断开连接，这种情况下是不会触发返回-1的，这样下面read和write方法里的cancel和close就都无法触发，这样会导致死循环异常（read/write处理失败，事件又未被cancel，因此会不断的被select到，不断的报异常） System.err.println(\"read或send时发生异常！异常信息：\" + e.getMessage()); selectionKey.cancel(); try { socketChannel.close(); } catch (IOException e2) { System.err.println(\"关闭通道时发生异常！异常信息：\" + e2.getMessage()); e2.printStackTrace(); } } } private void read() throws IOException { if (selectionKey.isValid()) { readBuffer.clear(); int count = socketChannel.read(readBuffer); //read方法结束，意味着本次\"读就绪\"变为\"读完毕\"，标记着一次就绪事件的结束 if (count &gt; 0) { System.out.println(String.format(\"收到来自 %s 的消息: %s\", socketChannel.getRemoteAddress(), new String(readBuffer.array()))); status = SEND; selectionKey.interestOps(SelectionKey.OP_WRITE); //注册写方法 } else { //读模式下拿到的值是-1，说明客户端已经断开连接，那么将对应的selectKey从selector里清除，否则下次还会select到，因为断开连接意味着读就绪不会变成读完毕，也不cancel，下次select会不停收到该事件 //所以在这种场景下，（服务器程序）你需要关闭socketChannel并且取消key，最好是退出当前函数。注意，这个时候服务端要是继续使用该socketChannel进行读操作的话，就会抛出“远程主机强迫关闭一个现有的连接”的IO异常。 selectionKey.cancel(); socketChannel.close(); System.out.println(\"read时-------连接关闭\"); } } } void send() throws IOException { if (selectionKey.isValid()) { sendBuffer.clear(); sendBuffer.put(String.format(\"我收到来自%s的信息辣：%s, 200ok;\", socketChannel.getRemoteAddress(), new String(readBuffer.array())).getBytes()); sendBuffer.flip(); int count = socketChannel.write(sendBuffer); //write方法结束，意味着本次写就绪变为写完毕，标记着一次事件的结束 if (count &lt; 0) { //同上，write场景下，取到-1，也意味着客户端断开连接 selectionKey.cancel(); socketChannel.close(); System.out.println(\"send时-------连接关闭\"); } //没断开连接，则再次切换到读 status = READ; selectionKey.interestOps(SelectionKey.OP_READ); } }} 代码块4 细节已标注。 关键模块已实现，下面来启动服务端： 1new Thread(new Reactor(2333)).start(); 代码块5 三、客户端的编写接下来同样利用selector编写客户端，客户端需要做的事情就是发送消息到服务端，等待服务端响应，然后再次发送消息，发够10条消息断开连接： 3.1：Client入口模块1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class NIOClient implements Runnable { private Selector selector; private SocketChannel socketChannel; NIOClient(String ip, int port) { try { selector = Selector.open(); //打开一个Selector socketChannel = SocketChannel.open(); socketChannel.configureBlocking(false); //设置为非阻塞模式 socketChannel.connect(new InetSocketAddress(ip, port)); //连接服务 //入口，最初给一个客户端channel注册上去的事件都是连接事件 SelectionKey sk = socketChannel.register(selector, SelectionKey.OP_CONNECT); //附加处理类，第一次初始化放的是连接就绪处理类 sk.attach(new Connector(socketChannel, selector)); } catch (IOException e) { e.printStackTrace(); } } @Override public void run() { try { while (!Thread.interrupted()) { selector.select(); //就绪事件到达之前，阻塞 Set selected = selector.selectedKeys(); //拿到本次select获取的就绪事件 Iterator it = selected.iterator(); while (it.hasNext()) { //这里进行任务分发 dispatch((SelectionKey) (it.next())); } selected.clear(); } } catch (IOException e) { e.printStackTrace(); } } void dispatch(SelectionKey k) { Runnable r = (Runnable) (k.attachment()); //这里很关键，拿到每次selectKey里面附带的处理对象，然后调用其run，这个对象在具体的Handler里会进行创建，初始化的附带对象为Connector（看上面构造器） //调用之前注册的callback对象 if (r != null) { r.run(); } }} 代码块6 细节已标注。 3.2：Connector模块（建连）123456789101112131415161718192021222324public class Connector implements Runnable { private final Selector selector; private final SocketChannel socketChannel; Connector(SocketChannel socketChannel, Selector selector) { this.socketChannel = socketChannel; this.selector = selector; } @Override public void run() { try { if (socketChannel.finishConnect()) { //这里连接完成（与服务端的三次握手完成） System.out.println(String.format(\"已完成 %s 的连接\", socketChannel.getRemoteAddress())); new Handler(socketChannel, selector); //连接建立完成后，接下来的动作交给Handler去处理（读写等） } } catch (IOException e) { e.printStackTrace(); } }} 代码块7 细节已标注。 3.3：客户端Handler模块实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public class Handler implements Runnable { private final SelectionKey selectionKey; private final SocketChannel socketChannel; private ByteBuffer readBuffer = ByteBuffer.allocate(2048); private ByteBuffer sendBuffer = ByteBuffer.allocate(1024); private final static int READ = 0; private final static int SEND = 1; private int status = SEND; //与服务端不同，默认最开始是发送数据 private AtomicInteger counter = new AtomicInteger(); Handler(SocketChannel socketChannel, Selector selector) throws IOException { this.socketChannel = socketChannel; //接收客户端连接 this.socketChannel.configureBlocking(false); //置为非阻塞模式（selector仅允非阻塞模式） selectionKey = socketChannel.register(selector, 0); //将该客户端注册到selector，得到一个SelectionKey，以后的select到的就绪动作全都是由该对象进行封装 selectionKey.attach(this); //附加处理对象，当前是Handler对象，run是对象处理业务的方法 selectionKey.interestOps(SelectionKey.OP_WRITE); //走到这里，说明之前Connect已完成，那么接下来就是发送数据，因此这里首先将写事件标记为“感兴趣”事件 selector.wakeup(); //唤起select阻塞 } @Override public void run() { try { switch (status) { case SEND: send(); break; case READ: read(); break; default: } } catch (IOException e) { //这里的异常处理是做了汇总，同样的，客户端也面临着正在与服务端进行写/读数据时，突然因为网络等原因，服务端直接断掉连接，这个时候客户端需要关闭自己并退出程序 System.err.println(\"send或read时发生异常！异常信息：\" + e.getMessage()); selectionKey.cancel(); try { socketChannel.close(); } catch (IOException e2) { System.err.println(\"关闭通道时发生异常！异常信息：\" + e2.getMessage()); e2.printStackTrace(); } } } void send() throws IOException { if (selectionKey.isValid()) { sendBuffer.clear(); int count = counter.incrementAndGet(); if (count &lt;= 10) { sendBuffer.put(String.format(\"客户端发送的第%s条消息\", count).getBytes()); sendBuffer.flip(); //切换到读模式，用于让通道读到buffer里的数据 socketChannel.write(sendBuffer); //则再次切换到读，用以接收服务端的响应 status = READ; selectionKey.interestOps(SelectionKey.OP_READ); } else { selectionKey.cancel(); socketChannel.close(); } } } private void read() throws IOException { if (selectionKey.isValid()) { readBuffer.clear(); //切换成buffer的写模式，用于让通道将自己的内容写入到buffer里 socketChannel.read(readBuffer); System.out.println(String.format(\"收到来自服务端的消息: %s\", new String(readBuffer.array()))); //收到服务端的响应后，再继续往服务端发送数据 status = SEND; selectionKey.interestOps(SelectionKey.OP_WRITE); //注册写事件 } }} 代码块8 细节已标注。 下面启动客户端去连接之前的服务端： 12new Thread(new NIOClient(\"127.0.0.1\", 2333)).start();new Thread(new NIOClient(\"127.0.0.1\", 2333)).start(); 代码块9 上面模拟了两个客户端同时连到服务端，运行结果如下： 单线程Reactor模型有个致命的缺点，通过上述例子可以看出，整个执行流程都是线性的，客户端请求→服务端读取→服务端响应→客户端收到响应→客户端再次发送请求，那么在这个链路中，如果handler中某个位置存在性能瓶颈，比如我们可以改造下服务端的send方法： 1234567try { Thread.sleep(2000L); //响应2s} catch (InterruptedException e) { e.printStackTrace();}int count = socketChannel.write(sendBuffer); 代码块10 在响应客户端之前睡眠2s，当做是性能瓶颈点，同样的再次开两个客户端同时访问服务端，每个客户端发送10条消息，会发现，程序直接运行了40s，这是大多数情况下不愿意看到的，因此，就有了多线程Reactor模式，跟BIO为了提高性能将读操作放到一个独立线程处理一样，Reactor这样做，也是为了解决上面提到的性能问题，只不过NIO比BIO做异步有个最大的优势就是NIO不会阻塞一个线程，类似read这种操作状态都是由selector负责监听的，不像BIO里都是阻塞的，只要被异步出去，那么一定是非阻塞的业务代码（除非是人为将代码搞成阻塞），而BIO由于read本身阻塞，因此会阻塞掉整个业务线程，这也是同样是异步为什么NIO可以更加高效的原因之一。 那么单线程Reactor适用于什么情况呢？适用于那种程序复杂度很低的系统，例如redis，其大部分操作都是非常高效的，很多命令的时间复杂度直接为O(1)，这种情况下适合这种简单的Reactor模型实现服务端。","link":"/2019/03/27/Java%20NIO%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%B0%E5%BD%95%EF%BC%88%E4%B8%83%EF%BC%89%EF%BC%9A%20Reactor%E5%8D%95%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AE%9E%E7%8E%B0/"},{"title":"Java NIO学习与记录（二）：FileChannel与Buffer用法与说明","text":"上一篇简单介绍了NIO，这一篇将介绍FileChannel结合Buffer的用法，主要介绍Buffer 一、FileChannel例子上一篇说到，这个Channel属于文件通道，专门读取文件信息，NIO读取文件内容的简单的例子： 123456789101112131415161718192021222324252627public static void readFile() { RandomAccessFile file = null; try { file = new RandomAccessFile(\"D:\\\\rua.txt\", \"rw\"); FileChannel fileChannel = file.getChannel(); //获取文件通道 ByteBuffer buf = ByteBuffer.allocate(2); //分配容积为2字节的一块Buffer，用来读取数据 int bytesRead = fileChannel.read(buf); //从通道里读取数据到Buffer内（最大不超过Buffer容积） while (bytesRead != -1) { //当读不到任何东西时返回-1 buf.flip(); //切换到Buffer读模式，读模式下可以读取到之前写入Buffer的数据 while (buf.hasRemaining()) { //循环输出Buffer中的数据 System.out.print((char) buf.get()); } buf.compact(); //或者调用clear，切换回Buffer的写模式 bytesRead = fileChannel.read(buf); //跟上面一样，再次从通道读取数据到Buffer中 } } catch (IOException e) { e.printStackTrace(); } finally { try { if (file != null) { file.close(); } } catch (IOException e) { e.printStackTrace(); } } } 代码块1 rua.txt文件内容为：123456789 上述代码运行后输出如下： 1123456789 文件正常读取，可以结合上面的注释，来分析下过程，接下来要利用上面的例子介绍Buffer的一些概念。 二、Buffer的概念2.1：Buffer操作的步骤第一篇说过，Buffer是一个缓冲区，是一个容器，负责从通道读取数据或者写数据给通道，通过上面的例子，我们可以看到Buffer在读取通道数据时的几个步骤： step1：分配空间 1ByteBuffer.allocate(1024); //除此之外，还可以通过allocateDirector分配空间（具体不了解，先放一边，回头补） 代码块2 step2：从通道读取数据，写入Buffer 1int bytesRead = fileChannel.read(buf); 代码块3 step3：读取Buffer内的内容，切换回Buffer读模式 1buf.flip(); //切换到Buffer读模式，读模式下可以读取到之前写入Buffer的数据 代码块4 step4：循环执行读写操作，每取完一次Buffer中的值，都切换回写模式，再次从通道读取数据到Buffer 12345678while (bytesRead != -1) { //当读不到任何东西时返回-1 buf.flip(); //切换到Buffer读模式，读模式下可以读取到之前写入Buffer的数据 while (buf.hasRemaining()) { //循环输出Buffer中的数据 System.out.print((char) buf.get()); } buf.compact(); //或者调用clear，切换回Buffer的写模式 bytesRead = fileChannel.read(buf); //跟上面一样，再次从通道读取数据到Buffer中} 代码块5 2.2：Buffer读写流程详解2.2.1：重要属性的介绍Buffer具备的几个重要概念： capacity：缓冲区数组的总长度（容积） position：下一个需要操作的数据元素的位置 limit：缓冲区不可操作的下一个元素的位置，limit &lt;= capacity mark：用于记录position的前一个位置或默认是-1 2.2.2：Buffer内部的操作流程结合上面的概念，除了mark（再往下介绍），其余几个指标的操作变化如下图： 初始化一个容积为10的Buffer，初识位置limit = capacity，position位于第一个位置 当容器内写入了5个数据元素之后，position的位置变到了第6个位置，标记当前写入到哪里了 这时候不再写入数据了，开始切换回Buffer的读模式（flip），发生的变化如下： 发现，原先读模式下的position的位置被limit替换掉了，而position被重置为了第一个位置，这是因为现在读模式下想要读取之前写入的内容，为了保证读取的数据都是可读的（之前写入的），就需要有一个标记，来记录之前写模式下，操作到哪里了，position被重置为第一个位置，也很容易理解，因为切换了读模式，从头开始读取已写入的数据。 通过上面的描述，我们清楚了buffer是如何利用position、limit、capacity来完成读写操作的，下面我们来介绍下具体读写操作时Bufer发生的操作： Buffer切换读模式的方法有：flip Buffer切换写模式的方法有：clear、compact Buffer读数据：get 使用clear切换回写模式的时候，position会被置为0（也就是最初的位置），limit置为capacity（也就是最后的位置），意味着切换写模式之前未读的数据，将会被新一轮的写入覆盖，就再也找不回来了，所以除clear这个操作，Buffer还提供了compact方法来切换读模式，这个方法会把所有未读的数据拷贝到Buffer的起始位置，然后position指向最后一个未读数据的后一位，这样，下次开启读模式的时候，position操作同上，置为0，因此之前未读完被落下的数据也就在这时候被读到了。 下面我们来还原下这个转换过程： 走到上面的步骤后，我们切换成写模式，下面这个图分别表示了clear和compact两个方法下的两种操作： 根据图4和图5，结合上面的话，更容易理解clear和compact两种方式切换写模式所做的内部操作，以及为什么clear会丢数据，而compact不会。 下面通过一开始的例子，把中间读取数据的地方稍微做下修改： 12345678910ByteBuffer buf = ByteBuffer.allocate(2);int bytesRead = readChannel.read(buf);while (bytesRead != -1) { buf.flip(); char result = (char) buf.get(); //虽然读进来了2个字节，但这里只取一个 System.out.print(result); buf.clear(); // 使用clear切换回Buffer的写模式 bytesRead = readChannel.read(buf);}System.out.println(\"-----------程序结束\"); 代码块6 输出结果： 113579-----------程序结束 发现丢了一些数据，现在把clear改成compact，运行结果为： 112345678-----------程序结束 发现，除了9，都输出来了（至于9为啥没输出，因为每次只取了一个字节的数据呀~） 那么，如果切换到读模式，但是不读，然后切换回写模式继续写，会发生什么？ 改造上述代码如下： 12345678ByteBuffer buf = ByteBuffer.allocate(2);int bytesRead = readChannel.read(buf);while (bytesRead != -1) { buf.flip(); buf.clear(); // 不读，立刻切回写模式 bytesRead = readChannel.read(buf);}System.out.println(\"-----------程序结束\"); 代码块7 调用clear的情况下输出： 1-----------程序结束 而调用compact方法，却发生阻塞(死循环)了，结合之前的图，我们可以知道，如果不读，意味着在compact下会把未读的数据copy到Buffer里，如果一点都不读，那么意味着被copy的这批数据会占满整个Buffer，以至于position没有下一个位置可用，就会发生文件里的数据没办法被安排进缓冲区（意味着文件读不完），bytesRead一直不等于-1，发生死循环。 通过上面的图和例子，基本上可以理清楚读模式、写模式（包含不同的切换方式）下的Buffer内部处理方式。 2.3：Buffer的其他操作除了上面几种常规用法，Buffer还提供了其他的几个操作方法 2.3.1：rewind这个方法可以在读模式下，重置position的位置，也就是说在get执行后。position发生了位移，这个方法可以重置position的位置为初始位置，看例子： 12345678910ByteBuffer buf = ByteBuffer.allocate(2); //每次可读入两个字节int bytesRead = readChannel.read(buf);while (bytesRead != -1) { buf.flip(); System.out.print((char) buf.get()); buf.rewind(); //重置position System.out.print((char) buf.get());//这时候读到的数据跟上面是同一个 buf.clear(); bytesRead = readChannel.read(buf); } 代码块8 运行结果： 11133557799 可以看到，每次循环拿到两个字节，但两次获取的数据都是同一个，因为rewind把读取游标重置成初始位置了（也即是位置0） ⭐️ 这里说下，如果把上面的第二个get方法去掉，然后把clear模式改成compact模式同样也会发生死循环，因为rewind重置了游标，重置后又没有get方法再次读取，导致把本次的两个字节又复制进了Buffer，跟之前说的不读一样，会导致Buffer没有多余的空间放文件里的数据，导致一直读不完，发生死循环。 2.3.2：mark &amp; reset这两个方法放到一起说，因为mark跟reset不放在一起使用，没有任何意义。 mark：用于标记当前position的位置 reset：用于恢复被mark标记的position的位置 例子： 1234567891011ByteBuffer buf = ByteBuffer.allocate(2);int bytesRead = readChannel.read(buf);while (bytesRead != -1) { buf.flip(); buf.mark(); //标记当前位置，这里也就是初始位置 System.out.print((char) buf.get()); //读取到了初识位置数据 buf.reset(); //重置position到mark标记时那个值 System.out.print((char) buf.get()); //这里由于被reset了，因此输出的还是初识位置的数据 buf.clear(); bytesRead = readChannel.read(buf);} 代码块9 输出结果： 11133557799 会发现，上下两个打印都是是一样的数据。嘛，还是跟上面一样，再回顾一下，这里如果用compact会怎么操作？如果使用compact会打印如下语句： 11122334455667788 这个现在也很好理解了，因为重置了位置所以每个数据被打印了两次，由于mark的原因，每次实际上相当于只读了一个数据，所以剩下的一个数据被顺延到下次循环里打印，以此类推。 2.3.3：equals &amp; compareTo equals：用来比较两个Buffer是否相等，判等条件为 类型相同（byte、char等） 剩余元素个数相等 剩余元素相同 compareTo：比较两个Buffer中剩余元素的大小，如果满足如下条件，则认为buffer1小于buffer2： buffer1中第一个与buffer2不相等的元素小于buffer2的那个元素 所有元素相同，但是buffer1先比buffer2耗尽 三、实例：边读边写例子：将rua.txt里的内容在读的同时写入文件haha.txt里 12345678910111213readFile = new RandomAccessFile(\"D:\\\\rua.txt\", \"r\");writeFile = new RandomAccessFile(\"D:\\\\haha.txt\", \"rw\");FileChannel readChannel = readFile.getChannel(); //获取只读文件通道FileChannel writeChannel = writeFile.getChannel(); //获取写文件通道ByteBuffer readBuf = ByteBuffer.allocate(2); //分配容积为2字节的一块Buffer，用来读取数据int bytesRead = readChannel.read(readBuf); //从通道里读取数据到Buffer内（最大不超过Buffer容积）while (bytesRead != -1) { //当读不到任何东西时返回-1 readBuf.flip(); //切换到Buffer读模式，读模式下可以读取到之前写入Buffer的数据 writeChannel.write(readBuf); //将现在的buffer里的数据写到文件haha.txt里 readBuf.compact(); // 切换回Buffer的写模式 bytesRead = readChannel.read(readBuf); //跟上面一样，再次从通道读取数据到Buffer中} 代码块10 结果haha.txt里的内容为：123456789 四、Buffer的分类 类别 解释 ByteBuffer 支持存放字节类型数据，抽象类，有DirectByteBuffer、HeapByteBuffer、MappedByteBuffer两个子类，下面进行说明 CharBuffer 支持存放char类型数据 DoubleBuffer 支持存放double类型数据 FloatBuffer 支持存放float类型数据 IntBuffer 支持存放int类型数据 LongBuffer 支持存放long类型数据 ShortBuffer 支持存放short类型数据 表1 通过上表可以看到，Buffer有很多实现，其中大部分都对应一种基本类型，ByteBuffer比较特殊，下面介绍下它的两个子类。 ByteBuffer—-&gt;HeapByteBuffer 直接通过byte数组实现的在java堆上的缓冲区。 ByteBuffer—-&gt;DirectByteBuffer 直接在java堆外申请的一块内存，将文件映射到该内存空间，在大文件读写方面的效率非常高。 ByteBuffer—–&gt;MappedByteBuffer 同样写效率非常高。 关于这几个Buffer后续会专门整理一篇文章来写。","link":"/2019/03/05/Java%20NIO%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%B0%E5%BD%95%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9AFileChannel%E4%B8%8EBuffer%E7%94%A8%E6%B3%95%E4%B8%8E%E8%AF%B4%E6%98%8E/"},{"title":"Java NIO学习与记录（五）： 操作系统的I/O模型","text":"在开始介绍NIO Reactor模式之前，先来介绍下操作系统的五种I/O模型，了解了这些模型，对理解java nio会有不小的帮助。 前言：一次网络请求的流程先来看下一个服务端处理一次网络请求的流程图： 一、图1解析1.1：内核空间&amp;用户空间内核空间：指操作系统运行时用于程序调度、虚拟内存的使用或者连接硬件资源的程序逻辑。 用户空间：应用程序能够申请使用的空间。 操作系统采用虚拟存储器，操作系统核心是内核（Kernel），独立于普通应用程序，它既可以访问受保护的内存空间，又有访问底层硬件设备的所有权限，为了保证内核安全，使得用户进程不直接操作内核，因此操作系统将虚拟存储器分为两个部分：内核空间&amp;用户空间 1.2：网络请求流程根据图1，客户端发起一个请求到服务端，请求首先到达的是服务端网卡（步骤1），然后将请求数据copy到内核空间的内核缓冲区内（步骤2），到这一步，我们说一个数据报已经准备好了。 用户空间里的web服务进程（我们真正的业务程序）发起读取内核缓冲区里的数据，若内核缓冲区准备好了数据报，则会将数据报由内核缓冲区copy到用户空间的web服务进程内（步骤3），然后拿着这些数据进行逻辑处理（步骤4），然后将处理结果copy到内和缓冲区（步骤5），然后内核缓冲区将该数据copy到网卡（步骤6），然后远程传输给客户端（步骤7），这就完成了一次网络请求-响应处理。 这里需要指出步骤3下面这一步，这一步没有计入步骤，但这一步恰好是理解I/O是否发生阻塞的关键，下面介绍阻塞/非阻塞IO时会详细讲。 1.3：套接字(socket)&amp;文件描述符(fd)TCP用主机的IP地址加上主机上的端口号作为TCP连接的端点，这种端点就叫做套接字（socket），套接字提供了很多供应用程序使用的API，比如accept、read、write等。 文件描述符(fd)，Unix/Linux系统下，其作为一个socket的句柄，可以看做是一个文件，在socket上收发数据，相当于对一个文件进行读写，所以一个socket句柄，通常也用表示文件句柄的fd来表示。 二、I/O模型2.1：阻塞&amp;非阻塞调用阻塞与非阻塞的概念是针对调用方（一般指我们的业务程序，如图1中的web服务器进程）来说的。 阻塞调用：图1中步骤1、2执行期间，没有数据到达内核缓冲区，这个时候web服务器进程发起的获取数据的请求会被直接阻塞，当前相关线程会被挂起，直到步骤1、2完成，有数据写入内核缓冲区，这个时候才会唤醒线程执行步骤3和4. 非阻塞调用：与阻塞调用相反，当没有数据到达内核缓冲区时，web服务发起的获取数据的请求不会发生阻塞，相关线程可以选择做其他事情，然后轮询着查询请求结果即可，当某次轮询出结果，则进行步骤3和4的操作。 2.2：同步&amp;异步处理同步与异步的概念是针对被调用方（一般是指内核空间里的IO处理，如图1中的步骤1和2）来说的（一定要区分和理解阻塞/非阻塞、同步/异步这两个概念）。 同步处理：被调用方得到最终处理结果才返回给调用方。 异步处理：被调用方不用得到结果，只需返回一个状态给调用方，然后开始IO处理，处理完了就主动返回通知调用方。 2.3：数据输入的两个阶段一个网络输入流程包含下面两个阶段： 数据准备（步骤1、2）。 将准备好的数据从内核空间复制到用户空间（步骤3）。 2.4：阻塞IO模型我们从图1的步骤3下面的那次请求开始画图，阻塞式I/O模型处理流程如下： 从上图可以看出，阻塞IO模型是指从应用程序发起从socket获取数据（recvfrom）那一刻起，如果内核里没有准备好的数据报，则直接阻塞应用程序，导致应用程序无法去做别的任何事情，直到数据报准备好，被阻塞的程序才会被唤醒，继续处理下面拿到的数据报。 阻塞IO模型只允许一个线程处理一个连接请求，因此当并发量大的时候，会创建大量线程，线程切换开销很大，导致程序处理性能低下。具体参考BIO模式的服务端实现：SocketChannel与BIO服务器 2.5：非阻塞IO模型同样从应用程序发起获取数据的地方开始画图，非阻塞式I/O模型处理流程如下： 从上图可以看出，非阻塞模式也是相对于调用者的，调用者在发送获取数据的请求时会将对应套接口设置为非阻塞，这样在数据报还未准备好的时候，应用程序就不会被阻塞了，然后应用程序再通过轮询的方式进行询问数据报是否已经准备好，当准备好后停止轮询，接下来的逻辑跟阻塞IO一致。对比可以发现，阻塞与非阻塞都是以调用方的角度看的，而且阻塞与否全在第一个阶段，第二个阶段都是一致的。非阻塞IO虽然不会阻塞应用程序，但是因为需要长时间的轮询，对于CPU来说，将会进行大量无意义的切换，资源利用率较低。 2.6：非阻塞IO-多路复用模型2.6.1：模型介绍IO多路复用模型处理流程如下： 从上图可以看出，IO多路复用，其实是找了个代理select，帮助监听多个IO通道的状态，某个通道有新状态产生，才触发recvfrom操作，没有新的状态产生，则select会阻塞。注意这里的阻塞，与阻塞IO模型里的不同，阻塞IO模型是指一个IO操作发生的阻塞行为，而这里select可以同时阻塞多个IO通道，也就是说select可能会监听到一个以上的IO通道的状态，直到有数据可读、可写时，才真正触发IO操作的函数。 🌿 多路复用 图4里的多路复用是说利用某个IO函数（这里是指select）同时监听多个IO通道的状态变更，这样应用程序就可以通过一个函数同时监听多个通道的就绪状态（如连接就绪、读就绪），多路复用跟后面要讲的NIO不是同一个概念，它只是一种处理模型，而NIO是一组API，它提供的select函数恰好可以实现这种数据处理模型。 另外一种多路复用是指基于传输层协议（如TCP）的特性来实现的数据流传输方式，根据TCP特性，同一个TCP连接可以同时传输多条数据和接收多条数据，而实现这种多路复用的方式取决于应用层协议（全双工通信的应用层协议，比如HTTP2）。多路是指多个数据流，复用是指复用同一个资源（这个资源放到图4就是指select函数，放到通信方式里就是指TCP连接），可以参考其原始概念：多路复用-百度百科。以及这篇知乎上的回答：IO 多路复用是什么意思？ 2.6.2：select、poll、epoll函数上述三个函数均提供IO多路复用的解决方案，但是它们之间存在差异性，下面会介绍具体的区别： select： select 函数监视的fd分为writefds、readfds、exceptfds三类，调用后select函数会阻塞，直到有fd就绪（可读、可写、或except），或超时（指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以通过遍历fdset，来找到已经就绪的fd。 优点：跨平台支持，目前几乎所有的平台都支持。 缺点：单个进程内其监视的fd存在最大限制，一般为1024个（linux32）或者2048个（linux64）。另外一个缺点就是其会不断的轮询fdset，不管存不存在活跃的socket，它都会全部遍历一遍fdset来查找就绪的fd，导致浪费许多CPU的时间去做这件事。最后一个缺点是其可能会维护一个存放大量fd的数据结构，这样会使用户空间和内核空间在传递该结构时复制开销过大。 poll： 本质上和select没有区别，但是它解决了select监视fd个数的限制。 优点：对于监视的fd，采用链表结构存储，无个数限制。 缺点：基本上select有的缺点它都有，其次它还有个特点：水平触发，也就是说poll到的fd没有被处理掉，下次依旧能被poll到。 select和poll一样，在大量客户端连接进来时，它们的效率会随着客户端数量而线性下降。 epoll： Linux2.6开始支持的一个函数，是对select和poll的增强版本。 优点：没有监视fd个数的限制，主动通知（回调）机制，只关注活跃的fd，不用像select和poll那样全量遍历去找就绪的fd，因而也不存在随着客户端数量的增多而性能下降的问题。最后是内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递，即epoll使用mmap减少复制开销。 缺点：在大量客户端连接，并且大量活跃的fd时，其性能可能还不如select/poll。 2.7：信号驱动式IO模型信号驱动IO模型处理流程如下： 通过上图，在信号驱动 IO 模型中，应用程序使用套接口进行信号驱动 IO，并安装一个信号处理函数，进程继续运行并不会发生阻塞； 当数据准备好时，进程会收到一个 SIGIO 信号，可以在信号处理函数中调用 IO 操作函数处理数据。 这种模式下在大量IO操作时可能会发生信号队列溢出而导致无法通知。在TCP下，该模式几乎没用，TCP下可通知的条件过多，每一个都进行判断会消耗掉大量的资源。 2.8：异步IO模型（AIO）上面介绍的几种IO模型，对于IO处理本身而言，都是同步的，只有这个模型，针对IO处理本身来讲，是异步的。 下面来看看流程图： 由上图看出，此模型下首先由应用程序告知内核启动某个操作，并让内核在整个操作包括将数据从内核拷贝到应用程序的缓冲区的过程中，完成后通知应用程序。 这跟上面的信号驱动IO模型有所不同，这个模型通知给应用程序时，IO操作已经全部完成，应用程序直接拿数据就好，无需再做任何IO操作（这就是此模型叫异步IO处理的原因），而信号驱动通常是返回给应用程序一个数据报准备状态，真正的IO操作仍需要应用程序进行。 目前AIO并不完善，最常用的高性能IO模型仍然是IO多路复用模型。 三、总结这几种模型除了AIO属于异步IO以外，其余的几种全都是同步IO（即需要应用程序主动进行IO操作），而是否阻塞应用程序取决于第一个阶段的处理方式，前几种IO模型的区别全在于第一阶段的处理。 本文参考：https://zhuanlan.zhihu.com/p/43933717","link":"/2019/03/19/Java%20NIO%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%B0%E5%BD%95%EF%BC%88%E4%BA%94%EF%BC%89%EF%BC%9A%20%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84IO%E6%A8%A1%E5%9E%8B/"},{"title":"Java NIO学习与记录（六）： NIO线程模型","text":"上一篇说的是基于操作系统的IO处理模型，那么这一篇来介绍下服务器端基于IO模型和自身线程的处理方式。 一、基于BIO下的线程处理模式这种处理模型是基于阻塞IO进行的，上一篇讲过，阻塞IO会阻塞每一个IO操作，直到事件就绪，下面来看下阻塞IO下的服务端线程模型： 如上图所示，该线程模型基于阻塞IO模型实现，针对每个请求都需要抽出来一个线程进行处理读入数据、业务处理数据、返回响应结果给客户端，这个过程中读、写操作均会阻塞，且跟业务处理串行执行，该模式下，并发量过大时会大量创建线程，发生的大量上下文切换，从而导致CPU资源占用过大，当连接建立后，若当前线程暂无可读数据，则线程会一直阻塞在读操作上，造成线程资源浪费，即便使用线程池进行优化，虽然避免了大量创建线程，但也会出现线程资源浪费的问题，高并发下可能会造成排队、响应不及时的问题。 具体BIO服务器的实现参考：SocketChannel与BIO服务器 二、基于NIO下的Reactor线程模型利用操作系统NIO的API实现，Java对其API的调用进行了封装（select等），这里先不探讨怎么利用java的api去调用，先来看看它的基本流程是怎样的，Reactor模式下的线程模型又会根据线程数量、线程池数量的不同，细分了三种线程模型。 2.1：单Reactor单线程模型这是最简单的Reactor模型，整个过程中的事件处理全部发生在一个线程里： 上图示意就是个简单的NIO单Reactor单线程处理模型，流程如下： Reactor对象通过select监听客户端的请求事件，收到事件消息后通过dispatch进行任务分发。 如果是建连请求，则交由Acceptor对象处理连接请求，然后创建一个Handler对象继续完成后续处理 若不是建连请求，则dispatch会调用对应连接的Handler进行处理，Handle负责完成连接成功后的后续处理（读操作、写操作、业务处理等） 此模型很简单，易于理解，但是存在一定的问题，比如单线处理程模型下，无法发挥多核CPU的性能，如果Handler上的业务处理很慢，则意味着整个程序无法处理其他连接事件，造成性能问题。适用于业务处理快速、客户端连接较少的情况。 2.2：单Reactor多线程模型相较于上面的模型，对业务处理模块进行了异步处理，流程图如下： 上图示意属于单Reactor多线程处理模型，流程如下： Reactor对象通过select监听客户端的请求事件，收到事件消息后通过dispatch进行任务分发。 如果是建连请求，则交由Acceptor对象处理连接请求，然后创建一个Handler对象继续完成后续处理 若不是建连请求，则dispatch会调用对应连接的Handler进行处理，Handle负责完成连接成功后的读操作，读出来数据后的业务处理部分交由线程池异步处理，业务处理完成后发送给Handler处理完成的消息，然后再由Handler发送处理响应信息给对应的Client。 本模型充分利用了多核CPU的处理能力，降低了由业务处理引起的性能问题，Reactor线程仅负责接收连接、读写操作。但是Reactor除了负责连接处理外仍然负责读写操作，大量的请求下仍然可能仍然存在性能问题。 2.3：主从Reactor多线程模型这个模型中将会独立出另一个Reactor对象来处理非连接处理的其他处理，命名为从Reactor（SubReactor），流程图如下： 上图示意属于主从Reactor多线程处理模型，流程如下： 主Reactor对象（MainReactor）通过select监听客户端的连接事件，收到连接事件后交由Acceptor处理。 Acceptor处理完成后，MainReactor将此连接分配给SubReactor处理，SubReactor将此连接加入连接队列进行事件监听并建立Handler进行后续的各种操作，同上面的模型一致，SubReactor会监听新的事件，如果有新的事件发生，则调用Handler进行相应的处理。 Handler读出来数据后的业务处理部分交由线程池异步处理，业务处理完成后发送给Handler处理完成的消息，然后再由Handler发送处理响应信息给对应的Client。 该模型存在两个线程分别处理Reactor事件，主线程只负责处理连接事件，子线程只负责处理读写事件，这样主线程可以处理更多的连接，而不用关心子线程里的读写处理是否会影响到自己。目前这种模型被广泛使用在各种项目中（如Netty、Memcached等）。 以上的线程模型都是基于同步IO，异步IO这里不作说明，目前大部分项目都采用NIO的API进行实现（该模式下又分成了上述3种线程处理模型）。 下一篇将会针对NIO下的三种线程处理模型，介绍下Selector，以及利用Selector来写一下具体的实现代码。","link":"/2019/03/20/Java%20NIO%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%B0%E5%BD%95%EF%BC%88%E5%85%AD%EF%BC%89%EF%BC%9A%20NIO%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/"},{"title":"Java NIO学习与记录（四）： SocketChannel与BIO服务器","text":"SocketChannel可以创建连接TCP服务的客户端，用于为服务发送数据，SocketChannel的写操作和连接操作在非阻塞模式下不会发生阻塞，这篇文章里的客户端采用SocketChannel实现，利用线程池模拟多个客户端并发访问服务端的情景。服务端仍然采用ServerSocket来实现，主要用来看下阻塞模式下的服务端在并发访问时所做出的的处理。 一、使用SocketChannel实现一个客户端1234567891011121314151617181920212223242526272829303132333435363738394041424344private static ExecutorService ctp = Executors.newCachedThreadPool(); public static void main(String[] args) { for (int i = 0; i &lt; 10; i++) { ctp.submit(IOTest::client); //并发十个客户端连接过去 } } public static void client() { ByteBuffer buffer = ByteBuffer.allocate(1024); //定义缓冲区 SocketChannel socketChannel = null; try { socketChannel = SocketChannel.open(); //打开SocketChannel socketChannel.configureBlocking(false); //设置为非阻塞模式 socketChannel.connect(new InetSocketAddress(\"127.0.0.1\", 2333)); //连接服务 while (true) { if(socketChannel.finishConnect()){ //这里的finishConnect是尝试连接，有可能返回false，因此使用死循环进行连接检查，确保连接已经正常建立。 System.out.println(\"客户端已连接到服务器\"); int i = 0; while (i &lt; 5) { TimeUnit.SECONDS.sleep(1); //隔一秒钟写一条 String info = \"来自客户端的第\" + (i++) + \"条消息\"; buffer.clear(); buffer.put(info.getBytes()); buffer.flip(); while (buffer.hasRemaining()) { socketChannel.write(buffer); //给服务写消息 } } break; } } } catch (IOException | InterruptedException e) { e.printStackTrace(); } finally { try { if (socketChannel != null) { System.out.println(\"客户端Channel关闭\"); socketChannel.close(); } } catch (IOException e) { e.printStackTrace(); } } 代码块1 上面会同时产生10个客户端去连接服务端 二、使用ServerSocket实现一个BIO的TCP服务12345678910111213141516171819202122232425262728293031323334ServerSocket serverSocket = null; int recvMsgSize = 0; InputStream in = null; try { serverSocket = new ServerSocket(2333); //开一个监听2333端口的TCP服务 byte[] recvBuf = new byte[1024]; while (true) { Socket clntSocket = serverSocket.accept(); //探听有没有新的客户端连接进来，没有就阻塞 SocketAddress clientAddress = clntSocket.getRemoteSocketAddress(); //通过跟服务连接上的客户端socket，拿到客户端地址 System.out.println(\"连接成功，处理客户端：\" + clientAddress); in = clntSocket.getInputStream(); //数据流 while ((recvMsgSize = in.read(recvBuf)) != -1) { //读取发送的数据，当客户端未断开连接，且不往服务端发数据的时候，说明一直处于准备读的状态，会一直阻塞下去，直到有数据写入（读就绪） byte[] temp = new byte[recvMsgSize]; System.arraycopy(recvBuf, 0, temp, 0, recvMsgSize); System.out.println(\"收到客户端\" + clientAddress + \"的消息内容：\" + new String(temp)); //打印消息 } System.out.println(\"-----------------------------------\"); } } catch (IOException e) { e.printStackTrace(); } finally { try { if (serverSocket != null) { System.out.println(\"socket关闭！\"); serverSocket.close(); } if (in != null) { System.out.println(\"stream连接关闭！\"); in.close(); } } catch (IOException e) { e.printStackTrace(); } } 代码块2 运行上面的代码，服务端打印如下： 12345678910111213141516171819202122232425262728293031323334连接成功，处理客户端：/127.0.0.1:54688收到客户端/127.0.0.1:54688的消息内容：来自客户端的第0条消息收到客户端/127.0.0.1:54688的消息内容：来自客户端的第1条消息收到客户端/127.0.0.1:54688的消息内容：来自客户端的第2条消息收到客户端/127.0.0.1:54688的消息内容：来自客户端的第3条消息收到客户端/127.0.0.1:54688的消息内容：来自客户端的第4条消息-----------------------------------连接成功，处理客户端：/127.0.0.1:54680收到客户端/127.0.0.1:54680的消息内容：来自客户端的第0条消息来自客户端的第1条消息来自客户端的第2条消息来自客户端的第3条消息来自客户端的第4条消息-----------------------------------连接成功，处理客户端：/127.0.0.1:54689收到客户端/127.0.0.1:54689的消息内容：来自客户端的第0条消息来自客户端的第1条消息来自客户端的第2条消息来自客户端的第3条消息来自客户端的第4条消息-----------------------------------连接成功，处理客户端：/127.0.0.1:54682收到客户端/127.0.0.1:54682的消息内容：来自客户端的第0条消息来自客户端的第1条消息来自客户端的第2条消息来自客户端的第3条消息来自客户端的第4条消息-----------------------------------连接成功，处理客户端：/127.0.0.1:54683收到客户端/127.0.0.1:54683的消息内容：来自客户端的第0条消息来自客户端的第1条消息来自客户端的第2条消息来自客户端的第3条消息来自客户端的第4条消息-----------------------------------连接成功，处理客户端：/127.0.0.1:54684收到客户端/127.0.0.1:54684的消息内容：来自客户端的第0条消息来自客户端的第1条消息来自客户端的第2条消息来自客户端的第3条消息来自客户端的第4条消息-----------------------------------连接成功，处理客户端：/127.0.0.1:54685收到客户端/127.0.0.1:54685的消息内容：来自客户端的第0条消息来自客户端的第1条消息来自客户端的第2条消息来自客户端的第3条消息来自客户端的第4条消息-----------------------------------连接成功，处理客户端：/127.0.0.1:54681收到客户端/127.0.0.1:54681的消息内容：来自客户端的第0条消息来自客户端的第1条消息来自客户端的第2条消息来自客户端的第3条消息来自客户端的第4条消息-----------------------------------连接成功，处理客户端：/127.0.0.1:54686收到客户端/127.0.0.1:54686的消息内容：来自客户端的第0条消息来自客户端的第1条消息来自客户端的第2条消息来自客户端的第3条消息来自客户端的第4条消息-----------------------------------连接成功，处理客户端：/127.0.0.1:54687收到客户端/127.0.0.1:54687的消息内容：来自客户端的第0条消息来自客户端的第1条消息来自客户端的第2条消息来自客户端的第3条消息来自客户端的第4条消息----------------------------------- 可以看到，消息是按照顺序，一个一个连接进来，然后完成处理的，至于后面的消息为什么会被合并成一个，也是这个原因，因为阻塞，所以等第一个连接逐条输出完成后，第二个连接进来，这时很可能客户端的SocketChannel已经将十条消息全部写入channel，等第一个连接处理完成后，接到第二条消息时就已经是全部的消息了，因此一次性输出，后面的合并也是这个原因（主要客户端使用NIO实现，因此写和连接服务不会发生阻塞，因此在第次个请求服务端还在处理时，其余的客户端数据也在执行并写入通道，最终服务端处理完第一个连接，然后继续接收第二个连接时，数据便是完整的5条数据了）。 上面的服务端是一个典型的阻塞IO的服务，accept在没有连接进来时会发生阻塞，read在客户端连接没关闭，且不再写消息时，服务端的read将一直处于读等待状态并阻塞，直到收到新的消息转为读就绪才会继续往下执行（这就是上面例子里第一个进来的连接可以逐条输出的原因），完全串行化，过程如下图： 下面，来改造下服务端，让其处理能力更好一些，除了accept，下面的处理逻辑全部交给线程池处理： 1234567891011121314151617181920212223while (true) { Socket clntSocket = serverSocket.accept(); //探听有没有新的客户端连接进来，没有就阻塞 SocketAddress clientAddress = clntSocket.getRemoteSocketAddress(); //通过跟服务连接上的客户端socket，拿到客户端地址 System.out.println(\"连接成功，处理客户端：\" + clientAddress); ctp.execute(() -&gt; { int recvMsgSize = 0; InputStream in = null; //数据流 try { in = clntSocket.getInputStream(); while ((recvMsgSize = in.read(recvBuf)) != -1) { //读取发送的数据，当客户端未断开连接，且不往服务端发数据的时候，说明一直处于准备读的状态，会一直阻塞下去，直到有数据写入（读就绪） byte[] temp = new byte[recvMsgSize]; System.arraycopy(recvBuf, 0, temp, 0, recvMsgSize); System.out.println(\"收到客户端\" + clientAddress + \"的消息内容：\" + new String(temp)); //打印消息 } System.out.println(\"-----------------------------------\"); } catch (IOException e) { e.printStackTrace(); } }); } 代码块3 运行结果： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970连接成功，处理客户端：/127.0.0.1:55259连接成功，处理客户端：/127.0.0.1:55265连接成功，处理客户端：/127.0.0.1:55266连接成功，处理客户端：/127.0.0.1:55257连接成功，处理客户端：/127.0.0.1:55260连接成功，处理客户端：/127.0.0.1:55258连接成功，处理客户端：/127.0.0.1:55261连接成功，处理客户端：/127.0.0.1:55262连接成功，处理客户端：/127.0.0.1:55263连接成功，处理客户端：/127.0.0.1:55264收到客户端/127.0.0.1:55265的消息内容：来自客户端的第0条消息收到客户端/127.0.0.1:55266的消息内容：来自客户端的第0条消息收到客户端/127.0.0.1:55258的消息内容：来自客户端的第0条消息收到客户端/127.0.0.1:55257的消息内容：来自客户端的第0条消息收到客户端/127.0.0.1:55261的消息内容：来自客户端的第0条消息收到客户端/127.0.0.1:55262的消息内容：来自客户端的第0条消息收到客户端/127.0.0.1:55263的消息内容：来自客户端的第0条消息收到客户端/127.0.0.1:55260的消息内容：来自客户端的第0条消息收到客户端/127.0.0.1:55259的消息内容：来自客户端的第0条消息收到客户端/127.0.0.1:55264的消息内容：来自客户端的第0条消息收到客户端/127.0.0.1:55265的消息内容：来自客户端的第1条消息收到客户端/127.0.0.1:55266的消息内容：来自客户端的第1条消息收到客户端/127.0.0.1:55258的消息内容：来自客户端的第1条消息收到客户端/127.0.0.1:55257的消息内容：来自客户端的第1条消息收到客户端/127.0.0.1:55261的消息内容：来自客户端的第1条消息收到客户端/127.0.0.1:55260的消息内容：来自客户端的第1条消息收到客户端/127.0.0.1:55262的消息内容：来自客户端的第1条消息收到客户端/127.0.0.1:55263的消息内容：来自客户端的第1条消息收到客户端/127.0.0.1:55259的消息内容：来自客户端的第1条消息收到客户端/127.0.0.1:55264的消息内容：来自客户端的第1条消息收到客户端/127.0.0.1:55266的消息内容：来自客户端的第2条消息收到客户端/127.0.0.1:55262的消息内容：来自客户端的第2条消息收到客户端/127.0.0.1:55261的消息内容：来自客户端的第2条消息收到客户端/127.0.0.1:55260的消息内容：来自客户端的第2条消息收到客户端/127.0.0.1:55263的消息内容：来自客户端的第2条消息收到客户端/127.0.0.1:55257的消息内容：来自客户端的第2条消息收到客户端/127.0.0.1:55265的消息内容：来自客户端的第2条消息收到客户端/127.0.0.1:55258的消息内容：来自客户端的第2条消息收到客户端/127.0.0.1:55259的消息内容：来自客户端的第2条消息收到客户端/127.0.0.1:55264的消息内容：来自客户端的第2条消息收到客户端/127.0.0.1:55258的消息内容：来自客户端的第3条消息收到客户端/127.0.0.1:55266的消息内容：来自客户端的第3条消息收到客户端/127.0.0.1:55257的消息内容：来自客户端的第3条消息收到客户端/127.0.0.1:55262的消息内容：来自客户端的第3条消息收到客户端/127.0.0.1:55261的消息内容：来自客户端的第3条消息收到客户端/127.0.0.1:55263的消息内容：来自客户端的第3条消息收到客户端/127.0.0.1:55265的消息内容：来自客户端的第3条消息收到客户端/127.0.0.1:55260的消息内容：来自客户端的第3条消息收到客户端/127.0.0.1:55264的消息内容：来自客户端的第3条消息收到客户端/127.0.0.1:55259的消息内容：来自客户端的第3条消息收到客户端/127.0.0.1:55266的消息内容：来自客户端的第4条消息收到客户端/127.0.0.1:55265的消息内容：来自客户端的第4条消息-----------------------------------收到客户端/127.0.0.1:55263的消息内容：来自客户端的第4条消息收到客户端/127.0.0.1:55261的消息内容：来自客户端的第4条消息-----------------------------------收到客户端/127.0.0.1:55260的消息内容：来自客户端的第4条消息-----------------------------------收到客户端/127.0.0.1:55262的消息内容：来自客户端的第4条消息-----------------------------------收到客户端/127.0.0.1:55257的消息内容：来自客户端的第4条消息----------------------------------------------------------------------收到客户端/127.0.0.1:55258的消息内容：来自客户端的第4条消息----------------------------------------------------------------------收到客户端/127.0.0.1:55264的消息内容：来自客户端的第4条消息-----------------------------------收到客户端/127.0.0.1:55259的消息内容：来自客户端的第4条消息----------------------------------- 消息被分开了，接收连接虽然仍然是串行，但实际的处理速度在多线程的帮助下已经比之前快很多了，流程如下图： 三、BIO总结综合看下来，传统的阻塞IO，按照图2的方式进行，虽然利用多线程避免了read等操作的阻塞对accept的影响，提高了处理效率，但想象下，如果现在存在高并发的情况，图2的模型如果不使用线程池，就会创建大量线程，会发生大量的线程上下文切换，影响整体效率，并且会影响新的线程，如果使用线程池，虽然某种程度上避免了线程的创建和上下文切换的量级，但是在大量并发的场景下，会发生排队，一旦发生排队，紧接着就会影响到accept。","link":"/2019/03/08/Java%20NIO%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%B0%E5%BD%95%EF%BC%88%E5%9B%9B%EF%BC%89%EF%BC%9A%20SocketChannel%E4%B8%8EBIO%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"title":"Kingdom Rush Origins","text":"中学时玩的一款游戏，当时玩的应该是初版，今天下午在steam下载了最新版-起源，感觉游戏画面很舒服，风格也是以前的样子，一款休闲的塔防游戏 Kingdom Rush发展史： Kingdom Rush Origins游戏截图：","link":"/2019/04/13/Kingdom%20Rush%20Origins/"},{"title":"Redis小记-内存解析&内存消耗篇","text":"前置：redis内存指标 注：本文默认读者已初步学会使用redis了。 首先我们通过info命令查看相关指标，其中几个memory的重要指标整理出来如下： 属性 解释 used_memory redis内部存储的所有数据的内存总占用量（自身内存+对象内存+缓冲内存） used_memory_ress redis进程占用的总物理内存 mem_fragmentation_ratio used_memory_ress与used_memory的比值，即为内存碎片率 mem_allocator 内存分配器，默认为jemalloc 表1 一、碎片率 当内存碎片率 &gt; 1时，说明redis进程占用物理内存的总量大于Redis实际存储数据（表1第一行）的内存占用量，溢出来的部分内存被内存碎片消耗，如果溢出部分过大，则说明内存碎片率严重。 相反的，如果碎片率 &lt; 1时，则说明Redis存储的数据总量已经超出了redis进程占用内存的总量，造成这种情况是因为操作系统把Redis内存交换至硬盘导致（swap），由于硬盘读取速度远远慢与内存，因此这种情况下redis性能极差，可能出现僵死。 二、redis内存消耗的几个来源2.1：自身内存redis启动后自身运行所需内存； 2.2：对象内存内存占用最大的一部分，这里面存储的就是用户自身的数据（业务数据），数据以key-value类型存储，内存消耗可表示为：key内存+value内存。 2.3：缓冲内存主要由客户端缓冲区+复制积压缓冲区+AOF缓冲区组成，具体解释如下： 客户端缓冲区指的是所有接入redis服务器的TCP连接的输入和输出缓冲，输入缓冲无法被控制，最大空间为1G，超过立即断开连接，输出缓冲通过client-output-buffer-limit控制。 复制积压缓冲区指的是redis在2.8版本以后提供了一块可以重复利用的固定大小的缓冲区，用来实现部分复制功能，使用repl-backlog-size参数控制，默认1MB（主从结构下，主节点只存在一个该缓冲区，从节点共用，那时可以设置较大的缓冲区空间），该缓冲区可以避免全量复制。 AOF缓冲区用于存储在redis重写期间保存最近的写入命令，无法控制，通常取决于AOF重写时间以及写入命令量，一般情况下很小。 2.4：内存碎片redis默认的内存分配器是jemalloc，可选的还有glibc和tcmalloc；内存分配器为了更好的管理以及重复利用内存，分配策略一般采用固定范围的内存块进行分配；因此，我们在存储一块5kb的内容时，内存分配器可能会为我们分配8kb的块存储，剩下的3kb不能再次分配给其他对象存储，因而沦为了内存碎片；jemalloc对碎片化问题做了优化，一般来讲碎片化率保持在1.03左右。 可能造成内存碎片率过高的场景： 频繁的更新操作，例如频繁对已存在的键做append、setrange等操作； 大量过期键删除，键对象过期删除后释放的空间无法得到充分的利用，导致碎片率上升。 解决办法： 数据对齐，尽量采用数字类型或固定长度的字符串（大部分业务场景不满足这种方式）； 重启，重启节点可以使内存重整理，利用高可用的结构（节点集群+主从结构），将碎片率过高的节点主节点转换为从节点，然后进行安全重启。 2.5：子进程内存消耗子进程内存消耗指的是执行AOF/RDB重写时redis创建的子进程内存消耗；redis执行fork操作产生的子进程内存占用量对外表现为与父进程相同，理论上需要一倍的物理内存来完成重写的操作。但是linux具备写时复制技术（copy-on-write），父子进程会共享相同的物理内存页，当父进程处理写请求时会对需要修改的页复制出一份副本来完成写操作，而子进程依然读取fork时整个父进程的内存快照，总结： 子进程并不需要消耗一倍的父进程内存，实际消耗根据期间写入命令量决定，但依然要预留出一些内存防止溢出； 需要设置sysctl vm.overcommit_memory = 1允许内核可以分配所有的物理内存，防止redis进程执行fork时因剩余内存不足导致失败； 排查当前系统是否支持开启THP，如果开启建议关闭，防止copy-on-write期间内存过度消耗。","link":"/2017/08/12/Redis%E5%B0%8F%E8%AE%B0-%E5%86%85%E5%AD%98%E8%A7%A3%E6%9E%90&%E5%86%85%E5%AD%98%E6%B6%88%E8%80%97%E7%AF%87/"},{"title":"ThreadLocal系列（一）-ThreadLocal的使用及原理解析","text":"项目中我们如果想要某个对象在程序运行中的任意位置获取到，就需要借助ThreadLocal来实现，这个对象称作线程的本地变量，下面就介绍下ThreadLocal是如何做到线程内本地变量传递的， 一、基本使用先来看下基本用法： 1234567891011121314private static ThreadLocal tl = new ThreadLocal&lt;&gt;();public static void main(String[] args) throws Exception { tl.set(1); System.out.println(String.format(\"当前线程名称: %s, main方法内获取线程内数据为: %s\", Thread.currentThread().getName(), tl.get())); fc(); new Thread(ThreadLocalTest::fc).start();}private static void fc() { System.out.println(String.format(\"当前线程名称: %s, fc方法内获取线程内数据为: %s\", Thread.currentThread().getName(), tl.get()));} 代码块1 运行结果： 123当前线程名称: main, main方法内获取线程内数据为: 1当前线程名称: main, fc方法内获取线程内数据为: 1当前线程名称: Thread-0, fc方法内获取线程内数据为: null 可以看到，main线程内任意地方都可以通过ThreadLocal获取到当前线程内被设置进去的值，而被异步出去的fc调用，却由于替换了执行线程，而拿不到任何数据值，那么我们现在再来改造下上述代码，在异步发生之前，给Thread-0线程也设置一个上下文数据： 12345678910111213141516171819private static ThreadLocal tl = new ThreadLocal&lt;&gt;(); public static void main(String[] args) throws Exception { tl.set(1); System.out.println(String.format(\"当前线程名称: %s, main方法内获取线程内数据为: %s\", Thread.currentThread().getName(), tl.get())); fc(); new Thread(()-&gt;{ tl.set(2); //在子线程里设置上下文内容为2 fc(); }).start(); Thread.sleep(1000L); //保证下面fc执行一定在上面异步代码之后执行 fc(); //继续在主线程内执行，验证上面那一步是否对主线程上下文内容造成影响 } private static void fc() { System.out.println(String.format(\"当前线程名称: %s, fc方法内获取线程内数据为: %s\", Thread.currentThread().getName(), tl.get())); } 代码块2 运行结果为： 1234当前线程名称: main, main方法内获取线程内数据为: 1当前线程名称: main, fc方法内获取线程内数据为: 1当前线程名称: Thread-0, fc方法内获取线程内数据为: 2当前线程名称: main, fc方法内获取线程内数据为: 1 可以看到，主线程和子线程都可以获取到自己的那份上下文里的内容，而且互不影响。 二、原理分析ok，上面通过一个简单的例子，我们可以了解到ThreadLocal（以下简称TL）具体的用法，这里先不讨论它实质上能给我们带来什么好处，先看看其实现原理，等这些差不多了解完了，我再通过我曾经做过的一个项目，去说明TL的作用以及在企业级项目里的用处。 我以前在不了解TL的时候，想着如果让自己实现一个这种功能的轮子，自己会怎么做，那时候的想法很单纯，觉得通过一个Map就可以解决，Map的key设置为Thread.currentThread()，value设置为当前线程的本地变量即可，但后来想想就觉得不太现实了，实际项目中可能存在大量的异步线程，对于内存的开销是不可估量的，而且还有个严重的问题，线程是运行结束后就销毁的，如果按照上述的实现方案，map内是一直持有这个线程的引用的，导致明明执行结束的线程对象不能被jvm回收，造成内存泄漏，时间久了，会直接OOM。 所以，java里的实现肯定不是这么简单的，下面，就来看看java里的具体实现吧。 先来了解下，TL的基本实现，为了避免上述中出现的问题，TL实际上是把我们设置进去的值以k-v的方式放到了每个Thread对象内（TL对象做k，设置的值做v），也就是说，TL对象仅仅起到一个标记、对Thread对象维护的map赋值的作用。 先从set方法看起： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public void set(T value) { Thread t = Thread.currentThread(); //获取当前线程 ThreadLocal.ThreadLocalMap map = getMap(t); //获取到当前线程持有的ThreadLocalMap对象 if (map != null) map.set(this, value); //直接set值，具体方法在下面 else createMap(t, value); // 为空就给当前线程创建一个ThreadLocalMap对象，赋值给Thread对象，具体方法在下面 } ThreadLocal.ThreadLocalMap getMap(Thread t) { return t.threadLocals; //每个线程都有一个ThreadLocalMap，key为TL对象（其实是根据对象hash计算出来的值），value为该线程在此TL对象下存储的内容值 } private void set(ThreadLocal&lt;?&gt; key, Object value) { ThreadLocal.ThreadLocalMap.Entry[] tab = table; //获取存储k-v对象的数组（散列表） int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); //根据TL对象的hashCode（也是特殊计算出来的，保证每个TL对象的hashCode不同）计算出下标 for (ThreadLocal.ThreadLocalMap.Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) { //线性探查法解决哈希冲突问题，发现下标i已经有Entry了，则就查看i+1位置处是否有值，以此类推 ThreadLocal&lt;?&gt; k = e.get(); //获取k if (k == key) { //若k就是当前TL对象，则直接为其value赋值 e.value = value; return; } if (k == null) { //若k为空，则认为是可回收的Entry，则利用当前k和value组成新的Entry替换掉该可回收Entry replaceStaleEntry(key, value, i); return; } } //for循环执行完没有终止程序，说明遇到了空槽，这个时候直接new对象赋值即可 tab[i] = new ThreadLocal.ThreadLocalMap.Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) //这里用来清理掉k为null的废弃Entry rehash(); //如果没有发生清除Entry并且size超过阈值（阈值 = 最大长度 * 2/3），则进行扩容 } //直接为当前Thread初始化它的ThreadLocalMap对象 void createMap(Thread t, T firstValue) { t.threadLocals = new ThreadLocal.ThreadLocalMap(this, firstValue); } ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) { table = new ThreadLocal.ThreadLocalMap.Entry[INITIAL_CAPACITY]; //初始化数组 int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); //计算初始位置 table[i] = new ThreadLocal.ThreadLocalMap.Entry(firstKey, firstValue); //因为初始化不存在hash冲突，直接new size = 1; setThreshold(INITIAL_CAPACITY); //给阈值赋值，上面已经提及，阈值 = 最大长度 * 2/3 } 代码块3 通过上述代码，我们大致了解了TL在set值的时候发生的一些操作，结合之前说的，我们可以确定的是，TL其实对于线程来说，只是一个标识，而真正线程的本地变量被保存在每个线程对象的ThreadLocalMap里，这个map里维护着一个Entry[]的数组（散列表），Entry是个k-v结构的对象（如图1-1），k为TL对象，v为对应TL保存在该线程内的本地变量值，值得注意的是，这里的k针对TL对象的引用是个弱引用，来看下源码： 123456789static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; { /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) { super(k); value = v; } } 代码块4 为什么这里需要弱引用呢？我们先来看一张图，结合上面的介绍和这张图，来了解TL和Thread间的关系： 图中虚线表示弱引用，那么为什么要这么做呢？ 简单来说，一个TL对象被创建出来，并且被一个线程放到自己的ThreadLocalMap里，假如TL对象失去原有的强引用，但是该线程还没有死亡，如果k不是弱引用，那么就意味着TL并不能被回收，现在k为弱引用，那么在TL失去强引用的时候，gc可以直接回收掉它，弱引用失效，这就是上面代码里会进行检查，k=null的清除释放内存的原因（这个可以参考下面expungeStaleEntry方法，而且set、get、remove都会调用该方法，这也是TL防止内存泄漏所做的处理）。 综上，简单来说这个弱引用就是用来解决由于使用TL不当导致的内存泄漏问题的，假如没有弱引用，那么你又用到了线程池（池化后线程不会被销毁），然后TL对象又是局部的，那么就会导致线程池内线程里的ThreadLocalMap存在大量的无意义的TL对象引用，造成过多无意义的Entry对象，因为即便调用了set、get等方法检查k=null，也没有作用，这就导致了内存泄漏，长时间这样最终可能导致OOM，所以TL的开发者为了解决这种问题，就将ThreadLocalMap里对TL对象的引用改为弱引用，一旦TL对象失去强引用，TL对象就会被回收，那么这里的弱引用指向的值就为null，结合上面说的，调用操作方法时会检查k=null的Entry进行回收，从而避免了内存泄漏的可能性。 因为TL解决了内存泄漏的问题，因此即便是局部变量的TL对象且启用线程池技术，也比较难造成内存泄漏的问题，而且我们经常使用的场景就像一开始的示例代码一样，会初始化一个全局的static的TL对象，这就意味着该对象在程序运行期间都不会存在强引用消失的情况，我们可以利用不同的TL对象给不同的Thread里的ThreadLocalMap赋值，通常会set值（覆盖原有值），因此在使用线程池的时候也不会造成问题，异步开始之前set值，用完以后remove，TL对象可以多次得到使用，启用线程池的情况下如果不这样做，很可能业务逻辑也会出问题（一个线程存在之前执行程序时遗留下来的本地变量，一旦这个线程被再次利用，get时就会拿到之前的脏值）； 说完了set，我们再来看下get： 123456789101112131415161718192021222324252627282930313233343536373839404142434445public T get() { Thread t = Thread.currentThread(); ThreadLocal.ThreadLocalMap map = getMap(t); //获取线程内的ThreadLocalMap对象 if (map != null) { ThreadLocal.ThreadLocalMap.Entry e = map.getEntry(this); //根据当前TL对象（key）获取对应的Entry if (e != null) { @SuppressWarnings(\"unchecked\") T result = (T)e.value; return result; //直接返回value即可 } } return setInitialValue(); //如果发现当前线程还没有ThreadLocalMap对象，则进行初始化 } private ThreadLocal.ThreadLocalMap.Entry getEntry(ThreadLocal&lt;?&gt; key) { int i = key.threadLocalHashCode &amp; (table.length - 1); //计算下标 ThreadLocal.ThreadLocalMap.Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) //根据下标获取的Entry对象如果key也等于当前TL对象，则直接返回结果即可 return e; else return getEntryAfterMiss(key, i, e); //上面说过，有些情况下存在下标冲突的问题，TL是通过线性探查法来解决的，所以这里也一样，如果上面没找到，则继续通过下标累加的方式继续寻找 } private ThreadLocal.ThreadLocalMap.Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, ThreadLocal.ThreadLocalMap.Entry e) { ThreadLocal.ThreadLocalMap.Entry[] tab = table; int len = tab.length; while (e != null) { ThreadLocal&lt;?&gt; k = e.get(); //继续累加下标的方式一点点的往下找 if (k == key) //找到了就返回出去结果 return e; if (k == null) //这里也会检查k==null的Entry，满足就执行删除操作 expungeStaleEntry(i); else //否则继续累加下标查找 i = nextIndex(i, len); e = tab[i]; } return null; //找不到返回null } //这里也放一下nextIndex方法 private static int nextIndex(int i, int len) { return ((i + 1 &lt; len) ? i + 1 : 0); } 代码块5 最后再来看看remove方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public void remove() { ThreadLocal.ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this); //清除掉当前线程ThreadLocalMap里以当前TL对象为key的Entry } private void remove(ThreadLocal&lt;?&gt; key) { ThreadLocal.ThreadLocalMap.Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); //计算下标 for (ThreadLocal.ThreadLocalMap.Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) { if (e.get() == key) { //找到目标Entry e.clear(); //清除弱引用 expungeStaleEntry(i); //通过该方法将自己清除 return; } } } private int expungeStaleEntry(int staleSlot) { //参数为目标下标 ThreadLocal.ThreadLocalMap.Entry[] tab = table; int len = tab.length; tab[staleSlot].value = null; //首先将目标value清除 tab[staleSlot] = null; size--; // Rehash until we encounter null ThreadLocal.ThreadLocalMap.Entry e; int i; // 由目标下标开始往后逐个检查，k==null的清除掉，不等于null的要进行rehash for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) { ThreadLocal&lt;?&gt; k = e.get(); if (k == null) { e.value = null; tab[i] = null; size--; } else { int h = k.threadLocalHashCode &amp; (len - 1); if (h != i) { tab[i] = null; // Unlike Knuth 6.4 Algorithm R, we must scan until // null because multiple entries could have been stale. while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; } } } return i; } 代码块6 目前主要方法set、get、remove已经介绍完了，包含其内部存在的弱引用的作用，以及实际项目中建议的用法，以及为什么要这样用，也进行了简要的说明，下面一篇会进行介绍InheritableThreadLocal的用法以及其原理性分析。","link":"/2019/02/15/ThreadLocal%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89-ThreadLocal%E7%9A%84%E4%BD%BF%E7%94%A8%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/"},{"title":"ThreadLocal系列（二）-InheritableThreadLocal的使用及原理解析","text":"一、基本使用我们继续来看之前写的例子： 123456789101112131415161718private static ThreadLocal tl = new ThreadLocal&lt;&gt;();public static void main(String[] args) throws Exception { tl.set(1); System.out.println(String.format(\"当前线程名称: %s, main方法内获取线程内数据为: %s\", Thread.currentThread().getName(), tl.get())); fc(); new Thread(() -&gt; { fc(); }).start(); Thread.sleep(1000L); //保证下面fc执行一定在上面异步代码之后执行 fc(); //继续在主线程内执行，验证上面那一步是否对主线程上下文内容造成影响 } private static void fc() { System.out.println(String.format(\"当前线程名称: %s, fc方法内获取线程内数据为: %s\", Thread.currentThread().getName(), tl.get())); } 代码块1 输出为： 1234当前线程名称: main, main方法内获取线程内数据为: 1当前线程名称: main, fc方法内获取线程内数据为: 1当前线程名称: Thread-0, fc方法内获取线程内数据为: null当前线程名称: main, fc方法内获取线程内数据为: 1 我们会发现，父线程的本地变量是无法传递给子线程的，这当然是正常的，因为线程本地变量来就不应该相互有交集，但是有些时候，我们的确是需要子线程里仍然可以获取到父线程里的本地变量，现在就需要借助TL的一个子类：InheritableThreadLocal（下面简称ITL），来完成上述要求 现在我们将例子里的 1private static ThreadLocal tl = new ThreadLocal&lt;&gt;(); 代码块2 改为： 1private static ThreadLocal tl = new InheritableThreadLocal&lt;&gt;(); 代码块3 然后我们再来运行下结果： 1234当前线程名称: main, main方法内获取线程内数据为: 1当前线程名称: main, fc方法内获取线程内数据为: 1当前线程名称: Thread-0, fc方法内获取线程内数据为: 1当前线程名称: main, fc方法内获取线程内数据为: 1 可以发现，子线程里已经可以获得父线程里的本地变量了。 结合之前讲的TL的实现，简单理解起来并不难，基本可以认定，是在创建子线程的时候，父线程的ThreadLocalMap（下面简称TLMap）里的值递给了子线程，子线程针对上述tl对象持有的k-v进行了copy，其实这里不是真正意义上对象copy，只是给v的值多了一条子线程TLMap的引用而已，v的值在父子线程里指向的均是同一个对象，因此任意线程改了这个值，对其他线程是可见的，为了验证这一点，我们可以改造以上测试代码： 12345678910111213141516171819202122232425private static ThreadLocal tl = new InheritableThreadLocal&lt;&gt;(); private static ThreadLocal tl2 = new InheritableThreadLocal&lt;&gt;(); public static void main(String[] args) throws Exception { tl.set(1); Hello hello = new Hello(); hello.setName(\"init\"); tl2.set(hello); System.out.println(String.format(\"当前线程名称: %s, main方法内获取线程内数据为: tl = %s，tl2.name = %s\", Thread.currentThread().getName(), tl.get(), tl2.get().getName())); fc(); new Thread(() -&gt; { Hello hello1 = tl2.get(); hello1.setName(\"init2\"); fc(); }).start(); Thread.sleep(1000L); //保证下面fc执行一定在上面异步代码之后执行 fc(); //继续在主线程内执行，验证上面那一步是否对主线程上下文内容造成影响 } private static void fc() { System.out.println(String.format(\"当前线程名称: %s, fc方法内获取线程内数据为: tl = %s，tl2.name = %s\", Thread.currentThread().getName(), tl.get(), tl2.get().getName())); } 代码块4 输出结果为： 1234当前线程名称: main, main方法内获取线程内数据为: tl = 1，tl2.name = init当前线程名称: main, fc方法内获取线程内数据为: tl = 1，tl2.name = init当前线程名称: Thread-0, fc方法内获取线程内数据为: tl = 1，tl2.name = init2当前线程名称: main, fc方法内获取线程内数据为: tl = 1，tl2.name = init2 可以确认，子线程里持有的本地变量跟父线程里那个是同一个对象。 二、原理分析通过上述的测试代码，基本可以确定父线程的TLMap被传递到了下一级，那么我们基本可以确认ITL是TL派生出来专门解决线程本地变量父传子问题的，那么下面通过源码来分析一下ITL到底是怎么完成这个操作的。 先来了解下Thread类，上节说到，其实最终线程本地变量是通过TLMap存储在Thread对象内的，那么来看下Thread对象内关于TLMap的两个属性： 12ThreadLocal.ThreadLocalMap threadLocals = null;ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; 代码块5 Thread类里其实有两个TLMap属性，第一个就是普通TL对象为其赋值，第二个则由ITL对象为其赋值，来看下TL的set方法的实现，这次针对该方法介绍下TL子类的相关方法实现： 123456789101112131415161718192021// TL的set方法，如果是子类的实现，那么获取（getMap）和初始化赋值（createMap）都是ITL对象里的方法 // 其余操作不变（因为hash计算、查找、扩容都是TLMap里需要做的，这里子类ITL只起到一个为Thread对象里哪个TLMap属性赋值的作用） public void set(T value) { Thread t = Thread.currentThread(); ThreadLocal.ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); } // ITL里getMap方法的实现 ThreadLocal.ThreadLocalMap getMap(Thread t) { return t.inheritableThreadLocals; //返回的其实是Thread对象的inheritableThreadLocals属性 } // ITL里createMap方法的实现 void createMap(Thread t, T firstValue) { // 也是给Thread的inheritableThreadLocals属性赋值 t.inheritableThreadLocals = new ThreadLocal.ThreadLocalMap(this, firstValue); } 代码块6 而inheritableThreadLocals里的信息通过Thread的init方法是可以被传递下去的： 123456789101112131415161718192021222324252627282930313233343536373839404142// 初始化一个Thread对象时的代码段（Thread类的init方法） Thread parent = currentThread(); if (parent.inheritableThreadLocals != null){ //可以看到，如果父线程存在inheritableThreadLocals的时候，会赋值给子线程（当前正在被初始化的线程） // 利用父线程的TLMap对象，初始化一个TLMap，赋值给自己的inheritableThreadLocals（这就意味着这个TLMap里的值会一直被传递下去） this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); } // 看下TL里对应的方法 static ThreadLocal.ThreadLocalMap createInheritedMap(ThreadLocal.ThreadLocalMap parentMap) { return new ThreadLocal.ThreadLocalMap(parentMap); //这里就开始初始化TLMap对象了 } // 根据parentMap来进行初始化子线程的TLMap对象 private ThreadLocalMap(ThreadLocal.ThreadLocalMap parentMap) { ThreadLocal.ThreadLocalMap.Entry[] parentTable = parentMap.table; //拿到父线程里的哈希表 int len = parentTable.length; setThreshold(len); // 设置阈值（具体方法参考上一篇） table = new ThreadLocal.ThreadLocalMap.Entry[len]; for (int j = 0; j &lt; len; j++) { ThreadLocal.ThreadLocalMap.Entry e = parentTable[j]; //将父线程里的Entry取出 if (e != null) { @SuppressWarnings(\"unchecked\") ThreadLocal&lt;Object&gt; key = (ThreadLocal&lt;Object&gt;) e.get(); //获取key if (key != null) { Object value = key.childValue(e.value); //获取value ThreadLocal.ThreadLocalMap.Entry c = new ThreadLocal.ThreadLocalMap.Entry(key, value); //根据k-v重新生成一个Entry int h = key.threadLocalHashCode &amp; (len - 1); //计算哈希值 while (table[h] != null) h = nextIndex(h, len); //线性探查解决哈希冲突问题（具体方法参考上一篇） table[h] = c; //找到合适的位置后进行赋值 size++; } } } } // ITL里的childValue的实现 protected T childValue(T parentValue) { return parentValue; //直接将父线程里的值返回 } 代码块7 三、ITL所带来的的问题看过上述代码后，现在关于ITL的实现我们基本上有了清晰的认识了，根据其实现性质，可以总结出在使用ITL时可能存在的问题： 3.1：线程不安全 写在前面：这里讨论的线程不安全对象不包含Integer等类型，因为这种对象被重新赋值，变掉的是整个引用，这里说的是那种不改变对象引用，直接可以修改其内容的对象（典型的就是自定义对象的set方法） 如果说线程本地变量是只读变量不会受到影响，但是如果是可写的，那么任意子线程针对本地变量的修改都会影响到主线程的本地变量（本质上是同一个对象），参考上面的第三个例子，子线程写入后会覆盖掉主线程的变量，也是通过这个结果，我们确认了子线程TLMap里变量指向的对象和父线程是同一个。 3.2：线程池中可能失效按照上述实现，在使用线程池的时候，ITL会完全失效，因为父线程的TLMap是通过init一个Thread的时候进行赋值给子线程的，而线程池在执行异步任务时可能不再需要创建新的线程了，因此也就不会再传递父线程的TLMap给子线程了。 针对上述2，我们来做个实验，来证明下猜想： 123456789101112131415161718192021// 为了方便观察，我们假定线程池里只有一个线程 private static ExecutorService executorService = Executors.newFixedThreadPool(1); private static ThreadLocal tl = new InheritableThreadLocal&lt;&gt;(); public static void main(String[] args) { tl.set(1); System.out.println(String.format(\"线程名称-%s, 变量值=%s\", Thread.currentThread().getName(), tl.get())); executorService.execute(()-&gt;{ System.out.println(String.format(\"线程名称-%s, 变量值=%s\", Thread.currentThread().getName(), tl.get())); }); executorService.execute(()-&gt;{ System.out.println(String.format(\"线程名称-%s, 变量值=%s\", Thread.currentThread().getName(), tl.get())); }); System.out.println(String.format(\"线程名称-%s, 变量值=%s\", Thread.currentThread().getName(), tl.get())); } 代码块8 输出结果为： 1234线程名称-main, 变量值=1线程名称-pool-1-thread-1, 变量值=1线程名称-main, 变量值=1线程名称-pool-1-thread-1, 变量值=1 会发现，并没有什么问题，和我们预想的并不一样，原因是什么呢？因为线程池本身存在一个初始化的过程，第一次使用的时候发现里面的线程数（worker数）少于核心线程数时，会进行创建线程，既然是创建线程，一定会执行Thread的init方法，参考上面提到的源码，在第一次启用线程池的时候，类似做了一次new Thread的操作，因此是没有什么问题的，父线程的TLMap依然可以传递下去。 现在我们改造下代码，把tl.set(1)改到第一次启用线程池的下面一行，然后再看看： 12345678910111213141516public static void main(String[] args) throws Exception{ System.out.println(String.format(\"线程名称-%s, 变量值=%s\", Thread.currentThread().getName(), tl.get())); executorService.execute(()-&gt;{ System.out.println(String.format(\"线程名称-%s, 变量值=%s\", Thread.currentThread().getName(), tl.get())); }); tl.set(1); // 等上面的线程池第一次启用完了，父线程再给自己赋值 executorService.execute(()-&gt;{ System.out.println(String.format(\"线程名称-%s, 变量值=%s\", Thread.currentThread().getName(), tl.get())); }); System.out.println(String.format(\"线程名称-%s, 变量值=%s\", Thread.currentThread().getName(), tl.get())); } 代码块9 输出结果为： 1234线程名称-main, 变量值=null线程名称-main, 变量值=1线程名称-pool-1-thread-1, 变量值=null线程名称-pool-1-thread-1, 变量值=null 很明显，第一次启用时没有递进去的值，在后续的子线程启动时就再也传递不进去了。 尾声但是，在实际项目中我们大多数采用线程池进行做异步任务，假如真的需要传递主线程的本地变量，使用ITL的问题显然是很大的，因为是有极大可能性拿不到任何值的，显然在实际项目中，ITL的位置实在是尴尬，所以在启用线程池的情况下，不建议使用ITL做值传递。为了解决这种问题，阿里做了transmittable-thread-local（TTL）来解决线程池异步值传递问题，下一篇，我们将会分析TTL的用法及原理。","link":"/2019/02/19/ThreadLocal%E7%B3%BB%E5%88%97%EF%BC%88%E4%BA%8C%EF%BC%89-InheritableThreadLocal%E7%9A%84%E4%BD%BF%E7%94%A8%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/"},{"title":"ThreadLocal系列（三）-TransmittableThreadLocal的使用及原理解析","text":"一、基本使用首先，TTL是用来解决ITL解决不了的问题而诞生的，所以TTL一定是支持父线程的本地变量传递给子线程这种基本操作的，ITL也可以做到，但是前面有讲过，ITL在线程池的模式下，就没办法再正确传递了，所以TTL做出的改进就是即便是在线程池模式下，也可以很好的将父线程本地变量传递下去，先来看个例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103// 需要注意的是，使用TTL的时候，要想传递的值不出问题，线程池必须得用TTL加一层代理（下面会讲这样做的目的） private static ExecutorService executorService = TtlExecutors.getTtlExecutorService(Executors.newFixedThreadPool(2)); private static ThreadLocal tl = new TransmittableThreadLocal&lt;&gt;(); //这里采用TTL的实现 public static void main(String[] args) { new Thread(() -&gt; { String mainThreadName = \"main_01\"; tl.set(1); executorService.execute(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之前(1), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }); executorService.execute(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之前(1), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }); executorService.execute(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之前(1), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }); sleep(1L); //确保上面的会在tl.set执行之前执行 tl.set(2); // 等上面的线程池第一次启用完了，父线程再给自己赋值 executorService.execute(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之后(2), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }); executorService.execute(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之后(2), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }); executorService.execute(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之后(2), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }); System.out.println(String.format(\"线程名称-%s, 变量值=%s\", Thread.currentThread().getName(), tl.get())); }).start(); new Thread(() -&gt; { String mainThreadName = \"main_02\"; tl.set(3); executorService.execute(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之前(3), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }); executorService.execute(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之前(3), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }); executorService.execute(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之前(3), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }); sleep(1L); //确保上面的会在tl.set执行之前执行 tl.set(4); // 等上面的线程池第一次启用完了，父线程再给自己赋值 executorService.execute(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之后(4), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }); executorService.execute(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之后(4), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }); executorService.execute(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之后(4), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }); System.out.println(String.format(\"线程名称-%s, 变量值=%s\", Thread.currentThread().getName(), tl.get())); }).start(); } private static void sleep(long time) { try { Thread.sleep(time); } catch (InterruptedException e) { e.printStackTrace(); } } 代码块1 运行结果： 1234567891011121314线程名称-Thread-2, 变量值=4本地变量改变之前(3), 父线程名称-main_02, 子线程名称-pool-1-thread-1, 变量值=3线程名称-Thread-1, 变量值=2本地变量改变之前(1), 父线程名称-main_01, 子线程名称-pool-1-thread-2, 变量值=1本地变量改变之前(1), 父线程名称-main_01, 子线程名称-pool-1-thread-1, 变量值=1本地变量改变之前(3), 父线程名称-main_02, 子线程名称-pool-1-thread-2, 变量值=3本地变量改变之前(3), 父线程名称-main_02, 子线程名称-pool-1-thread-2, 变量值=3本地变量改变之前(1), 父线程名称-main_01, 子线程名称-pool-1-thread-1, 变量值=1本地变量改变之后(2), 父线程名称-main_01, 子线程名称-pool-1-thread-2, 变量值=2本地变量改变之后(4), 父线程名称-main_02, 子线程名称-pool-1-thread-1, 变量值=4本地变量改变之后(4), 父线程名称-main_02, 子线程名称-pool-1-thread-1, 变量值=4本地变量改变之后(4), 父线程名称-main_02, 子线程名称-pool-1-thread-2, 变量值=4本地变量改变之后(2), 父线程名称-main_01, 子线程名称-pool-1-thread-1, 变量值=2本地变量改变之后(2), 父线程名称-main_01, 子线程名称-pool-1-thread-2, 变量值=2 程序有些啰嗦，为了说明问题，加了很多说明，但至少通过上面的例子，不难发现，两个主线程里都使用线程池异步，而且值在主线程里还发生过改变，测试结果展示一切正常，由此可以知道TTL在使用线程池的情况下，也可以很好的完成传递，而且不会发生错乱。 那么是不是对普通线程异步也有这么好的支撑呢？ 改造下上面的测试代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192private static ThreadLocal tl = new TransmittableThreadLocal&lt;&gt;(); public static void main(String[] args) { new Thread(() -&gt; { String mainThreadName = \"main_01\"; tl.set(1); new Thread(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之前(1), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }).start(); new Thread(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之前(1), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }).start(); new Thread(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之前(1), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }).start(); sleep(1L); //确保上面的会在tl.set执行之前执行 tl.set(2); // 等上面的线程池第一次启用完了，父线程再给自己赋值 new Thread(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之后(2), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }).start(); new Thread(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之后(2), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }).start(); new Thread(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之后(2), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }).start(); System.out.println(String.format(\"线程名称-%s, 变量值=%s\", Thread.currentThread().getName(), tl.get())); }).start(); new Thread(() -&gt; { String mainThreadName = \"main_02\"; tl.set(3); new Thread(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之前(3), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }).start(); new Thread(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之前(3), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }).start(); new Thread(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之前(3), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }).start(); sleep(1L); //确保上面的会在tl.set执行之前执行 tl.set(4); // 等上面的线程池第一次启用完了，父线程再给自己赋值 new Thread(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之后(4), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }).start(); new Thread(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之后(4), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }).start(); new Thread(() -&gt; { sleep(1L); System.out.println(String.format(\"本地变量改变之后(4), 父线程名称-%s, 子线程名称-%s, 变量值=%s\", mainThreadName, Thread.currentThread().getName(), tl.get())); }).start(); System.out.println(String.format(\"线程名称-%s, 变量值=%s\", Thread.currentThread().getName(), tl.get())); }).start(); } 代码块2 相比代码块1，这一段的异步全都是普通异步，未采用线程池的方式进行异步，看下运行结果： 1234567891011121314本地变量改变之后(4), 父线程名称-main_02, 子线程名称-Thread-14, 变量值=4本地变量改变之前(1), 父线程名称-main_01, 子线程名称-Thread-5, 变量值=1线程名称-Thread-1, 变量值=2本地变量改变之前(1), 父线程名称-main_01, 子线程名称-Thread-3, 变量值=1本地变量改变之后(2), 父线程名称-main_01, 子线程名称-Thread-11, 变量值=2本地变量改变之前(3), 父线程名称-main_02, 子线程名称-Thread-6, 变量值=3本地变量改变之后(4), 父线程名称-main_02, 子线程名称-Thread-12, 变量值=4本地变量改变之后(4), 父线程名称-main_02, 子线程名称-Thread-10, 变量值=4本地变量改变之前(3), 父线程名称-main_02, 子线程名称-Thread-8, 变量值=3本地变量改变之前(3), 父线程名称-main_02, 子线程名称-Thread-4, 变量值=3本地变量改变之前(1), 父线程名称-main_01, 子线程名称-Thread-7, 变量值=1线程名称-Thread-2, 变量值=4本地变量改变之后(2), 父线程名称-main_01, 子线程名称-Thread-9, 变量值=2本地变量改变之后(2), 父线程名称-main_01, 子线程名称-Thread-13, 变量值=2 ok，可以看到，达到了跟第一个测试一致的结果。 到这里，通过上述两个例子，TTL的基本使用，以及其解决的问题，我们已经有了初步的了解，下面我们来解析一下其内部原理，看看TTL是怎么完成对ITL的优化的。 二、原理分析先来看TTL里面的几个重要属性及方法 TTL定义： 1public class TransmittableThreadLocal extends InheritableThreadLocal 代码块3 可以看到，TTL继承了ITL，意味着TTL首先具备ITL的功能。 再来看看一个重要属性holder： 12345678910111213141516/** * 这是一个ITL类型的对象，持有一个全局的WeakMap（weakMap的key是弱引用，同TL一样，也是为了解决内存泄漏的问题），里面存放了TTL对象 * 并且重写了initialValue和childValue方法，尤其是childValue，可以看到在即将异步时父线程的属性是直接作为初始化值赋值给子线程的本地变量对象（TTL）的 */ private static InheritableThreadLocal&lt;Map&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt;&gt; holder = new InheritableThreadLocal&lt;Map&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt;&gt;() { @Override protected Map&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt; initialValue() { return new WeakHashMap&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt;(); } @Override protected Map&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt; childValue(Map&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt; parentValue) { return new WeakHashMap&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt;(parentValue); } }; 代码块4 再来看下set和get： 123456789101112131415161718192021222324//下面的方法均属于TTL类@Override public final void set(T value) { super.set(value); if (null == value) removeValue(); else addValue(); } @Override public final T get() { T value = super.get(); if (null != value) addValue(); return value; } private void removeValue() { holder.get().remove(this); //从holder持有的map对象中移除 } private void addValue() { if (!holder.get().containsKey(this)) { holder.get().put(this, null); //从holder持有的map对象中添加 } } 代码块5 TTL里先了解上述的几个方法及对象，可以看出，单纯的使用TTL是达不到支持线程池本地变量的传递的，通过第一部分的例子，可以发现，除了要启用TTL，还需要通过TtlExecutors.getTtlExecutorService包装一下线程池才可以，那么，下面就来看看在程序即将通过线程池异步的时候，TTL帮我们做了哪些操作（这一部分是TTL支持线程池传递的核心部分）： 首先打开包装类，看下execute方法在执行时做了些什么。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// 此方法属于线程池包装类ExecutorTtlWrapper@Override public void execute(@Nonnull Runnable command) { executor.execute(TtlRunnable.get(command)); //这里会把Rannable包装一层，这是关键，有些逻辑处理，需要在run之前执行 } // 对应上面的get方法，返回一个TtlRunnable对象，属于TtLRannable包装类 @Nullable public static TtlRunnable get(@Nullable Runnable runnable) { return get(runnable, false, false); } // 对应上面的get方法 @Nullable public static TtlRunnable get(@Nullable Runnable runnable, boolean releaseTtlValueReferenceAfterRun, boolean idempotent) { if (null == runnable) return null; if (runnable instanceof TtlEnhanced) { // 若发现已经是目标类型了（说明已经被包装过了）直接返回 // avoid redundant decoration, and ensure idempotency if (idempotent) return (TtlRunnable) runnable; else throw new IllegalStateException(\"Already TtlRunnable!\"); } return new TtlRunnable(runnable, releaseTtlValueReferenceAfterRun); //最终初始化 } // 对应上面的TtlRunnable方法 private TtlRunnable(@Nonnull Runnable runnable, boolean releaseTtlValueReferenceAfterRun) { this.capturedRef = new AtomicReference&lt;Object&gt;(capture()); //这里将捕获后的父线程本地变量存储在当前对象的capturedRef里 this.runnable = runnable; this.releaseTtlValueReferenceAfterRun = releaseTtlValueReferenceAfterRun; } // 对应上面的capture方法，用于捕获当前线程（父线程）里的本地变量，此方法属于TTL的静态内部类Transmitter @Nonnull public static Object capture() { Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt; captured = new HashMap&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt;(); for (TransmittableThreadLocal&lt;?&gt; threadLocal : holder.get().keySet()) { // holder里目前存放的k-v里的key，就是需要传给子线程的TTL对象 captured.put(threadLocal, threadLocal.copyValue()); } return captured; // 这里返回的这个对象，就是当前将要使用线程池异步出来的子线程，所继承的本地变量合集 } // 对应上面的copyValue，简单的将TTL对象里的值返回（结合之前的源码可以知道get方法其实就是获取当前线程（父线程）里的值，调用super.get方法） private T copyValue() { return copy(get()); } protected T copy(T parentValue) { return parentValue; } 代码块6 结合上述代码，大致知道了在线程池异步之前需要做的事情，其实就是把当前父线程里的本地变量取出来，然后赋值给Rannable包装类里的capturedRef属性，到此为止，下面会发生什么，我们大致上可以猜出来了，接下来大概率会在run方法里，将这些捕获到的值赋给子线程的holder赋对应的TTL值，那么我们继续往下看Rannable包装类里的run方法是怎么实现的： 1234567891011121314151617181920//run方法属于Rannable的包装类TtlRunnable@Override public void run() { Object captured = capturedRef.get(); // 获取由之前捕获到的父线程变量集 if (captured == null || releaseTtlValueReferenceAfterRun &amp;&amp; !capturedRef.compareAndSet(captured, null)) { throw new IllegalStateException(\"TTL value reference is released after run!\"); } /** * 重点方法replay，此方法用来给当前子线程赋本地变量，返回的backup是此子线程原来就有的本地变量值（原生本地变量，下面会详细讲）， * backup用于恢复数据（如果任务执行完毕，意味着该子线程会归还线程池，那么需要将其原生本地变量属性恢复） */ Object backup = replay(captured); try { runnable.run(); // 执行异步逻辑 } finally { restore(backup); // 结合上面对于replay的解释，不难理解，这个方法就是用来恢复原有值的 } } 代码块7 根据上述代码，我们看到了TTL在异步任务执行前，会先进行赋值操作（就是拿着异步发生时捕获到的父线程的本地变量，赋给自己），当任务执行完，就恢复原生的自己本身的线程变量值。 下面来具体看这俩方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677//下面的方法均属于TTL的静态内部类Transmittable@Nonnull public static Object replay(@Nonnull Object captured) { @SuppressWarnings(\"unchecked\") Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt; capturedMap = (Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt;) captured; //使用此线程异步时捕获到的父线程里的本地变量值 Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt; backup = new HashMap&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt;(); //当前线程原生的本地变量，用于使用完线程后恢复用 //注意：这里循环的是当前子线程原生的本地变量集合，与本方法相反，restore方法里循环这个holder是指：该线程运行期间产生的变量+父线程继承来的变量 for (Iterator&lt;? extends Map.Entry&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt;&gt; iterator = holder.get().entrySet().iterator(); iterator.hasNext(); ) { Map.Entry&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt; next = iterator.next(); TransmittableThreadLocal&lt;?&gt; threadLocal = next.getKey(); backup.put(threadLocal, threadLocal.get()); // 所有原生的本地变量都暂时存储在backup里，用于之后恢复用 /** * 检查，如果捕获到的线程变量里，不包含当前原生变量值，则从当前原生变量里清除掉，对应的线程本地变量也清掉 * 这就是为什么会将原生变量保存在backup里的原因，为了恢复原生值使用 * 那么，为什么这里要清除掉呢？因为从使用这个子线程做异步那里，捕获到的本地变量并不包含原生的变量，当前线程 * 在做任务时的首要目标，是将父线程里的变量完全传递给任务，如果不清除这个子线程原生的本地变量， * 意味着很可能会影响到任务里取值的准确性。 * * 打个比方，有ttl对象tl，这个tl在线程池的某个子线程里存在对应的值2，当某个主线程使用该子线程做异步任务时 * tl这个对象在当前主线程里没有值，那么如果不进行下面这一步的操作，那么在使用该子线程做的任务里就可以通过 * 该tl对象取到值2，不符合预期 */ if (!capturedMap.containsKey(threadLocal)) { iterator.remove(); threadLocal.superRemove(); } } // 这一步就是直接把父线程本地变量赋值给当前线程了（这一步起就刷新了holder里的值了，具体往下看该方法，在异步线程运行期间，还可能产生别的本地变量，比如在真正的run方法内的业务代码，再用一个tl对象设置一个值） setTtlValuesTo(capturedMap); // 这个方法属于扩展方法，ttl本身支持重写异步任务执行前后的操作，这里不再具体赘述 doExecuteCallback(true); return backup; } // 结合之前Rannable包装类的run方法来看，这个方法就是使用上面replay记录下的原生线程变量做恢复用的 public static void restore(@Nonnull Object backup) { @SuppressWarnings(\"unchecked\") Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt; backupMap = (Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt;) backup; // call afterExecute callback doExecuteCallback(false); // 注意，这里的holder取出来的，实际上是replay方法设置进去的关于父线程里的所有变量（结合上面来看，就是：该线程运行期间产生的变量+父线程继承来的变量） for (Iterator&lt;? extends Map.Entry&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt;&gt; iterator = holder.get().entrySet().iterator(); iterator.hasNext(); ) { Map.Entry&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt; next = iterator.next(); TransmittableThreadLocal&lt;?&gt; threadLocal = next.getKey(); /** * 同样的，如果子线程原生变量不包含某个父线程传来的对象，那么就删除，可以思考下，这里的清除跟上面replay里的有什么不同？ * 这里会把不属于原生变量的对象给删除掉（这里被删除掉的可能是父线程继承下来的，也可能是异步任务在执行时产生的新值） */ if (!backupMap.containsKey(threadLocal)) { iterator.remove(); threadLocal.superRemove(); } } // 同样调用这个方法，进行值的恢复 setTtlValuesTo(backupMap); } // 真正给当前子线程赋值的方法，对应上面的setTtlValuesTo方法 private static void setTtlValuesTo(@Nonnull Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt; ttlValues) { for (Map.Entry&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt; entry : ttlValues.entrySet()) { @SuppressWarnings(\"unchecked\") TransmittableThreadLocal&lt;Object&gt; threadLocal = (TransmittableThreadLocal&lt;Object&gt;) entry.getKey(); threadLocal.set(entry.getValue()); //赋值，注意，从这里开始，子线程的holder里的值会被重新赋值刷新，可以参照上面ttl的set方法的实现 } } 代码块8 ok，到这里基本上把TTL比较核心的代码看完了，下面整理下整个流程，这是官方给出的时序图： 上图第一行指的是类名称，下面的流程指的是类所做的事情，根据上面罗列出来的源码，结合这个时序图，可以比较直观一些的理解整个流程。 三、TTL中线程池子线程原生变量的产生这一节是为了验证上面replay和restore，现在通过一个例子来验证下，先把源码down下来，在源码的restore和replay上分别加上输出语句，遍历holder： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657//replay前后打印holder里面的值public static Object replay(@Nonnull Object captured) { @SuppressWarnings(\"unchecked\") Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt; capturedMap = (Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt;) captured; Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt; backup = new HashMap&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt;(); System.out.println(\"--------------------replay前置，当前拿到的holder里的TTL列表\"); for (Iterator&lt;? extends Map.Entry&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt;&gt; iterator = holder.get().entrySet().iterator(); iterator.hasNext(); ) { Map.Entry&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt; next = iterator.next(); TransmittableThreadLocal&lt;?&gt; threadLocal = next.getKey(); System.out.println(String.format(\"replay前置里拿到原生的ttl_k=%s, ttl_value=%s\", threadLocal.hashCode(), threadLocal.get())); } for...//代码省略，具体看上面 setTtlValuesTo(capturedMap); doExecuteCallback(true); System.out.println(\"--------------------reply后置，当前拿到的holder里的TTL列表\"); for (Iterator&lt;? extends Map.Entry&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt;&gt; iterator = holder.get().entrySet().iterator(); iterator.hasNext(); ) { Map.Entry&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt; next = iterator.next(); TransmittableThreadLocal&lt;?&gt; threadLocal = next.getKey(); System.out.println(String.format(\"replay后置里拿到原生的ttl_k=%s, ttl_value=%s\", threadLocal.hashCode(), threadLocal.get())); } return backup; }//restore前后打印holder里面的值public static void restore(@Nonnull Object backup) { @SuppressWarnings(\"unchecked\") Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt; backupMap = (Map&lt;TransmittableThreadLocal&lt;?&gt;, Object&gt;) backup; // call afterExecute callback doExecuteCallback(false); System.out.println(\"--------------------restore前置，当前拿到的holder里的TTL列表\"); for (Iterator&lt;? extends Map.Entry&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt;&gt; iterator = holder.get().entrySet().iterator(); iterator.hasNext(); ) { Map.Entry&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt; next = iterator.next(); TransmittableThreadLocal&lt;?&gt; threadLocal = next.getKey(); System.out.println(String.format(\"restore前置里拿到当前线程内变量，ttl_k=%s, ttl_value=%s\", threadLocal.hashCode(), threadLocal.get())); } for...//省略代码，具体具体看上面 setTtlValuesTo(backupMap); System.out.println(\"--------------------restore后置，当前拿到的holder里的TTL列表\"); for (Iterator&lt;? extends Map.Entry&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt;&gt; iterator = holder.get().entrySet().iterator(); iterator.hasNext(); ) { Map.Entry&lt;TransmittableThreadLocal&lt;?&gt;, ?&gt; next = iterator.next(); TransmittableThreadLocal&lt;?&gt; threadLocal = next.getKey(); System.out.println(String.format(\"restore后置里拿到当前线程内变量，ttl_k=%s, ttl_value=%s\", threadLocal.hashCode(), threadLocal.get())); } } 代码块9 代码这样做的目的，就是要说明线程池所谓的原生本地变量是怎么产生的，以及replay和restore是怎么设置和恢复的，下面来看个简单的例子： 123456789101112131415161718192021private static ExecutorService executorService = TtlExecutors.getTtlExecutorService(Executors.newFixedThreadPool(1)); private static ThreadLocal tl = new TransmittableThreadLocal(); private static ThreadLocal tl2 = new TransmittableThreadLocal(); public static void main(String[] args) throws InterruptedException { tl.set(1); tl2.set(2); executorService.execute(new Runnable() { @Override public void run() { try { Thread.sleep(1000L); } catch (InterruptedException e) { e.printStackTrace(); } } }); } 代码块10 运行结果如下： 123456789101112--------------------replay前置，当前拿到的holder里的TTL列表replay前置里拿到原生的ttl_k=1259475182, ttl_value=2replay前置里拿到原生的ttl_k=929338653, ttl_value=1--------------------reply后置，当前拿到的holder里的TTL列表replay后置里拿到原生的ttl_k=1259475182, ttl_value=2replay后置里拿到原生的ttl_k=929338653, ttl_value=1--------------------restore前置，当前拿到的holder里的TTL列表restore前置里拿到当前线程内变量，ttl_k=1259475182, ttl_value=2restore前置里拿到当前线程内变量，ttl_k=929338653, ttl_value=1--------------------restore后置，当前拿到的holder里的TTL列表restore后置里拿到当前线程内变量，ttl_k=1259475182, ttl_value=2restore后置里拿到当前线程内变量，ttl_k=929338653, ttl_value=1 我们会发现，原生值产生了，从异步开始，就确定了线程池里的线程具备了1和2的值，那么，再来改动下上面的测试代码： 12345678910111213141516171819202122232425262728293031public static void main(String[] args) throws InterruptedException { tl.set(1); executorService.execute(new Runnable() { @Override public void run() { try { Thread.sleep(100L); } catch (InterruptedException e) { e.printStackTrace(); } } }); Thread.sleep(1000L); tl2.set(2);//较第一次换下位置，换到第一次使用线程池后执行（这意味着下面这次异步不会再触发Thread的init方法了） System.out.println(\"---------------------------------------------------------------------------------\"); executorService.execute(new Runnable() { @Override public void run() { try { Thread.sleep(1000L); } catch (InterruptedException e) { e.printStackTrace(); } } }); } 代码块11 运行结果为： 12345678910111213141516171819--------------------replay前置，当前拿到的holder里的TTL列表replay前置里拿到原生的ttl_k=929338653, ttl_value=1--------------------reply后置，当前拿到的holder里的TTL列表replay后置里拿到原生的ttl_k=929338653, ttl_value=1--------------------restore前置，当前拿到的holder里的TTL列表restore前置里拿到当前线程内变量，ttl_k=929338653, ttl_value=1--------------------restore后置，当前拿到的holder里的TTL列表restore后置里拿到当前线程内变量，ttl_k=929338653, ttl_value=1-----------------------------------------------------------------------------------------------------replay前置，当前拿到的holder里的TTL列表replay前置里拿到原生的ttl_k=929338653, ttl_value=1--------------------reply后置，当前拿到的holder里的TTL列表replay后置里拿到原生的ttl_k=1020371697, ttl_value=2replay后置里拿到原生的ttl_k=929338653, ttl_value=1--------------------restore前置，当前拿到的holder里的TTL列表restore前置里拿到当前线程内变量，ttl_k=1020371697, ttl_value=2restore前置里拿到当前线程内变量，ttl_k=929338653, ttl_value=1--------------------restore后置，当前拿到的holder里的TTL列表restore后置里拿到当前线程内变量，ttl_k=929338653, ttl_value=1 可以发现，第一次异步时，只有一个值被传递了下去，然后第二次异步，新加了一个tl2的值，但是看第二次异步的打印，会发现，restore恢复后，仍然是第一次异步发生时放进去的那个tl的值。 通过上面的例子，基本可以确认，所谓线程池内线程的本地原生变量，其实是第一次使用线程时被传递进去的值，我们之前有说过TTL是继承至ITL的，之前的文章也说过，线程池第一次启用时是会触发Thread的init方法的，也就是说，在第一次异步时拿到的主线程的变量会被传递给子线程，作为子线程的原生本地变量保存起来，后续是replay操作和restore操作也是围绕着这个原生变量（即原生holder里的值）来进行设置、恢复的，设置的是当前父线程捕获到的本地变量，恢复的是子线程原生本地变量。 holder里持有的可以理解就是当前线程内的所有本地变量，当子线程将异步任务执行完毕后，会执行restore进行恢复原生本地变量，具体参照上面的代码和测试代码。 四、总结到这里基本上确认了TTL是如何进行线程池传值的，以及被包装的run方法执行异步任务之前，会使用replay进行设置父线程里的本地变量给当前子线程，任务执行完毕，会调用restore恢复该子线程原生的本地变量（目前原生本地变量的产生，就只碰到上述测试代码中的这一种情况，即线程第一次使用时通过ITL属性以及Thread的init方法传给子线程，还不太清楚有没有其他方式设置）。 其实，正常程序里想要完成线程池上下文传递，使用TL就足够了，我们可以效仿TTL包装线程池对象的原理，进行值传递，异步任务结束后，再remove，以此类推来完成线程池值传递，不过这种方式过于单纯，且要求上下文为只读对象，否则子线程存在写操作，就会发生上下文污染。 TTL项目地址（可以详细了解下它的其他特性和用法）：https://github.com/alibaba/transmittable-thread-local","link":"/2019/02/20/ThreadLocal%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%89%EF%BC%89-TransmittableThreadLocal%E7%9A%84%E4%BD%BF%E7%94%A8%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/"},{"title":"java实现二叉树","text":"定义一个节点下面最多拥有两个子节点，并且两个子节点分为左值和右值，左值比父节点要小，右值比父节点要大 java实现下面，我们来利用java实现一棵如下图中的二叉树： 大家可以根据我的描述分析一下这棵二叉树 下面就来写代码实现这棵二叉树： 首先是要建立一个节点类Node： 123456789101112131415161718192021222324252627282930313233343536package Tree;/** * 节点类 * @author javadaodechengxuyuan * */public class Node { private long value; private Node leftNode;//节点下面的左节点 private Node RightNode;//节点下面的右节点 //构造器 public Node(long value){ this.value=value; } public long getValue() { return value; } public void setValue(long value) { this.value = value; } public Node getLeftNode() { return leftNode; } public void setLeftNode(Node leftNode) { this.leftNode = leftNode; } public Node getRightNode() { return RightNode; } public void setRightNode(Node rightNode) { RightNode = rightNode; }} 代码块1 这是二叉树类，就是这个类用来操作节点类的： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package Tree;/** * @author javadaodechengxuyuan * 二叉树：每个节点有最多两个分叉， * 分别作为父节点的左值和右值，遵循左小右大的规则进行分叉 */public class Tree { private Node root; private Node current; private Node parent; /** * @author javadaodechengxuyuan * 为一颗二叉树添加节点 */ public void insert(long value){//为二叉树插入新的节点 //创建新的节点 Node newNode=new Node(value); //创建完后就该考虑把这个节点放在哪里了，下面这些代码就是用来判断将这个节点放在哪里的 if(root==null){ this.root=newNode;//如果root为空，那么第一次调用添加时应给root初始化 }else{ this.current=root;//初始化current while(true){//进入死循环，一直等到给newNode找到合适的位置时进行终止死循环 if(this.current.getValue()&gt;value){//比root小，放在左侧 this.parent=this.current;//让parent一直保留本次的current this.current=this.current.getLeftNode(); if(this.current==null){//如果当前的左值为空，那么就终止循环并赋值给这个左值 this.parent.setLeftNode(newNode);//将这个新节点放在这个位置 return;//最终找到合适位置，死循环终止 } }else{//比root大，放在右侧 this.parent=this.current;//让parent一直保留本次的current this.current=this.current.getRightNode();//将当前的节点重新赋值给下一次需要比较的节点 if(this.current==null){//如果当前的右值为空，那么就终止循环并赋值给这个左值 this.parent.setRightNode(newNode);//将这个新节点放在这个位置 return;//最终找到合适位置，死循环终止 } } } } } public Node getRoot() { return root; } public void setRoot(Node root) { this.root = root; }} 代码块2 这是测试类： 12345678910111213141516171819202122package Tree;/** * 测试类 * @author javadaodechengxuyuan * */public class Test { public static void main(String args[]){ Tree t=new Tree(); t.insert(10);//根节点 t.insert(20); t.insert(15); t.insert(9); t.insert(35); System.out.print(t.getRoot().getValue()+\"、\");//第0层：根节点 System.out.print(t.getRoot().getLeftNode().getValue()+\"、\");//第一层左值 System.out.print(t.getRoot().getRightNode().getValue()+\"、\");//第一层右值 System.out.print(t.getRoot().getRightNode().getLeftNode().getValue()+\"、\");//第二层左值 System.out.print(t.getRoot().getRightNode().getRightNode().getValue());//第二层右值 //输出结果应为：10、9、20、15、35 }} 代码块3 输出结果应该为： 110、9、20、15、35 这只是简单的插入功能，下一节我会写如何查找二叉树的节点以及删除节点、还有如何遍历一棵二叉树","link":"/2014/07/04/java%E5%AE%9E%E7%8E%B0%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"title":"java性能火焰图的生成","text":"一、前言开始之前，你需要准备的环境： Linux系统机器或者虚拟机一台，里面需要安装的软件：git、jdk、perl。 二、简单介绍java性能分析火焰图的所做的事情就是能够分析出java程序运行期间存在的性能问题，因为某段代码拖慢整个程序执行是不允许的，因此靠火焰图的绘制和分析就可以找出类似的“问题代码段”。 那么这个图是怎么来的呢？首先跟大多数监控系统一样，数据采集+前端绘图，这个图也是根据某些数据绘制而成的，绘图工具本篇文章采用FlameGraph，而负责收集这些数据的工具，本篇采用async-profiler，这个工具会在程序运行期间向jvm发送信号采集其运行期数据（简单来说就是通过该工具可以找出程序中占用CPU资源时间最长的代码块，这里async-profiler的实现使用了jvmti，戳这里简单了解一下），然后生成相应的数据格式文件，而FlameGraph则负责读取和解析数据文件生成对应的火焰图（svg文件）。 三、使用&amp;安装🔥3.1：环境搭建确认你的机器已经安装了git、jdk、perl、c++编译器，部分可参考：安装杂记 🔥3.2：clone相关项目下载下来所需要的两个项目（这里建议放到data目录下）： 12git clone https://github.com/jvm-profiling-tools/async-profilergit clone https://github.com/brendangregg/FlameGraph 🔥3.3：编译下载好以后，需要打开async-profiler文件，输入make指令进行编译： 12cd async-profilermake 🔥3.4：编写测试程序编译完成后，我们来写一个简单的java程序： 123456789101112131415161718192021222324public class Test { public static void main(String[] args) throws Exception { Test test = new Test(); while (true) { test.func1(); test.func2(); test.func3(); } } public void func1() throws Exception { //调用第一个方法，需要100ms Thread.sleep(100L); } public void func2() throws Exception { //调用第二个方法，需要500ms Thread.sleep(500L); } public void func3() throws Exception { //调用第三个方法，需要1500ms Thread.sleep(1500L); }} 代码块1 非常简单的一个java类，main方法里所做的事情也很简单，现在把这个文件搞到data目录下，javac命令编译，java命令启动。 然后找到这个java程序的进程id： 123ps -ef | grep javaroot 30937 17605 0 19:12 pts/0 00:00:00 java Testroot 30961 23135 0 19:12 pts/1 00:00:00 /bin/grep --color=auto java 可以确认此时Test类运行时的java进程pid = 30937，当然也可以使用jps命令直接查看java进程，效果是一样的。 🔥3.5：生成火焰图数据ok，上述步骤完成后，现在进入async-profiler那个项目的目录下，然后输入如下指令： 1./profiler.sh -d 60 -o collapsed -f /tmp/test_01.txt ${pid} 上面的-d表示的是持续时长，后面60代表持续采集时间60s，-o表示的是采集规范，这里用的是collapsed，-f后面的路径，表示的是数据采集后生成的数据存放的文件路径（这里放在了/tmp/test_01.txt），${pid}表示的是采集目标进程的pid，也就是上面提到的30937 回车运行，运行期间阻塞，知道约定时间完成。运行完成后，现在去tmp下看看有没有对应文件： 🔥3.6：生成svg文件上一步产生的文件里的内容，肉眼是很难看懂的，所以现在FlameGraph的作用就体现出来了，它可以读取该文件并生成直观的火焰图，现在进入该项目目录下面，执行如下语句： 1perl flamegraph.pl --colors=java /tmp/test_01.txt &gt; test_01.svg 因为是perl文件，这里使用perl指令运行该文件，后面--colors表示着色风格，这里是java，后面的是数据文件的路径，这里是刚刚上面生成的那个文件/tmp/test_01.txt，最后的test_01.svg就是最终生成的火焰图文件存放的路径和文件命名，这里是命名为test_01.svg并保存在当前路径，运行后看到该文件已经存在于当前目录下： 🔥3.7：展示现在下载下来该文件，使用浏览器打开，效果如下： 果然还是看不懂啊-_-|| 后续会更新这东西怎么看和分析，或者说我这篇文章里的java例子可能并不能很好的体现出什么。 续更续更，公司内部火焰图已经上线，通过更为复杂的业务场景生成的图反而看起来更容易理解一些，因为业务代码的调用也会打印出来，下面贴一下内部某业务系统火焰图： 这张图是在某个业务系统运行时，采样60s生成的火焰图，通过这样一张图可以看出，x轴为调用顺序，y轴为栈深，线条颜色无实际意义（并不是越红性能越差之类的），线条长度代表CPU执行该方法时所花费的时间占比，一般来说需要关注的就是栈顶，且宽度比较大的那个。因为一般处于栈顶的，而且宽度比较大的调用栈，说明其存在性能问题，这样分析的原因如下： 栈深度与y轴高度成正比，一般造成性能问题的都在调用栈的栈顶位置，因为栈顶位置的性能问题会间接拖慢整个调用栈，比如上图中每个栈底的线条都很长，这是因为越往上栈越深，对下层的影响就越大，可以简单抽象成方法调用：A调用B，B调用C，C慢会间接导致B慢，从而导致A慢，当然符合这种情况就适合之前说的看栈顶分析瓶颈的方法，如果A本身就慢呢？通过火焰图也是可以看出来的，比如栈底的线条宽度很宽，但是建立在该栈底的调用链上，线条都很窄，火焰图呈现┻型，那么就可以认定，栈底方法存在性能问题，一般情况下都是从栈顶看起，视情况而定~","link":"/2019/03/22/java%E6%80%A7%E8%83%BD%E7%81%AB%E7%84%B0%E5%9B%BE%E7%9A%84%E7%94%9F%E6%88%90/"},{"title":"【杂记】linux下各种软件安装方法（持续记录）","text":"1.安装jdk网上一堆说先从windows下压缩包，然后通过共享文件夹copy到linux系统里，然后解压安装，emmmmm 首先进入usr文件夹，新建java文件夹： 1mkdir java 直接通过wget命令下载压缩包（如果找不到wget工具，可以通过apt-get install wget安装此工具）： 1wget --no-cookies --no-check-certificate --header \"Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie\" \"http://download.oracle.com/otn-pub/java/jdk/8u141-b15/336fa29ff2bb4ef291e347e091f7f4a7/jdk-8u141-linux-x64.tar.gz\" 后面url需要按照自己需要调整。 进入所在文件夹（这里指java文件夹）解压： 1tar -zxvf jdk-8u141-linux-x64.tar.gz 解压好了如下： 12root@xxx-xxx-xxx-01:/usr/java # ls -a. .. jdk1.8.0_141 jdk-8u141-linux-x64.tar.gz 接着配置环境变量，输入指令： 1vim /etc/profile 然后编辑： 1234export JAVA_HOME=/usr/java/jdk1.8.0_141 export PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarexport JRE_HOME=$JAVA_HOME/jre 然后让其生效： 1source /etc/profile 最后进行测试看看是否生效了： 1234root@xxx-xxx1-xxx-01:~# java -versionjava version \"1.8.0_141\"Java(TM) SE Runtime Environment (build 1.8.0_141-b15)Java HotSpot(TM) 64-Bit Server VM (build 25.141-b15, mixed mode) 出现版本号，视为安装配置成功。 2.安装Perl1234567wget http://www.cpan.org/src/5.0/perl-5.26.1.tar.gztar zxvf perl-5.26.1.tar.gzcd perl-5.26.1./Configure -demakemake testmake install wget后面的路径可以按需更改。安装过程比较耗时间，安装完成后可通过perl -version查看是否安装成功。 3.tcpdump抓包工具12apt-get updateapt-get install tcpdump 抓包工具tcpdump可以抓到容器内的网络请求，具体用法如下： 1tcpdump -i any -A -n port 80 | grep -C 50 'path' 上面是抓取端口为80的网络交互，且过滤出包含path关键词的交互，展示50行。 比如你想抓取http请求，知道http请求端口是80，还知道http请求具体的path，那么就可以抓取一个接口的请求信息（包含请求报文、响应报文），redis等同理，知道端口，知道关键词，就可以抓到交互。 4.C++编译器1apt-get install g++ 一般用于编译c++程序，缺少这个编译器进行make编译c++代码时，会报g++: not found的错误。 5.zookeeper的安装&amp;启动先下载zookeeper的安装包，然后解压： 1tar -zxvf zookeeper-3.4.6.tar.gz 解压后进入该包路径，然后进入conf目录修改zoo_sample.cfg的名字为zoo.cfg： 1mv zoo_sample.cfg zoo.cfg 然后打开该文件： 12345678910111213141516171819202122232425262728# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial # synchronization phase can takeinitLimit=10# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just # example sakes.dataDir=/tmp/zookeeper# the port at which the clients will connectclientPort=2181# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the # administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to \"0\" to disable auto purge feature#autopurge.purgeInterval=1 重要解释： tickTime：这个时间是作为 Zookeeper服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime时间就会发送一个心跳。dataDir：顾名思义就是Zookeeper保存数据的目录，默认情况下，Zookeeper的日志文件是在bin目录下，有一个zookeeper.out文件。clientPort：这个端口就是客户端连接 Zookeeper服务器的端口，Zookeeper会监听这个端口，接受客户端的访问请求。伪集群模式下，这个端口需要配置成不同的。如果是多台虚拟机或者服务器下，则无需更改。 接下来，我们来标记下该zk节点的id（节点号），在dataDir显示的路径下新建myid文件，写上一个数字（1~255间），这里写的是1： 123vim myid1:wq 然后继续回到conf目录下，编辑zoo.cfg，在下面添加如下配置： 1server.1=xx.xx.xxx.xx:8881:7771 前面的server.1里的1就是之前在myid里写的id号，zk节点唯一标识，后面的xx.xx.xxx.xx标识本机ip； 再往后的8881表示的是这个服务器与集群中的 Leader 服务器交换信息的端口（自定义）； 再后面的7771表示的是万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，选出一个新的 Leader，而这个端口就是用来执行选举时服务器相互通信的端口。 接下来返回到zk的bin目录，进行启动这个zk服务： 1./zkServer.sh start 看到下面的打印说明启动成功： 123JMX enabled by defaultUsing config: /usr/zk/zookeeper-3.4.6/bin/../conf/zoo.cfgStarting zookeeper ... STARTED 集群搭建比较简单，直接改下配置，把zoo.cfg下面的ip+port往下面加节点就行了，例子： 123server.x=yyy.yy.yyy.yy:8881:7771server.x=yyy.yy.yyy.yy:8881:7771server.x=yyy.yy.yyy.yy:8881:7771 注意，集群里的每一个节点都要加上上面的配置，上面配置里的x就是指之前单机的myid文件放的id号，需要注意的是集群模式下，这些id是不允许有重复的，后面的yy.yy指的是节点ip地址，再往后的8881和7771之前有解释过，上翻查看。 这样配置后，将所有节点重启一遍即可，期间会进行Leader的选举，完成后可以运行bin目录下的zkServer.sh status查看其身份。","link":"/2019/03/22/%E3%80%90%E6%9D%82%E8%AE%B0%E3%80%91linux%E4%B8%8B%E5%90%84%E7%A7%8D%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95%EF%BC%88%E6%8C%81%E7%BB%AD%E8%AE%B0%E5%BD%95%EF%BC%89/"},{"title":"一Van♂年以后","text":"一VAN♂年以后（视频插入测试）","link":"/2019/03/10/%E4%B8%80Van%E2%99%82%E5%B9%B4%E4%BB%A5%E5%90%8E/"},{"title":"利用CompletableFuture优化程序的执行效率","text":"一、线程池的Future模式在了解java8的CompletableFuture之前，先通过Future来解决一个问题，看个例子： 假设现在有一个网站，首页有顶部Banner位、左边栏、右边栏、用户信息几大模块需要加载，现在出一个接口，要求包装并吐出这几大模块的内容 先来抽象一个首页接口对象： 1234567891011121314151617public class WebModule { private String top; //顶部Banner位 private String left; //左边栏 private String right; //右边栏 private String user; //用户信息 //...get...set... @Override public String toString() { return String.format(\"top: %s; left: %s; right: %s; user: %s\", top, left, right, user); }} 代码块1 现在提供下面几个业务方法来获取这些信息： 1234567891011121314151617181920212223242526272829303132333435private String getTop() { // 这里假设getTop需要执行200ms try { Thread.sleep(200L); } catch (InterruptedException e) { e.printStackTrace(); } return \"顶部banner位\"; } private String getLeft() { // 这里假设getLeft需要执行50ms try { Thread.sleep(50L); } catch (InterruptedException e) { e.printStackTrace(); } return \"左边栏\"; } private String getRight() { // 这里假设getRight需要执行80ms try { Thread.sleep(80L); } catch (InterruptedException e) { e.printStackTrace(); } return \"右边栏\"; } private String getUser() { // 这里假设getUser需要执行100ms try { Thread.sleep(100L); } catch (InterruptedException e) { e.printStackTrace(); } return \"用户信息\"; } 代码块2 ok，现在来实现下这个接口： 123456789// 同步获取public WebModule getWebModuleMsgSync() { WebModule webModule = new WebModule(); webModule.setTop(getTop()); webModule.setLeft(getLeft()); webModule.setRight(getRight()); webModule.setUser(getUser()); return webModule;} 代码块3 上面的代码会一次调用一个方法来赋值，最终返回接口对象，这个方法的最终耗时为几个业务方法耗时的总和： 12通过同步方法获取首页全部信息消耗时间：435ms结果为：top: 顶部banner位; left: 左边栏; right: 右边栏; user: 用户信息 430ms左右的执行时间，其实这几个模块是相互独立没有影响的，因此可以使用线程池的Future模式来进行多线程处理优化： 12345678910111213// 异步获取public WebModule getWebModuleMsgAsync() throws ExecutionException, InterruptedException { Future top = executorService.submit(this::getTop); Future left = executorService.submit(this::getLeft); Future right = executorService.submit(this::getRight); Future user = executorService.submit(this::getUser); WebModule webModule = new WebModule(); webModule.setTop(top.get()); webModule.setLeft(left.get()); webModule.setRight(right.get()); webModule.setUser(user.get()); return webModule;} 代码块4 这几个方法会被异步执行，get方法会被阻塞，直到执行结束，运行结果如下： 12通过异步方法获取首页全部信息消耗时间：276ms结果为：top: 顶部banner位; left: 左边栏; right: 右边栏; user: 用户信息 可以看到，执行速度几乎降了近200ms，这取决于最慢的那个任务的耗时。 通过上述的例子可以发现，很多程序都是可以通过异步充分利用CPU资源的方式来进行优化处理的，单看上面的程序没什么问题，但是仔细想想会发现太过局限，因为几个模块相互独立，但在实际开发中，我们可能存在B方法需要拿到A方法的结果才可以往下进行的问题，所以上面的程序就不太适用了，java8出现了今天要说的一个内容：CompletableFuture，该类可以帮助你实现上面所说的任务顺序调度，不相干的程序依然在异步，相干的存在先后顺序的将会通过一定的设置来满足自己的顺序期望。 二、CompletableFuture现在再来假设一个例子，现在存在以下几个方法的调用： zero方法、a方法、b方法、ab方法、c方法、d方法、e方法 定义如下： 123456789101112131415161718192021222324252627282930313233343536//各个方法，sleep当成是执行时间private void zero() { sleep(100L); System.out.println(\"zero方法触发！\\n-----------------------------\");}private String a() { sleep(500L); return \"a\";}private String b(String a) { sleep(1000L); return a + \"b\";}private String c() { sleep(500L); return \"c\";}private String ab(String a, String b) { sleep(100L); return a + \"|\" + b;}private void d(String a) { sleep(1000L); System.out.println(\"d方法触发，拿到的a = \" + a);}private String e(String a) { sleep(100L); return a + \"e\";} 代码块5 根据上面的方法定义，可以整理出来其执行关系： zero、a、c都是独立调用的方法，而b、d、e方法都需要拿到a的执行结果值才能触发，ab方法则要求更加苛刻，需要同时拿到a和b的执行结果才可以触发，现在假设需要把所有的方法都触发一遍，我们又期望通过异步的方式来尽可能的优化代码，这个时候如果还用上面例子里的方式，恐怕就很难进行下去了，因为很多方法存在相互依赖的现象，不过现在有了CompletableFuture，这个问题就可以解决了，来看下代码（方法及作用都写在注释上了，下面的文章就不多做说明了）： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public static void main(String[] args) throws ExecutionException, InterruptedException { long s = System.currentTimeMillis(); Test t = new Test(); //runAsync用于执行没有返回值的异步任务 CompletableFuture future0 = CompletableFuture.runAsync(t::zero) .exceptionally(e -&gt; { System.out.println(\"Zero出错！\"); return null; }); //这里是异常处理，指的是该异步任务执行中出错，应该做的处理 //supplyAsync方法用于执行带有返回值的异步任务 CompletableFuture futureA = CompletableFuture.supplyAsync(t::a) .exceptionally(e -&gt; { System.out.println(\"方法A出错！\"); return null; }); //thenCompose方法用于连接两个CompletableFuture任务，如下代表futureA结束后将执行结果交由另外一个CompletableFuture处理，然后将执行链路最终赋值给futureB CompletableFuture futureB = futureA.thenCompose(a -&gt; CompletableFuture.supplyAsync(() -&gt; t.b(a))) .exceptionally(e -&gt; { System.out.println(\"方法B出错！\"); return null; }); //thenAccept方法用于将一个任务的结果，传给需要该结果的任务，如下表示futureD的执行需要futureA的结果，与thenApply不同的是，这个方法没有有返回值 CompletableFuture futureD = futureA.thenAccept(t::d); //thenApply方法用于将一个任务的结果，传给需要该结果的任务，如下表示futureE的执行需要futureA的结果，与thenAccept不同的是，这个方法有返回值 CompletableFuture futureE = futureA.thenApply(t::e) .exceptionally(e -&gt; { System.out.println(\"方法E出错！\"); return null; }); /** * thenApply方法概念容易与thenCompose混淆，毕竟最终目的很相似 */ //thenCombine方法用于连接多个异步任务的结果，如下ab方法需要futureA和futureB的执行结果，那么就可以使用thenCombine进行连接 //注意，执行到ab这里，说明futureA和futureB一定已经执行完了 CompletableFuture futureAB = futureA.thenCombine(futureB, t::ab) .exceptionally(e -&gt; { System.out.println(\"方法AB出错！\"); return null; }); //单纯的一个异步任务，不依赖任何其他任务 CompletableFuture futureC = CompletableFuture.supplyAsync(t::c) .exceptionally(e -&gt; { System.out.println(\"方法C出错！\"); return null; }); //allOf如果阻塞结束则表示所有任务都执行结束了 CompletableFuture.allOf(future0, futureA, futureB, futureAB, futureC, futureD, futureE).get(); System.out.println(\"方法Zero输出：\" + future0.get()); System.out.println(\"方法A输出：\" + futureA.get()); System.out.println(\"方法B输出：\" + futureB.get()); System.out.println(\"方法AB输出：\" + futureAB.get()); System.out.println(\"方法C输出：\" + futureC.get()); System.out.println(\"方法D输出：\" + futureD.get()); System.out.println(\"方法E输出：\" + futureE.get()); System.out.println(\"耗时：\" + (System.currentTimeMillis() - s) + \"ms\"); } 代码块6 输出结果如下： 1234567891011zero方法触发！-----------------------------d方法触发，拿到的a = a方法Zero输出：null方法A输出：a方法B输出：ab方法AB输出：a|ab方法C输出：c方法D输出：null方法E输出：ae耗时：1668ms 可以看到，逻辑方面是没有任何问题的，也按照预期的顺序和方式进行了，注意看这里的运行时间，约等于1600ms，与第一个例子时长取决于执行时间最长的那个方法不同，上面的例子时长取决于有序的执行链的耗时最长的执行时间，分析下上面的程序，顺序链最长的，就是ab这条，ab需要a和b全部执行完，而b又依赖a的结果，因此ab执行完的时间就是500+1000的时间（a需要500ms，b又需要等待a，500ms后b触发，b自身又需要1000ms，等都结束了，再触发ab方法，而ab方法又需要100ms的执行时间，因此ab是最长的耗时方法，ab耗时=500+1000+100） 需要说明的是上述例子里用到的方法，几乎每个都有个重载方法，用来传递一个线程池对象，例子里用的都是不传的，用的是其内部的ForkJoinPool.commonPool()。 CompletableFuture的用法还有很多很多，较常用的应该就是例子里的几种，更多的用法以后会继续记录到这里。","link":"/2019/03/14/%E5%88%A9%E7%94%A8CompletableFuture%E4%BC%98%E5%8C%96%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%89%A7%E8%A1%8C%E6%95%88%E7%8E%87/"},{"title":"利用ReentrantLock简单实现一个阻塞队列","text":"借助juc里的ReentrantLock实现一个阻塞队列结构： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677package demo.concurrent.lock.queue;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.ReentrantLock;/** * @author sunqinwen * @version \\: SimpleQueue.java,v 0.1 2019-01-16 14:47 * 利用重入锁和重入锁的线程调度实现的简单阻塞队列 */public class SimpleQueue { private static ReentrantLock lock = new ReentrantLock(); private T[] nodes; private int tail = 0; // 入元素下标 private int count = 0; // 元素个数 private int head = 0; // 出元素下标 public SimpleQueue(int size) { nodes = (T[]) new Object[size]; } private static Condition notFull = lock.newCondition(); private static Condition notEmpty = lock.newCondition(); public void put(T t) { try { lock.lock(); if (count == nodes.length) { // 队列已满，阻塞 System.out.println(\"目前队列已满，等待取值中\"); notFull.await(); } if (tail &gt; (nodes.length - 1)) { // 当前游标值已经大于数组游标最大值了，则从0开始计算 tail = 0; } nodes[tail] = t; // 给当前游标位赋值 count++; // 入元素元素个数+1 tail++; // 游标值+1 notEmpty.signalAll(); // 走到这里说明队列内至少有一个元素，则唤醒取值 } catch (Exception e) { e.printStackTrace(); } finally { lock.unlock(); } } public T take() { T t = null; try { lock.lock(); if (count == 0) { // 队列已空，等待加值 System.out.println(\"目前队列已空，等待入值中\"); notEmpty.await(); } if (head &gt; (nodes.length - 1)) { // 若取值游标大于游标最大值，则从0开始计算 head = 0; } t = nodes[head]; // 拿到元素值 nodes[head] = null; // 清空原有位置上的值 head++; // 取值游标+1 count--; // 元素个数-1 notFull.signalAll(); // 走到这里说明队列至少有一个空位，则唤醒入值 } catch (Exception e) { e.printStackTrace(); } finally { lock.unlock(); } return t; }} 代码块1 以上为主要代码，下面进行简单的测试： 12345678910111213141516171819202122232425262728293031@Testpublic void simpleQueueTest() throws Exception { executorService.execute(() -&gt; { simpleQueue.put(1); simpleQueue.put(2); simpleQueue.put(3); simpleQueue.put(4); simpleQueue.put(5); simpleQueue.put(6); simpleQueue.put(7); simpleQueue.put(8); simpleQueue.put(9); simpleQueue.put(10); simpleQueue.put(11); simpleQueue.put(12); }); Thread.sleep(5000L); executorService.execute(() -&gt; { Integer r; while ((r = simpleQueue.take()) != null) { System.out.println(r); } }); Thread.sleep(5000L);} 代码块2 运行结果： 123456789101112131415161718目前队列已满，等待取值中目前队列已满，等待取值中12目前队列已满，等待取值中3目前队列已满，等待取值中456789目前队列已空，等待入值中101112目前队列已空，等待入值中","link":"/2019/02/12/%E5%88%A9%E7%94%A8ReentrantLock%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97/"},{"title":"利用java实现一个简单的链表结构","text":"定义所谓链表就是指在某节点存储数据的过程中还要有一个属性用来指向下一个链表节点，这样的数据存储方式叫做链表 链表的优缺点优点：易于存储和删除 缺点：查询起来较麻烦 java实现下面我们用java来实现如下链表结构： 首先定义节点类： 123456789101112131415161718192021222324252627282930package LinkTest;/** * 链表节点类 * @author admin * */public class Node { private int value;//存储数据 private Node next;//下一个节点 /** * 定义构造器 * @param vlaue * @param value */ public Node(int value){ this.value=value; } public int getValue() { return value; } public void setValue(int value) { this.value = value; } public Node getNext() { return next; } public void setNext(Node next) { this.next = next; }} 代码块1 然后定义一个链表类： 注意：遍历链表定义了两个方法，一个是普通方法，一个是递归方法，都可以遍历出来 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package LinkTest;/** * 链表 * @author admin * */public class Link { private Node current; private Node root; public void insert(int vlaue){ Node newNode=new Node(vlaue); if(this.current==null){ this.current=newNode; this.root=this.current; }else{ this.current.setNext(newNode); this.current=this.current.getNext(); } } //普通遍历 public void getList(){ this.current=this.root; while(this.current!=null){ System.out.print(this.current.getValue()); this.current=this.current.getNext(); if(this.current!=null){ System.out.print(\"-------&gt;\"); } } } //递归遍历 public void getList2(){ DG(this.root); } //递归方法 public void DG(Node node){ System.out.print(node.getValue()+\"-----&gt;\"); if(node.getNext()!=null){ DG(node.getNext()); }else{ return; } }} 代码块2 测试类： 123456789101112131415161718package LinkTest;/** * 测试类 * @author admin * */public class Test { public static void main(String[] args){ Link l=new Link(); l.insert(1); l.insert(4); l.insert(5); l.insert(6); l.insert(9); l.insert(8); l.getList(); }} 代码块3 测试类运行结果： 11-------&gt;4-------&gt;5-------&gt;6-------&gt;9-------&gt;8 这样我们就用java实现了一个简单的链表结构。","link":"/2014/07/04/%E5%88%A9%E7%94%A8java%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E9%93%BE%E8%A1%A8%E7%BB%93%E6%9E%84/"},{"title":"图解java多线程设计模式（一）","text":"去年看完的《图解java多线程设计模式》，可惜当时没做笔记，导致后来忘了许多东西，打算再温习下这本书，顺便在这里记录一下~ 一、顺序执行、并行、并发 顺序执行：多个操作按照顺序依次执行。 并行：多个任务同时进行，同一时间内可以执行多个任务，这种方式，叫做并行执行，比如多核处理器，多个核可以同时处理多个任务。 并发：多个任务通过切分时间段，来达到“同时进行”的效果，比如单核处理器，在“同时”处理多个任务时，就会不停的切换来执行不同的任务，不可能有同一时间执行不同任务的情况。 下面引用别人的一句话来说明下并行和并发： 并发是两个任务可以在重叠的时间段内启动，运行和完成。并行是任务在同一时间运行，例如，在多核处理器上，并发是独立执行过程的组合，而并行是同时执行（可能相关的）计算。 并发是一次处理很多事情，并行是同时做很多事情。 应用程序可以是并发的，但不是并行的，这意味着它可以同时处理多个任务，但是没有两个任务在同一时刻执行。应用程序可以是并行的，但不是并发的，这意味着它同时处理多核CPU中的任务的多个子任务。一个应用程序可以即不是并行的，也不是并发的，这意味着它一次一个地处理所有任务。应用程序可以即是并行的也是并发的，这意味着它同时在多核CPU中同时处理多个任务。 二、synchronized修饰符当我们说一个线程获得锁以后，则意味着这个线程可以执行当前对象（或类）里的synchronized方法，而且他线程则需要排队等待该线程释放锁以后才可能获得锁，进而执行锁里面的程序。 synchronized修饰后，存在对象锁和类锁两种类型。 2.1：对象锁123synchronized (this){ ...略} 代码块1 2.2：类锁123synchronized (XXX.class){ ...略} 代码块2 2.3：区别和作用域对象锁指的是当前线程获得了某个实例的锁，假如有个Word类，有A、B两个同步方法，C属于普通方法，如图所示： 可以发现，对象锁的作用域只针对当前对象生效，就像w1和w2里的A方法可以被不同的线程同时执行，但是同一个对象内的同步块，却只允许持有当前对象锁的线程执行，如t2、t3均被挡在了外面，当t1释放锁以后，t2、t3才会重新竞争锁，竞争到锁以后就会执行自己想要执行的同步逻辑。 类锁指的是当前线程获得了某个类的锁，还是Word类，有A、B两个static方法（静态方法属于类方法，加synchronized修饰符后等效于上面提到的synchronized(Word.class))，C属于普通static方法，如图所示： 跟上面相比较，这里的t5受到了t1的影响，因为t1获得了Word类的锁，w1和w2共属一个类，因此t1获得类锁以后，其他线程想要访问这个类里的同步块，就得等到t1释放锁以后才可以继续竞争锁然后执行自己想要执行的同步逻辑。 三、线程间的通信3.1：Wait这几个方法是属于每个实例对象的，所有实例都拥有一个“等待队列”（虚拟概念，实例里并不存在该字段），它是在实例的wait方法调用后存放停止操作线程的队列。执行wait方法后，线程进入当前实例的“等待队列”，以下几种情况可以让线程退出“等待队列”： 其他线程调用notify、notifyAll方法来将其唤醒 其他线程调用interrupt来将其唤醒 wait方法本身超时 当执行了下面的代码： 1obj.wait(); 代码块3 我们可以说当前线程在obj上发生了等待，当前线程进入了obj的“等待队列”，此时当前线程会让出锁，让其他线程继续竞争获得该实例的锁（因此这里有个规则，调用wait的线程必须持有当前实例对象的锁） 过程如下图： 3.2：notify现在先来介绍下notify，该方法会将等待队列里的线程取出，让其退出等待并参与锁竞争然后继续执行上次wait后没有执行完的语句。整体过程如下图所示： 可以看到，t1在被挂起后，会因为t2调用了同实例的notify方法，而让t1被从等待队列里释放，重新加入到所得竞争力，t2执行完毕后释放锁，锁又再次被t1竞争到，t1将继续执行上次被挂起时后面未执行完的语句。 需要指出的是，如果等待队列里的线程是多个，那么被唤醒的那一个，将会是等待队列里所有线程随机的一个，不会特定哪一个线程会被唤起。 3.3：notifyAll接下来介绍notifyAll方法，顾名思义，就是将等待队列里的线程全部唤起，然后这些线程将全部加入到锁竞争，竞争到，继续完成上次被挂起时未执行完毕的操作，流程图如下： 说明，当线程调用实例的wait、notify、notifyAll方法有个大前提，就是必须要求该线程拥有该实例的锁，否则会抛IllegalMonitorStateException异常。 在编写程序时，是该选择notify还是选择notifyAll？这个可以指出的是，notifyAll往往更加健壮，而notify由于唤起的线程少，因此效率会更高，但是存在程序停止的风险。 附上使用wait、notify进行线程通信的例子： 利用ReentrantLock简单实现一个阻塞队列 java设计模式：简单实现生产者和消费者模式","link":"/2019/02/26/%E5%9B%BE%E8%A7%A3java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%88%E4%B8%80%EF%BC%89/"},{"title":"图解java多线程设计模式（二）","text":"一、join &amp; interrupt这俩方法属于线程对象里的方法，属于线程本身的操作。 1.1：join方法用于等待一个线程的终止，等待期间将会阻塞，直到被等待的线程终止结束。 所以join可以用来做多任务异步处理，比如还是拿利用CompletableFuture优化程序的执行效率这篇里的第一个例子做优化，这篇文章里使用线程池的future模式进行多任务异步处理，现在使用join改写下： 再来简单贴下这几个方法： 1234567891011121314151617181920212223242526272829303132333435private String getTop() { // 这里假设getTop需要执行200ms try { Thread.sleep(200L); } catch (InterruptedException e) { e.printStackTrace(); } return \"顶部banner位\"; } private String getLeft() { // 这里假设getLeft需要执行50ms try { Thread.sleep(50L); } catch (InterruptedException e) { e.printStackTrace(); } return \"左边栏\"; } private String getRight() { // 这里假设getRight需要执行80ms try { Thread.sleep(80L); } catch (InterruptedException e) { e.printStackTrace(); } return \"右边栏\"; } private String getUser() { // 这里假设getUser需要执行100ms try { Thread.sleep(100L); } catch (InterruptedException e) { e.printStackTrace(); } return \"用户信息\"; } 代码块1 然后现在使用简单的线程做异步处理： 123456789101112131415161718192021222324// 简单异步获取 public WebModule getWebModuleMsgSimpleAsync() throws ExecutionException, InterruptedException { WebModule webModule = new WebModule(); Thread topTask = new Thread(() -&gt; webModule.setTop(this.getTop())); Thread leftTask = new Thread(() -&gt; webModule.setLeft(this.getLeft())); Thread rightTask = new Thread(() -&gt; webModule.setRight(this.getRight())); Thread userTask = new Thread(() -&gt; webModule.setUser(this.getUser())); //触发各个异步任务 topTask.start(); leftTask.start(); rightTask.start(); userTask.start(); //等待所有的任务均执行完毕 topTask.join(); leftTask.join(); rightTask.join(); userTask.join(); return webModule; } 代码块2 测试代码： 12345678@Test public void testSimpleASync() throws Exception { // 同步方法测试，预估耗时200ms long start = System.currentTimeMillis(); WebModule module = webHome.getWebModuleMsgSimpleAsync(); System.out.println(\"通过异步方法获取首页全部信息消耗时间：\" + (System.currentTimeMillis() - start) + \"ms\"); System.out.println(\"结果为：\" + module.toString()); } 代码块3 测试结果： 12通过异步方法获取首页全部信息消耗时间：272ms结果为：top: 顶部banner位; left: 左边栏; right: 右边栏; user: 用户信息 比预估的要多72ms，经过后来的测试，发现这72ms耗时发生在线程创建的时候，以及后续线程状态转换带来的消耗，下面等待异步结束的时间约等于200ms，符合预期。 1.2：interrupt方法用于主动终止一个线程，线程本身调用该方法后，视为已终止状态，join解除阻塞，下面来用interrupt和join来做个实验： 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class JoinTest { private boolean isStop = false; public static void main(String[] args) throws Exception { JoinTest test = new JoinTest(); Thread loopT = new Thread(test::loopTask); loopT.start(); sleep(2000L); //2s后终止线程 test.setStop(true); long s = System.currentTimeMillis(); loopT.join(); System.out.println(\"线程终止后，join阻塞时间为：\" + (System.currentTimeMillis() - s)); System.out.println(\"end~\"); } public void setStop(boolean stop) { isStop = stop; } public void loopTask() { while (!isStop) { //若状态为false，则继续执行下面的逻辑，每隔1s打印一次 sleep(1000L); System.out.println(\"loop trigger ~\"); } Thread.currentThread().interrupt(); //在这里终止掉当前线程 //事实上，在终止掉线程后，还有接下来的逻辑要执行 long s = System.currentTimeMillis(); for (int i = 0; i &lt; 1000000; i++) { int[] a = new int[100]; //模拟耗时操作，这里不能用sleep了，因为当前线程已经被终止了 } System.out.println(\"线程终止后，逻辑块运行时间：\" + (System.currentTimeMillis() - s)); } public static void sleep(long time) { try { Thread.sleep(time); } catch (InterruptedException e) { e.printStackTrace(); } }} 代码块4 执行结果： 12345loop trigger ~loop trigger ~线程终止后，逻辑块运行时间：129线程终止后，join阻塞时间为：129end~ 即便线程被终止了，后面的逻辑也会触发，join依旧会选择阻塞，直到后续逻辑执行完毕，事实上，大部分任务都可以及时的终止，比如第一个例子，异步出去的任务，最终都会执行完成，线程变为终止状态，join都可以顺利结束，但是反观上例，如果没人及时的设置isStop的值，程序会一直执行下去，没有终止态，join会无止境的终止下去，这里提一下stop，线程的stop方法已被官方标记为不建议使用的方法，如果把上例的interrupt的调用换成stop，来看看其运行结果： 1234loop trigger ~loop trigger ~线程终止后，join阻塞时间为：0end~ 可以看到，线程终止后的后续逻辑均没有触发，等于说stop是一种很粗暴的终止线程的方式，一旦被stop，那么里面的业务逻辑将直接断掉，因此官方并不推荐使用该方法来终止线程。 而interrupt，仅仅是对目标线程发送了了一个中断信号（改变了线程的中断状态而已），当目标线程再次通过obj.wait、thread.sleep、thread.join方法进入阻塞状态时，接收到该信号，就会抛出InterruptedException异常，这时候需要业务方自行处理或者直接抛出，以结束线程阻塞状态（这里需要注意的是被obj.wait方法阻塞时，抛出该异常需要目标线程再次获得实例对象obj的锁才行）。 上述三个需要花费时间的方法均抛出了InterruptedException异常，针对这些特性，想要完成以下操作就非常方便了： 取消wait方法等待notify/notifyAll的处理 取消在sleep方法指定时间内停止的处理 取消join方法等待其他线程终止的处理 取消之后所做的处理，取决于需求，可能会终止线程，或者通知用户已取消，或者终止当前处理进入下一个处理阶段。 二、线程状态迁移图 上面的图太多太杂，我们通过对一些可以影响线程状态的操作的分类，来简化一下上面的图：","link":"/2019/03/13/%E5%9B%BE%E8%A7%A3java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%88%E4%BA%8C%EF%BC%89/"},{"title":"数据库事务的隔离级别","text":"一、数据库事务的几个特性1.1：原子性最基本的特性，意思是在一个事务内里所有关于数据库的操作，要么全部成功，要么全部失败；成功时意味着本次操作所有数据库相关的写操作全部持久化，无法更改，失败意味着本次操作相对于操作前对数据库没有任何影响和改变。 1.2：一致性指的是一次完整的事务必须将数据库的一个一致状态转变到另外一个一致状态。 一致性写 例如：事务A要做的操作是将A、B、C三个记录修改为D、E、F，那么A、B、C—–&gt;D、E、F的过程就满足了事务一致性，但是如果出现类似：A、B、C—-&gt;D、E、C（A、B修改成功，但是C未修改）则认定违背了事务的一致性，简单理解一致性就是指事务的“初始状态”到“修改完成状态”与“目标状态一致”。 一致性读 事务A在某一刻发起查询请求，那么查询结果是以那一刻为准，保证了数据在查询一刻的一致性。 1.3：持久性指一次事务的成功提交对数据库造成的修改是永久性的。 1.4：隔离性当多个用户并发访问数据库时，数据库为每一个用户开启的事务不可以被其他事务所影响，也就是说并发事务间要相互独立不受到干扰。关于隔离性分了集中隔离等级，本篇文章将详细介绍这几种隔离等级。 二、事务并发时的隔离级别2.1：Read Uncommitted（读未提交）这个隔离级别下未被提交的事务下所做的任何操作都可以被其他事务所读取到，这时候会造成数据的脏读、幻读、不可重复读问题。 2.2：Read Committed（读已提交）这个隔离级别下未被提交的操作不可以被其他事务所读取到，简单来讲就是单个事务里的内容在事务成功提交之前，是不会被其他事务所读取（发现）到的，但是这样同样会出现幻读、不可重复读现象。 举个栗子：事务T1要对C表做添加操作，同时事务T2里要读取C表，T2第一次读取C表时返回1条数据，这时T1执行完毕，那么T2如果再次取一次C表数据就会发现多出一条数据。 2.3：Repeatable Read（可重读）Mysql默认的隔离级别，这个隔离级别下同一事务读取到的数据一致（简单点说就是T1一旦开始，读取到数据如果中间被T2修改，那么T1再次读取该数据是和第一次读取时一样的），因此，在该隔离级别下，不会造成脏读、不可重复读，但依旧会造成幻读现象。 2.4：Serializable（串行）最高隔离级别，会为每个事务排序（为每条数据都加上锁），使之执行串行化，不可能产生冲突，因此解决了脏读、幻读、不可重复读问题，但是会造成锁竞争甚至超时，一般不会采用这种极端的隔离机制。 三、事务并发过程中产生的问题3.1：脏读一个事务读取到了另外一个事务中未提交的数据。 3.2：不可重复读一个事务读取到了另外一个事务中提交的修改掉的数据。 3.3：幻读一个事务读取到了另外一个事务中添加的数据。 Tip：不可重复读和幻读的区别在于着重点一个是update，一个是insert 四、各种隔离级别下对应的问题通过设置不同的事务隔离级别，可以避免事务并发时所造成的部分问题。 总结四种隔离级别所造成和避免的问题（请先看以上内容后再看此表）： 隔离级别 脏读 不可重复读 幻读 Read Uncommitted 是 是 是 Read Committed 否 是 是 Repeatable Read 否 否 是 Serializable 否 否 否 表1","link":"/2017/04/10/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1%E7%9A%84%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/"},{"title":"深入理解map系列-HashMap（一）","text":"Map系列之HashMap（源码基于java8） HashMap是我们最常用的map实现之一，这篇文章将会介绍HashMap内部是如何工作的，以及内部的数据结构是怎样的 一、数据结构简图 二、源码解析首先看下Map接口里常用的几个方法： 1234V put(K key, V value);V get(Object key);V remove(Object key);boolean containsKey(Object key); 代码块1 上面是常用的主要操作方法，下面来看下map的基本存储单位Entry： 12345678910111213interface Entry&lt;K,V&gt; { K getKey(); //返回当前存储数据里的key V getValue(); //返回当前存储数据里的value V setValue(V value); //给value赋值 boolean equals(Object o); //重写equals方法 int hashCode(); //重写hashCode方法 } 代码块2 然后我们来看下HashMap里对该接口的实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243// 基本存储结构，可以看出来这是一个简单的链表结构，这里的实现类叫Nodestatic class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final int hash; //根据key计算出来的哈希值 final K key; //数据键 V value; //数据值 Node&lt;K,V&gt; next; //下一个数据节点 Node(int hash, K key, V value, Node&lt;K,V&gt; next) { this.hash = hash; this.key = key; this.value = value; this.next = next; } public final K getKey() { return key; } public final V getValue() { return value; } public final String toString() { return key + \"=\" + value; } public final int hashCode() { return Objects.hashCode(key) ^ Objects.hashCode(value); } public final V setValue(V newValue) { V oldValue = value; value = newValue; return oldValue; } // 判等，要求k，v必须满足相等才行 public final boolean equals(Object o) { if (o == this) return true; if (o instanceof Map.Entry) { Map.Entry e = (Map.Entry)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; } return false; } } 代码块3 我们再来看看hash值的计算，在哈希表中，哈希值取决了散列度，最终插入的数据会分布到哪个数组下标下，hash值起着至关重要的作用： 1234static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); } 代码块4 下面我们来看看具体插入数据时做的操作，具体解释已经加上注释： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { HashMap.Node&lt;K,V&gt;[] tab; //存储链表的数组结构 HashMap.Node&lt;K,V&gt; p; //被插入的元素链表头部元素 int n, i; //n表示当前哈希表数组长度，i表示本次插入元素被分配的下标 if ((tab = table) == null || (n = tab.length) == 0) { //表示哈希表数组还未被初始化 n = (tab = resize()).length; //初始化，resize用来扩容 } //表示当前（下标由最大下标值和当前元素哈希值位运算得出）位置还没有任何链表结构，这时直接初始化即可 if ((p = tab[i = (n - 1) &amp; hash]) == null) { tab[i] = newNode(hash, key, value, null); } else { // 否则，需要进行链表数据插入的操作，注意现在p已经是计算出来的链表头元素了 HashMap.Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) { e = p; // 若发现插入的数据跟p哈希值、key完全一致，则直接让新插入的数据等于p即可 } else if (p instanceof HashMap.TreeNode){ // 结合下面的代码，链表深度大于8后，就是个红黑树结构了，这时启用下面的代码加入新数据 e = ((HashMap.TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); } else { // 说明插入的是新元素 for (int binCount = 0; ; ++binCount) { // 遍历链表 if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); //插入链表尾部 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // java8新引入的概念，当链表深度大于8时，就转换为红黑树结构了 treeifyBin(tab, hash); break; } if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) { break; // 若发现遍历过程中存在与插入值一致的，直接break } p = e; } } if (e != null) { // 说明未成功插入 V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; // 返回已存在的旧值 } } ++modCount; if (++size &gt; threshold) { //新插入值后，满足扩容条件则进行扩容 resize(); //扩容 } afterNodeInsertion(evict); return null; } 代码块5 由于java8做了根据元素数量，转换成红黑树结构的优化处理，所以上述代码中会掺杂一些相关的代码，这里先不用关心，我们按照最基本的哈希表结构来看就行，下一讲将会分析红黑树结构。 我们接下来来看下get方法： 1234public V get(Object key) { Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;} 代码块6 然后getNode方法： 1234567891011121314151617181920212223242526final HashMap.Node&lt;K,V&gt; getNode(int hash, Object key) { HashMap.Node&lt;K,V&gt;[] tab; //哈希表数组 HashMap.Node&lt;K,V&gt; first, e; //根据hash查找数组内的第一个元素 int n; K k; // n表示数组长度 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) { // 根据下标（下标由最大下标值和当前元素哈希值位运算得出）获取当前对应第一个元素（链表或者红黑树的根元素） if (first.hash == hash &amp;&amp; // 检查第一个节点的key是否等于当前查找的key，若等，直接返回 ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))){ return first; } // 否则继续遍历查找 if ((e = first.next) != null) { if (first instanceof HashMap.TreeNode) { //红黑树结构的查询 return ((HashMap.TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); } // 普通链表结构遍历查询，查到直接返回 do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))){ return e; } } while ((e = e.next) != null); } } return null; } 代码块7 ok,上面说完了put和get，现在我们来看下remove，也是先抛开红黑树不谈，只看链表部分，会很容易： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public V remove(Object key) { HashMap.Node&lt;K, V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value; }final HashMap.Node&lt;K, V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) { HashMap.Node&lt;K, V&gt;[] tab; //哈希表数组 HashMap.Node&lt;K, V&gt; p; //需要被移除的元素所属的根元素 int n, index; //n表示数组长度，index表示需要被移除元素根元素位于数组的下标值 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) { HashMap.Node&lt;K, V&gt; node = null, e; // node表示最终需要被移除的元素 K k; V v; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) { node = p; // 若根元素就等于需要被移除的元素，则直接将node赋值为p } else if ((e = p.next) != null) { // 否则继续往下查找，结构依然分为两种，红黑树暂不看 if (p instanceof HashMap.TreeNode) { node = ((HashMap.TreeNode&lt;K, V&gt;) p).getTreeNode(hash, key); } else { do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) { node = e; break; // 找到对应的元素，break } p = e; // 找不到对应元素时，让p一直下移（e.next） } while ((e = e.next) != null); } } if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) { if (node instanceof HashMap.TreeNode) { //红黑树移除 ((HashMap.TreeNode&lt;K, V&gt;) node).removeTreeNode(this, tab, movable); } else if (node == p) { // 待移除元素等于根元素时，直接让对应下标下的数组元素赋值为根元素的下一个值 tab[index] = node.next; } else { //否则，就进行链表正常删除逻辑，让被移除元素的前一个元素（为什么现在的p是前一个元素呢？因为在上述do while操作时已经重新赋值了）的下一个值指向被移除元素的下一个值 p.next = node.next; } ++modCount; --size; afterNodeRemoval(node); return node; } } return null; } 代码块8 好了，目前基本上把重要的一些操作给介绍完了，现在再看下containsKay这个方法，这个方法极度简单，直接调用getNode方法判空即可： 123public boolean containsKey(Object key) { return getNode(hash(key), key) != null;} 代码块9 本篇的侧重点在于HashMap在使用纯链表时的插入、移除、查找方式，下一篇将会介绍HashMap如何扩容数组、以及在启用红黑树结构下，会如何做插入、移除、查找这几种操作方式。","link":"/2019/02/12/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map%E7%B3%BB%E5%88%97-HashMap%EF%BC%88%E4%B8%80%EF%BC%89/"},{"title":"简单实现生产者和消费者模式","text":"本实例中单独为生产者和消费者各开辟一个线程作为生产者和消费者的执行线程，在生产者消费者设计模式中存在一个数据缓冲区，使生产者和消费者的“生产”和“消费”动作都在该缓冲区进行，这样做的目的就是保证了生产者和消费者的完美解耦，试想一下如果没了这个缓冲区，生产者和消费者中的方法互调，那么两个类的关联度（耦合度）就会很高，一旦一个发生变化，势必会影响另外一个； 下面开始我们的实例： 首先是生产者的代码： 12345678910111213141516171819202122/** * 生产者 */public class Product implements Runnable{ private Queue queue; public Product(Queue queue){ this.queue = queue; } @Override public void run() { try{ for(int i = 0; i &lt; 10; i++){ queue.product(\"Product------\" + \"No.\" + i);//开始生产 } }catch (Exception e){ e.printStackTrace(); } }} 代码块1 这是消费者： 12345678910111213141516171819202122/** * 消费者 */public class Consumer implements Runnable{ private Queue queue; public Consumer(Queue queue){ this.queue = queue; } @Override public void run() { try{ for(int i = 0; i &lt; 10; i++){ System.out.println(\"already gone : \" + queue.consumer());//开始消费 } }catch (Exception e){ e.printStackTrace(); } }} 代码块2 这是缓冲区，几乎所有的逻辑都是在这里实现的： 123456789101112131415161718192021222324252627282930313233343536373839/** * 队列缓冲区 */public class Queue { private Object signal = new Object();//当前线程的挂起和执行标记 private boolean isFull = false;//队列是否已满 private List list = new ArrayList&lt;&gt;();//队列 public void product(String msg) throws Exception{ synchronized (signal){ if(!isFull){//如果没有满，执行如下代码 list.add(msg);//加进队列 isFull = true; System.out.println(\"Product One !\"); signal.notify();//唤醒当前消费者里面被挂起的线程 } signal.wait();//否则，如果当前满了，说明消费者正在消费，挂起当前生产线程 } } public String consumer() throws Exception{ synchronized (signal){ if(!isFull){ //不满，说明生产者正在生产，应当挂起consumer线程 System.out.println(\"Empty Product !\"); signal.wait(); } isFull = false;//已消费，队列被标记为不满状态 signal.notify();//通知生产者 } //消费（读取） String result = \"\"; if(list.size() &gt; 0){ result = this.list.get(list.size() - 1); this.list.remove(list.size() - 1); } return result; }} 代码块3 上面这个模式利用java现有的阻塞队列很容易实现，可以避免上述代码中很大一部分代码（线程的挂起、唤醒、队列弹出数据等）","link":"/2016/04/15/%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0%E7%94%9F%E4%BA%A7%E8%80%85%E5%92%8C%E6%B6%88%E8%B4%B9%E8%80%85%E6%A8%A1%E5%BC%8F/"},{"title":"简单工厂模式&策略模式-简介与区别","text":"前言：两种模式的相似点与不同点不得不说，这两种模式真的很像。 相似点：都用到了面向对象的继承、多态、抽象，都拥有相似的结构。 不同点：工厂模式仅提供具体的实例对象，怎么使用这个对象是client的自由，策略模式client可以通过策略类来决定使用哪个实例的哪个方法。 一、两种模式的公共相同部分下面，我们假设有一台红白机，里面有一些游戏，每个游戏拥有play（玩）和uninstall（卸载）两个方法。 按照工厂和策略模式，我们抽象出来一个Game接口： 1234567public interface Game { void play(); void uninstall();} 代码块1 然后，我们假设游戏机里有魂斗罗、马戏团、默认的俄罗斯方块三款游戏，每个游戏有不同的玩法和卸载算法： 123456789101112131415161718192021222324252627282930313233343536373839404142// 魂斗罗，实现Gamepublic class Hundouluo implements Game { @Override public void play() { System.out.println(\"游戏：魂斗罗...playing\"); } @Override public void uninstall() { System.out.println(\"游戏：魂斗罗...卸载\"); }}// 马戏团，实现Gamepublic class Maxituan implements Game { @Override public void play() { System.out.println(\"游戏：马戏团...playing\"); } @Override public void uninstall() { System.out.println(\"游戏：马戏团...卸载\"); }}// 默认的俄罗斯方块，实现Gamepublic class Default implements Game { @Override public void play() { System.out.println(\"游戏：俄罗斯方块...playing\"); } @Override public void uninstall() { System.out.println(\"游戏：俄罗斯方块...卸载\"); }} 代码块2 ok，工厂模式和策略模式的相同部分就已经写好了，通过上面的代码，我们可以发现这两种模式都是需要把相同的部分抽象出来，通过多态来实例化不同的对象，调用其对应的实现。 二、两种模式的不同部分的实现2.1：工厂模式工厂需要一个工厂类，用来返回具体的实例对象用，代码如下： 1234567891011121314public class GameFactory { public static Game getGame(String name) { switch (name) { //根据传来的游戏名（这里偷懒用了首字母），来实例化具体的对象 case \"hdl\": return new Hundouluo(); case \"mxt\": return new Maxituan(); default: return new Default(); } }} 代码块3 2.2：策略模式策略模式需要策略类来封装具体的行为（方法），并且还可以指定使用哪个实例的哪个行为，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839// 为了和工厂做充分的区分，这里定义了两个类型的context，分别维护一个行为算法（也就是方法函数，其次建立两个context是为了说明问题，实际使用时可能不需要这么多）// 用来维护play这个算法的实现public class PlayContext { private Game game; public PlayContext() { this.game = new Default(); } public PlayContext(Game game) { this.game = game; // 这里根据传入的具体实例赋值 } public void trigger() { this.game.play(); // 这里是对行为的封装，只提供play方法的触发 }}// 用来维护uninstall这个算法的实现public class UninstallContext { private Game game; public UninstallContext() { this.game = new Default(); } public UninstallContext(Game game) { this.game = game; // 这里根据传入的具体实例赋值 } public void trigger() { this.game.uninstall(); // 这里是对行为的封装，只提供uninstall方法的触发 }} 代码块4 测试代码： 1234new PlayContext(new Hundouluo()).trigger();new UninstallContext(new Hundouluo()).trigger();new PlayContext(new Maxituan()).trigger();new UninstallContext(new Maxituan()).trigger(); 代码块5 运行结果： 1234游戏：魂斗罗...playing游戏：魂斗罗...卸载游戏：马戏团...playing游戏：马戏团...卸载 通过上面的实验，和对比，会发现，工厂模式是简单的对实例的封装，而策略模式更在意的是对具体实例的具体行为（方法）的封装。 还有一种情况就是利用工厂模式的思想，实现的策略模式，我们现在来改造下上面的PlayContext源码： 1234567891011121314151617181920212223242526public class PlayContext { private Game game; public PlayContext() { this.game = new Default(); } public PlayContext(String name) { switch (name) { //根据传来的游戏名（这里偷懒用了首字母），来实例化具体的对象 case \"hdl\": this.game = new Hundouluo(); break; case \"mxt\": this.game = new Maxituan(); break; default: this.game = new Default(); } } public void trigger() { this.game.play(); // 这里是对行为的封装，只提供play方法的触发 }} 代码块6 测试类： 1234new PlayContext(\"hdl\").trigger();new UninstallContext(new Hundouluo()).trigger();new PlayContext(\"mxt\").trigger();new UninstallContext(new Maxituan()).trigger(); 代码块7 测试结果： 1234游戏：魂斗罗...playing游戏：魂斗罗...卸载游戏：马戏团...playing游戏：马戏团...卸载 三、总结策略模式是一种定义一系列算法的方法，所有这些算法完成的都是相同的工作，只是实现不同，它可以以相同的方式调用所有算法，减少了各种算法类与使用算法类之间的耦合。 工厂模式仅提供对应的实例，不对其方法做封装，减少了具体实现的实例与使用实例的业务方的耦合。 （↑描述待改进）","link":"/2019/02/27/%E7%AE%80%E5%8D%95%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F&%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F-%E7%AE%80%E4%BB%8B%E4%B8%8E%E5%8C%BA%E5%88%AB/"},{"title":"简单模拟spring的ioc和aop","text":"spring最核心的部分莫过于ioc和aop了，下面来简单模拟下这两种思想 ps：如果有哪里理解的不对或者代码上有瑕疵的地方欢迎大家指正，大家互相学习，还有就是这只是模仿一下spring思想，只是把事务管理和bean管理简单模仿一下，完全不代表spring，如果想深入理解请看spring源码 下面就开始进行简单的模拟。 这个项目不是web项目，只是一个简单的java项目，测试用junit，废话不多说了，下面上代码： 项目的目录结构： 说明：图中划红线的部分都是核心部分 红线部分说明： BeanFactory：所有bean的核心生成器（spring容器） ConnBean：jdbc连接生成器（没用连接池哦~） Transaction：事务管理的代理类 beans.properties：配置文件 其余的没划线的就是domain、dao、service、controller这些web基本层次结构，待会会说 主要几个类的代码： ① BeanFactory： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package sun.juwin.factory;import java.io.BufferedReader;import java.io.InputStreamReader;import java.util.HashMap;/** * 本类用来读取配置文件中的信息对每个接口对象生成具体的实现 * 主要是将接口作为key，实例作为value存储进去，这是个单例， * spring默认为每个层次生成实现也是单例，但可以通过@Scope * 来指定，我们简单模仿一下，只是单例 */public class BeanFactory { private static HashMap&lt;String, Object&gt; mapResult; public static HashMap&lt;String, Object&gt; getBean() { if (mapResult == null) { synchronized (BeanFactory.class) {//双重检查的单例，防止多线程访问时多次new对象 if (mapResult == null) { BufferedReader bf = null; String line = null; try { /** *下面这句代码通过流来读取资源包下面的配置文件，为了省去不必要的麻烦， * 我们没有用xml，而是用了properties */ InputStreamReader inputStreamReader = new InputStreamReader(BeanFactory.class.getClassLoader().getResourceAsStream(\"beans.properties\")); bf = new BufferedReader(inputStreamReader); mapResult = new HashMap&lt;&gt;(); while ((line = bf.readLine()) != null) {//每次仅读一行 if (\"\".equals(line)){//有可能读到换行时隔了一行（即只有一个换行符） continue; } String[] point = line.trim().split(\"=\");//按照等号拼接 if (point.length &gt; 2) { throw new Exception(\"beans文件格式不对！\"); } Object obj = Class.forName(point[1].trim()).newInstance();//反射实例化出目标对象 mapResult.put(point[0].trim(), obj);//然后以键值对的形式存入 } } catch (Exception e) { e.printStackTrace(); } } } } return mapResult; }} 代码块1 上面的类可以通过配置文件来实例化不同的对象，符合ioc最基本的思想，下面让我们来看看配置文件beans.properties的内容吧： 12userDao = sun.juwin.dao.impl.UserDaoImpluserDetailDao = sun.juwin.dao.impl.UserDetailDaoImpl 这里面只有两句话，指定dao层接口对象的实现类的路径，其实已经很接近spring的xml里对bean的配置了，只不过这里是properties文件，简化了许多 ② TransactionProxy代理类： 123456789101112131415161718192021222324252627282930313233343536package sun.juwin.proxy.transctional;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.sql.Connection;/** * 事务代理类，通过这个类可以为要执行的方法加上事务管理 */public class TransactionProxy implements InvocationHandler { private Object targetObj; public Object getTargetObj(Object targetObj){ this.targetObj = targetObj; return Proxy.newProxyInstance(this.targetObj.getClass().getClassLoader(), this.targetObj.getClass().getInterfaces(), this); } /*下面这个方法会在被代理类执行方法时调用，拿到被代理类的要执行的method对象*/ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { Object result = null; Connection connection = (Connection)args[0];//要求第一个参数必须是conn try{ connection.setAutoCommit(false);//开启事务 result = method.invoke(this.targetObj, args);//执行目标方法 connection.commit();//事务提交 System.out.print(\"commit success!\"); }catch (Exception e){ connection.rollback();//事务回滚 System.err.println(\"rollback!\"); e.printStackTrace(); }finally { connection.close();//关闭连接 System.out.println(\"connection closed!\"); } return result; }} 代码块2 说明：java在1.3版本的时候就为我们提供了一个用作代理类实现的接口InvacationHandler，通过实现这个接口可以很随意的写一个耦合度特别低的动态代理类（即这一个代理类可以代理任何类） ③ ConnBean，用来生成一个数据库连接对象，在不用连接池的情况下，我们用ThreadLocal进行封装，代码如下： 123456789101112131415161718192021222324package sun.juwin.db;import java.sql.Connection;import java.sql.DriverManager;/*原始产生数据库连接的类*/public class ConnBean { private static ThreadLocal conn = new ThreadLocal&lt;&gt;(); private ConnBean(){} public static Connection getConn(){ Connection connection = conn.get(); if(connection == null){ synchronized (ConnBean.class){//由于用到了ThreadLocal，因此该单例仅仅相对于当前线程是单例的 if(connection == null){ try{ Connection realConn = DriverManager.getConnection(\"jdbc:mysql://localhost:3306/db_useradd\", \"root\", \"\"); conn.set(realConn); }catch (Exception e){ e.printStackTrace(); } } } } return conn.get();//返回给当前线程一个Connection对象 }} 代码块3 以上就是核心的一些实现代码，下面让我们来看一下我们的业务吧： 实体类：User，UserDetail，要求添加一个User的同时要添加一个UserDetail User： 1234private Long id;private String userName;private String address;private int money; 代码块4 UserDetail： 123private Long id;private int age;private String realname; 代码块5 dao层的接口和实现： UserDao： 123public interface UserDao { public void save(User user, Connection conn)throws Exception;} 代码块6 UserDaoImpl： 123456789101112public class UserDaoImpl implements UserDao{ @Override public void save(User user, Connection conn) throws Exception { Statement statement = conn.createStatement();//为了省去不必要的麻烦，我们不用预编译语句 String sql = \"insert into tb_user (userName, address, money) values ('\" + user.getUserName() + \"', '\" + user.getAddress() + \"', \" + user.getMoney() + \")\"; statement.executeUpdate(sql); statement.close(); }} 代码块7 UserDetailDao： 123public interface UserDetailDao { public void save(UserDetail userDetail, Connection connection) throws Exception;} 代码块8 UserDetailDaoImpl： 12345678910public class UserDetailDaoImpl implements UserDetailDao { @Override public void save(UserDetail userDetail, Connection connection) throws Exception { Statement statement = connection.createStatement(); String sql = \"insert into user_detail (age, realname) values (\" +userDetail.getAge()+\", '\" +userDetail.getRealname()+\"')\"; statement.executeUpdate(sql); }} 代码块9 UserService： 123public interface UserService { public void saveService(Connection connection, User user) throws Exception;} 代码块10 UserServiceImpl： 123456789101112131415161718192021222324/** * 业务层 * juwin * 2015-12-04 */public class UserServiceImpl implements UserService { //下面的dao层实例由BeanFactory通过properties配置文件帮我们生成对应的实例对象 private UserDao userDao = (UserDao) BeanFactory.getBean().get(\"userDao\"); private UserDetailDao userDetailDao = (UserDetailDao) BeanFactory.getBean().get(\"userDetailDao\"); @Override public void saveService( Connection connection, User user)throws Exception { /** * 这个业务层方法执行了两个dao层方法，可以看做一个事务， * 任意一个dao层调用过程中如果发生异常，整个业务方法进行的所有dao层操作就会回滚 */ userDao.save(user, connection); /*要求在添加user的同时生产一个对应的detail，这里偷个懒，就自己new一个UserDetail对象吧*/ UserDetail userDetail = new UserDetail(); userDetail.setAge(22); userDetail.setRealname(\"juwin\"); userDetailDao.save(userDetail, connection); throw new Exception(\"拦-路-虎\");//这个异常是用来测试事务会不会回滚的，正常情况下不加这个 }} 代码块11 UserController： 12345678910111213141516171819202122/** * 程序入口，类似于controller层 */public class UserController { public void SaveUser(User user)throws Exception{ /** * 这一步很关键，为每一个执行这个操作的线程分配一个connection连接对象 * 说明：在实际web开发中客户端通过发送http请求到业务后台，这时候tomcat会为这次请求分配一个线程 * 因此就出现了并发甚至并行的现象，假象一下，我们如果只是利用单例写一个生成connection对象的方法， * 那么多线程并发访问的时候就有可能出现：线程1利用完connection对象将其状态修改为close，而此时线程2 * 也要用connection，这时候就会报“connection已经关闭”的异常 * 因此我们采用ThreadLocal，为单独一个线程生成一个单例的connection对象 */ Connection connection = ConnBean.getConn(); /** * 下面这个实例要加一层事务代理，就是让TransactionProxy这个代理类搅合一下， * 这样我们再利用service层对象调用任何方法时，都会加上事务管理了 */ UserService userService = (UserService) new TransactionProxy().getTargetObj(new UserServiceImpl()); userService.saveService(connection,user); }} 代码块12 测试类： 123456789101112public class UserAddTest { @Test public void Test1() throws Exception{ User user = new User(); user.setUserName(\"weixiaojie1993\"); user.setAddress(\"beijing\"); user.setMoney(1); UserController userController = new UserController(); userController.SaveUser(user); System.out.print(\"Done !\"); }} 代码块13 ok，大功告成了，现在让我们用junit来测试一下吧： service层不加： 1throw new Exception(\"拦-路-虎\"); 代码块14 执行结果： 可以看出来事务已经提交了，我们来看看数据库里面的变化： tb_user表： user_detail表： 然后在业务层加上： 1throw new Exception(\"拦-路-虎\"); 代码块15 运行结果： 仔细观察划绿色线的部分就能发现，事务已经回滚了，看数据库表也是没有记录的 我们主键id由于是递增的，因此我们还要确定一下事务是不是真的回滚了，我们把异常代码去掉，然后再往里面插入成功一次数据，运行后的数据库表记录如下： tb_user： user_detail： 大家仔细看id，已经是3了，说明原来事务成功回滚了 说明：其实connection对象不必每次都作为参数传递给方法，这里只是为了更清楚的展示connection的流向，其实我们用ThreadLocal封装成一个单例的时候就已经注定了本次访问（即当前线程从controller层调用到dao层）所有get到的connection对象都是同一个； 最后，个人感觉这个程序有个非常要命的地方，就是我要给service层加事务代理，这样就导致了sevice层的对象不能通过配置文件来实例化，正在纠结中。。以后还会优化，这只是简单实现以下，真正的spring要复杂的多得多，第一次在开源中国发表博客，以后也会多发一些，大家互相学习~","link":"/2015/12/04/%E7%AE%80%E5%8D%95%E6%A8%A1%E6%8B%9Fspring%E7%9A%84ioc%E5%92%8Caop/"},{"title":"致十年后的我-歌词","text":"这是由doriko制作、初音ミク演唱的一首歌，2015年初遇这首歌，转眼间到了2019年。 歌词 好きな人と歩いた場所も曾和喜欢的人一起走过的地方その時見た景色も那时曾看到的景色振り返らず 今を駆け抜け统统抛掉 不再回头 向前飞奔私は何と出会うの我将会遇见些什么呢 立ち止まるほど驻足不前意味を問うほど探索意义きっとまだ大人ではなくて一定是我还不够成熟今見てるもの现在看到的事物今出会う人现在遇见的人その中でただ前だけを見てる在这片纷繁喧嚣之中 我只会看向前方10年後の私へ致十年以后的我今は幸せでしょうか现在的你感到幸福么？それとも悲しみで还是正沉浸在悲伤中泣いているのでしょうか默默地流着泪？けどあなたの傍に不过在你的身旁変わらないものがあり依然会有不变的存在気付いていないだけで未能察觉的你守られていませんか依然在被守护着吧過ぎし日々に 想いを预け把思念寄托于流逝的日子里時間だけ ただ追いかけてく只有时间在不停的追赶背に寄り添った 誰かの夢に托付在我肩上的 是谁的梦想振り向ける日がいつか来るのかな总有一天必须要面对的吧10年後の私へ致十年以后的我今は誰を好きですか现在的你喜欢着谁呢？それとも変わらずに还是和以前一样あの人が好きですか继续喜欢着那个人呢？けどいつか不过 现在的你知らない誰かを爱する前に在爱上某个人之前自分のことを好きと“喜欢自己”这句话言えるようになりましたか能否先说出来呢大切な人たちは我所珍爱的朋友们今も変わらずいますか依然在反复平凡的生活吗？それとも遠く離れ还是已经远去それぞれ歩んでますか踏上了各自的旅途けど そんな出会いを但是在重复了无数次的相遇别れを 缲り返して和离别之后今の私よりも是否比现在的我すてきになっていますか更有魅力呢？10年後の私へ致十年后的我今がもし幸せなら如果现在的你是幸福的あの日の私のこと从前的我思い出してくれますか能否请你想起来呢そこにはつらいことに回忆中的我泣いた私がいるけど一定在伤心的哭泣吧その涙を優しく请将这温柔的泪水思い出に変えてください融入记忆的海洋","link":"/2019/02/12/%E8%87%B4%E5%8D%81%E5%B9%B4%E5%90%8E%E7%9A%84%E6%88%91-%E6%AD%8C%E8%AF%8D/"},{"title":"链路追踪（一）-分布式链路追踪系统的介绍","text":"一、分布式链路追踪可以做什么？1.1：简单集群架构&amp;微服务架构先来看下最简单的网站集群架构图： 在这个图里，存在从1~n个服务器，通过负载均衡器SLB进行请求分发，在每个服务器里，都做同一件事情。 现在来看下这个系统的具体业务逻辑（就是图1中每台服务器执行的逻辑，这里是假设其中一个业务接口的处理，真实系统中可能存在n多业务接口）： 图2是对系统中某一个接口（API）的逻辑做了描述，假设处理流程就是请求一次Redis服务，然后做下处理，然后再请求下Memecached服务，在做下业务处理，后续可能还有其他各种业务逻辑，我们统称为逻辑块。 现在假设这个接口存在性能问题，那么找对应开发负责人排查是比较容易的，因为服务器只执行一套逻辑，瓶颈点一定发生在当前接口对应代码里的某个点，那么就找接口对应的负责人去排查优化即可。 但是当业务发展到一定的程度，比如上述单系统逻辑越来越复杂（业务接口越来越多，逻辑越来越复杂），就会造成很多我们不愿意看到的问题发生： 每一次微小的改动都需要整体走一次打包、发版的流程，对测试也是种负担，因为n多个人如果同时开发不同的功能，这时候就会对测试和发布流程造成很大的困扰。 如果因为做某次活动，某一个接口可能引入大量请求，需要紧急扩容，那么只能对整体扩容（因为该接口与其他接口都处于同一个系统中）。 系统各模块高度耦合，不适合多人开发和维护。 简单集群带来的问题会随着系统复杂度的提升，维护成本变得越来越大，基于此，便有了微服务架构（微服务是一种架构思想，简单来说就是将复杂庞大耦合度高的系统按照功能特性拆分成一个个独立的系统，通过网络互相通信，这种架构可以借助RPC框架（比如grpc、dubbo）实现拆分。当然，熟悉的HTTP框架也可以做到（比如okhttp），但是受限于HTTP协议，性能可能并没有普通RPC框架高，比如grpc采用HTTP2应用层协议进行数据通信，这个协议相比HTTP1来说，支持数据流的标记，可以在一个长连接上做N多请求和接收的并发处理，属于全双工网络通信，这点放到HTTP1就很难做到，此外，它还采用了轻量级且跨语言的protobuf来编解码信息，在性能上尽可能做到极致）。 结合图2，我们来简单按照业务划分一下服务，可以将A代码块里的逻辑抽象成A服务，将B代码块里的逻辑抽象成B服务，当然还有可能有其他n多细化的服务，网关层API（负责聚合信息以及业务处理的模块，对应上面简单集群里的具体接口），服务注册与发现、SLB等。 下面再来看一下被拆分后的架构图： 这张图是一个很简单的微服务化的架构图，图中虚线部分都是在各服务启动时或者运行期发生的调用，负责注册与发现（如zookeeper、Eurake等都可以作服务注册与发现，这里不再细说，只关注实线部分即可）。 这种架构很好的解决了普通集群架构带来的问题（参考上述1、2、3），微服务架构的好处： 降低了系统（逻辑块）间的耦合度，可以独立开发、独立部署和测试，系统间的边界明确，可以细分相关负责人，开发效率大大提升。 如果因为做某次活动，某一个接口可能引入大量请求，需要紧急扩容，那么只需要将该接口涉及到的服务进行扩容即可，而不是像之前那样整体扩容，降低了维护成本（某种意义上的降低，维护人员要足够多，每个人去负责自己的小模块，如果一个公司只有一个维护人员，微服务反而是在加重维护人员的工作:）。 提高了系统（逻辑块）的复用性，比如上面的服务A做自己的事情，万一以后有个API仍然需要A逻辑块，那么该API只需要再次调用A服务即可（实际应用当中的例子：用户服务）。 服务化以后，每个服务甚至可以用不同的语言来实现（存在支持跨语言的RPC框架，比如grpc），一个公司大了以后，可能存在语言差异，有的组使用JAVA，有的组用Go，通过服务化的方式，来将两个不同语言的系统互联。 上面简单介绍了普通集群架构和微服务架构，同样的，微服务化也意味着系统调用的复杂化，有可能一次API的调用对应大批量的服务调用，服务方自己又有一堆服务调用，那么针对这种问题，我们来模拟一次复杂的API调用（注册与发现服务已隐藏），如图4所示: 这是模拟了一次微服务架构中比较复杂的系统调用。 ⚠️注意：图画的有点歪，微服务架构的设计目标是要高度解耦，每个独立的服务最好都有一份自己独立的资源访问，比如服务A只访问A业务相关的数据库和缓存等资源，图中针对这些资源划分做的很糙 那么现在如果这个较复杂的链路调用上的其中一环发生了性能瓶颈，拖慢了整个API的调用，比如图中的慢标识，现在我们再来模拟一下这个性能问题的排查过程（过程相当鬼畜）： 负责API编写的同学发现API的响应时间总是达不到预期，自己debug发现导致性能问题的原因是服务C，于是找到了服务C的服务负责人，假设就叫他C服务负责人，C服务负责人紧接着排查，发现原来是服务D的调用过慢，于是又跑去找D服务负责人，D服务负责人收到C服务负责人的反馈，然后去查自己的服务，发现自己调用的服务E响应缓慢，于是D服务负责人又跑去找E服务负责人，E服务负责人紧接着排查，发现原来是自己这里调用的Redis_02服务有问题，然后自己排查，如果不是自己调用方式有问题，接下来还可能去联系对应的Redis_02相关维护人员帮助检查瓶颈点。 对比简单集群方式中的单系统性能问题排查，微服务针对此类问题的排查简直是一场噩梦，这其中涉及到的人跟瓶颈节点的深度成正比，因为任何一个环节都有可能存在性能问题，而拖慢整个进度的根源未知，那么有没有一种工具可以完成跨服务跨系统的去跟踪这次的调用链路呢？ 1.2：分布式链路追踪结合上面的问题，分布式链路追踪系统就诞生了，来看下Google的这篇文章：Dapper，大规模分布式系统的跟踪系统，可以对分布式链路追踪系统有个系统的认识。 单纯的理解链路追踪，就是指一次任务的开始到结束，期间调用的所有系统及耗时（时间跨度）都可以完整记录下来，比如上面图4的例子，假设总耗时100ms，存在瓶颈链路C--&gt;D--&gt;E--&gt;Redis02，如果链路追踪系统做好了，链路数据有了，借助前端解析和渲染工具，可以达到下图中的效果： 可以看到从API的调用开始到每个涉及到的系统调用以及系统内部的调用链路和时间跨度被直观的展示出来了，通过上图，可以看到时间跨度最长的就是Redis_02，该服务的调用间接拖慢了E服务、D服务、C服务的响应，最后由C服务直接导致API整体响应缓慢，通过这个图，就可以直接找到对应的责任人去排查对应的问题，而不是像之前那样找一群人。 二、分布式链路追踪系统的组成类似很多监控系统，该系统也分为基础数据采集+数据存储+前端展示几个部分，来看下一个分布式链路系统的基本结构： 上图比较粗略的展示了一个完整的链路追踪系统的结构，本篇文章不会介绍具体的链路追踪系统的实现，可以先简单将该系统理解为接收+存储链路数据的作用，前端也一样，可以先简单理解为请求链路系统API，API内部负责读取db，并将数据封装成前端需要的格式，前端负责绘制图5中的页面即可（只要数据结构约定好，对于专业的前端工程师做出图5的效果是很容易的，当然网上也有现成的前端工具）。 本篇文章主要介绍链路追踪究竟是什么，可以解决什么问题，下一篇将会详细介绍“链路数据采集SDK”，因为这一部分是跟业务组件开发人员直接挂钩的，下一篇会说明链路追踪的数据结构、如何做到链路数据的采集和上报、如何做到跨服务的链路追踪。 开始前可以先了解一个标准：OpenTracing语义标准 这里面讲了两个很重要的概念：Tracer和Span，一个Tracer认为是一次完整的链路，内部包含n多个Span，Span表示具体的一次调用，图5中就是一次完整的调用链路，里面每个耗时条都是一个Span，Tracer和Span存在一对多的关系（看到这里，图6中的链路追踪API的实现可以认为是根据Tracer的id聚合一批存在父子关系的Span封装成定义好的数据结构传给前端进行渲染的），根据图5，可以知道Span与Span之间又存在父子关系。 具体的实现方案和实现方法，下一篇会通过一个针对简单实现了OpenTracing协议的例子来介绍，下一篇会围绕着图5进行展开。","link":"/2019/04/11/%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA%EF%BC%88%E4%B8%80%EF%BC%89-%E5%88%86%E5%B8%83%E5%BC%8F%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA%E7%B3%BB%E7%BB%9F%E7%9A%84%E4%BB%8B%E7%BB%8D/"},{"title":"链路追踪（二）-分布式链路追踪系统数据采集","text":"本篇文章基于上一篇，只针对数据采集做介绍，会提供一个SDK的实现和使用，会做实现方案的介绍，具体详细介绍下面边框加粗的部分： 一、数据采集接着拿上一篇里的例子来说，把例子里的图贴过来： 简单回顾下上图，一次API调用，完成上面各个业务服务的调用，然后聚合所有服务的信息，然后Redis_02的调用发生瓶颈，继而影响到E、D、C三个服务，现在需要直观的展示这条链路上的瓶颈点，于是需要一个链路系统，展示成如下图的效果： 要想展示成上图中的效果，则必须要进行数据的采集和上报，那么这就牵扯到两个概念，Span和Tracer，抽象成数据库的设计层面，可以理解成Tracer对Span等于一对多的关系，而一个Span可能包含多个子Span，一个Tracer表示一次调用所经过的整个系统链路，里面包含N多Span，每个Span表示一次事件的触发（也就是调用），那么就用图2来解释下这种关系： 所以上报数据最关键的地方就是要做到如下几点： 在调用之处（比如例子中API调用开始的地方），创建Tracer，生成唯一Trace ID； 在需要追踪的地方（比如例子中发生服务调用的地方），创建Span，指定Trace ID，并生成唯一Span ID，然后按需建立父子关系，追踪结束时（比如例子中调用完成时）释放Span（即置为finished，此时计时已完成）； 跨系统追踪时做好协议约定，每次跨系统调用时可以在协议头传输发起调用系统的TraceID，以便链路可以做到跨系统顺利传输。 最终主链路执行完毕（例子中就是指API调用结束）时，推送此链路产生的所有Span到链路系统，链路系统负责落库、数据分析和展示。 以上便是链路追踪业务SDK需要参与做到的事情。 Tracer是个虚拟概念，负责聚合Span使用，实际上报的数据全是Span，下面来看下Span的结构定义（JSON）： 12345678910111213{ \"spanId\": 123456, \"traceId\": 1234, \"parentId\": 123455, \"title\": \"getSomeThing\", \"project\": \"project.tree.group.project_name\", \"startTime\": 1555731560000, \"endTime\": 1555731570000, \"tags\": { \"component\": \"rpc\", \"span.kind\": \"client\" }} 这是一个span的基本结构定义，startTime和endTime可以推算出本次Span耗时（交给链路系统前端时可以用来展示时间轴的长短），title表示的是Span本身的描述，一般是一个method的名字，project是当前所处项目的全称，项目的全称可以交给链路系统前端用来搜索出该项目的所有链路信息。spanId、traceId、parentId结合上面的图理解即可，tags表示的是一些描述信息，这里有一些标准化的东西：标准的Span tag 和 log field 二、数据采集基于Java语言的实现一般基于io.opentracing标准实现上报SDK，下面来逐步实现一个最简单的数据收集器，首先在项目中引入io.opentracing的jar包，然后追加两个基本类SimpleTracer和SimpleSpan，这里只贴出关键代码。 SimpleTracer定义： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475// 追踪器，实现Tracer接口public class SimpleTracer implements Tracer { private final List finishedSpans = new ArrayList&lt;&gt;(); //存放链路中已执行完成的span（finished span） private String project; //项目名称 private Boolean sampled; //是否上报（由采样率算法生成该值） public SimpleTracer(boolean sampled, String project) { this.project = project; this.sampled = sampled; } public SimpleTracer(String uri, String project) { this.project = project; this.sampled = PushUtils.sampled(uri); //本次追踪是否上报 } @Override public SpanBuilder buildSpan(String operationName) { return new SpanBuilder(operationName); //创建span一般交给Tracer去做，这里由其内部类SpanBuilder触发创建 } //上报span，这个方法一般在一次链路完成时调用，负责将finishedSpans里的数据上报给追踪系统 public synchronized void pushSpans() { if (sampled != null &amp;&amp; sampled) { List finished = this.finishedSpans; if (finished.size() &gt; 0) { finished.stream().filter(SimpleSpan::sampled).forEach(span -&gt; PushHandler.getHandler().pushSpan(span)); //实际负责推送的方法 this.reset(); //每发生一次推送，则清理一次已完成span集合 } } } // Tracer对象内部类SpanBuilder，实现了标准里的Tracer.SpanBuilder接口，用来负责创建span public final class SpanBuilder implements Tracer.SpanBuilder { private final String title; //操作名，也就是span的title private long startMicros; //初始化开始时间 private List references = new ArrayList&lt;&gt;(); //父子关系 private Map&lt;String, Object&gt; initialTags = new HashMap&lt;&gt;(); //tag描述信息初始化 //创建span用的title传入 SpanBuilder(String title) { this.title = title; } @Override public SpanBuilder asChildOf(SpanContext parent) { //传入父子关系 return addReference(References.CHILD_OF, parent); } @Override public SpanBuilder addReference(String referenceType, SpanContext referencedContext) { if (referencedContext != null) { //添加父子关系，其实这里就是初始化了Span里的Reference对象，这个对象会在创建Span对象时作为参数传进去，然后具体关系的确立，是在Span对象内（具体Span类的代码段会展示） this.references.add(new SimpleSpan.Reference((SimpleSpan.SimpleSpanContext) referencedContext, referenceType)); } return this; } @Override public SimpleSpan start() { return startManual(); } @Override public SimpleSpan startManual() { //创建并开始一个span if (this.startMicros == 0) { this.startMicros = SimpleSpan.nowMicros(); //就是在这里初始化startTime的 } //这里触发SimpleSpan的构造方法，之前的references会被传入，此外初始化的tag信息、title、开始时间等也会被传入参与初始化 return new SimpleSpan(SimpleTracer.this, title, startMicros, initialTags, references); } }} 代码块1 上面放了SimpleTracer的代码片段，关键信息已标注，这个类的作用就是帮助创建span，上面还有一个比较重要的方法，也就是sampled方法，该方法用来生成这次链路是否上报（也就是采样率，实际的追踪系统不可能每次的请求都上报，对于一些QPS较高的系统，会带来额外大量的存储数据，因此需要一个上报率），下面来简单看下上报率的实现： 12345678910111213141516171819202122232425262728293031public class PushUtils { public static final Random random = new Random(); private static final Map&lt;String, Long&gt; requestMap = Maps.newConcurrentMap(); public static boolean sampled(String uri) { if (Strings.isNullOrEmpty(uri)) { return false; } Long start = requestMap.get(uri); Long end = System.currentTimeMillis(); if (start == null) { requestMap.put(uri, end); return true; } if ((end - start) &gt;= 60000) { //距离上次上报已经超过1min了 requestMap.put(uri, end); return true; } else { // 没超过1min，则按照1/1000的概率上报 if (random.nextInt(999) == 0) { requestMap.put(uri, end); return true; } } return false; }} 代码块2 这种是比较适中的做法，如果1min内没有上报一次，则必定上报，如果1min内连续上报多次，则按照千分之一的概率上报，这样既保证了低QPS的系统可以有相对较多的链路数据，也可以保证高QPS的系统可以有相对较少的链路数据。 下面来看下SimpleSpan的关键代码段： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788// 链路Span，实现标准里的Span接口public class SimpleSpan implements Span { private final SimpleTracer simpleTracer; //链路追踪对象（一次追踪建议生成一个链路对象，尽量不要用单例，会有同步锁影响并发效率） private final long parentId; // 父span该值为0 private final long startTime; // 计时开始开始时间戳 private final Map&lt;String, Object&gt; tags; //一些扩展信息 private final List references; // 关系，外部传入 private final List errors = new ArrayList&lt;&gt;(); private SimpleSpanContext context; // spanContext,内部包含traceId、span自身id private boolean finished; // 当前span是否结束标识 private long endTime; // 计时结束时间戳 private boolean sampled; // 是否为抽样数据，取决于父节点，依次嫡传下来给其子节点 private String project; // 追踪目标的项目名 private String title; //方法名 SimpleSpan(SimpleTracer tracer, String title, long startTime, Map&lt;String, Object&gt; initialTags, List refs) { this.simpleTracer = tracer; // 这里传入的tracer是针对本次跟踪过程唯一对象，负责收集已完成的span this.title = title; this.startTime = startTime; this.project = tracer.getProject(); this.sampled = tracer.isSampled(); //是否上报，该字段根据具体的采样率方法生成 if (initialTags == null) { this.tags = new HashMap&lt;&gt;(); } else { this.tags = new HashMap&lt;&gt;(initialTags); } if (refs == null) { //span对象由tracer对象创建，创建时会把父子关系传入 this.references = Collections.emptyList(); } else { this.references = new ArrayList&lt;&gt;(refs); } SimpleSpanContext parent = findPreferredParentRef(this.references); //查看是否存在父span if (parent == null) { //通常父span为空的情况，都是链路开始的地方，这里会生成traceId // 当前链路还不存在父span，则本次span就置为父span，下面会生成traceId和当前父span的spanId this.context = new SimpleSpanContext(nextId(), nextId(), new HashMap&lt;&gt;()); this.parentId = 0; //父span的parentId是0 } else { // 当前链路已经存在父span了，那么子span的parentId置为当前父span的id，表示当前span是属于这个父span的子span，同时traceId也延用父span的（表示属于同一链路） this.context = new SimpleSpanContext(parent.traceId, nextId(), mergeBaggages(this.references)); this.parentId = parent.spanId; } } @Nullable private static SimpleSpanContext findPreferredParentRef(List references) { if (references.isEmpty()) { return null; } for (Reference reference : references) { if (References.CHILD_OF.equals(reference.getReferenceType())) { //现有的reference中存在父子关系（简单理解，这个关系就是BuildSpan的时候传入的） return reference.getContext(); //返回父span的context信息（包含traceId和它的spanId） } } return references.get(0).getContext(); } @Override public synchronized void finish(long endTime) { finishedCheck(\"当前span处于完成态\"); this.endTime = endTime; this.simpleTracer.appendFinishedSpan(this); //span完成时放进链路对象的finishedSpans集合里 this.finished = true; } // SimpleSpan的内部类SimpleSpanContext，存放当前Span的id、链路id，实现了标准里的SpanContext接口 public static final class SimpleSpanContext implements SpanContext { private final long traceId; //链路id private final Map&lt;String, String&gt; baggage; private final long spanId; //spanId public SimpleSpanContext(long traceId, long spanId, Map&lt;String, String&gt; baggage) { this.baggage = baggage; this.traceId = traceId; this.spanId = spanId; } } public static final class Reference { //用于建立Span间关系的内部类 private final SimpleSpanContext context; //存放了某一个Span的context（用于跟当前span建立关系时使用） private final String referenceType; //关系类型，目前有两种：child_of和follows_from，第一种代表当前span是上面context里span的子span，第二个则表示同级顺序关系 public Reference(SimpleSpanContext context, String referenceType) { this.context = context; this.referenceType = referenceType; } }} 代码块3 上面就是SimpleSpan的关键实现，关键点已标注，下面来看下数据上报这里的实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class PushHandler { private static final PushHandler handler = new PushHandler(); private BlockingQueue queue; private PushHandler() { this.queue = new LinkedBlockingQueue&lt;&gt;(); //数据管道 new Thread(this::pushTask).start(); } public static PushHandler getHandler() { return handler; } public void pushSpan(SimpleSpan span) { queue.offer(span); } private void pushTask() { if (queue != null) { SimpleSpan span; while (true) { try { span = queue.take(); //为了测试，这里只打印了基本信息，实际环境中这里需要做数据推送（kafka、UnixSocket等） StringBuilder sb = new StringBuilder() .append(\"tracerId=\") .append(span.context().traceId()) .append(\", parentId=\") .append(span.parentId()) .append(\", spanId=\") .append(span.context().spanId()) .append(\", title=\") .append(span.title()) .append(\", 耗时=\") .append((span.endTime() / 1000000) - (span.startTime() / 1000000)) .append(\"ms, tags=\") .append(span.tags().toString()); System.out.println(sb.toString()); } catch (InterruptedException e) { e.printStackTrace(); } } } }} 代码块4 只是做了简单的测试，所以处理逻辑只是简单的做了打印，实际当中这里要上报链路数据（spans）。这里使用了一个阻塞队列做数据接收的缓冲区。 这套实现是非常简单的，只进行简单的计时、推送，并没有涉及active方式的用法，一切创建、建立父子关系均交由开发人员自己把控，清晰度也更高些。 代码完整地址：simple-trace 三、simple-trace的使用看了上面的实现，这里利用simple-trace来进行程序追踪，看一个简单的例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384public class SimpleTest { private SimpleTracer tracer = null; private SimpleSpan parent = null; //假设这里是链路开始的地方 @Test public void test1() { //创建链路 tracer = new SimpleTracer(\"test1\", \"projectName\"); parent = tracer.buildSpan(\"test1\") .withTag(SpanTags.COMPONENT, \"http\") .withTag(SpanTags.SPAN_KIND, \"server\") .start(); //span开始 //-------------------------------------------------- String result1 = getResult1(); //假设getResult1需要链路追踪 System.out.println(\"r1 = \" + result1); String result2 = getResult2(); //假设getResult2需要链路追踪 System.out.println(\"r2 = \" + result2); //-------------------------------------------------- //下面标记着一次链路追踪的结束 parent.finish(); //主span结束 tracer.pushSpans(); //触发span数据推送 } public String getResult1() { //前戏，建立getResult1自己的追踪span SimpleSpan currentSpan = null; if (tracer != null &amp;&amp; parent != null) { //当前链路视为test1方法的子链路，建立父子关系 SimpleSpan.SimpleSpanContext context = new SimpleSpan.SimpleSpanContext(parent.context().traceId(), parent.context().spanId(), new HashMap&lt;&gt;()); //建立父子关系，traceId和父spanId被指定 currentSpan = tracer.buildSpan(\"getResult1\") .addReference(References.CHILD_OF, context) .withTag(SpanTags.COMPONENT, \"redis\") .withTag(SpanTags.SPAN_KIND, \"client\").start(); //启动自己的追踪span } try { Thread.sleep(1000L); return \"result1\"; } catch (InterruptedException e) { e.printStackTrace(); return \"\"; } finally { if (currentSpan != null) { currentSpan.finish(); //最后完成本次链路追踪 } } } public String getResult2() { //前戏，建立getResult2自己的追踪span SimpleSpan currentSpan = null; if (tracer != null &amp;&amp; parent != null) { //当前链路视为test2方法的子链路，建立父子关系 SimpleSpan.SimpleSpanContext context = new SimpleSpan.SimpleSpanContext(parent.context().traceId(), parent.context().spanId(), new HashMap&lt;&gt;()); //建立父子关系，traceId和父spanId被指定 currentSpan = tracer.buildSpan(\"getResult2\") .addReference(References.CHILD_OF, context) .withTag(SpanTags.COMPONENT, \"redis\") .withTag(SpanTags.SPAN_KIND, \"client\").start(); //启动自己的追踪span } try { Thread.sleep(2000L); return \"result2\"; } catch (InterruptedException e) { e.printStackTrace(); return \"\"; } finally { if (currentSpan != null) { currentSpan.finish(); //最后完成本次链路追踪 } } }} 代码块5 运行结果： 12345r1 = result1r2 = result2tracerId=1507767477962777317, parentId=2107142446015091038, spanId=5095502823334701185, title=getResult1, 耗时=1555839336570 - 1555839335569 = 1001ms, tags={span.kind=client, component=redis}tracerId=1507767477962777317, parentId=2107142446015091038, spanId=9071431876337611242, title=getResult2, 耗时=1555839338572 - 1555839336571 = 2001ms, tags={span.kind=client, component=redis}tracerId=1507767477962777317, parentId=0, spanId=2107142446015091038, title=test1, 耗时=1555839338572 - 1555839334687 = 3885ms, tags={span.kind=server, component=http} 通过该实例，关于simple-trace的基本用法已经展示出来了（创建tracer、span、建立关系、tags、finish等），看下打印结果（打印结果就是simple-trace推送数据时直接打印的，耗时是根据startTime和endTime推算出来的），父子关系建立完成，假如说这些数据已经落库完成，那么通过链路系统的API解析和前端渲染，会变成下面这样（绘图和上面测试结果不是同一次，所以图里耗时跟上面打印的耗时不一致😭）： 本篇不讨论图如何生成，可以说下后端可以给前端提供的接口结构以及组装方式：首先可以根据traceId查出来所有相关span，然后根据parentId进行封装层级，比如图4的API结构大致上如下： 123456789101112131415161718192021222324252627282930313233343536373839404142{ \"spanId\": 2107142446015091038, \"traceId\": 1507767477962777317, \"parentId\": 0, \"title\": \"test1\", \"project\": \"projectName\", \"startTime\": 1555839334687, \"endTime\": 1555839338572, \"tags\": { \"span.kind\": \"server\", \"component\": \"http\" }, \"children\": [{ \"spanId\": 5095502823334701185, \"traceId\": 1507767477962777317, \"parentId\": 2107142446015091038, \"title\": \"getResult1\", \"project\": \"projectName\", \"startTime\": 1555839335569, \"endTime\": 1555839336570, \"tags\": { \"span.kind\": \"client\", \"component\": \"redis\" }, \"children\": [] }, { \"spanId\": 9071431876337611242, \"traceId\": 1507767477962777317, \"parentId\": 2107142446015091038, \"title\": \"getResult2\", \"project\": \"projectName\", \"startTime\": 1555839336571, \"endTime\": 1555839338572, \"tags\": { \"span.kind\": \"client\", \"component\": \"redis\" }, \"children\": [] } ]} 包装成上面的结构，前端根据层级关系、startTime、endTime进行调用树和时间轴的渲染即可，在实际生产中，这个层级树可能更加庞大，比如图2。 基本使用很简单，那么基于简单的例子再进行一层抽象，如果在生实际项目中，就不能单单像上面那样使用了，需要封装、解耦，那么实际项目中一般会通过怎样的方式来使用呢？跨系统的时候如何建立层级关系呢？下面针对图2中的例子，进行简单的方案设计（图2过于复杂，这里只说服务A的调用链路，其余按照服务A类推即可），下面将会采用伪代码的方式进行说明问题的解决方案，实际当中需要自己按照实现思路自行封装。 现在引入两个概念，拦截器和Context（上下文），它们属于正常业务中常用的概念，Context是指一次调用产生的上下文信息，上下文信息可以在单次程序调用中的任意位置取到，一般上下文都是利用ThreadLocal（简称TL）实现的，线程本地变量，单纯理解就是只要本次调用的信息都处于同一个线程，那么任意地方都可以通过TL对象拿到上下文对象信息，但是由于系统的复杂度越来越高，一些地方会采用线程池来进行优化业务代码，比如一次调用可能会利用CompletableFuture来进行异步任务调度来优化当前代码执行效率，这个时候单纯使用TL就办不成事儿了，而使用InheritableThreadLocal（简称ITL）又解决不了线程池传递问题，于是就有了阿里推出的TransmittableThreadLocal（简称TTL），这个可以完美解决跨线程传递上下文信息（不管是new Thread还是线程池，都可以准确传递），当然，你也可以仿照TTL的实现，简单代理线程池对象，仍然使用TL实现跨线程传递，也是可以的，TL系列文章传送门：ThreadLocal、InheritableThreadLocal、TransmittableThreadLocal 下面是关于系统上下文的简单定义： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849//自定上下文类public class Context { private SimpleTracer simpleTracer; //当前链路对象 private SimpleSpan parent; //当前链路全局父span //也可以放很多别的上下文内容，这里省略... public SimpleTracer getSimpleTracer() { return simpleTracer; } public void setSimpleTracer(SimpleTracer simpleTracer) { this.simpleTracer = simpleTracer; } public SimpleSpan getParent() { return parent; } public void setParent(SimpleSpan parent) { this.parent = parent; }}public class ContextHolder { //这里仅用TL简单实现，如果项目里使用了线程池，那么这里的实现要变成TTL，并让TTL代理全局的线程池对象，也可以不用TTL，自己代理线程池对象，这里不再详述 private static ThreadLocal contextThreadLocal = new ThreadLocal&lt;&gt;(); private ContextHolder() { } public static void removeContext() { contextThreadLocal.remove(); } public static Context getContext() { return contextThreadLocal.get(); } public static void setContext(Context context) { if (context == null) { removeContext(); } contextThreadLocal.set(context); }} 代码块6 我们把链路对象和链路第一次产生的父span放到上下文，意味着我们可以在这次调用的任意位置通过ContextHolder获取到当前链路对象（伪代码会出现该类），下面来结合图2的A服务链路，结合aop思想，写一次从图2API调用开始到Redis01调用结束的代码。 按照流程，API属于一次Http调用，也是链路入口，那么利用这一点，和Http服务的拦截器功能（大部分系统都会用到一个http调用的拦截器，一般上下文也是这里产生的），伪代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class ApiInterceptor { //开始Http处理请求之前要做的，一般这里产生上下文，并交给TL传递上下文对象，这里也是链路初始化的地方 public void beforeHandle(Request request) { Context context = new Context(); //上下文对象 SimpleTracer tracer = null; SimpleSpan parent = null; //这里是为跨系统调用做的协议头传递，因为我们这个API也可能是公司内别的业务方内部调用，那么这个时候就需要约定协议头，一旦协议头中带有约定好的链路字段，那么就认为我们这个API本次调用相对于别的系统是个子链路 String traceId = request.headers.get(\"x1-trace-id\"); //拿到协议头的父链路id，子链路继承之 String parentId = request.headers.get(\"x1-span-id\"); //拿到协议头的父span信息 String sampled = request.headers.get.get(\"x1-sampled\"); //是否上报 if (traceId != null &amp;&amp; parentId != null &amp;&amp; sampled == true) { tracer = new SimpleTracer(request.getUri, \"所属项目名\"); //这里用url当成是初始化span的title // 符合这种情况的，我们这里的parent其实只是一个相对于别的系统的child SimpleSpan.SimpleSpanContext simpleSpanContext = new SimpleSpan.SimpleSpanContext(traceId, parentId, new HashMap&lt;&gt;()); parent = tracer.buildSpan(request.getUri) .addReference(References.CHILD_OF, simpleSpanContext) //建立父子关系，如果是别的业务方调用我们这个http服务，那么这里这一步，也就建立了跟调用方的父子关系，traceId等是继承的调用方的，意味着本次调用也属于调用方的一环，这也就实现了跨系统的链路追踪 .withTag(SpanTags.COMPONENT, \"http\") .withTag(SpanTags.SPAN_KIND, \"server\").start(); //启动span } else { //执行else，说明该http调用是一次自己完整的调用，不属于任何父链路，那么就无需建立关系，直接初始化tracer即可 tracer = new SimpleTracer(request.getUri, \"所属项目名\"); parent = tracer.buildSpan(request.getUri) .withTag(SpanTags.COMPONENT, \"http\") .withTag(SpanTags.SPAN_KIND, \"server\") .start(); //启动span } //将封装好的tracer和parentSpan设置到上下文对象里去 context.setSimpleTracer(tracer); context.setParent(parent); ContextHolder.setContext(context); //将本次请求生成的上下文对象放进ContextHolder（也就是TL里），方便在任意位置取出使用 } //业务逻辑处理中 public void hadle() { //本次API请求实际走的业务逻辑，也就是A服务调用、B服务调用等这些实际的业务逻辑处理 doing(); } //Http业务处理完成后的触发 public void afterHandler() { //Http调用结束的时候，取出当前链路信息，完成数据的上报 SimpleTracer tracer = ContextHolder.getContext().getTracer(); SimpleSpan parent = ContextHolder.getContext().getParent(); if (tracer != null &amp;&amp; parent != null) { parent.finish(); //结束掉parent Span tracer.pushSpans(); //上报这次产生的链路数据（spans） } }} 代码块7 通过这个外部的API链路包装，可以知道的事情是上下文在这里面充当的角色，API调用是一个系统的入口，这种入口有很多，一次系统调用都会有一个类似的入口，比如RPC调用，跨系统后的rpcServer端也是一个入口，这种入口级的拦截器，before里面做的通常都是建立Tracer，但是代码里不是简单的创建一个Tracer对象就完事儿了，还有协议头的分析，链路系统如何实现跨系统的传输呢？这就牵扯到协议约定，比如Http请求，可以在协议头里约定几个特殊字符串来存放来源系统的tracerId等，结合上面的例子，假如我们这个API是公司内别的系统API01发起的http调用，API01本身也会有链路追踪，API01系统内发起对我们API的http请求，这就属于跨系统调用，我们这次API调用相对于API01是一个子链路，需要建立父子关系，结合上面的例子简单画下这次调用图： 包括API的其他跨系统的调用，比如A服务的调用，也是使用同样的原理进行链路跨系统传输的（很多RPC框架上层协议也是支持扩展协议头（即协议的元数据信息）的，比如grpc的上层协议就是http2，同样有header），那么接下来看下图中（截自图2）标红模块对应的伪代码吧： 这块是指当前系统通过rpc client发起对A服务的调用，从发起调用到A服务响应，这个过程仍然属于API这次调用的子span（没有出系统），但是到了A服务的触发，就牵扯到跨系统，A服务的链路相对于rpc client（图6标红的操作）的span，是一个子span，通过上面对跨系统的处理，这里rpc client里一定会把自身的spanId作为A服务的parentId传过去，包括traceId等，来看下伪代码： 1234567891011121314151617181920212223242526272829public class RpcClient { //等待服务端响应方法 public void requestRpc(RpcRequest request) { //调用前执行 SimpleSpan span = null; SimpleSpan parent = ContextHolder.getContext().getParent(); SimpleTracer tracer = ContextHolder.getContext().getTracer(); if (tracer != null &amp;&amp; parent != null) {//↓这个title就设置成rpc调用的那个方法名即可 span = tracer.buildSpan(request.getRpcMethod).asChildOf(parent) //建立父子关系，因为rpc client调用属于API调用的子链路 .withTag(SpanTags.COMPONENT, \"grpc\") .withTag(SpanTags.PEER_SERVICE, request.getRpcMethod) .withTag(SpanTags.SPAN_KIND, \"client\") .start(); //启动这个span //设置协议头，因为被调用的RPC服务相对于我们来说是个子链路 request.setHeader(\"x1-rpc-span-id\", span.context().spanId()); request.setHeader(\"x1-rpc-trace-id\", span.context().traceId()); request.setHeader(\"x1-rpc-sampled\", span.sampled()); } rpcServerRequest(request); //实际调用rpc服务 //调用后执行 if(span != null){ span.finish(); //完成本次追踪 } }} 代码块8 这样就完成了图6中红线部分的span，然后来看下被调用的服务A内部是怎么处理的（其实很像上面http入口的处理方式）： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class RpcServerInterceptor { //服务的入口，Rpc服务处理请求之前要做的，一般这里产生上下文，并交给TL传递上下文对象，这里也是链路初始化的地方 public void beforeHandle(RpcRequest request) { Context context = new Context(); //上下文对象 SimpleTracer tracer = null; SimpleSpan parent = null; //解析协议头 String traceId = request.headers.get(\"x1-rpc-trace-id\"); //拿到协议头的父链路id，子链路继承之 String parentId = request.headers.get(\"x1-rpc-span-id\"); //拿到协议头的父span信息 String sampled = request.headers.get.get(\"x1-rpc-sampled\"); //是否上报 if (traceId != null &amp;&amp; parentId != null &amp;&amp; sampled == true) { tracer = new SimpleTracer(request.getMethod, \"所属项目名\"); // 符合这种情况的，我们这里的parent其实只是一个相对于别的系统的child SimpleSpan.SimpleSpanContext simpleSpanContext = new SimpleSpan.SimpleSpanContext(traceId, parentId, new HashMap&lt;&gt;()); parent = tracer.buildSpan(request.getMethod) .addReference(References.CHILD_OF, simpleSpanContext) //建立父子关系，如果是别的业务方调用我们这个服务，那么这里这一步，也就建立了跟调用方的父子关系，traceId等是继承的调用方的，意味着本次调用也属于调用方的一环，这也就实现了跨系统的链路追踪 .withTag(SpanTags.COMPONENT, \"rpc\") .withTag(SpanTags.SPAN_KIND, \"server\").start(); //启动span } else { //执行else，说明该rpc调用是一次自己完整的调用，不属于任何父链路，那么就无需建立关系，直接初始化tracer即可 tracer = new SimpleTracer(request.getMethod, \"所属项目名\"); parent = tracer.buildSpan(request.getMethod) .withTag(SpanTags.COMPONENT, \"rpc\") .withTag(SpanTags.SPAN_KIND, \"server\") .start(); //启动span } //将封装好的tracer和parentSpan设置到上下文对象里去 context.setSimpleTracer(tracer); context.setParent(parent); ContextHolder.setContext(context); //将本次请求生成的上下文对象放进ContextHolder（也就是TL里），方便在任意位置取出使用 } //业务逻辑处理中 public void rpcServerHadle() { doing(); } //Rpc业务处理完成后的触发 public void afterHandler() { //Rpc Server调用结束的时候，取出当前链路信息，完成数据的上报 SimpleTracer tracer = ContextHolder.getContext().getTracer(); SimpleSpan parent = ContextHolder.getContext().getParent(); if (tracer != null &amp;&amp; parent != null) { parent.finish(); //结束掉parent Span tracer.pushSpans(); //上报这次产生的链路数据（spans） } }} 代码块9 可以看到，client发起调用时传递的协议字段，在服务端这里被解析了，建立好父子关系后，A服务再去处理自己的逻辑和链路。 没有牵扯到跨系统的链路追踪，如对redis、memcached、mysql等DB的调用，可以简单在调用元方法上搞个aop代理，然后通过通过上下文对象里的Tracer和parent建立父子关系，结束时finish即可，而pushSpans这个动作通常发生在一次系统调用执行完毕的时候发生，比如API的调用结束时、A服务调用结束时，都是pushSpans的触发点。 到这里基本上关于链路追踪的介绍算结束了，因为系统级的实现方式想要完整的展现在一篇文章里不太现实，所以在使用simple-trace sdk的时候使用了伪代码，便于说明问题，文章没有针对整个链路系统作说明，主要是针对数据采集、数据跨系统追踪做了描述，因为数据采集这一环算是比较重要的一环，也是跟业务开发人员息息相关的一环，如果想要完整搞一个链路追踪系统，可以参考之前的架构搭建一套，以完成采集、上报、落库、解析、展示整个流程。","link":"/2019/04/15/%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA%EF%BC%88%E4%BA%8C%EF%BC%89-%E5%88%86%E5%B8%83%E5%BC%8F%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA%E7%B3%BB%E7%BB%9F%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/"},{"title":"顾村的樱花-20190323","text":"记录于2019年3月23日，上海，多云，7~16℃ 下午从杨浦出发去顾村公园，据说撒苦辣开了，兴奋的骑车过去，骑行1.5小时，逛了1.5小时，回来时找不到共享单车，坐了528路公交，因为顾村连个地铁站都没有==，公交到站，又骑了一小时的车回家。 BGM：夜の向日葵","link":"/2019/03/23/%E9%A1%BE%E6%9D%91%E7%9A%84%E6%A8%B1%E8%8A%B1-20190323/"}],"tags":[{"name":"NIO","slug":"NIO","link":"/tags/NIO/"},{"name":"网络编程","slug":"网络编程","link":"/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"},{"name":"游戏","slug":"游戏","link":"/tags/%E6%B8%B8%E6%88%8F/"},{"name":"皇城突袭","slug":"皇城突袭","link":"/tags/%E7%9A%87%E5%9F%8E%E7%AA%81%E8%A2%AD/"},{"name":"Kingdom Rush","slug":"Kingdom-Rush","link":"/tags/Kingdom-Rush/"},{"name":"数据库","slug":"数据库","link":"/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"nosql","slug":"nosql","link":"/tags/nosql/"},{"name":"ThreadLocal","slug":"ThreadLocal","link":"/tags/ThreadLocal/"},{"name":"并发编程","slug":"并发编程","link":"/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"树","slug":"树","link":"/tags/%E6%A0%91/"},{"name":"数据结构","slug":"数据结构","link":"/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"火焰图","slug":"火焰图","link":"/tags/%E7%81%AB%E7%84%B0%E5%9B%BE/"},{"name":"鬼畜","slug":"鬼畜","link":"/tags/%E9%AC%BC%E7%95%9C/"},{"name":"juc","slug":"juc","link":"/tags/juc/"},{"name":"CompletableFuture","slug":"CompletableFuture","link":"/tags/CompletableFuture/"},{"name":"阻塞队列","slug":"阻塞队列","link":"/tags/%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97/"},{"name":"ReentrantLock","slug":"ReentrantLock","link":"/tags/ReentrantLock/"},{"name":"链表","slug":"链表","link":"/tags/%E9%93%BE%E8%A1%A8/"},{"name":"多线程","slug":"多线程","link":"/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"事务","slug":"事务","link":"/tags/%E4%BA%8B%E5%8A%A1/"},{"name":"map","slug":"map","link":"/tags/map/"},{"name":"散列表","slug":"散列表","link":"/tags/%E6%95%A3%E5%88%97%E8%A1%A8/"},{"name":"集合类","slug":"集合类","link":"/tags/%E9%9B%86%E5%90%88%E7%B1%BB/"},{"name":"设计模式","slug":"设计模式","link":"/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"生产者消费者模式","slug":"生产者消费者模式","link":"/tags/%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%85%E6%A8%A1%E5%BC%8F/"},{"name":"工厂模式","slug":"工厂模式","link":"/tags/%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/"},{"name":"策略模式","slug":"策略模式","link":"/tags/%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F/"},{"name":"spring","slug":"spring","link":"/tags/spring/"},{"name":"ioc","slug":"ioc","link":"/tags/ioc/"},{"name":"aop","slug":"aop","link":"/tags/aop/"},{"name":"miku","slug":"miku","link":"/tags/miku/"},{"name":"letter song","slug":"letter-song","link":"/tags/letter-song/"},{"name":"链路追踪","slug":"链路追踪","link":"/tags/%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA/"},{"name":"OpenTracing","slug":"OpenTracing","link":"/tags/OpenTracing/"},{"name":"顾村公园","slug":"顾村公园","link":"/tags/%E9%A1%BE%E6%9D%91%E5%85%AC%E5%9B%AD/"},{"name":"樱花","slug":"樱花","link":"/tags/%E6%A8%B1%E8%8A%B1/"},{"name":"旅行","slug":"旅行","link":"/tags/%E6%97%85%E8%A1%8C/"}],"categories":[{"name":"网络编程","slug":"网络编程","link":"/categories/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"},{"name":"NIO","slug":"网络编程/NIO","link":"/categories/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/NIO/"},{"name":"游戏","slug":"游戏","link":"/categories/%E6%B8%B8%E6%88%8F/"},{"name":"数据库","slug":"数据库","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"并发编程","slug":"并发编程","link":"/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"NIO基础","slug":"网络编程/NIO/NIO基础","link":"/categories/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/NIO/NIO%E5%9F%BA%E7%A1%80/"},{"name":"数据结构","slug":"数据结构","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"服务治理","slug":"服务治理","link":"/categories/%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86/"},{"name":"杂记","slug":"杂记","link":"/categories/%E6%9D%82%E8%AE%B0/"},{"name":"日常","slug":"日常","link":"/categories/%E6%97%A5%E5%B8%B8/"},{"name":"设计模式","slug":"设计模式","link":"/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"框架","slug":"框架","link":"/categories/%E6%A1%86%E6%9E%B6/"},{"name":"NoSQL","slug":"数据库/NoSQL","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/NoSQL/"},{"name":"ThreadLocal","slug":"并发编程/ThreadLocal","link":"/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/ThreadLocal/"},{"name":"树","slug":"数据结构/树","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/"},{"name":"火焰图","slug":"服务治理/火焰图","link":"/categories/%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86/%E7%81%AB%E7%84%B0%E5%9B%BE/"},{"name":"划水","slug":"日常/划水","link":"/categories/%E6%97%A5%E5%B8%B8/%E5%88%92%E6%B0%B4/"},{"name":"juc","slug":"并发编程/juc","link":"/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/juc/"},{"name":"链表","slug":"数据结构/链表","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/"},{"name":"图解多线程设计模式","slug":"并发编程/图解多线程设计模式","link":"/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%9B%BE%E8%A7%A3%E5%A4%9A%E7%BA%BF%E7%A8%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"关系型数据库","slug":"数据库/关系型数据库","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"散列表","slug":"数据结构/散列表","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%A3%E5%88%97%E8%A1%A8/"},{"name":"生产&消费模式","slug":"设计模式/生产-消费模式","link":"/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E7%94%9F%E4%BA%A7-%E6%B6%88%E8%B4%B9%E6%A8%A1%E5%BC%8F/"},{"name":"spring","slug":"框架/spring","link":"/categories/%E6%A1%86%E6%9E%B6/spring/"},{"name":"redis","slug":"数据库/NoSQL/redis","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/NoSQL/redis/"},{"name":"链路追踪","slug":"服务治理/链路追踪","link":"/categories/%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86/%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA/"},{"name":"旅行","slug":"日常/旅行","link":"/categories/%E6%97%A5%E5%B8%B8/%E6%97%85%E8%A1%8C/"},{"name":"mysql","slug":"数据库/关系型数据库/mysql","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/"},{"name":"framework","slug":"框架/spring/framework","link":"/categories/%E6%A1%86%E6%9E%B6/spring/framework/"}]}